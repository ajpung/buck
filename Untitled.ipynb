{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c341ac-a19e-40b1-907b-535644a40383",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "\n",
    "In notebook `teeth - 3`, the basic prototype of the ensemble and method of building the ensemble were determined. However, ALL of the data were used during training, and this is not useful to the academic community since the model never has a reliably separate amount of test data. In this notebook, the data are properly split, loss curves are recorded, and all splits are kept as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a263606-5080-4210-94a5-d5cbeac897a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b56ba2-3b3a-4be4-bb0d-13ef38ec4978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academically Rigorous Multi-Architecture Ensemble Training\n",
      "================================================================================\n",
      "Available architectures: ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'mobilenetv3_large_100']\n",
      "Number of folds: 5\n",
      "Image size: 448x224\n",
      "Augmentation target: 1000 samples per class\n",
      "Loading data...\n",
      "Total images: 243\n",
      "Age distribution: {0.5: 39, 2.5: 33, 3.5: 29, 1.5: 62, 4.5: 20, 5.5: 60}\n",
      "\n",
      "--- ACADEMIC TRAIN/TEST SPLIT ---\n",
      "Training data: 194 images\n",
      "Test data: 49 images\n",
      "Test set will NOT be used until final evaluation\n",
      "Results will be saved to: academic_ensemble_20250721_075823\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "\n",
      "--- CROSS-VALIDATION ON TRAINING DATA ONLY ---\n",
      "Training Fold 1/5\n",
      "  Testing resnet18...\n"
     ]
    }
   ],
   "source": [
    "# Academically Rigorous Multi-Architecture Ensemble Training Script\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "AVAILABLE_ARCHITECTURES = ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'mobilenetv3_large_100']\n",
    "AUGMENTATION_TARGET = 1000\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 448)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train):\n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class MultiArchEnsembleTrainer:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"academic_ensemble_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        print(f\"Results will be saved to: {self.save_dir}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        if 'resnet' in architecture:\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "            for name, param in model.named_parameters():\n",
    "                for frozen_layer in frozen_layers:\n",
    "                    if name.startswith(frozen_layer):\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'mobilenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.0' in name or 'features.1' in name or 'features.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "                model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_model(self, train_loader, val_loader, architecture):\n",
    "        model = self.create_model(architecture)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            if epoch % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history, architecture\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        best_model = None\n",
    "        best_acc = 0.0\n",
    "        best_history = None\n",
    "        best_arch = None\n",
    "        \n",
    "        for arch in AVAILABLE_ARCHITECTURES:\n",
    "            try:\n",
    "                print(f\"  Testing {arch}...\")\n",
    "                model, val_acc, history, architecture = self.train_single_model(train_loader, val_loader, arch)\n",
    "                \n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "                    best_arch = architecture\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to train {arch}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_model, best_acc, best_history, best_arch\n",
    "    \n",
    "    def save_fold_immediately(self, model, fold_num, architecture, cv_score, label_mapping, history):\n",
    "        model_path = os.path.join(self.save_dir, f\"{architecture}_fold_{fold_num}_{cv_score:.1f}pct.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': architecture,\n",
    "            'fold': fold_num,\n",
    "            'cv_score': cv_score,\n",
    "            'num_classes': self.num_classes,\n",
    "            'label_mapping': label_mapping,\n",
    "            'input_size': IMAGE_SIZE,\n",
    "            'training_history': history\n",
    "        }, model_path)\n",
    "        \n",
    "        print(f\"  Saved fold {fold_num} to: {model_path}\")\n",
    "        return model_path\n",
    "    \n",
    "    def train_ensemble_academic(self, X_train, y_train, label_mapping):\n",
    "        skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "        fold_splits = list(skf.split(X_train, y_train))\n",
    "        \n",
    "        with open(os.path.join(self.save_dir, \"label_mapping.json\"), 'w') as f:\n",
    "            json.dump(label_mapping, f, indent=2)\n",
    "        \n",
    "        with open(os.path.join(self.save_dir, \"fold_splits.pkl\"), 'wb') as f:\n",
    "            pickle.dump(fold_splits, f)\n",
    "        \n",
    "        trained_models = []\n",
    "        cv_scores = []\n",
    "        training_histories = []\n",
    "        architectures_used = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(fold_splits):\n",
    "            fold_num = fold_idx + 1\n",
    "            print(f\"Training Fold {fold_num}/{NUM_FOLDS}\")\n",
    "            \n",
    "            X_train_fold = X_train[train_idx]\n",
    "            y_train_fold = y_train[train_idx]\n",
    "            X_val_fold = X_train[val_idx]\n",
    "            y_val_fold = y_train[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            batch_size = 16 if torch.cuda.is_available() else 8\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "            model, val_acc, history, best_arch = self.train_single_fold(train_loader, val_loader, fold_num)\n",
    "            \n",
    "            if model is not None:\n",
    "                self.save_fold_immediately(model, fold_num, best_arch, val_acc, label_mapping, history)\n",
    "                \n",
    "                trained_models.append(model)\n",
    "                cv_scores.append(val_acc)\n",
    "                training_histories.append(history)\n",
    "                architectures_used.append(best_arch)\n",
    "                print(f\"Fold {fold_num}/{NUM_FOLDS} completed: {val_acc:.1f}% with {best_arch}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return trained_models, cv_scores, training_histories, architectures_used\n",
    "    \n",
    "    def evaluate_ensemble(self, models, cv_scores, test_loader):\n",
    "        scores_array = np.array(cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_ensemble_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                ensemble_outputs = torch.zeros(images.size(0), self.num_classes).to(self.device)\n",
    "                \n",
    "                for model, weight in zip(models, weights):\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    avg_outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    ensemble_outputs += weight * F.softmax(avg_outputs, dim=1)\n",
    "                \n",
    "                _, predicted = torch.max(ensemble_outputs, 1)\n",
    "                \n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_ensemble_probs.extend(ensemble_outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        ensemble_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        return ensemble_acc, np.array(all_ensemble_probs), np.array(all_labels)\n",
    "\n",
    "def save_final_ensemble(trainer, models, cv_scores, label_mapping, ensemble_acc, training_histories, architectures_used):\n",
    "    ensemble_path = os.path.join(trainer.save_dir, \"academic_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': architectures_used,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    with open(os.path.join(trainer.save_dir, \"training_histories.pkl\"), 'wb') as f:\n",
    "        pickle.dump(training_histories, f)\n",
    "    \n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        'architectures_used': architectures_used,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': f'{IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}',\n",
    "        'augmentation_target': AUGMENTATION_TARGET,\n",
    "        'completed': True,\n",
    "        'academic_split': True\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(trainer.save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Final ensemble saved to: {ensemble_path}\")\n",
    "    return trainer.save_dir\n",
    "\n",
    "def plot_training_curves(training_histories, architectures_used, save_dir):\n",
    "    Path(os.path.join(save_dir, \"training_plots\")).mkdir(exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, NUM_FOLDS, figsize=(4*NUM_FOLDS, 4))\n",
    "    if NUM_FOLDS == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for fold, (history, arch) in enumerate(zip(training_histories, architectures_used)):\n",
    "        ax = axes[fold]\n",
    "        epochs = range(1, len(history['train_accs']) + 1)\n",
    "        \n",
    "        ax.plot(epochs, history['train_accs'], 'b-', label='Training', linewidth=2, alpha=0.8)\n",
    "        ax.plot(epochs, history['val_accs'], 'r-', label='Validation', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Fold {fold + 1} ({arch})')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"training_plots\", \"training_curves.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, NUM_FOLDS, figsize=(4*NUM_FOLDS, 4))\n",
    "    if NUM_FOLDS == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for fold, (history, arch) in enumerate(zip(training_histories, architectures_used)):\n",
    "        ax = axes[fold]\n",
    "        epochs = range(1, len(history['train_losses']) + 1)\n",
    "        \n",
    "        ax.plot(epochs, history['train_losses'], 'b-', label='Training Loss', linewidth=2, alpha=0.8)\n",
    "        ax.plot(epochs, history['val_losses'], 'r-', label='Validation Loss', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_title(f'Fold {fold + 1} Loss ({arch})')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"training_plots\", \"loss_curves.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    print(\"Academically Rigorous Multi-Architecture Ensemble Training\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Available architectures: {AVAILABLE_ARCHITECTURES}\")\n",
    "    print(f\"Number of folds: {NUM_FOLDS}\")\n",
    "    print(f\"Image size: {IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}\")\n",
    "    print(f\"Augmentation target: {AUGMENTATION_TARGET} samples per class\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        print(f\"Total images: {len(images)}\")\n",
    "        print(f\"Age distribution: {dict(Counter(ages))}\")\n",
    "        \n",
    "        print(\"\\n--- ACADEMIC TRAIN/TEST SPLIT ---\")\n",
    "        X_train_all, X_test_final, y_train_all, y_test_final = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        print(f\"Training data: {len(X_train_all)} images\")\n",
    "        print(f\"Test data: {len(X_test_final)} images\")\n",
    "        print(\"Test set will NOT be used until final evaluation\")\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(num_classes=len(unique_ages))\n",
    "        \n",
    "        print(\"\\n--- CROSS-VALIDATION ON TRAINING DATA ONLY ---\")\n",
    "        models, cv_scores, training_histories, architectures_used = trainer.train_ensemble_academic(\n",
    "            X_train_all, y_train_all, label_mapping\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- FINAL EVALUATION ON HELD-OUT TEST SET ---\")\n",
    "        test_dataset = OptimizedDataset(X_test_final, y_test_final, test_time_aug=True)\n",
    "        batch_size = 32 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "        \n",
    "        print(\"Saving final ensemble...\")\n",
    "        save_dir = save_final_ensemble(trainer, models, cv_scores, label_mapping, ensemble_acc, training_histories, architectures_used)\n",
    "        \n",
    "        print(\"Generating training curves...\")\n",
    "        plot_training_curves(training_histories, architectures_used, save_dir)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\n=== ACADEMIC RESULTS ===\")\n",
    "        print(\"Cross-Validation Results (Training Data Only):\")\n",
    "        for i, (score, arch) in enumerate(zip(cv_scores, architectures_used)):\n",
    "            print(f\"Fold {i+1}: {score:.1f}% ({arch})\")\n",
    "        print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "        print(f\"\\nFinal Test Accuracy (Held-Out Data): {ensemble_acc:.1f}%\")\n",
    "        print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"All results saved to: {save_dir}\")\n",
    "        \n",
    "        print(\"\\n=== OVERFITTING ANALYSIS ===\")\n",
    "        print(\"Check training_plots/ for loss curves to verify no overfitting\")\n",
    "        \n",
    "        return {\n",
    "            'models': models,\n",
    "            'cv_scores': cv_scores,\n",
    "            'test_accuracy': ensemble_acc,\n",
    "            'architectures_used': architectures_used,\n",
    "            'save_directory': save_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1eb24-db10-4a0b-9bd1-61751aa96b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
