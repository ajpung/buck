{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e5eff5-c905-4da2-b77d-3ed7a7ca0e9d",
   "metadata": {},
   "source": [
    "### Check RTX5090 running CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6ab5f0-9231-4ae0-8fc4-d27217483190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0.dev20250922+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 5090\n",
      "GPU memory: 31.8 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 works!\n",
      "EfficientNet works!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Check if CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected by PyTorch\")\n",
    "\n",
    "# Test ResNet50 specifically\n",
    "model = models.resnet50(pretrained=True).cuda()\n",
    "test_batch = torch.randn(2, 3, 224, 224).cuda()\n",
    "try:\n",
    "    output = model(test_batch)\n",
    "    print(\"ResNet50 works!\")\n",
    "except Exception as e:\n",
    "    print(f\"ResNet50 failed: {e}\")\n",
    "\n",
    "# Test EfficientNet\n",
    "try:\n",
    "    model_eff = models.efficientnet_b0(pretrained=True).cuda()\n",
    "    output_eff = model_eff(test_batch)\n",
    "    print(\"EfficientNet works!\")\n",
    "except Exception as e:\n",
    "    print(f\"EfficientNet failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bc11f-e647-462f-a1f3-466206538d7d",
   "metadata": {},
   "source": [
    "### Process deer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43154fba-18c6-4690-a3cd-6d4e8c863549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal Deer Age Prediction\n",
      "Images + Date + State Features\n",
      "============================================================\n",
      "Loading color images...\n",
      "Loaded 64 color images\n",
      "Loading grayscale images...\n",
      "Loaded 59 grayscale images\n",
      "Total images: 123\n",
      "Final dataset: 123 images\n",
      "Age distribution: {5.5: 36, 4.5: 17, 2.5: 16, 3.5: 43, 1.5: 11}\n",
      "Unique states: [np.str_('AK'), np.str_('AL'), np.str_('FL'), np.str_('GA'), np.str_('IA'), np.str_('IL'), np.str_('IN'), np.str_('KS'), np.str_('KY'), np.str_('LA'), np.str_('MI'), np.str_('MN'), np.str_('MO'), np.str_('MS'), np.str_('NC'), np.str_('NY'), np.str_('OC'), np.str_('OH'), np.str_('OK'), np.str_('PA'), np.str_('SC'), np.str_('TN'), np.str_('TX'), np.str_('VA'), np.str_('WI')]\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "GPU Memory: 34.2 GB\n",
      "MULTIMODAL EVALUATION - 13 models, 10 folds\n",
      "Image size: 600x600\n",
      "Feature dimensions: 4\n",
      "Classes: 5\n",
      "\n",
      "============================================================\n",
      "TESTING MODEL: EFFICIENTNET_B0\n",
      "Batch size: 128\n",
      "============================================================\n",
      "\n",
      "[Fold 1/10] efficientnet_b0\n",
      "Dataset: 5000 samples from 78 base images\n",
      "Dataset: 1000 samples from 20 base images\n",
      "Dataset: 1000 samples from 25 base images\n",
      "Loading efficientnet_b0...\n",
      "Parameters: 4,785,823 trainable, 19,090 frozen\n",
      "    Epoch 0: Train 74.3%, Val 38.2%\n",
      "    Epoch 20: Train 100.0%, Val 51.1%\n",
      "    Epoch 40: Train 100.0%, Val 44.1%\n",
      "    Early stopping at epoch 55\n",
      "    efficientnet_b0 Fold 1: Train 100.0%, Val 62.5%, Test 35.9%, Mult 2243.8\n",
      "\n",
      "[Fold 2/10] efficientnet_b0\n",
      "Dataset: 5000 samples from 78 base images\n",
      "Dataset: 1000 samples from 20 base images\n",
      "Dataset: 1000 samples from 25 base images\n",
      "Loading efficientnet_b0...\n",
      "Parameters: 4,785,823 trainable, 19,090 frozen\n",
      "    Epoch 0: Train 72.6%, Val 53.3%\n",
      "    Epoch 20: Train 100.0%, Val 54.5%\n",
      "    Epoch 40: Train 100.0%, Val 56.0%\n",
      "    Early stopping at epoch 48\n",
      "    efficientnet_b0 Fold 2: Train 100.0%, Val 61.2%, Test 37.5%, Mult 2295.0\n",
      "\n",
      "[Fold 3/10] efficientnet_b0\n",
      "Dataset: 5000 samples from 78 base images\n",
      "Dataset: 1000 samples from 20 base images\n",
      "Dataset: 1000 samples from 25 base images\n",
      "Loading efficientnet_b0...\n",
      "Parameters: 4,785,823 trainable, 19,090 frozen\n",
      "    Epoch 0: Train 68.2%, Val 27.0%\n",
      "    Epoch 20: Train 100.0%, Val 44.8%\n",
      "    Epoch 40: Train 100.0%, Val 49.4%\n",
      "    Epoch 60: Train 100.0%, Val 35.2%\n",
      "    Early stopping at epoch 69\n",
      "    efficientnet_b0 Fold 3: Train 100.0%, Val 53.4%, Test 33.7%, Mult 1799.6\n",
      "\n",
      "[Fold 4/10] efficientnet_b0\n",
      "Dataset: 5000 samples from 78 base images\n",
      "Dataset: 1000 samples from 20 base images\n",
      "Dataset: 1000 samples from 25 base images\n",
      "Loading efficientnet_b0...\n",
      "Parameters: 4,785,823 trainable, 19,090 frozen\n",
      "    Epoch 0: Train 73.8%, Val 25.5%\n",
      "    Epoch 20: Train 99.9%, Val 23.7%\n",
      "    Early stopping at epoch 38\n",
      "    efficientnet_b0 Fold 4: Train 100.0%, Val 29.4%, Test 37.7%, Mult 1108.4\n",
      "\n",
      "[Fold 5/10] efficientnet_b0\n",
      "Dataset: 5000 samples from 78 base images\n",
      "Dataset: 1000 samples from 20 base images\n",
      "Dataset: 1000 samples from 25 base images\n",
      "Loading efficientnet_b0...\n",
      "Parameters: 4,785,823 trainable, 19,090 frozen\n",
      "    Epoch 0: Train 74.0%, Val 26.0%\n",
      "    Epoch 20: Train 100.0%, Val 34.4%\n",
      "    Early stopping at epoch 27\n",
      "    efficientnet_b0 Fold 5: Train 99.9%, Val 41.0%, Test 33.3%, Mult 1365.3\n",
      "\n",
      "[Fold 6/10] efficientnet_b0\n",
      "Dataset: 5000 samples from 78 base images\n",
      "Dataset: 1000 samples from 20 base images\n",
      "Dataset: 1000 samples from 25 base images\n",
      "Loading efficientnet_b0...\n",
      "Parameters: 4,785,823 trainable, 19,090 frozen\n",
      "    Epoch 0: Train 73.0%, Val 44.1%\n",
      "    Epoch 20: Train 100.0%, Val 57.5%\n",
      "    Epoch 40: Train 100.0%, Val 58.0%\n",
      "    Epoch 60: Train 100.0%, Val 54.2%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "IMAGE_SIZE = (600, 600)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "NUM_FOLDS = 10\n",
    "NUM_WORKERS = 0\n",
    "MIXED_PRECISION = True\n",
    "COMPILE_MODEL = False\n",
    "\n",
    "# Simplified to best performing models\n",
    "MODEL_CONFIGS = {\n",
    "    'efficientnet_b0': {'model_fn': models.efficientnet_b0, 'batch_size': 128, 'freeze_layers': 3},\n",
    "    'efficientnet_b1': {'model_fn': models.efficientnet_b1, 'batch_size': 96, 'freeze_layers': 3},\n",
    "    'efficientnet_b2': {'model_fn': models.efficientnet_b2, 'batch_size': 80, 'freeze_layers': 3},\n",
    "    'efficientnet_b3': {'model_fn': models.efficientnet_b3, 'batch_size': 64, 'freeze_layers': 3},\n",
    "    'efficientnet_b4': {'model_fn': models.efficientnet_b4, 'batch_size': 48, 'freeze_layers': 3},\n",
    "    'efficientnet_b5': {'model_fn': models.efficientnet_b5, 'batch_size': 32, 'freeze_layers': 3},\n",
    "    'efficientnet_b6': {'model_fn': models.efficientnet_b6, 'batch_size': 24, 'freeze_layers': 3},\n",
    "    'efficientnet_b7': {'model_fn': models.efficientnet_b7, 'batch_size': 16, 'freeze_layers': 3},\n",
    "    'resnet18': {'model_fn': models.resnet18, 'batch_size': 256, 'freeze_layers': 2},\n",
    "    'resnet34': {'model_fn': models.resnet34, 'batch_size': 192, 'freeze_layers': 2},\n",
    "    'resnet50': {'model_fn': models.resnet50, 'batch_size': 128, 'freeze_layers': 2},\n",
    "    'resnet101': {'model_fn': models.resnet101, 'batch_size': 80, 'freeze_layers': 2},\n",
    "    'resnet152': {'model_fn': models.resnet152, 'batch_size': 64, 'freeze_layers': 2},\n",
    "}\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    'backbone_lr': 0.0001,\n",
    "    'classifier_lr': 0.0005,\n",
    "    'optimizer': 'adamw',\n",
    "    'weight_decay': 0.05,\n",
    "    'scheduler': 'cosine',\n",
    "    'label_smoothing': 0.1,\n",
    "    'dropout': 0.3,\n",
    "    'max_epochs': 80,\n",
    "    'patience': 25,\n",
    "    'augmentation_strength': 'medium'\n",
    "}\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"Parse filename: YYMMDD_YYMMDD_CC_EpE_NDA\"\"\"\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) < 5:\n",
    "        return None\n",
    "    \n",
    "    date_saved = parts[0]\n",
    "    date_taken = parts[1]\n",
    "    state = parts[2]\n",
    "    age_part = parts[3]\n",
    "    \n",
    "    # Filter out unknown values\n",
    "    if 'U' in date_taken or 'U' in state or 'U' in age_part:\n",
    "        return None\n",
    "    \n",
    "    # Validate formats\n",
    "    if len(date_taken) != 6 or not date_taken.isdigit():\n",
    "        return None\n",
    "    if len(state) < 2 or not state[:2].isalpha():\n",
    "        return None\n",
    "    if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        age = float(age_part.replace('p', '.'))\n",
    "        \n",
    "        # Parse date taken to numeric features\n",
    "        year = int(date_taken[0:2])\n",
    "        month = int(date_taken[2:4])\n",
    "        day = int(date_taken[4:6])\n",
    "        \n",
    "        # Validate date components\n",
    "        if month < 1 or month > 12 or day < 1 or day > 31:\n",
    "            return None\n",
    "        \n",
    "        return {\n",
    "            'age': age,\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'state': state[:2].upper()\n",
    "        }\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def load_combined_data():\n",
    "    color_path = \"D:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*.png\"\n",
    "    gray_path = \"D:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    features = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            \n",
    "            parsed = parse_filename(filename_no_ext)\n",
    "            if parsed is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            images.append(img_resized)\n",
    "            ages.append(parsed['age'])\n",
    "            features.append({\n",
    "                'year': parsed['year'],\n",
    "                'month': parsed['month'],\n",
    "                'day': parsed['day'],\n",
    "                'state': parsed['state']\n",
    "            })\n",
    "            sources.append('color')\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            \n",
    "            parsed = parse_filename(filename_no_ext)\n",
    "            if parsed is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            images.append(img_resized)\n",
    "            ages.append(parsed['age'])\n",
    "            features.append({\n",
    "                'year': parsed['year'],\n",
    "                'month': parsed['month'],\n",
    "                'day': parsed['day'],\n",
    "                'state': parsed['state']\n",
    "            })\n",
    "            sources.append('grayscale')\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter by minimum class count\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_features = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, feat, source in zip(images, ages_grouped, features, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_features.append(feat)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    # Encode states\n",
    "    states = [f['state'] for f in filtered_features]\n",
    "    state_encoder = LabelEncoder()\n",
    "    state_encoded = state_encoder.fit_transform(states)\n",
    "    \n",
    "    print(f\"Unique states: {list(state_encoder.classes_)}\")\n",
    "    \n",
    "    # Create feature matrix: [year, month, day, state_encoded]\n",
    "    feature_matrix = np.array([\n",
    "        [f['year'], f['month'], f['day'], state_enc]\n",
    "        for f, state_enc in zip(filtered_features, state_encoded)\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    return (np.array(filtered_images, dtype=np.uint8), \n",
    "            filtered_ages, \n",
    "            feature_matrix, \n",
    "            state_encoder,\n",
    "            filtered_sources)\n",
    "\n",
    "def enhanced_augment_image(image, strength='medium'):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if strength == 'light':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.5, 0.3, 0.6, 0.2, 0.1\n",
    "        rot_range, bright_range = 8, (0.85, 1.15)\n",
    "    elif strength == 'medium':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.7, 0.5, 0.8, 0.4, 0.3\n",
    "        rot_range, bright_range = 12, (0.75, 1.25)\n",
    "    else:\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.8, 0.6, 0.9, 0.5, 0.4\n",
    "        rot_range, bright_range = 18, (0.65, 1.35)\n",
    "    \n",
    "    if random.random() < rot_prob:\n",
    "        angle = random.uniform(-rot_range, rot_range)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < flip_prob:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    if random.random() < bright_prob:\n",
    "        alpha = random.uniform(*bright_range)\n",
    "        beta = random.randint(-20, 20)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < gamma_prob:\n",
    "        gamma = random.uniform(0.85, 1.15)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < noise_prob:\n",
    "        noise = np.random.normal(0, 5, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, base_images, labels, features, aug_strength='medium', target_per_class=1000, training=True):\n",
    "        self.base_images = base_images\n",
    "        self.labels = np.array(labels)\n",
    "        self.features = features\n",
    "        self.aug_strength = aug_strength\n",
    "        self.training = training\n",
    "        self.target_per_class = target_per_class\n",
    "        \n",
    "        unique_classes = np.unique(labels)\n",
    "        self.class_to_indices = {}\n",
    "        for cls in unique_classes:\n",
    "            self.class_to_indices[cls] = np.where(self.labels == cls)[0]\n",
    "        \n",
    "        self.num_classes = len(unique_classes)\n",
    "        self.class_list = sorted(unique_classes)\n",
    "        self.length = self.num_classes * self.target_per_class\n",
    "        \n",
    "        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape(3, 1, 1)\n",
    "        self.std = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(3, 1, 1)\n",
    "        \n",
    "        print(f\"Dataset: {self.length} samples from {len(base_images)} base images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        class_idx = idx // self.target_per_class\n",
    "        within_class_idx = idx % self.target_per_class\n",
    "        \n",
    "        target_class = self.class_list[class_idx]\n",
    "        available_indices = self.class_to_indices[target_class]\n",
    "        \n",
    "        base_idx = available_indices[within_class_idx % len(available_indices)]\n",
    "        image = self.base_images[base_idx].copy()\n",
    "        feature_vec = self.features[base_idx].copy()\n",
    "        \n",
    "        if self.training and within_class_idx >= len(available_indices):\n",
    "            image = enhanced_augment_image(image, self.aug_strength)\n",
    "        \n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        if len(image.shape) == 3:\n",
    "            image = image.transpose(2, 0, 1)\n",
    "        \n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = np.flip(image, axis=2).copy()\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return (torch.from_numpy(image.astype(np.float32)), \n",
    "                torch.from_numpy(feature_vec.astype(np.float32)), \n",
    "                target_class)\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, num_features, model_type='efficientnet'):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        # Get feature dimension from base model\n",
    "        if hasattr(base_model, 'classifier'):\n",
    "            if isinstance(base_model.classifier, nn.Sequential):\n",
    "                feat_dim = base_model.classifier[-1].in_features\n",
    "                base_model.classifier = nn.Identity()\n",
    "            else:\n",
    "                feat_dim = base_model.classifier.in_features\n",
    "                base_model.classifier = nn.Identity()\n",
    "        elif hasattr(base_model, 'fc'):\n",
    "            feat_dim = base_model.fc.in_features\n",
    "            base_model.fc = nn.Identity()\n",
    "        elif hasattr(base_model, 'head'):\n",
    "            feat_dim = base_model.head.in_features\n",
    "            base_model.head = nn.Identity()\n",
    "        \n",
    "        # Feature MLP\n",
    "        self.feature_mlp = nn.Sequential(\n",
    "            nn.Linear(num_features, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Combined classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(TRAINING_CONFIG['dropout']),\n",
    "            nn.Linear(feat_dim + 16, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(TRAINING_CONFIG['dropout'] * 0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(TRAINING_CONFIG['dropout'] * 0.25),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image, features):\n",
    "        img_features = self.base_model(image)\n",
    "        feat_embedding = self.feature_mlp(features)\n",
    "        combined = torch.cat([img_features, feat_embedding], dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "class MultiModelTrainer:\n",
    "    def __init__(self, num_classes, num_features, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"multimodal_600_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        self.results = []\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "            \n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            \n",
    "            if MIXED_PRECISION:\n",
    "                self.scaler = torch.amp.GradScaler('cuda')\n",
    "            else:\n",
    "                self.scaler = None\n",
    "    \n",
    "    def create_model(self, model_name, model_config):\n",
    "        print(f\"Loading {model_name}...\")\n",
    "        base_model = model_config['model_fn'](weights='DEFAULT')\n",
    "        \n",
    "        freeze_layers = model_config.get('freeze_layers', 2)\n",
    "        \n",
    "        if hasattr(base_model, 'features'):\n",
    "            layers_to_freeze = list(base_model.features.children())[:freeze_layers]\n",
    "            for layer in layers_to_freeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "            model_type = 'efficientnet'\n",
    "        \n",
    "        elif hasattr(base_model, 'fc'):\n",
    "            if hasattr(base_model, 'layer1'):\n",
    "                layers_to_freeze = [base_model.conv1, base_model.bn1]\n",
    "                if freeze_layers >= 1:\n",
    "                    layers_to_freeze.append(base_model.layer1)\n",
    "                if freeze_layers >= 2:\n",
    "                    layers_to_freeze.append(base_model.layer2)\n",
    "            \n",
    "            for layer in layers_to_freeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "            model_type = 'resnet'\n",
    "        \n",
    "        model = MultiModalModel(base_model, self.num_classes, self.num_features, model_type)\n",
    "        \n",
    "        frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Parameters: {trainable_params:,} trainable, {frozen_params:,} frozen\")\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_optimizer(self, model):\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'classifier' in name or 'feature_mlp' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': TRAINING_CONFIG['backbone_lr']},\n",
    "            {'params': classifier_params, 'lr': TRAINING_CONFIG['classifier_lr']}\n",
    "        ]\n",
    "        \n",
    "        return optim.AdamW(param_groups, weight_decay=TRAINING_CONFIG['weight_decay'], fused=True)\n",
    "    \n",
    "    def get_scheduler(self, optimizer):\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=TRAINING_CONFIG['max_epochs'], eta_min=1e-6\n",
    "        )\n",
    "    \n",
    "    def train_model(self, model, model_name, train_loader, val_loader, test_loader, fold_num):\n",
    "        optimizer = self.get_optimizer(model)\n",
    "        scheduler = self.get_scheduler(optimizer)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=TRAINING_CONFIG['label_smoothing'])\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        best_train_acc = 0.0\n",
    "        best_test_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(TRAINING_CONFIG['max_epochs']):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for images, features, labels in train_loader:\n",
    "                images = images.to(self.device)\n",
    "                features = features.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if MIXED_PRECISION and self.scaler:\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = model(images, features)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images, features)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, features, labels in val_loader:\n",
    "                    images = images.to(self.device)\n",
    "                    features = features.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    \n",
    "                    if MIXED_PRECISION:\n",
    "                        with torch.amp.autocast('cuda'):\n",
    "                            outputs = model(images, features)\n",
    "                    else:\n",
    "                        outputs = model(images, features)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_train_acc = train_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "                \n",
    "                model.eval()\n",
    "                test_correct = 0\n",
    "                test_total = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for images, features, labels in test_loader:\n",
    "                        images = images.to(self.device)\n",
    "                        features = features.to(self.device)\n",
    "                        labels = labels.to(self.device)\n",
    "                        \n",
    "                        if MIXED_PRECISION:\n",
    "                            with torch.amp.autocast('cuda'):\n",
    "                                outputs1 = model(images, features)\n",
    "                                outputs2 = model(torch.flip(images, [3]), features)\n",
    "                                outputs = (outputs1 + outputs2) / 2\n",
    "                        else:\n",
    "                            outputs1 = model(images, features)\n",
    "                            outputs2 = model(torch.flip(images, [3]), features)\n",
    "                            outputs = (outputs1 + outputs2) / 2\n",
    "                        \n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        test_total += labels.size(0)\n",
    "                        test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                best_test_acc = 100 * test_correct / test_total\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= TRAINING_CONFIG['patience']:\n",
    "                print(f\"    Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        multiplicative_score = (best_val_acc / 100) * (best_test_acc / 100) * 10000\n",
    "        \n",
    "        save_path = os.path.join(self.save_dir, f\"{model_name}_fold{fold_num}_val{best_val_acc:.1f}_test{best_test_acc:.1f}_mult{multiplicative_score:.1f}.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': best_state,\n",
    "            'model_name': model_name,\n",
    "            'fold_number': fold_num,\n",
    "            'train_accuracy': best_train_acc,\n",
    "            'validation_accuracy': best_val_acc,\n",
    "            'test_accuracy': best_test_acc,\n",
    "            'multiplicative_score': multiplicative_score,\n",
    "            'image_size': IMAGE_SIZE,\n",
    "            'training_config': TRAINING_CONFIG,\n",
    "            'num_features': self.num_features\n",
    "        }, save_path)\n",
    "        \n",
    "        result = {\n",
    "            'model_name': model_name,\n",
    "            'fold': fold_num,\n",
    "            'train_acc': best_train_acc,\n",
    "            'val_acc': best_val_acc,\n",
    "            'test_acc': best_test_acc,\n",
    "            'multiplicative_score': multiplicative_score,\n",
    "            'save_path': save_path\n",
    "        }\n",
    "        \n",
    "        print(f\"    {model_name} Fold {fold_num}: Train {best_train_acc:.1f}%, Val {best_val_acc:.1f}%, Test {best_test_acc:.1f}%, Mult {multiplicative_score:.1f}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def run_comprehensive_evaluation(self, images, ages, features, sources):\n",
    "        print(f\"MULTIMODAL EVALUATION - {len(MODEL_CONFIGS)} models, {NUM_FOLDS} folds\")\n",
    "        print(f\"Image size: {IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}\")\n",
    "        print(f\"Feature dimensions: {self.num_features}\")\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        print(f\"Classes: {len(unique_ages)}\")\n",
    "        \n",
    "        for model_name, model_config in MODEL_CONFIGS.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"TESTING MODEL: {model_name.upper()}\")\n",
    "            print(f\"Batch size: {model_config['batch_size']}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            for fold in range(1, NUM_FOLDS + 1):\n",
    "                print(f\"\\n[Fold {fold}/{NUM_FOLDS}] {model_name}\")\n",
    "                \n",
    "                try:\n",
    "                    X_train, X_test, y_train, y_test, feat_train, feat_test = train_test_split(\n",
    "                        images, y_indices, features, test_size=0.2, random_state=fold * 42, stratify=y_indices\n",
    "                    )\n",
    "                    \n",
    "                    X_train_final, X_val, y_train_final, y_val, feat_train_final, feat_val = train_test_split(\n",
    "                        X_train, y_train, feat_train, test_size=0.2, random_state=fold * 42 + 1, stratify=y_train\n",
    "                    )\n",
    "                    \n",
    "                    train_dataset = MultiModalDataset(X_train_final, y_train_final, feat_train_final,\n",
    "                                                    TRAINING_CONFIG['augmentation_strength'], AUGMENTATION_TARGET, True)\n",
    "                    val_dataset = MultiModalDataset(X_val, y_val, feat_val, 'light', 200, False)\n",
    "                    test_dataset = MultiModalDataset(X_test, y_test, feat_test, 'light', 200, False)\n",
    "                    \n",
    "                    batch_size = model_config['batch_size']\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "                    \n",
    "                    model = self.create_model(model_name, model_config)\n",
    "                    result = self.train_model(model, model_name, train_loader, val_loader, test_loader, fold)\n",
    "                    self.results.append(result)\n",
    "                    \n",
    "                    del model, train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    FAILED: {str(e)}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "        \n",
    "        self.save_results()\n",
    "        self.print_summary()\n",
    "    \n",
    "    def save_results(self):\n",
    "        results_path = os.path.join(self.save_dir, \"comprehensive_results.json\")\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        print(f\"\\nResults saved to: {results_path}\")\n",
    "    \n",
    "    def print_summary(self):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COMPREHENSIVE EVALUATION SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        model_results = {}\n",
    "        for result in self.results:\n",
    "            model_name = result['model_name']\n",
    "            if model_name not in model_results:\n",
    "                model_results[model_name] = []\n",
    "            model_results[model_name].append(result)\n",
    "        \n",
    "        for model_name, results in model_results.items():\n",
    "            if not results:\n",
    "                continue\n",
    "            \n",
    "            avg_train = np.mean([r['train_acc'] for r in results])\n",
    "            avg_val = np.mean([r['val_acc'] for r in results])\n",
    "            avg_test = np.mean([r['test_acc'] for r in results])\n",
    "            avg_mult = np.mean([r['multiplicative_score'] for r in results])\n",
    "            \n",
    "            print(f\"{model_name:20} | Train: {avg_train:5.1f}% | Val: {avg_val:5.1f}% | Test: {avg_test:5.1f}% | Mult: {avg_mult:6.1f}\")\n",
    "        \n",
    "        if self.results:\n",
    "            best_result = max(self.results, key=lambda x: x['multiplicative_score'])\n",
    "            print(f\"\\nBest model: {best_result['model_name']} (Fold {best_result['fold']})\")\n",
    "            print(f\"Multiplicative score: {best_result['multiplicative_score']:.1f}\")\n",
    "            print(f\"Val: {best_result['val_acc']:.1f}%, Test: {best_result['test_acc']:.1f}%\")\n",
    "\n",
    "def main():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    print(\"Multimodal Deer Age Prediction\")\n",
    "    print(\"Images + Date + State Features\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    images, ages, features, state_encoder, sources = load_combined_data()\n",
    "    \n",
    "    trainer = MultiModelTrainer(num_classes=len(set(ages)), num_features=features.shape[1])\n",
    "    trainer.run_comprehensive_evaluation(images, ages, features, sources)\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f\"\\nComplete evaluation finished in: {elapsed:.1f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561f6ee-b954-43c4-b2f7-fcf0cb6639ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
