{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e5eff5-c905-4da2-b77d-3ed7a7ca0e9d",
   "metadata": {},
   "source": [
    "### Check RTX5090 running CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ab5f0-9231-4ae0-8fc4-d27217483190",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Check if CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"âŒ CUDA not detected by PyTorch\")\n",
    "\n",
    "# Test ResNet50 specifically\n",
    "model = models.resnet50(pretrained=True).cuda()\n",
    "test_batch = torch.randn(2, 3, 224, 224).cuda()\n",
    "try:\n",
    "    output = model(test_batch)\n",
    "    print(\"ResNet50 works!\")\n",
    "except Exception as e:\n",
    "    print(f\"ResNet50 failed: {e}\")\n",
    "\n",
    "# Test EfficientNet\n",
    "try:\n",
    "    model_eff = models.efficientnet_b0(pretrained=True).cuda()\n",
    "    output_eff = model_eff(test_batch)\n",
    "    print(\"EfficientNet works!\")\n",
    "except Exception as e:\n",
    "    print(f\"EfficientNet failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bc11f-e647-462f-a1f3-466206538d7d",
   "metadata": {},
   "source": [
    "### Process deer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a71f470c-4190-42dc-a26e-417e27e17726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Test Mode for RTX 5090\n",
      "============================================================\n",
      "Loading color images...\n",
      "Loaded 201 color images\n",
      "Loading grayscale images...\n",
      "Loaded 40 grayscale images\n",
      "Total images: 241\n",
      "Final dataset: 241 images\n",
      "Age distribution: {2.5: 41, 3.5: 50, 4.5: 57, 5.5: 60, 1.5: 33}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MinimalTestModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 613\u001b[39m\n\u001b[32m    610\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTest completed in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 606\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    602\u001b[39m start_time = time.time()\n\u001b[32m    604\u001b[39m images, ages, sources = load_combined_data()\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m trainer = \u001b[43mMinimalTestModel\u001b[49m(num_classes=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(ages)))\n\u001b[32m    607\u001b[39m trainer.run_test(images, ages, sources)\n\u001b[32m    609\u001b[39m elapsed = (time.time() - start_time) / \u001b[32m60\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'MinimalTestModel' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RTX 5090 Calculated Configuration - Targeting ~27GB VRAM usage\n",
    "FIXED_HYPERPARAMS = {\n",
    "    'backbone_lr': 0.0001,\n",
    "    'classifier_lr': 0.0005,\n",
    "    'batch_size': 384,  # Calculated to use ~27GB total VRAM\n",
    "    'optimizer': 'adamw',\n",
    "    'dropout': 0.4,\n",
    "    'freeze_layers': 3\n",
    "}\n",
    "\n",
    "# Missing hyperparameters to test\n",
    "MISSING_HYPERPARAMS = {\n",
    "    'weight_decay': [0.05, 0.08],\n",
    "    'scheduler': ['cosine', 'plateau'],\n",
    "    'label_smoothing': [0.15, 0.2],\n",
    "    'augmentation_strength': ['medium', 'heavy']\n",
    "}\n",
    "\n",
    "# Calculated RTX 5090 settings\n",
    "IMAGE_SIZE = (576, 576)  # Calculated to fit with batch_size=384 in ~27GB total\n",
    "AUGMENTATION_TARGET = 2000\n",
    "NUM_FOLDS = 25\n",
    "NUM_WORKERS = 0\n",
    "MIXED_PRECISION = True\n",
    "COMPILE_MODEL = False\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    color_path = \"D:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"D:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    return np.array(filtered_images, dtype=np.uint8), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image, strength='medium'):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if strength == 'light':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.5, 0.3, 0.6, 0.2, 0.1\n",
    "        rot_range, bright_range = 10, (0.8, 1.2)\n",
    "    elif strength == 'medium':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.7, 0.5, 0.8, 0.4, 0.3\n",
    "        rot_range, bright_range = 15, (0.7, 1.3)\n",
    "    else:  # heavy\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.8, 0.6, 0.9, 0.5, 0.4\n",
    "        rot_range, bright_range = 20, (0.6, 1.4)\n",
    "    \n",
    "    if random.random() < rot_prob:\n",
    "        angle = random.uniform(-rot_range, rot_range)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < flip_prob:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    if random.random() < bright_prob:\n",
    "        alpha = random.uniform(*bright_range)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < gamma_prob:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < noise_prob:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "class MemoryEfficientDataset(Dataset):\n",
    "    def __init__(self, base_images, labels, aug_strength='medium', target_per_class=2000, training=True):\n",
    "        self.base_images = base_images\n",
    "        self.labels = np.array(labels)\n",
    "        self.aug_strength = aug_strength\n",
    "        self.training = training\n",
    "        self.target_per_class = target_per_class\n",
    "        \n",
    "        unique_classes = np.unique(labels)\n",
    "        self.class_to_indices = {}\n",
    "        for cls in unique_classes:\n",
    "            self.class_to_indices[cls] = np.where(self.labels == cls)[0]\n",
    "        \n",
    "        self.num_classes = len(unique_classes)\n",
    "        self.class_list = sorted(unique_classes)\n",
    "        self.length = self.num_classes * self.target_per_class\n",
    "        \n",
    "        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape(3, 1, 1)\n",
    "        self.std = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(3, 1, 1)\n",
    "        \n",
    "        print(f\"Memory-efficient dataset: {self.length} samples from {len(base_images)} base images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        class_idx = idx // self.target_per_class\n",
    "        within_class_idx = idx % self.target_per_class\n",
    "        \n",
    "        target_class = self.class_list[class_idx]\n",
    "        available_indices = self.class_to_indices[target_class]\n",
    "        \n",
    "        base_idx = available_indices[within_class_idx % len(available_indices)]\n",
    "        image = self.base_images[base_idx].copy()\n",
    "        \n",
    "        if self.training and within_class_idx >= len(available_indices):\n",
    "            image = enhanced_augment_image(image, self.aug_strength)\n",
    "        \n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        if len(image.shape) == 3:\n",
    "            image = image.transpose(2, 0, 1)\n",
    "        \n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = np.flip(image, axis=2).copy()\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return torch.from_numpy(image.astype(np.float32)), target_class\n",
    "\n",
    "class RTX5090OptimizedModel:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"rtx5090_optimized_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        self.best_multiplicative_score = 0.0\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "            \n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            \n",
    "            if MIXED_PRECISION:\n",
    "                print(\"Mixed precision enabled\")\n",
    "                self.scaler = torch.amp.GradScaler('cuda')\n",
    "            else:\n",
    "                self.scaler = None\n",
    "    \n",
    "    def create_model(self, dropout=0.3, freeze_layers=3):\n",
    "        print(\"Loading EfficientNet-B4 (optimized for RTX 5090)\")\n",
    "        model = models.efficientnet_b4(weights='DEFAULT')\n",
    "        \n",
    "        layers_to_freeze = list(model.features.children())[:freeze_layers]\n",
    "        for layer in layers_to_freeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Model parameters: {trainable_params:,} trainable, {frozen_params:,} frozen\")\n",
    "        \n",
    "        original_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(original_features, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.25),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_optimizer(self, model, opt_type, backbone_lr, classifier_lr, weight_decay):\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': backbone_lr},\n",
    "            {'params': classifier_params, 'lr': classifier_lr}\n",
    "        ]\n",
    "        \n",
    "        print(f\"Optimizer groups: {len(backbone_params)} backbone, {len(classifier_params)} classifier params\")\n",
    "        \n",
    "        if opt_type == 'adamw':\n",
    "            return optim.AdamW(param_groups, weight_decay=weight_decay, fused=True)\n",
    "        elif opt_type == 'sgd':\n",
    "            return optim.SGD(param_groups, weight_decay=weight_decay, momentum=0.9, fused=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {opt_type}\")\n",
    "    \n",
    "    def get_scheduler(self, optimizer, scheduler_type, max_epochs):\n",
    "        if scheduler_type == 'cosine':\n",
    "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=1e-6)\n",
    "        elif scheduler_type == 'plateau':\n",
    "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=12, factor=0.5, verbose=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler: {scheduler_type}\")\n",
    "    \n",
    "    def train_with_hyperparams(self, train_loader, val_loader, test_loader, hyperparams, fold_num):\n",
    "        print(f\"Creating model for fold {fold_num}...\")\n",
    "        model = self.create_model(\n",
    "            dropout=hyperparams['dropout'], \n",
    "            freeze_layers=hyperparams['freeze_layers']\n",
    "        )\n",
    "        \n",
    "        optimizer = self.get_optimizer(\n",
    "            model, hyperparams['optimizer'], \n",
    "            hyperparams['backbone_lr'], hyperparams['classifier_lr'], \n",
    "            hyperparams['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = self.get_scheduler(optimizer, hyperparams['scheduler'], 100)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=hyperparams['label_smoothing'])\n",
    "        \n",
    "        start_memory = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"Starting VRAM usage: {start_memory:.1f} GB\")\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 35\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(100):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if MIXED_PRECISION and self.scaler:\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                if batch_idx == 0:\n",
    "                    current_memory = torch.cuda.memory_allocated() / 1e9\n",
    "                    print(f\"    Training VRAM: {current_memory:.1f} GB\", end=\"\")\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if MIXED_PRECISION:\n",
    "                        with torch.amp.autocast('cuda'):\n",
    "                            outputs = model(images)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if hyperparams['scheduler'] == 'plateau':\n",
    "                scheduler.step(val_acc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "            if epoch % 25 == 0 and epoch > 0:\n",
    "                print(f\" - Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}% ({epoch_time:.1f}s)\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                if MIXED_PRECISION:\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs1 = model(images)\n",
    "                        outputs2 = model(torch.flip(images, [3]))\n",
    "                        outputs = (outputs1 + outputs2) / 2\n",
    "                else:\n",
    "                    outputs1 = model(images)\n",
    "                    outputs2 = model(torch.flip(images, [3]))\n",
    "                    outputs = (outputs1 + outputs2) / 2\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        multiplicative_score = (best_val_acc / 100) * (test_acc / 100) * 10000\n",
    "        \n",
    "        if multiplicative_score > self.best_multiplicative_score:\n",
    "            self.best_multiplicative_score = multiplicative_score\n",
    "            \n",
    "            save_path = os.path.join(self.save_dir, f\"best_rtx5090_mult_{multiplicative_score:.1f}_val_{best_val_acc:.1f}_test_{test_acc:.1f}_fold_{fold_num}.pth\")\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'hyperparams': hyperparams,\n",
    "                'val_accuracy': best_val_acc,\n",
    "                'test_accuracy': test_acc,\n",
    "                'train_accuracy': train_acc,\n",
    "                'multiplicative_score': multiplicative_score,\n",
    "                'fold_number': fold_num,\n",
    "                'model_info': 'EfficientNet-B4_576x576_batch384'\n",
    "            }, save_path)\n",
    "            print(f\"    NEW GLOBAL BEST! Mult: {multiplicative_score:.1f}, Val: {best_val_acc:.1f}%, Test: {test_acc:.1f}% (Fold {fold_num})\")\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def run_fold_search(self, images, ages, sources):\n",
    "        print(f\"RTX 5090 Optimized Training - {NUM_FOLDS} folds\")\n",
    "        print(f\"Configuration: EfficientNet-B4, {IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}, batch_size={FIXED_HYPERPARAMS['batch_size']}\")\n",
    "        print(f\"Target VRAM usage: ~27GB\")\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        print(f\"Classes: {len(unique_ages)}\")\n",
    "        print(f\"Label mapping: {label_mapping}\")\n",
    "        \n",
    "        missing_keys = list(MISSING_HYPERPARAMS.keys())\n",
    "        missing_values = list(MISSING_HYPERPARAMS.values())\n",
    "        missing_combos = list(itertools.product(*missing_values))\n",
    "        \n",
    "        best_found = False\n",
    "        \n",
    "        for combo_idx, missing_combo in enumerate(missing_combos, 1):\n",
    "            hyperparams = FIXED_HYPERPARAMS.copy()\n",
    "            for key, value in zip(missing_keys, missing_combo):\n",
    "                hyperparams[key] = value\n",
    "            \n",
    "            print(f\"\\n[Config {combo_idx}/{len(missing_combos)}] Testing:\")\n",
    "            print(f\"  EfficientNet-B4, batch={hyperparams['batch_size']}, lr={hyperparams['backbone_lr']}/{hyperparams['classifier_lr']}\")\n",
    "            print(f\"  wd={hyperparams['weight_decay']}, sched={hyperparams['scheduler']}, smooth={hyperparams['label_smoothing']}, aug={hyperparams['augmentation_strength']}\")\n",
    "            \n",
    "            for fold in range(1, NUM_FOLDS + 1):\n",
    "                random.seed(fold * 42)\n",
    "                np.random.seed(fold * 42)\n",
    "                torch.manual_seed(fold * 42)\n",
    "                \n",
    "                print(f\"\\n  [Fold {fold:2d}/{NUM_FOLDS}]\", end=\" \")\n",
    "                \n",
    "                try:\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        images, y_indices, test_size=0.2, random_state=fold * 42, stratify=y_indices\n",
    "                    )\n",
    "                    \n",
    "                    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "                        X_train, y_train, test_size=0.2, random_state=fold * 42 + 1, stratify=y_train\n",
    "                    )\n",
    "                    \n",
    "                    train_dataset = MemoryEfficientDataset(X_train_final, y_train_final, \n",
    "                                                         hyperparams['augmentation_strength'], AUGMENTATION_TARGET, True)\n",
    "                    val_dataset = MemoryEfficientDataset(X_val, y_val, 'medium', 100, False)\n",
    "                    test_dataset = MemoryEfficientDataset(X_test, y_test, 'medium', 100, False)\n",
    "                    \n",
    "                    train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], \n",
    "                                            shuffle=True, num_workers=0)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=hyperparams['batch_size'], \n",
    "                                          shuffle=False, num_workers=0)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=hyperparams['batch_size'], \n",
    "                                           shuffle=False, num_workers=0)\n",
    "                    \n",
    "                    was_best = self.train_with_hyperparams(\n",
    "                        train_loader, val_loader, test_loader, hyperparams, fold\n",
    "                    )\n",
    "                    \n",
    "                    if was_best:\n",
    "                        best_found = True\n",
    "                    \n",
    "                    # Aggressive cleanup\n",
    "                    del train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader, model\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "                    gc.collect()\n",
    "                    \n",
    "                    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                    if allocated > 5.0:\n",
    "                        print(f\"    Warning: {allocated:.1f}GB still allocated\")\n",
    "                        torch.cuda.empty_cache()\n",
    "                        torch.cuda.synchronize()\n",
    "                        gc.collect()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"FAILED: {str(e)}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.synchronize()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RTX 5090 OPTIMIZED TRAINING COMPLETE\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Best Multiplicative Score: {self.best_multiplicative_score:.1f}\")\n",
    "        print(f\"Configuration: EfficientNet-B4, {IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}, batch_size={FIXED_HYPERPARAMS['batch_size']}\")\n",
    "        print(f\"Results saved to: {self.save_dir}\")\n",
    "        \n",
    "        return best_found\n",
    "\n",
    "def main():\n",
    "    import gc\n",
    "    import time\n",
    "    import torch\n",
    "    # Force clean start\n",
    "    #torch.cuda.empty_cache()\n",
    "    #torch.cuda.reset_peak_memory_stats()\n",
    "    #torch.cuda.synchronize()\n",
    "    \n",
    "    #print(f\"After cleanup - Allocated: {torch.cuda.memory_allocated() / 1e9:.3f} GB\")\n",
    "    #print(f\"After cleanup - Reserved: {torch.cuda.memory_reserved() / 1e9:.3f} GB\")\n",
    "    \n",
    "    print(\"Minimal Test Mode for RTX 5090\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "     #gc.collect()\n",
    "    \n",
    "    #torch.cuda.empty_cache()    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    trainer = MinimalTestModel(num_classes=len(set(ages)))\n",
    "    trainer.run_test(images, ages, sources)\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f\"\\nTest completed in: {elapsed:.1f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46542ae7-173c-4008-a9a3-3f5498f3f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0.dev20250910+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 5090\n",
      "GPU memory: 34.2 GB\n",
      "Initial allocated: 0.018 GB\n",
      "Initial reserved: 0.107 GB\n",
      "Loading color images...\n",
      "Loaded 201 color images\n",
      "Loading grayscale images...\n",
      "Loaded 40 grayscale images\n",
      "Total images: 241\n",
      "Final dataset: 241 images\n",
      "Age distribution: {2.5: 41, 3.5: 50, 4.5: 57, 5.5: 60, 1.5: 33}\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "GPU Memory: 34.2 GB\n",
      "MINIMAL TEST MODE - 2 folds only\n",
      "Configuration: ResNet18, 512x512, batch_size=16\n",
      "Classes: 5\n",
      "Testing hyperparams: {'backbone_lr': 0.0001, 'classifier_lr': 0.0005, 'batch_size': 16, 'optimizer': 'adamw', 'dropout': 0.3, 'freeze_layers': 4, 'weight_decay': 0.05, 'scheduler': 'cosine', 'label_smoothing': 0.1, 'augmentation_strength': 'light'}\n",
      "\n",
      "[Fold 1/2]\n",
      "Simple dataset: 500 samples from 153 base images\n",
      "Simple dataset: 250 samples from 39 base images\n",
      "Simple dataset: 250 samples from 49 base images\n",
      "Creating model for fold 1...\n",
      "Before model creation - Allocated: 0.018 GB, Reserved: 0.107 GB\n",
      "Loading ResNet18 (minimal model for testing)\n",
      "Model parameters: 11,006,440 trainable, 683,072 frozen\n",
      "After model creation - Allocated: 0.063 GB, Reserved: 0.111 GB\n",
      "Optimizer groups: 30 backbone, 4 classifier params\n",
      "Ready to train - Allocated: 0.063 GB\n",
      "    First batch loaded - VRAM: 0.114 GB\n",
      "    Epoch 0: Train 41.8%, Val 37.6%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Epoch 5: Train 99.4%, Val 54.0%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Epoch 10: Train 100.0%, Val 64.0%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Epoch 15: Train 100.0%, Val 64.4%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Fold 1 completed - Best val acc: 64.8%\n",
      "    After cleanup: 0.018 GB allocated\n",
      "\n",
      "[Fold 2/2]\n",
      "Simple dataset: 500 samples from 153 base images\n",
      "Simple dataset: 250 samples from 39 base images\n",
      "Simple dataset: 250 samples from 49 base images\n",
      "Creating model for fold 2...\n",
      "Before model creation - Allocated: 0.018 GB, Reserved: 0.107 GB\n",
      "Loading ResNet18 (minimal model for testing)\n",
      "Model parameters: 11,006,440 trainable, 683,072 frozen\n",
      "After model creation - Allocated: 0.063 GB, Reserved: 0.111 GB\n",
      "Optimizer groups: 30 backbone, 4 classifier params\n",
      "Ready to train - Allocated: 0.063 GB\n",
      "    First batch loaded - VRAM: 0.114 GB\n",
      "    Epoch 0: Train 43.8%, Val 38.8%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Epoch 5: Train 99.4%, Val 47.2%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Epoch 10: Train 100.0%, Val 50.4%\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    First batch loaded - VRAM: 0.241 GB\n",
      "    Early stopping at epoch 13\n",
      "    Fold 2 completed - Best val acc: 60.8%\n",
      "    After cleanup: 0.018 GB allocated\n",
      "\n",
      "MINIMAL TEST COMPLETE\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 479\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTest completed in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 475\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    472\u001b[39m trainer = MinimalTestModel(num_classes=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(ages)))\n\u001b[32m    473\u001b[39m trainer.run_test(images, ages, sources)\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m elapsed = (time.time() - \u001b[43mstart_time\u001b[49m) / \u001b[32m60\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTest completed in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'start_time' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check PyTorch and CUDA setup first\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"Initial allocated: {torch.cuda.memory_allocated() / 1e9:.3f} GB\")\n",
    "    print(f\"Initial reserved: {torch.cuda.memory_reserved() / 1e9:.3f} GB\")\n",
    "\n",
    "# MINIMAL CONFIGURATION - Testing if basic functionality works\n",
    "FIXED_HYPERPARAMS = {\n",
    "    'backbone_lr': 0.0001,\n",
    "    'classifier_lr': 0.0005,\n",
    "    'batch_size': 16,  # Very small to test basic functionality\n",
    "    'optimizer': 'adamw',\n",
    "    'dropout': 0.3,\n",
    "    'freeze_layers': 4\n",
    "}\n",
    "\n",
    "# Minimal hyperparameter testing\n",
    "MISSING_HYPERPARAMS = {\n",
    "    'weight_decay': [0.05],\n",
    "    'scheduler': ['cosine'],\n",
    "    'label_smoothing': [0.1],\n",
    "    'augmentation_strength': ['light']\n",
    "}\n",
    "\n",
    "# Conservative settings for testing\n",
    "IMAGE_SIZE = (512, 512)  # Standard ImageNet size\n",
    "AUGMENTATION_TARGET = 100  # Very small for testing\n",
    "NUM_FOLDS = 2  # Just test 2 folds\n",
    "NUM_WORKERS = 0\n",
    "MIXED_PRECISION = False  # Disable for testing\n",
    "COMPILE_MODEL = False\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    color_path = \"D:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"D:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    return np.array(filtered_images, dtype=np.uint8), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image, strength='light'):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Very light augmentation for testing\n",
    "    if strength == 'light':\n",
    "        if random.random() < 0.3:\n",
    "            image = cv2.flip(image, 1)\n",
    "        if random.random() < 0.2:\n",
    "            angle = random.uniform(-5, 5)\n",
    "            h, w = image.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "            image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    return image\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, base_images, labels, aug_strength='light', target_per_class=100, training=True):\n",
    "        self.base_images = base_images\n",
    "        self.labels = np.array(labels)\n",
    "        self.aug_strength = aug_strength\n",
    "        self.training = training\n",
    "        self.target_per_class = target_per_class\n",
    "        \n",
    "        unique_classes = np.unique(labels)\n",
    "        self.class_to_indices = {}\n",
    "        for cls in unique_classes:\n",
    "            self.class_to_indices[cls] = np.where(self.labels == cls)[0]\n",
    "        \n",
    "        self.num_classes = len(unique_classes)\n",
    "        self.class_list = sorted(unique_classes)\n",
    "        self.length = self.num_classes * self.target_per_class\n",
    "        \n",
    "        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape(3, 1, 1)\n",
    "        self.std = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(3, 1, 1)\n",
    "        \n",
    "        print(f\"Simple dataset: {self.length} samples from {len(base_images)} base images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        class_idx = idx // self.target_per_class\n",
    "        within_class_idx = idx % self.target_per_class\n",
    "        \n",
    "        target_class = self.class_list[class_idx]\n",
    "        available_indices = self.class_to_indices[target_class]\n",
    "        \n",
    "        base_idx = available_indices[within_class_idx % len(available_indices)]\n",
    "        image = self.base_images[base_idx].copy()\n",
    "        \n",
    "        if self.training and within_class_idx >= len(available_indices):\n",
    "            image = enhanced_augment_image(image, self.aug_strength)\n",
    "        \n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        if len(image.shape) == 3:\n",
    "            image = image.transpose(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return torch.from_numpy(image.astype(np.float32)), target_class\n",
    "\n",
    "class MinimalTestModel:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"minimal_test_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        self.best_multiplicative_score = 0.0\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    def create_model(self, dropout=0.3, freeze_layers=4):\n",
    "        print(\"Loading ResNet18 (minimal model for testing)\")\n",
    "        model = models.resnet18(weights='DEFAULT')\n",
    "        \n",
    "        # Freeze early layers\n",
    "        layers_to_freeze = [model.conv1, model.bn1, model.layer1]\n",
    "        if freeze_layers >= 2:\n",
    "            layers_to_freeze.append(model.layer2)\n",
    "        \n",
    "        for layer in layers_to_freeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Model parameters: {trainable_params:,} trainable, {frozen_params:,} frozen\")\n",
    "        \n",
    "        # Simple classifier\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(model.fc.in_features, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(128, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_optimizer(self, model, opt_type, backbone_lr, classifier_lr, weight_decay):\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': backbone_lr},\n",
    "            {'params': classifier_params, 'lr': classifier_lr}\n",
    "        ]\n",
    "        \n",
    "        print(f\"Optimizer groups: {len(backbone_params)} backbone, {len(classifier_params)} classifier params\")\n",
    "        \n",
    "        if opt_type == 'adamw':\n",
    "            return optim.AdamW(param_groups, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {opt_type}\")\n",
    "    \n",
    "    def get_scheduler(self, optimizer, scheduler_type, max_epochs):\n",
    "        if scheduler_type == 'cosine':\n",
    "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=1e-6)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler: {scheduler_type}\")\n",
    "    \n",
    "    def train_with_hyperparams(self, train_loader, val_loader, test_loader, hyperparams, fold_num):\n",
    "        print(f\"Creating model for fold {fold_num}...\")\n",
    "        \n",
    "        # Memory check before model creation\n",
    "        allocated_before = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved_before = torch.cuda.memory_reserved() / 1e9\n",
    "        print(f\"Before model creation - Allocated: {allocated_before:.3f} GB, Reserved: {reserved_before:.3f} GB\")\n",
    "        \n",
    "        model = self.create_model(\n",
    "            dropout=hyperparams['dropout'], \n",
    "            freeze_layers=hyperparams['freeze_layers']\n",
    "        )\n",
    "        \n",
    "        allocated_after = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved_after = torch.cuda.memory_reserved() / 1e9\n",
    "        print(f\"After model creation - Allocated: {allocated_after:.3f} GB, Reserved: {reserved_after:.3f} GB\")\n",
    "        \n",
    "        optimizer = self.get_optimizer(\n",
    "            model, hyperparams['optimizer'], \n",
    "            hyperparams['backbone_lr'], hyperparams['classifier_lr'], \n",
    "            hyperparams['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = self.get_scheduler(optimizer, hyperparams['scheduler'], 20)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=hyperparams['label_smoothing'])\n",
    "        \n",
    "        allocated_final = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"Ready to train - Allocated: {allocated_final:.3f} GB\")\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(20):  # Short training for testing\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                if batch_idx == 0:\n",
    "                    batch_memory = torch.cuda.memory_allocated() / 1e9\n",
    "                    print(f\"    First batch loaded - VRAM: {batch_memory:.3f} GB\")\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"    Fold {fold_num} completed - Best val acc: {best_val_acc:.1f}%\")\n",
    "        return False  # Don't save models in test mode\n",
    "    \n",
    "    def run_test(self, images, ages, sources):\n",
    "        print(f\"MINIMAL TEST MODE - {NUM_FOLDS} folds only\")\n",
    "        print(f\"Configuration: ResNet18, {IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}, batch_size={FIXED_HYPERPARAMS['batch_size']}\")\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        print(f\"Classes: {len(unique_ages)}\")\n",
    "        \n",
    "        hyperparams = FIXED_HYPERPARAMS.copy()\n",
    "        for key, value in zip(list(MISSING_HYPERPARAMS.keys()), [v[0] for v in MISSING_HYPERPARAMS.values()]):\n",
    "            hyperparams[key] = value\n",
    "        \n",
    "        print(f\"Testing hyperparams: {hyperparams}\")\n",
    "        \n",
    "        for fold in range(1, NUM_FOLDS + 1):\n",
    "            print(f\"\\n[Fold {fold}/{NUM_FOLDS}]\")\n",
    "            \n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    images, y_indices, test_size=0.2, random_state=fold * 42, stratify=y_indices\n",
    "                )\n",
    "                \n",
    "                X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "                    X_train, y_train, test_size=0.2, random_state=fold * 42 + 1, stratify=y_train\n",
    "                )\n",
    "                \n",
    "                train_dataset = SimpleDataset(X_train_final, y_train_final, \n",
    "                                           hyperparams['augmentation_strength'], AUGMENTATION_TARGET, True)\n",
    "                val_dataset = SimpleDataset(X_val, y_val, 'light', 50, False)\n",
    "                test_dataset = SimpleDataset(X_test, y_test, 'light', 50, False)\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], \n",
    "                                        shuffle=True, num_workers=0)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=hyperparams['batch_size'], \n",
    "                                      shuffle=False, num_workers=0)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=hyperparams['batch_size'], \n",
    "                                       shuffle=False, num_workers=0)\n",
    "                \n",
    "                self.train_with_hyperparams(train_loader, val_loader, test_loader, hyperparams, fold)\n",
    "                \n",
    "                # Cleanup\n",
    "                del train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "                final_memory = torch.cuda.memory_allocated() / 1e9\n",
    "                print(f\"    After cleanup: {final_memory:.3f} GB allocated\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"FAILED: {str(e)}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nMINIMAL TEST COMPLETE\")\n",
    "\n",
    "def main():\n",
    "    import gc\n",
    "    import time\n",
    "    import torch\n",
    "    # Force clean start\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    gc.collect()\n",
    "  \n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    trainer = MinimalTestModel(num_classes=len(set(ages)))\n",
    "    trainer.run_test(images, ages, sources)\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f\"\\nTest completed in: {elapsed:.1f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931a61c-d2c1-47b9-b3b6-de622962a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"Simple CUDA test:\")\n",
    "x = torch.randn(10, 10).cuda()\n",
    "print(f\"Created small tensor, allocated: {torch.cuda.memory_allocated() / 1e9:.3f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43154fba-18c6-4690-a3cd-6d4e8c863549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
