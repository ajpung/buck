{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a9ce06-de99-4d13-89f5-02a509fd73c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA recognized\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"❌ CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bf38a0-b457-4061-9fac-34fdcdb68261",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "Mixed Precision: Enabled\n",
      "Models will be saved to: deer_age_models_20250731_072915\n",
      "Loading images...\n",
      "Images loaded with shape: (466, 224, 224, 3)\n",
      "Classes: [0 1 2 3 4] (0=1.5yr, 1=2.5yr, 2=3.5yr, 3=4.5yr, 4=5.5yr)\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Loaded 466 images, age range: 0.0-4.0\n",
      "Train: 372, Test: 94\n",
      "\n",
      "Testing 6 model families...\n",
      "\n",
      "Testing ResNet50...\n",
      "Training ResNet50 on cuda\n",
      "  Epoch  0: Train 22.6%, Test 25.5%\n",
      "  Epoch 10: Train 100.0%, Test 47.9%\n",
      "  Epoch 19: Train 100.0%, Test 50.0%\n",
      "  Early stopping at epoch 19\n",
      "ResNet50: Accuracy=51.064, Saved: ResNet50_51p064.pth\n",
      "\n",
      "Testing EfficientNetB0...\n",
      "Training EfficientNetB0 on cuda\n",
      "  Epoch  0: Train 29.6%, Test 35.1%\n",
      "  Epoch 10: Train 100.0%, Test 50.0%\n",
      "  Epoch 18: Train 100.0%, Test 55.3%\n",
      "  Early stopping at epoch 18\n",
      "EfficientNetB0: Accuracy=55.319, Saved: EfficientNetB0_55p319.pth\n",
      "\n",
      "Testing VGG16...\n",
      "Training VGG16 on cuda\n",
      "  Epoch  0: Train 21.0%, Test 24.5%\n",
      "  Epoch 10: Train 24.2%, Test 21.3%\n",
      "  Epoch 20: Train 24.2%, Test 25.5%\n",
      "  Epoch 21: Train 24.7%, Test 19.1%\n",
      "  Early stopping at epoch 21\n",
      "VGG16: Accuracy=29.787, Saved: VGG16_29p787.pth\n",
      "\n",
      "Testing MobileNetV2...\n",
      "Training MobileNetV2 on cuda\n",
      "  Epoch  0: Train 29.3%, Test 29.8%\n",
      "  Epoch 10: Train 99.7%, Test 45.7%\n",
      "  Epoch 20: Train 100.0%, Test 47.9%\n",
      "  Epoch 26: Train 99.7%, Test 47.9%\n",
      "  Early stopping at epoch 26\n",
      "MobileNetV2: Accuracy=54.255, Saved: MobileNetV2_54p255.pth\n",
      "\n",
      "Testing InceptionV3...\n",
      "Training InceptionV3 on cuda\n",
      "  Epoch  0: Train 23.7%, Test 21.3%\n",
      "  Epoch 10: Train 92.5%, Test 39.4%\n",
      "  Epoch 20: Train 100.0%, Test 44.7%\n",
      "  Epoch 28: Train 99.7%, Test 43.6%\n",
      "  Early stopping at epoch 28\n",
      "InceptionV3: Accuracy=47.872, Saved: InceptionV3_47p872.pth\n",
      "\n",
      "Testing DenseNet121...\n",
      "Training DenseNet121 on cuda\n",
      "  Epoch  0: Train 27.4%, Test 24.5%\n",
      "  Epoch 10: Train 100.0%, Test 54.3%\n",
      "  Epoch 19: Train 100.0%, Test 55.3%\n",
      "  Early stopping at epoch 19\n",
      "DenseNet121: Accuracy=56.383, Saved: DenseNet121_56p383.pth\n",
      "\n",
      "Best family: DenseNet121 (accuracy: 56.383)\n",
      "\n",
      "Testing variations of DenseNet121...\n",
      "\n",
      "==================================================\n",
      "FINAL RESULTS\n",
      "==================================================\n",
      " 1. DenseNet121     - Accuracy: 56.383\n",
      " 2. EfficientNetB0  - Accuracy: 55.319\n",
      " 3. MobileNetV2     - Accuracy: 54.255\n",
      " 4. ResNet50        - Accuracy: 51.064\n",
      " 5. InceptionV3     - Accuracy: 47.872\n",
      " 6. VGG16           - Accuracy: 29.787\n",
      "\n",
      "Best model: DenseNet121 with 56.383 accuracy\n",
      "Saved as: DenseNet121_56p383.pth\n",
      "\n",
      "Total models tested: 6\n",
      "All models saved in folder: deer_age_models_20250731_072915\n",
      "All models saved with accuracy in filename.\n"
     ]
    }
   ],
   "source": [
    "# Broad model family search\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mixed precision imports (from your reference code)\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "# GPU Configuration (matching your reference code)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "        print(\"Mixed Precision: Disabled\")\n",
    "else:\n",
    "    use_amp = False\n",
    "    print(\"WARNING: GPU not available\")\n",
    "\n",
    "# Data paths\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            # Cap ages over 5.5 to 5.5\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            # Skip files with non-numeric age (e.g., \"xpx\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    # Process color images (convert to grayscale)\n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            assert img_resized.shape == img_size, f\"Image {filename} not resized correctly: {img_resized.shape}\"\n",
    "                            # Convert to 3-channel for pretrained models\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    # Process grayscale images\n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            assert img_resized.shape == img_size, f\"Image {filename} not resized correctly: {img_resized.shape}\"\n",
    "                            # Convert to 3-channel for pretrained models\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    # Verify final dimensions\n",
    "    assert images.shape[1:3] == img_size, f\"Final image dimensions incorrect: {images.shape}\"\n",
    "    print(f\"Images loaded with shape: {images.shape}\")\n",
    "    print(f\"Classes: {np.unique(ages)} (0=1.5yr, 1=2.5yr, 2=3.5yr, 3=4.5yr, 4=5.5yr)\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Normalize to [0,1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        # Convert to CHW format\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        # Normalize with ImageNet stats\n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_model(model_name, num_classes=5):\n",
    "    \"\"\"Create model using timm (matching your reference code)\"\"\"\n",
    "    if model_name == 'ResNet50':\n",
    "        model = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'VGG16':\n",
    "        model = timm.create_model('vgg16', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        model = timm.create_model('mobilenetv2_100', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'InceptionV3':\n",
    "        model = timm.create_model('inception_v3', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'DenseNet121':\n",
    "        model = timm.create_model('densenet121', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'ResNet101':\n",
    "        model = timm.create_model('resnet101', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'ResNet152':\n",
    "        model = timm.create_model('resnet152', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'EfficientNetB1':\n",
    "        model = timm.create_model('efficientnet_b1', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'EfficientNetB2':\n",
    "        model = timm.create_model('efficientnet_b2', pretrained=True, num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, test_loader, model_name, epochs=50):\n",
    "    \"\"\"Train model with your proven GPU configuration\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, min_lr=1e-6)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} on {device}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_loss_total = 0.0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_loss_total += loss.item()\n",
    "            \n",
    "            # Memory management (from your reference code)\n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        scheduler.step(test_acc)\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:2d}: Train {train_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        # Memory cleanup\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Restore best model\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "# Create timestamped output folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_models_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Models will be saved to: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "print(f\"Loaded {len(X)} images, age range: {y.min():.1f}-{y.max():.1f}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DeerDataset(X_train, y_train)\n",
    "test_dataset = DeerDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders (using your batch size from reference code)\n",
    "batch_size = 16  # From your reference code for RTX 2060\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model families to test\n",
    "model_families = [\n",
    "    'ResNet50', 'EfficientNetB0', 'VGG16', \n",
    "    'MobileNetV2', 'InceptionV3', 'DenseNet121'\n",
    "]\n",
    "\n",
    "results = []\n",
    "best_accuracy = 0\n",
    "best_family = None\n",
    "\n",
    "print(f\"\\nTesting {len(model_families)} model families...\")\n",
    "\n",
    "for model_name in model_families:\n",
    "    print(f\"\\nTesting {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        model = create_model(model_name)\n",
    "        trained_model, accuracy = train_model(\n",
    "            model, train_loader, test_loader, model_name\n",
    "        )\n",
    "        \n",
    "        # Save model with accuracy in filename\n",
    "        acc_str = f\"{accuracy:.3f}\".replace('.', 'p')\n",
    "        model_filename = f\"{model_name}_{acc_str}.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'filename': model_filename,\n",
    "            'full_path': model_path\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name}: Accuracy={accuracy:.3f}, Saved: {model_filename}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_family = model_name\n",
    "        \n",
    "        # Cleanup (from your reference code)\n",
    "        del model, trained_model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Find best performing family\n",
    "print(f\"\\nBest family: {best_family} (accuracy: {best_accuracy:.3f})\")\n",
    "\n",
    "# Test variations within best family\n",
    "if best_family:\n",
    "    print(f\"\\nTesting variations of {best_family}...\")\n",
    "    \n",
    "    if best_family == 'ResNet50':\n",
    "        variations = ['ResNet101', 'ResNet152']\n",
    "    elif best_family == 'EfficientNetB0':\n",
    "        variations = ['EfficientNetB1', 'EfficientNetB2']\n",
    "    else:\n",
    "        variations = []\n",
    "    \n",
    "    for var_name in variations:\n",
    "        print(f\"\\nTesting {var_name}...\")\n",
    "        \n",
    "        try:\n",
    "            model = create_model(var_name)\n",
    "            trained_model, accuracy = train_model(\n",
    "                model, train_loader, test_loader, var_name\n",
    "            )\n",
    "            \n",
    "            # Save model\n",
    "            acc_str = f\"{accuracy:.3f}\".replace('.', 'p')\n",
    "            model_filename = f\"{var_name}_{acc_str}.pth\"\n",
    "            model_path = os.path.join(output_dir, model_filename)\n",
    "            \n",
    "            torch.save({\n",
    "                'model_state_dict': trained_model.state_dict(),\n",
    "                'model_name': var_name,\n",
    "                'accuracy': accuracy,\n",
    "                'num_classes': 5\n",
    "            }, model_path)\n",
    "            \n",
    "            results.append({\n",
    "                'model': var_name,\n",
    "                'accuracy': accuracy,\n",
    "                'filename': model_filename,\n",
    "                'full_path': model_path\n",
    "            })\n",
    "            \n",
    "            print(f\"{var_name}: Accuracy={accuracy:.3f}, Saved: {model_filename}\")\n",
    "            \n",
    "            # Cleanup\n",
    "            del model, trained_model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {var_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"FINAL RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i:2d}. {result['model']:15s} - Accuracy: {result['accuracy']:.3f}\")\n",
    "\n",
    "if results:\n",
    "    best_result = results[0]\n",
    "    print(f\"\\nBest model: {best_result['model']} with {best_result['accuracy']:.3f} accuracy\")\n",
    "    print(f\"Saved as: {best_result['filename']}\")\n",
    "\n",
    "print(f\"\\nTotal models tested: {len(results)}\")\n",
    "print(f\"All models saved in folder: {output_dir}\")\n",
    "print(\"All models saved with accuracy in filename.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd175bbe-545a-4fb8-8e68-fbd05ab1f5d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "Mixed Precision: Enabled\n",
      "Models will be saved to: deer_age_deep_survey_20250731_075454\n",
      "Loading images...\n",
      "Images loaded with shape: (466, 224, 224, 3)\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Loaded 466 images\n",
      "Train: 372, Test: 94\n",
      "\n",
      "Deep survey: Testing 12 models with improved regularization...\n",
      "\n",
      "Testing DenseNet121...\n",
      "Training DenseNet121 with improved regularization\n",
      "  Epoch  0: Train 25.5%, Test 30.9%\n",
      "  Epoch 10: Train 85.8%, Test 56.4%\n",
      "  Epoch 20: Train 91.1%, Test 46.8%\n",
      "  Epoch 25: Train 95.7%, Test 47.9%\n",
      "  Early stopping at epoch 25\n",
      "DenseNet121: 56.383% - Saved: DenseNet121_56p383.pth\n",
      "\n",
      "Testing DenseNet169...\n",
      "Training DenseNet169 with improved regularization\n",
      "  Epoch  0: Train 27.7%, Test 34.0%\n",
      "  Epoch 10: Train 90.3%, Test 52.1%\n",
      "  Epoch 20: Train 95.7%, Test 60.6%\n",
      "  Epoch 30: Train 98.9%, Test 60.6%\n",
      "  Epoch 40: Train 99.7%, Test 63.8%\n",
      "  Epoch 46: Train 99.5%, Test 61.7%\n",
      "  Early stopping at epoch 46\n",
      "DenseNet169: 63.830% - Saved: DenseNet169_63p830.pth\n",
      "\n",
      "Testing DenseNet201...\n",
      "Training DenseNet201 with improved regularization\n",
      "  Epoch  0: Train 24.7%, Test 34.0%\n",
      "  Epoch 10: Train 93.3%, Test 50.0%\n",
      "  Epoch 20: Train 98.1%, Test 50.0%\n",
      "  Epoch 27: Train 98.7%, Test 56.4%\n",
      "  Early stopping at epoch 27\n",
      "DenseNet201: 59.574% - Saved: DenseNet201_59p574.pth\n",
      "\n",
      "Testing EfficientNetB0...\n",
      "Training EfficientNetB0 with improved regularization\n",
      "  Epoch  0: Train 22.8%, Test 16.0%\n",
      "  Epoch 10: Train 63.2%, Test 42.6%\n",
      "  Epoch 20: Train 67.2%, Test 46.8%\n",
      "  Epoch 30: Train 77.4%, Test 46.8%\n",
      "  Epoch 40: Train 79.6%, Test 48.9%\n",
      "  Epoch 50: Train 81.2%, Test 46.8%\n",
      "  Early stopping at epoch 50\n",
      "EfficientNetB0: 48.936% - Saved: EfficientNetB0_48p936.pth\n",
      "\n",
      "Testing EfficientNetB1...\n",
      "Training EfficientNetB1 with improved regularization\n",
      "  Epoch  0: Train 24.2%, Test 24.5%\n",
      "  Epoch 10: Train 67.7%, Test 34.0%\n",
      "  Epoch 20: Train 84.1%, Test 45.7%\n",
      "  Early stopping at epoch 20\n",
      "EfficientNetB1: 48.936% - Saved: EfficientNetB1_48p936.pth\n",
      "\n",
      "Testing EfficientNetB2...\n",
      "Training EfficientNetB2 with improved regularization\n",
      "  Epoch  0: Train 22.8%, Test 29.8%\n",
      "  Epoch 10: Train 67.7%, Test 42.6%\n",
      "  Epoch 20: Train 80.6%, Test 43.6%\n",
      "  Epoch 30: Train 83.3%, Test 46.8%\n",
      "  Epoch 36: Train 85.5%, Test 48.9%\n",
      "  Early stopping at epoch 36\n",
      "EfficientNetB2: 52.128% - Saved: EfficientNetB2_52p128.pth\n",
      "\n",
      "Testing EfficientNetB3...\n",
      "Training EfficientNetB3 with improved regularization\n",
      "  Epoch  0: Train 19.9%, Test 28.7%\n",
      "  Epoch 10: Train 59.7%, Test 42.6%\n",
      "  Epoch 20: Train 77.2%, Test 45.7%\n",
      "  Epoch 28: Train 83.9%, Test 50.0%\n",
      "  Early stopping at epoch 28\n",
      "EfficientNetB3: 50.000% - Saved: EfficientNetB3_50p000.pth\n",
      "\n",
      "Testing MobileNetV2...\n",
      "Training MobileNetV2 with improved regularization\n",
      "  Epoch  0: Train 22.6%, Test 19.1%\n",
      "  Epoch 10: Train 22.3%, Test 22.3%\n",
      "  Epoch 20: Train 22.3%, Test 21.3%\n",
      "  Epoch 30: Train 20.7%, Test 24.5%\n",
      "  Epoch 40: Train 25.5%, Test 26.6%\n",
      "  Epoch 41: Train 23.7%, Test 24.5%\n",
      "  Early stopping at epoch 41\n",
      "MobileNetV2: 32.979% - Saved: MobileNetV2_32p979.pth\n",
      "\n",
      "Testing MobileNetV3Small...\n",
      "Training MobileNetV3Small with improved regularization\n",
      "  Epoch  0: Train 20.4%, Test 19.1%\n",
      "  Epoch 10: Train 26.1%, Test 18.1%\n",
      "  Epoch 20: Train 26.6%, Test 25.5%\n",
      "  Epoch 30: Train 24.7%, Test 25.5%\n",
      "  Epoch 40: Train 26.9%, Test 25.5%\n",
      "  Epoch 50: Train 26.3%, Test 26.6%\n",
      "  Epoch 54: Train 24.5%, Test 24.5%\n",
      "  Early stopping at epoch 54\n",
      "MobileNetV3Small: 28.723% - Saved: MobileNetV3Small_28p723.pth\n",
      "\n",
      "Testing MobileNetV3Large...\n",
      "Training MobileNetV3Large with improved regularization\n",
      "  Epoch  0: Train 20.2%, Test 16.0%\n",
      "  Epoch 10: Train 24.7%, Test 21.3%\n",
      "  Epoch 20: Train 23.9%, Test 20.2%\n",
      "  Epoch 27: Train 23.4%, Test 23.4%\n",
      "  Early stopping at epoch 27\n",
      "MobileNetV3Large: 26.596% - Saved: MobileNetV3Large_26p596.pth\n",
      "\n",
      "Testing ResNet50_Regularized...\n",
      "Training ResNet50_Regularized with improved regularization\n",
      "  Epoch  0: Train 21.8%, Test 22.3%\n",
      "  Epoch 10: Train 64.8%, Test 40.4%\n",
      "  Epoch 20: Train 86.6%, Test 47.9%\n",
      "  Epoch 30: Train 92.5%, Test 50.0%\n",
      "  Epoch 40: Train 92.5%, Test 50.0%\n",
      "  Epoch 50: Train 94.4%, Test 53.2%\n",
      "ResNet50_Regularized: 55.319% - Saved: ResNet50_Regularized_55p319.pth\n",
      "\n",
      "Testing ResNeXt50...\n",
      "Training ResNeXt50 with improved regularization\n",
      "  Epoch  0: Train 20.4%, Test 24.5%\n",
      "  Epoch 10: Train 83.6%, Test 54.3%\n",
      "  Epoch 20: Train 98.9%, Test 57.4%\n",
      "  Epoch 30: Train 99.7%, Test 60.6%\n",
      "  Epoch 40: Train 100.0%, Test 60.6%\n",
      "  Epoch 50: Train 99.7%, Test 60.6%\n",
      "  Early stopping at epoch 50\n",
      "ResNeXt50: 63.830% - Saved: ResNeXt50_63p830.pth\n",
      "\n",
      "============================================================\n",
      "DEEP SURVEY RESULTS - TOP 3 FAMILIES + EXTRAS\n",
      "============================================================\n",
      "DENSENET FAMILY:\n",
      "  DenseNet169          - 63.830%\n",
      "  DenseNet201          - 59.574%\n",
      "  DenseNet121          - 56.383%\n",
      "\n",
      "EFFICIENTNET FAMILY:\n",
      "  EfficientNetB2       - 52.128%\n",
      "  EfficientNetB3       - 50.000%\n",
      "  EfficientNetB0       - 48.936%\n",
      "  EfficientNetB1       - 48.936%\n",
      "\n",
      "MOBILENET FAMILY:\n",
      "  MobileNetV2          - 32.979%\n",
      "  MobileNetV3Small     - 28.723%\n",
      "  MobileNetV3Large     - 26.596%\n",
      "\n",
      "OTHER MODELS:\n",
      "  ResNeXt50            - 63.830%\n",
      "  ResNet50_Regularized - 55.319%\n",
      "\n",
      "============================================================\n",
      "OVERALL RANKING:\n",
      " 1. DenseNet169          - 63.830%\n",
      " 2. ResNeXt50            - 63.830%\n",
      " 3. DenseNet201          - 59.574%\n",
      " 4. DenseNet121          - 56.383%\n",
      " 5. ResNet50_Regularized - 55.319%\n",
      " 6. EfficientNetB2       - 52.128%\n",
      " 7. EfficientNetB3       - 50.000%\n",
      " 8. EfficientNetB0       - 48.936%\n",
      " 9. EfficientNetB1       - 48.936%\n",
      "10. MobileNetV2          - 32.979%\n",
      "11. MobileNetV3Small     - 28.723%\n",
      "12. MobileNetV3Large     - 26.596%\n",
      "\n",
      "BEST MODEL: DenseNet169 - 63.830%\n",
      "Saved as: DenseNet169_63p830.pth\n",
      "\n",
      "Total models tested: 12\n",
      "All models saved in: deer_age_deep_survey_20250731_075454\n",
      "Note: Improved regularization should reduce train/test accuracy gap\n"
     ]
    }
   ],
   "source": [
    "# Deeper family search.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "# GPU Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "else:\n",
    "    use_amp = False\n",
    "\n",
    "# Data paths\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Enhanced augmentation to reduce overfitting\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 8, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    print(f\"Images loaded with shape: {images.shape}\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "class AugmentedDeerDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False):\n",
    "        self.X = X\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.augment = augment\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].copy()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Apply augmentation during training\n",
    "        if self.augment:\n",
    "            image = augment_image(image)\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        image = torch.FloatTensor(image)\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_model_with_regularization(model_name, num_classes=5, dropout_rate=0.5):\n",
    "    \"\"\"Create model with better regularization\"\"\"\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=dropout_rate)\n",
    "    \n",
    "    # Freeze more layers to reduce overfitting\n",
    "    if 'resnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('layer4' in name or 'fc' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'efficientnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('blocks.6' in name or 'blocks.7' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'densenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('denseblock4' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'mobilenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('features.18' in name or 'features.19' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_model_improved(model, train_loader, test_loader, model_name, epochs=60):\n",
    "    \"\"\"Improved training with better regularization\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    \n",
    "    # Lower learning rate and higher weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} with improved regularization\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:2d}: Train {train_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "# Create timestamped output folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_deep_survey_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Models will be saved to: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "print(f\"Loaded {len(X)} images\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create datasets with augmentation\n",
    "train_dataset = AugmentedDeerDataset(X_train, y_train, augment=True)\n",
    "test_dataset = AugmentedDeerDataset(X_test, y_test, augment=False)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Deep exploration of top 3 families\n",
    "model_configs = [\n",
    "    # DenseNet family (won previous round)\n",
    "    ('densenet121', 'DenseNet121'),\n",
    "    ('densenet169', 'DenseNet169'),\n",
    "    ('densenet201', 'DenseNet201'),\n",
    "    \n",
    "    # EfficientNet family (2nd place)\n",
    "    ('efficientnet_b0', 'EfficientNetB0'),\n",
    "    ('efficientnet_b1', 'EfficientNetB1'),\n",
    "    ('efficientnet_b2', 'EfficientNetB2'),\n",
    "    ('efficientnet_b3', 'EfficientNetB3'),\n",
    "    \n",
    "    # MobileNet family (3rd place)\n",
    "    ('mobilenetv2_100', 'MobileNetV2'),\n",
    "    ('mobilenetv3_small_100', 'MobileNetV3Small'),\n",
    "    ('mobilenetv3_large_100', 'MobileNetV3Large'),\n",
    "    \n",
    "    # Additional high-performers to test\n",
    "    ('resnet50', 'ResNet50_Regularized'),\n",
    "    ('resnext50_32x4d', 'ResNeXt50'),\n",
    "]\n",
    "\n",
    "results = []\n",
    "print(f\"\\nDeep survey: Testing {len(model_configs)} models with improved regularization...\")\n",
    "\n",
    "for model_timm_name, display_name in model_configs:\n",
    "    print(f\"\\nTesting {display_name}...\")\n",
    "    \n",
    "    try:\n",
    "        model = create_model_with_regularization(model_timm_name, dropout_rate=0.5)\n",
    "        trained_model, accuracy = train_model_improved(\n",
    "            model, train_loader, test_loader, display_name\n",
    "        )\n",
    "        \n",
    "        # Save model\n",
    "        acc_str = f\"{accuracy:.3f}\".replace('.', 'p')\n",
    "        model_filename = f\"{display_name}_{acc_str}.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': display_name,\n",
    "            'timm_name': model_timm_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        results.append({\n",
    "            'model': display_name,\n",
    "            'timm_name': model_timm_name,\n",
    "            'accuracy': accuracy,\n",
    "            'filename': model_filename,\n",
    "            'full_path': model_path\n",
    "        })\n",
    "        \n",
    "        print(f\"{display_name}: {accuracy:.3f}% - Saved: {model_filename}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del model, trained_model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {display_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DEEP SURVEY RESULTS - TOP 3 FAMILIES + EXTRAS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "print(\"DENSENET FAMILY:\")\n",
    "for result in results:\n",
    "    if 'DenseNet' in result['model']:\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(\"\\nEFFICIENTNET FAMILY:\")\n",
    "for result in results:\n",
    "    if 'EfficientNet' in result['model']:\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(\"\\nMOBILENET FAMILY:\")\n",
    "for result in results:\n",
    "    if 'MobileNet' in result['model']:\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(\"\\nOTHER MODELS:\")\n",
    "for result in results:\n",
    "    if not any(family in result['model'] for family in ['DenseNet', 'EfficientNet', 'MobileNet']):\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"OVERALL RANKING:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i:2d}. {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "if results:\n",
    "    best_result = results[0]\n",
    "    print(f\"\\nBEST MODEL: {best_result['model']} - {best_result['accuracy']:.3f}%\")\n",
    "    print(f\"Saved as: {best_result['filename']}\")\n",
    "\n",
    "print(f\"\\nTotal models tested: {len(results)}\")\n",
    "print(f\"All models saved in: {output_dir}\")\n",
    "print(\"Note: Improved regularization should reduce train/test accuracy gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59e44bc-dc57-4f40-b884-3bcc192bbfd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Mixed Precision: Enabled\n",
      "Ensemble models saved to: deer_age_ensemble_20250731_220115\n",
      "Loading images...\n",
      "Total images: 466\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Train: 372, Test: 94\n",
      "\n",
      "============================================================\n",
      "SMALL DATA STRATEGY: MIXUP + MULTI-SCALE + ENSEMBLE\n",
      "============================================================\n",
      "Approach: Conservative training + Mixup synthetic data\n",
      "\n",
      "========================================\n",
      "Training DenseNet169\n",
      "========================================\n",
      "Training DenseNet169 with Mixup + Multi-scale\n",
      "  Epoch   0: Train 29.8%, Test+TTA 37.2%\n",
      "  Epoch  20: Train 64.2%, Test+TTA 54.3%\n",
      "  Epoch  40: Train 80.1%, Test+TTA 56.4%\n",
      "  Epoch  60: Train 78.5%, Test+TTA 62.8%\n",
      "  Epoch  64: Train 81.5%, Test+TTA 57.4%\n",
      "  Early stopping at epoch 64\n",
      "DenseNet169: 64.9% - Saved\n",
      "\n",
      "========================================\n",
      "Training ResNeXt50\n",
      "========================================\n",
      "Training ResNeXt50 with Mixup + Multi-scale\n",
      "  Epoch   0: Train 23.1%, Test+TTA 24.5%\n",
      "  Epoch  20: Train 84.9%, Test+TTA 53.2%\n",
      "  Epoch  40: Train 84.7%, Test+TTA 52.1%\n",
      "  Epoch  58: Train 84.4%, Test+TTA 57.4%\n",
      "  Early stopping at epoch 58\n",
      "ResNeXt50: 57.4% - Saved\n",
      "\n",
      "========================================\n",
      "Training DenseNet201\n",
      "========================================\n",
      "Training DenseNet201 with Mixup + Multi-scale\n",
      "  Epoch   0: Train 28.2%, Test+TTA 36.2%\n",
      "  Epoch  20: Train 81.2%, Test+TTA 52.1%\n",
      "  Epoch  40: Train 82.8%, Test+TTA 54.3%\n",
      "  Epoch  56: Train 82.5%, Test+TTA 56.4%\n",
      "  Early stopping at epoch 56\n",
      "DenseNet201: 60.6% - Saved\n",
      "\n",
      "========================================\n",
      "ENSEMBLE EVALUATION\n",
      "========================================\n",
      "INDIVIDUAL MODEL RESULTS:\n",
      "  DenseNet169: 64.9%\n",
      "  ResNeXt50: 57.4%\n",
      "  DenseNet201: 60.6%\n",
      "\n",
      "ENSEMBLE RESULT: 57.4%\n",
      "Gap to 75%: 17.6%\n",
      "\n",
      "All models saved in: deer_age_ensemble_20250731_220115\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Second attempt at model families \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "else:\n",
    "    use_amp = False\n",
    "\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    \"\"\"Mixup augmentation to create synthetic training examples\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Mixup loss function\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "def conservative_augment(image):\n",
    "    \"\"\"Very light augmentation to preserve deer features\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        angle = random.uniform(-8, 8)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        alpha = random.uniform(0.9, 1.1)\n",
    "        beta = random.randint(-10, 10)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    return image\n",
    "\n",
    "class MultiScaleDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False, scale_size=224):\n",
    "        self.X = X\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.augment = augment\n",
    "        self.scale_size = scale_size\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].copy()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Multi-scale training\n",
    "        if self.augment:\n",
    "            scale_factor = random.choice([0.8, 0.9, 1.0, 1.1, 1.2])\n",
    "            new_size = int(self.scale_size * scale_factor)\n",
    "            image = cv2.resize(image, (new_size, new_size))\n",
    "            image = cv2.resize(image, (self.scale_size, self.scale_size))\n",
    "            \n",
    "            image = conservative_augment(image)\n",
    "        \n",
    "        image = torch.FloatTensor(image)\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_conservative_model(model_name, num_classes=5):\n",
    "    \"\"\"Back to simpler model creation that worked\"\"\"\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=0.4)\n",
    "    \n",
    "    # Conservative freezing (like the 63.8% model)\n",
    "    if 'densenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('denseblock4' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'resnext' in model_name or 'resnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('layer4' in name or 'fc' in name):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_with_mixup_and_multiscale(model, train_loader, test_loader, model_name, epochs=120):\n",
    "    \"\"\"Training with mixup + multi-scale + very conservative approach\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    # Conservative optimizer (back to what worked)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 30\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} with Mixup + Multi-scale\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training with mixup\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Apply mixup\n",
    "            if random.random() < 0.5:  # 50% chance of mixup\n",
    "                mixed_images, y_a, y_b, lam = mixup_data(images, labels, alpha=0.4)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(mixed_images)\n",
    "                        loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(mixed_images)\n",
    "                    loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # For accuracy calculation, use original labels\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == y_a).sum().item()\n",
    "            else:\n",
    "                # Normal training\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Simple TTA evaluation (not too heavy)\n",
    "        test_acc = evaluate_with_simple_tta(model, test_loader)\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 20 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:3d}: Train {train_acc:.1f}%, Test+TTA {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "def evaluate_with_simple_tta(model, test_loader):\n",
    "    \"\"\"Simple TTA - just 3 versions\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Original prediction\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs1 = model(images)\n",
    "            else:\n",
    "                outputs1 = model(images)\n",
    "            \n",
    "            # Horizontal flip\n",
    "            flipped = torch.flip(images, [3])\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs2 = model(flipped)\n",
    "            else:\n",
    "                outputs2 = model(flipped)\n",
    "            \n",
    "            # Slight zoom\n",
    "            zoomed = F.interpolate(images, scale_factor=0.95, mode='bilinear', align_corners=False)\n",
    "            zoomed = F.interpolate(zoomed, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs3 = model(zoomed)\n",
    "            else:\n",
    "                outputs3 = model(zoomed)\n",
    "            \n",
    "            # Average predictions\n",
    "            avg_outputs = (F.softmax(outputs1, dim=1) + F.softmax(outputs2, dim=1) + F.softmax(outputs3, dim=1)) / 3\n",
    "            _, predicted = torch.max(avg_outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "def ensemble_predict(models, test_loader):\n",
    "    \"\"\"Simple ensemble of multiple models\"\"\"\n",
    "    all_models_eval = [model.eval() for model in models]\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            ensemble_output = torch.zeros(images.size(0), 5).to(device)\n",
    "            \n",
    "            for model in models:\n",
    "                # Simple TTA for each model\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs1 = model(images)\n",
    "                        outputs2 = model(torch.flip(images, [3]))\n",
    "                else:\n",
    "                    outputs1 = model(images)\n",
    "                    outputs2 = model(torch.flip(images, [3]))\n",
    "                \n",
    "                avg_model_output = (F.softmax(outputs1, dim=1) + F.softmax(outputs2, dim=1)) / 2\n",
    "                ensemble_output += avg_model_output\n",
    "            \n",
    "            # Final ensemble prediction\n",
    "            _, predicted = torch.max(ensemble_output, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "# Main execution\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_ensemble_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Ensemble models saved to: {output_dir}\")\n",
    "\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultiScaleDataset(X_train, y_train, augment=True)\n",
    "test_dataset = MultiScaleDataset(X_test, y_test, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SMALL DATA STRATEGY: MIXUP + MULTI-SCALE + ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Approach: Conservative training + Mixup synthetic data\")\n",
    "\n",
    "# Train multiple models for ensemble\n",
    "model_configs = [\n",
    "    ('densenet169', 'DenseNet169'),\n",
    "    ('resnext50_32x4d', 'ResNeXt50'),\n",
    "    ('densenet201', 'DenseNet201'),\n",
    "]\n",
    "\n",
    "trained_models = []\n",
    "individual_scores = []\n",
    "\n",
    "for model_timm_name, display_name in model_configs:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Training {display_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    try:\n",
    "        model = create_conservative_model(model_timm_name)\n",
    "        trained_model, accuracy = train_with_mixup_and_multiscale(\n",
    "            model, train_loader, test_loader, display_name\n",
    "        )\n",
    "        \n",
    "        # Save individual model\n",
    "        acc_str = f\"{accuracy:.1f}\".replace('.', 'p')\n",
    "        model_filename = f\"{display_name}_{acc_str}pct.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': display_name,\n",
    "            'timm_name': model_timm_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        trained_models.append(trained_model)\n",
    "        individual_scores.append(accuracy)\n",
    "        \n",
    "        print(f\"{display_name}: {accuracy:.1f}% - Saved\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {display_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Ensemble evaluation\n",
    "if len(trained_models) > 1:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"ENSEMBLE EVALUATION\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    ensemble_accuracy = ensemble_predict(trained_models, test_loader)\n",
    "    \n",
    "    print(\"INDIVIDUAL MODEL RESULTS:\")\n",
    "    for i, (score, config) in enumerate(zip(individual_scores, model_configs)):\n",
    "        print(f\"  {config[1]}: {score:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nENSEMBLE RESULT: {ensemble_accuracy:.1f}%\")\n",
    "    \n",
    "    if ensemble_accuracy >= 75.0:\n",
    "        print(\"SUCCESS: 75% target achieved!\")\n",
    "    else:\n",
    "        gap = 75.0 - ensemble_accuracy\n",
    "        print(f\"Gap to 75%: {gap:.1f}%\")\n",
    "        \n",
    "        if ensemble_accuracy > max(individual_scores):\n",
    "            improvement = ensemble_accuracy - max(individual_scores)\n",
    "            print(f\"Ensemble improvement: +{improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nAll models saved in: {output_dir}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d49ddb-fc22-461c-87fc-db647028a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third attempt at model families"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
