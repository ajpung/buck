{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a9ce06-de99-4d13-89f5-02a509fd73c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA recognized\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"âŒ CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bf38a0-b457-4061-9fac-34fdcdb68261",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "Mixed Precision: Enabled\n",
      "Models will be saved to: deer_age_models_20250731_072915\n",
      "Loading images...\n",
      "Images loaded with shape: (466, 224, 224, 3)\n",
      "Classes: [0 1 2 3 4] (0=1.5yr, 1=2.5yr, 2=3.5yr, 3=4.5yr, 4=5.5yr)\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Loaded 466 images, age range: 0.0-4.0\n",
      "Train: 372, Test: 94\n",
      "\n",
      "Testing 6 model families...\n",
      "\n",
      "Testing ResNet50...\n",
      "Training ResNet50 on cuda\n",
      "  Epoch  0: Train 22.6%, Test 25.5%\n",
      "  Epoch 10: Train 100.0%, Test 47.9%\n",
      "  Epoch 19: Train 100.0%, Test 50.0%\n",
      "  Early stopping at epoch 19\n",
      "ResNet50: Accuracy=51.064, Saved: ResNet50_51p064.pth\n",
      "\n",
      "Testing EfficientNetB0...\n",
      "Training EfficientNetB0 on cuda\n",
      "  Epoch  0: Train 29.6%, Test 35.1%\n",
      "  Epoch 10: Train 100.0%, Test 50.0%\n",
      "  Epoch 18: Train 100.0%, Test 55.3%\n",
      "  Early stopping at epoch 18\n",
      "EfficientNetB0: Accuracy=55.319, Saved: EfficientNetB0_55p319.pth\n",
      "\n",
      "Testing VGG16...\n",
      "Training VGG16 on cuda\n",
      "  Epoch  0: Train 21.0%, Test 24.5%\n",
      "  Epoch 10: Train 24.2%, Test 21.3%\n",
      "  Epoch 20: Train 24.2%, Test 25.5%\n",
      "  Epoch 21: Train 24.7%, Test 19.1%\n",
      "  Early stopping at epoch 21\n",
      "VGG16: Accuracy=29.787, Saved: VGG16_29p787.pth\n",
      "\n",
      "Testing MobileNetV2...\n",
      "Training MobileNetV2 on cuda\n",
      "  Epoch  0: Train 29.3%, Test 29.8%\n",
      "  Epoch 10: Train 99.7%, Test 45.7%\n",
      "  Epoch 20: Train 100.0%, Test 47.9%\n",
      "  Epoch 26: Train 99.7%, Test 47.9%\n",
      "  Early stopping at epoch 26\n",
      "MobileNetV2: Accuracy=54.255, Saved: MobileNetV2_54p255.pth\n",
      "\n",
      "Testing InceptionV3...\n",
      "Training InceptionV3 on cuda\n",
      "  Epoch  0: Train 23.7%, Test 21.3%\n",
      "  Epoch 10: Train 92.5%, Test 39.4%\n",
      "  Epoch 20: Train 100.0%, Test 44.7%\n",
      "  Epoch 28: Train 99.7%, Test 43.6%\n",
      "  Early stopping at epoch 28\n",
      "InceptionV3: Accuracy=47.872, Saved: InceptionV3_47p872.pth\n",
      "\n",
      "Testing DenseNet121...\n",
      "Training DenseNet121 on cuda\n",
      "  Epoch  0: Train 27.4%, Test 24.5%\n",
      "  Epoch 10: Train 100.0%, Test 54.3%\n",
      "  Epoch 19: Train 100.0%, Test 55.3%\n",
      "  Early stopping at epoch 19\n",
      "DenseNet121: Accuracy=56.383, Saved: DenseNet121_56p383.pth\n",
      "\n",
      "Best family: DenseNet121 (accuracy: 56.383)\n",
      "\n",
      "Testing variations of DenseNet121...\n",
      "\n",
      "==================================================\n",
      "FINAL RESULTS\n",
      "==================================================\n",
      " 1. DenseNet121     - Accuracy: 56.383\n",
      " 2. EfficientNetB0  - Accuracy: 55.319\n",
      " 3. MobileNetV2     - Accuracy: 54.255\n",
      " 4. ResNet50        - Accuracy: 51.064\n",
      " 5. InceptionV3     - Accuracy: 47.872\n",
      " 6. VGG16           - Accuracy: 29.787\n",
      "\n",
      "Best model: DenseNet121 with 56.383 accuracy\n",
      "Saved as: DenseNet121_56p383.pth\n",
      "\n",
      "Total models tested: 6\n",
      "All models saved in folder: deer_age_models_20250731_072915\n",
      "All models saved with accuracy in filename.\n"
     ]
    }
   ],
   "source": [
    "# Broad model family search\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mixed precision imports (from your reference code)\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "# GPU Configuration (matching your reference code)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "        print(\"Mixed Precision: Disabled\")\n",
    "else:\n",
    "    use_amp = False\n",
    "    print(\"WARNING: GPU not available\")\n",
    "\n",
    "# Data paths\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            # Cap ages over 5.5 to 5.5\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            # Skip files with non-numeric age (e.g., \"xpx\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    # Process color images (convert to grayscale)\n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            assert img_resized.shape == img_size, f\"Image {filename} not resized correctly: {img_resized.shape}\"\n",
    "                            # Convert to 3-channel for pretrained models\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    # Process grayscale images\n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            assert img_resized.shape == img_size, f\"Image {filename} not resized correctly: {img_resized.shape}\"\n",
    "                            # Convert to 3-channel for pretrained models\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    # Verify final dimensions\n",
    "    assert images.shape[1:3] == img_size, f\"Final image dimensions incorrect: {images.shape}\"\n",
    "    print(f\"Images loaded with shape: {images.shape}\")\n",
    "    print(f\"Classes: {np.unique(ages)} (0=1.5yr, 1=2.5yr, 2=3.5yr, 3=4.5yr, 4=5.5yr)\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Normalize to [0,1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        # Convert to CHW format\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        # Normalize with ImageNet stats\n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_model(model_name, num_classes=5):\n",
    "    \"\"\"Create model using timm (matching your reference code)\"\"\"\n",
    "    if model_name == 'ResNet50':\n",
    "        model = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'VGG16':\n",
    "        model = timm.create_model('vgg16', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        model = timm.create_model('mobilenetv2_100', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'InceptionV3':\n",
    "        model = timm.create_model('inception_v3', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'DenseNet121':\n",
    "        model = timm.create_model('densenet121', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'ResNet101':\n",
    "        model = timm.create_model('resnet101', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'ResNet152':\n",
    "        model = timm.create_model('resnet152', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'EfficientNetB1':\n",
    "        model = timm.create_model('efficientnet_b1', pretrained=True, num_classes=num_classes)\n",
    "    elif model_name == 'EfficientNetB2':\n",
    "        model = timm.create_model('efficientnet_b2', pretrained=True, num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, test_loader, model_name, epochs=50):\n",
    "    \"\"\"Train model with your proven GPU configuration\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, min_lr=1e-6)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} on {device}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_loss_total = 0.0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_loss_total += loss.item()\n",
    "            \n",
    "            # Memory management (from your reference code)\n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        scheduler.step(test_acc)\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:2d}: Train {train_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        # Memory cleanup\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Restore best model\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "# Create timestamped output folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_models_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Models will be saved to: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "print(f\"Loaded {len(X)} images, age range: {y.min():.1f}-{y.max():.1f}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DeerDataset(X_train, y_train)\n",
    "test_dataset = DeerDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders (using your batch size from reference code)\n",
    "batch_size = 16  # From your reference code for RTX 2060\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model families to test\n",
    "model_families = [\n",
    "    'ResNet50', 'EfficientNetB0', 'VGG16', \n",
    "    'MobileNetV2', 'InceptionV3', 'DenseNet121'\n",
    "]\n",
    "\n",
    "results = []\n",
    "best_accuracy = 0\n",
    "best_family = None\n",
    "\n",
    "print(f\"\\nTesting {len(model_families)} model families...\")\n",
    "\n",
    "for model_name in model_families:\n",
    "    print(f\"\\nTesting {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        model = create_model(model_name)\n",
    "        trained_model, accuracy = train_model(\n",
    "            model, train_loader, test_loader, model_name\n",
    "        )\n",
    "        \n",
    "        # Save model with accuracy in filename\n",
    "        acc_str = f\"{accuracy:.3f}\".replace('.', 'p')\n",
    "        model_filename = f\"{model_name}_{acc_str}.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'filename': model_filename,\n",
    "            'full_path': model_path\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name}: Accuracy={accuracy:.3f}, Saved: {model_filename}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_family = model_name\n",
    "        \n",
    "        # Cleanup (from your reference code)\n",
    "        del model, trained_model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Find best performing family\n",
    "print(f\"\\nBest family: {best_family} (accuracy: {best_accuracy:.3f})\")\n",
    "\n",
    "# Test variations within best family\n",
    "if best_family:\n",
    "    print(f\"\\nTesting variations of {best_family}...\")\n",
    "    \n",
    "    if best_family == 'ResNet50':\n",
    "        variations = ['ResNet101', 'ResNet152']\n",
    "    elif best_family == 'EfficientNetB0':\n",
    "        variations = ['EfficientNetB1', 'EfficientNetB2']\n",
    "    else:\n",
    "        variations = []\n",
    "    \n",
    "    for var_name in variations:\n",
    "        print(f\"\\nTesting {var_name}...\")\n",
    "        \n",
    "        try:\n",
    "            model = create_model(var_name)\n",
    "            trained_model, accuracy = train_model(\n",
    "                model, train_loader, test_loader, var_name\n",
    "            )\n",
    "            \n",
    "            # Save model\n",
    "            acc_str = f\"{accuracy:.3f}\".replace('.', 'p')\n",
    "            model_filename = f\"{var_name}_{acc_str}.pth\"\n",
    "            model_path = os.path.join(output_dir, model_filename)\n",
    "            \n",
    "            torch.save({\n",
    "                'model_state_dict': trained_model.state_dict(),\n",
    "                'model_name': var_name,\n",
    "                'accuracy': accuracy,\n",
    "                'num_classes': 5\n",
    "            }, model_path)\n",
    "            \n",
    "            results.append({\n",
    "                'model': var_name,\n",
    "                'accuracy': accuracy,\n",
    "                'filename': model_filename,\n",
    "                'full_path': model_path\n",
    "            })\n",
    "            \n",
    "            print(f\"{var_name}: Accuracy={accuracy:.3f}, Saved: {model_filename}\")\n",
    "            \n",
    "            # Cleanup\n",
    "            del model, trained_model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {var_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"FINAL RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i:2d}. {result['model']:15s} - Accuracy: {result['accuracy']:.3f}\")\n",
    "\n",
    "if results:\n",
    "    best_result = results[0]\n",
    "    print(f\"\\nBest model: {best_result['model']} with {best_result['accuracy']:.3f} accuracy\")\n",
    "    print(f\"Saved as: {best_result['filename']}\")\n",
    "\n",
    "print(f\"\\nTotal models tested: {len(results)}\")\n",
    "print(f\"All models saved in folder: {output_dir}\")\n",
    "print(\"All models saved with accuracy in filename.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd175bbe-545a-4fb8-8e68-fbd05ab1f5d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "Mixed Precision: Enabled\n",
      "Models will be saved to: deer_age_deep_survey_20250731_075454\n",
      "Loading images...\n",
      "Images loaded with shape: (466, 224, 224, 3)\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Loaded 466 images\n",
      "Train: 372, Test: 94\n",
      "\n",
      "Deep survey: Testing 12 models with improved regularization...\n",
      "\n",
      "Testing DenseNet121...\n",
      "Training DenseNet121 with improved regularization\n",
      "  Epoch  0: Train 25.5%, Test 30.9%\n",
      "  Epoch 10: Train 85.8%, Test 56.4%\n",
      "  Epoch 20: Train 91.1%, Test 46.8%\n",
      "  Epoch 25: Train 95.7%, Test 47.9%\n",
      "  Early stopping at epoch 25\n",
      "DenseNet121: 56.383% - Saved: DenseNet121_56p383.pth\n",
      "\n",
      "Testing DenseNet169...\n",
      "Training DenseNet169 with improved regularization\n",
      "  Epoch  0: Train 27.7%, Test 34.0%\n",
      "  Epoch 10: Train 90.3%, Test 52.1%\n",
      "  Epoch 20: Train 95.7%, Test 60.6%\n",
      "  Epoch 30: Train 98.9%, Test 60.6%\n",
      "  Epoch 40: Train 99.7%, Test 63.8%\n",
      "  Epoch 46: Train 99.5%, Test 61.7%\n",
      "  Early stopping at epoch 46\n",
      "DenseNet169: 63.830% - Saved: DenseNet169_63p830.pth\n",
      "\n",
      "Testing DenseNet201...\n",
      "Training DenseNet201 with improved regularization\n",
      "  Epoch  0: Train 24.7%, Test 34.0%\n",
      "  Epoch 10: Train 93.3%, Test 50.0%\n",
      "  Epoch 20: Train 98.1%, Test 50.0%\n",
      "  Epoch 27: Train 98.7%, Test 56.4%\n",
      "  Early stopping at epoch 27\n",
      "DenseNet201: 59.574% - Saved: DenseNet201_59p574.pth\n",
      "\n",
      "Testing EfficientNetB0...\n",
      "Training EfficientNetB0 with improved regularization\n",
      "  Epoch  0: Train 22.8%, Test 16.0%\n",
      "  Epoch 10: Train 63.2%, Test 42.6%\n",
      "  Epoch 20: Train 67.2%, Test 46.8%\n",
      "  Epoch 30: Train 77.4%, Test 46.8%\n",
      "  Epoch 40: Train 79.6%, Test 48.9%\n",
      "  Epoch 50: Train 81.2%, Test 46.8%\n",
      "  Early stopping at epoch 50\n",
      "EfficientNetB0: 48.936% - Saved: EfficientNetB0_48p936.pth\n",
      "\n",
      "Testing EfficientNetB1...\n",
      "Training EfficientNetB1 with improved regularization\n",
      "  Epoch  0: Train 24.2%, Test 24.5%\n",
      "  Epoch 10: Train 67.7%, Test 34.0%\n",
      "  Epoch 20: Train 84.1%, Test 45.7%\n",
      "  Early stopping at epoch 20\n",
      "EfficientNetB1: 48.936% - Saved: EfficientNetB1_48p936.pth\n",
      "\n",
      "Testing EfficientNetB2...\n",
      "Training EfficientNetB2 with improved regularization\n",
      "  Epoch  0: Train 22.8%, Test 29.8%\n",
      "  Epoch 10: Train 67.7%, Test 42.6%\n",
      "  Epoch 20: Train 80.6%, Test 43.6%\n",
      "  Epoch 30: Train 83.3%, Test 46.8%\n",
      "  Epoch 36: Train 85.5%, Test 48.9%\n",
      "  Early stopping at epoch 36\n",
      "EfficientNetB2: 52.128% - Saved: EfficientNetB2_52p128.pth\n",
      "\n",
      "Testing EfficientNetB3...\n",
      "Training EfficientNetB3 with improved regularization\n",
      "  Epoch  0: Train 19.9%, Test 28.7%\n",
      "  Epoch 10: Train 59.7%, Test 42.6%\n",
      "  Epoch 20: Train 77.2%, Test 45.7%\n",
      "  Epoch 28: Train 83.9%, Test 50.0%\n",
      "  Early stopping at epoch 28\n",
      "EfficientNetB3: 50.000% - Saved: EfficientNetB3_50p000.pth\n",
      "\n",
      "Testing MobileNetV2...\n",
      "Training MobileNetV2 with improved regularization\n",
      "  Epoch  0: Train 22.6%, Test 19.1%\n",
      "  Epoch 10: Train 22.3%, Test 22.3%\n",
      "  Epoch 20: Train 22.3%, Test 21.3%\n",
      "  Epoch 30: Train 20.7%, Test 24.5%\n",
      "  Epoch 40: Train 25.5%, Test 26.6%\n",
      "  Epoch 41: Train 23.7%, Test 24.5%\n",
      "  Early stopping at epoch 41\n",
      "MobileNetV2: 32.979% - Saved: MobileNetV2_32p979.pth\n",
      "\n",
      "Testing MobileNetV3Small...\n",
      "Training MobileNetV3Small with improved regularization\n",
      "  Epoch  0: Train 20.4%, Test 19.1%\n",
      "  Epoch 10: Train 26.1%, Test 18.1%\n",
      "  Epoch 20: Train 26.6%, Test 25.5%\n",
      "  Epoch 30: Train 24.7%, Test 25.5%\n",
      "  Epoch 40: Train 26.9%, Test 25.5%\n",
      "  Epoch 50: Train 26.3%, Test 26.6%\n",
      "  Epoch 54: Train 24.5%, Test 24.5%\n",
      "  Early stopping at epoch 54\n",
      "MobileNetV3Small: 28.723% - Saved: MobileNetV3Small_28p723.pth\n",
      "\n",
      "Testing MobileNetV3Large...\n",
      "Training MobileNetV3Large with improved regularization\n",
      "  Epoch  0: Train 20.2%, Test 16.0%\n",
      "  Epoch 10: Train 24.7%, Test 21.3%\n",
      "  Epoch 20: Train 23.9%, Test 20.2%\n",
      "  Epoch 27: Train 23.4%, Test 23.4%\n",
      "  Early stopping at epoch 27\n",
      "MobileNetV3Large: 26.596% - Saved: MobileNetV3Large_26p596.pth\n",
      "\n",
      "Testing ResNet50_Regularized...\n",
      "Training ResNet50_Regularized with improved regularization\n",
      "  Epoch  0: Train 21.8%, Test 22.3%\n",
      "  Epoch 10: Train 64.8%, Test 40.4%\n",
      "  Epoch 20: Train 86.6%, Test 47.9%\n",
      "  Epoch 30: Train 92.5%, Test 50.0%\n",
      "  Epoch 40: Train 92.5%, Test 50.0%\n",
      "  Epoch 50: Train 94.4%, Test 53.2%\n",
      "ResNet50_Regularized: 55.319% - Saved: ResNet50_Regularized_55p319.pth\n",
      "\n",
      "Testing ResNeXt50...\n",
      "Training ResNeXt50 with improved regularization\n",
      "  Epoch  0: Train 20.4%, Test 24.5%\n",
      "  Epoch 10: Train 83.6%, Test 54.3%\n",
      "  Epoch 20: Train 98.9%, Test 57.4%\n",
      "  Epoch 30: Train 99.7%, Test 60.6%\n",
      "  Epoch 40: Train 100.0%, Test 60.6%\n",
      "  Epoch 50: Train 99.7%, Test 60.6%\n",
      "  Early stopping at epoch 50\n",
      "ResNeXt50: 63.830% - Saved: ResNeXt50_63p830.pth\n",
      "\n",
      "============================================================\n",
      "DEEP SURVEY RESULTS - TOP 3 FAMILIES + EXTRAS\n",
      "============================================================\n",
      "DENSENET FAMILY:\n",
      "  DenseNet169          - 63.830%\n",
      "  DenseNet201          - 59.574%\n",
      "  DenseNet121          - 56.383%\n",
      "\n",
      "EFFICIENTNET FAMILY:\n",
      "  EfficientNetB2       - 52.128%\n",
      "  EfficientNetB3       - 50.000%\n",
      "  EfficientNetB0       - 48.936%\n",
      "  EfficientNetB1       - 48.936%\n",
      "\n",
      "MOBILENET FAMILY:\n",
      "  MobileNetV2          - 32.979%\n",
      "  MobileNetV3Small     - 28.723%\n",
      "  MobileNetV3Large     - 26.596%\n",
      "\n",
      "OTHER MODELS:\n",
      "  ResNeXt50            - 63.830%\n",
      "  ResNet50_Regularized - 55.319%\n",
      "\n",
      "============================================================\n",
      "OVERALL RANKING:\n",
      " 1. DenseNet169          - 63.830%\n",
      " 2. ResNeXt50            - 63.830%\n",
      " 3. DenseNet201          - 59.574%\n",
      " 4. DenseNet121          - 56.383%\n",
      " 5. ResNet50_Regularized - 55.319%\n",
      " 6. EfficientNetB2       - 52.128%\n",
      " 7. EfficientNetB3       - 50.000%\n",
      " 8. EfficientNetB0       - 48.936%\n",
      " 9. EfficientNetB1       - 48.936%\n",
      "10. MobileNetV2          - 32.979%\n",
      "11. MobileNetV3Small     - 28.723%\n",
      "12. MobileNetV3Large     - 26.596%\n",
      "\n",
      "BEST MODEL: DenseNet169 - 63.830%\n",
      "Saved as: DenseNet169_63p830.pth\n",
      "\n",
      "Total models tested: 12\n",
      "All models saved in: deer_age_deep_survey_20250731_075454\n",
      "Note: Improved regularization should reduce train/test accuracy gap\n"
     ]
    }
   ],
   "source": [
    "# Deeper family search.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "# GPU Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "else:\n",
    "    use_amp = False\n",
    "\n",
    "# Data paths\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Enhanced augmentation to reduce overfitting\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 8, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    print(f\"Images loaded with shape: {images.shape}\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "class AugmentedDeerDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False):\n",
    "        self.X = X\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.augment = augment\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].copy()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Apply augmentation during training\n",
    "        if self.augment:\n",
    "            image = augment_image(image)\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        image = torch.FloatTensor(image)\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_model_with_regularization(model_name, num_classes=5, dropout_rate=0.5):\n",
    "    \"\"\"Create model with better regularization\"\"\"\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=dropout_rate)\n",
    "    \n",
    "    # Freeze more layers to reduce overfitting\n",
    "    if 'resnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('layer4' in name or 'fc' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'efficientnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('blocks.6' in name or 'blocks.7' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'densenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('denseblock4' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'mobilenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('features.18' in name or 'features.19' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_model_improved(model, train_loader, test_loader, model_name, epochs=60):\n",
    "    \"\"\"Improved training with better regularization\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    \n",
    "    # Lower learning rate and higher weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} with improved regularization\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:2d}: Train {train_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "# Create timestamped output folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_deep_survey_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Models will be saved to: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "print(f\"Loaded {len(X)} images\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create datasets with augmentation\n",
    "train_dataset = AugmentedDeerDataset(X_train, y_train, augment=True)\n",
    "test_dataset = AugmentedDeerDataset(X_test, y_test, augment=False)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Deep exploration of top 3 families\n",
    "model_configs = [\n",
    "    # DenseNet family (won previous round)\n",
    "    ('densenet121', 'DenseNet121'),\n",
    "    ('densenet169', 'DenseNet169'),\n",
    "    ('densenet201', 'DenseNet201'),\n",
    "    \n",
    "    # EfficientNet family (2nd place)\n",
    "    ('efficientnet_b0', 'EfficientNetB0'),\n",
    "    ('efficientnet_b1', 'EfficientNetB1'),\n",
    "    ('efficientnet_b2', 'EfficientNetB2'),\n",
    "    ('efficientnet_b3', 'EfficientNetB3'),\n",
    "    \n",
    "    # MobileNet family (3rd place)\n",
    "    ('mobilenetv2_100', 'MobileNetV2'),\n",
    "    ('mobilenetv3_small_100', 'MobileNetV3Small'),\n",
    "    ('mobilenetv3_large_100', 'MobileNetV3Large'),\n",
    "    \n",
    "    # Additional high-performers to test\n",
    "    ('resnet50', 'ResNet50_Regularized'),\n",
    "    ('resnext50_32x4d', 'ResNeXt50'),\n",
    "]\n",
    "\n",
    "results = []\n",
    "print(f\"\\nDeep survey: Testing {len(model_configs)} models with improved regularization...\")\n",
    "\n",
    "for model_timm_name, display_name in model_configs:\n",
    "    print(f\"\\nTesting {display_name}...\")\n",
    "    \n",
    "    try:\n",
    "        model = create_model_with_regularization(model_timm_name, dropout_rate=0.5)\n",
    "        trained_model, accuracy = train_model_improved(\n",
    "            model, train_loader, test_loader, display_name\n",
    "        )\n",
    "        \n",
    "        # Save model\n",
    "        acc_str = f\"{accuracy:.3f}\".replace('.', 'p')\n",
    "        model_filename = f\"{display_name}_{acc_str}.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': display_name,\n",
    "            'timm_name': model_timm_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        results.append({\n",
    "            'model': display_name,\n",
    "            'timm_name': model_timm_name,\n",
    "            'accuracy': accuracy,\n",
    "            'filename': model_filename,\n",
    "            'full_path': model_path\n",
    "        })\n",
    "        \n",
    "        print(f\"{display_name}: {accuracy:.3f}% - Saved: {model_filename}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del model, trained_model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {display_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DEEP SURVEY RESULTS - TOP 3 FAMILIES + EXTRAS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "print(\"DENSENET FAMILY:\")\n",
    "for result in results:\n",
    "    if 'DenseNet' in result['model']:\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(\"\\nEFFICIENTNET FAMILY:\")\n",
    "for result in results:\n",
    "    if 'EfficientNet' in result['model']:\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(\"\\nMOBILENET FAMILY:\")\n",
    "for result in results:\n",
    "    if 'MobileNet' in result['model']:\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(\"\\nOTHER MODELS:\")\n",
    "for result in results:\n",
    "    if not any(family in result['model'] for family in ['DenseNet', 'EfficientNet', 'MobileNet']):\n",
    "        print(f\"  {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"OVERALL RANKING:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i:2d}. {result['model']:20s} - {result['accuracy']:.3f}%\")\n",
    "\n",
    "if results:\n",
    "    best_result = results[0]\n",
    "    print(f\"\\nBEST MODEL: {best_result['model']} - {best_result['accuracy']:.3f}%\")\n",
    "    print(f\"Saved as: {best_result['filename']}\")\n",
    "\n",
    "print(f\"\\nTotal models tested: {len(results)}\")\n",
    "print(f\"All models saved in: {output_dir}\")\n",
    "print(\"Note: Improved regularization should reduce train/test accuracy gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59e44bc-dc57-4f40-b884-3bcc192bbfd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Mixed Precision: Enabled\n",
      "Ensemble models saved to: deer_age_ensemble_20250731_220115\n",
      "Loading images...\n",
      "Total images: 466\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Train: 372, Test: 94\n",
      "\n",
      "============================================================\n",
      "SMALL DATA STRATEGY: MIXUP + MULTI-SCALE + ENSEMBLE\n",
      "============================================================\n",
      "Approach: Conservative training + Mixup synthetic data\n",
      "\n",
      "========================================\n",
      "Training DenseNet169\n",
      "========================================\n",
      "Training DenseNet169 with Mixup + Multi-scale\n",
      "  Epoch   0: Train 29.8%, Test+TTA 37.2%\n",
      "  Epoch  20: Train 64.2%, Test+TTA 54.3%\n",
      "  Epoch  40: Train 80.1%, Test+TTA 56.4%\n",
      "  Epoch  60: Train 78.5%, Test+TTA 62.8%\n",
      "  Epoch  64: Train 81.5%, Test+TTA 57.4%\n",
      "  Early stopping at epoch 64\n",
      "DenseNet169: 64.9% - Saved\n",
      "\n",
      "========================================\n",
      "Training ResNeXt50\n",
      "========================================\n",
      "Training ResNeXt50 with Mixup + Multi-scale\n",
      "  Epoch   0: Train 23.1%, Test+TTA 24.5%\n",
      "  Epoch  20: Train 84.9%, Test+TTA 53.2%\n",
      "  Epoch  40: Train 84.7%, Test+TTA 52.1%\n",
      "  Epoch  58: Train 84.4%, Test+TTA 57.4%\n",
      "  Early stopping at epoch 58\n",
      "ResNeXt50: 57.4% - Saved\n",
      "\n",
      "========================================\n",
      "Training DenseNet201\n",
      "========================================\n",
      "Training DenseNet201 with Mixup + Multi-scale\n",
      "  Epoch   0: Train 28.2%, Test+TTA 36.2%\n",
      "  Epoch  20: Train 81.2%, Test+TTA 52.1%\n",
      "  Epoch  40: Train 82.8%, Test+TTA 54.3%\n",
      "  Epoch  56: Train 82.5%, Test+TTA 56.4%\n",
      "  Early stopping at epoch 56\n",
      "DenseNet201: 60.6% - Saved\n",
      "\n",
      "========================================\n",
      "ENSEMBLE EVALUATION\n",
      "========================================\n",
      "INDIVIDUAL MODEL RESULTS:\n",
      "  DenseNet169: 64.9%\n",
      "  ResNeXt50: 57.4%\n",
      "  DenseNet201: 60.6%\n",
      "\n",
      "ENSEMBLE RESULT: 57.4%\n",
      "Gap to 75%: 17.6%\n",
      "\n",
      "All models saved in: deer_age_ensemble_20250731_220115\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Second attempt at model families \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "else:\n",
    "    use_amp = False\n",
    "\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    \"\"\"Mixup augmentation to create synthetic training examples\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Mixup loss function\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "def conservative_augment(image):\n",
    "    \"\"\"Very light augmentation to preserve deer features\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        angle = random.uniform(-8, 8)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        alpha = random.uniform(0.9, 1.1)\n",
    "        beta = random.randint(-10, 10)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    return image\n",
    "\n",
    "class MultiScaleDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False, scale_size=224):\n",
    "        self.X = X\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.augment = augment\n",
    "        self.scale_size = scale_size\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].copy()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Multi-scale training\n",
    "        if self.augment:\n",
    "            scale_factor = random.choice([0.8, 0.9, 1.0, 1.1, 1.2])\n",
    "            new_size = int(self.scale_size * scale_factor)\n",
    "            image = cv2.resize(image, (new_size, new_size))\n",
    "            image = cv2.resize(image, (self.scale_size, self.scale_size))\n",
    "            \n",
    "            image = conservative_augment(image)\n",
    "        \n",
    "        image = torch.FloatTensor(image)\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_conservative_model(model_name, num_classes=5):\n",
    "    \"\"\"Back to simpler model creation that worked\"\"\"\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=0.4)\n",
    "    \n",
    "    # Conservative freezing (like the 63.8% model)\n",
    "    if 'densenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('denseblock4' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'resnext' in model_name or 'resnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('layer4' in name or 'fc' in name):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_with_mixup_and_multiscale(model, train_loader, test_loader, model_name, epochs=120):\n",
    "    \"\"\"Training with mixup + multi-scale + very conservative approach\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    # Conservative optimizer (back to what worked)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 30\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} with Mixup + Multi-scale\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training with mixup\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Apply mixup\n",
    "            if random.random() < 0.5:  # 50% chance of mixup\n",
    "                mixed_images, y_a, y_b, lam = mixup_data(images, labels, alpha=0.4)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(mixed_images)\n",
    "                        loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(mixed_images)\n",
    "                    loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # For accuracy calculation, use original labels\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == y_a).sum().item()\n",
    "            else:\n",
    "                # Normal training\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Simple TTA evaluation (not too heavy)\n",
    "        test_acc = evaluate_with_simple_tta(model, test_loader)\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 20 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:3d}: Train {train_acc:.1f}%, Test+TTA {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "def evaluate_with_simple_tta(model, test_loader):\n",
    "    \"\"\"Simple TTA - just 3 versions\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Original prediction\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs1 = model(images)\n",
    "            else:\n",
    "                outputs1 = model(images)\n",
    "            \n",
    "            # Horizontal flip\n",
    "            flipped = torch.flip(images, [3])\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs2 = model(flipped)\n",
    "            else:\n",
    "                outputs2 = model(flipped)\n",
    "            \n",
    "            # Slight zoom\n",
    "            zoomed = F.interpolate(images, scale_factor=0.95, mode='bilinear', align_corners=False)\n",
    "            zoomed = F.interpolate(zoomed, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs3 = model(zoomed)\n",
    "            else:\n",
    "                outputs3 = model(zoomed)\n",
    "            \n",
    "            # Average predictions\n",
    "            avg_outputs = (F.softmax(outputs1, dim=1) + F.softmax(outputs2, dim=1) + F.softmax(outputs3, dim=1)) / 3\n",
    "            _, predicted = torch.max(avg_outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "def ensemble_predict(models, test_loader):\n",
    "    \"\"\"Simple ensemble of multiple models\"\"\"\n",
    "    all_models_eval = [model.eval() for model in models]\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            ensemble_output = torch.zeros(images.size(0), 5).to(device)\n",
    "            \n",
    "            for model in models:\n",
    "                # Simple TTA for each model\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs1 = model(images)\n",
    "                        outputs2 = model(torch.flip(images, [3]))\n",
    "                else:\n",
    "                    outputs1 = model(images)\n",
    "                    outputs2 = model(torch.flip(images, [3]))\n",
    "                \n",
    "                avg_model_output = (F.softmax(outputs1, dim=1) + F.softmax(outputs2, dim=1)) / 2\n",
    "                ensemble_output += avg_model_output\n",
    "            \n",
    "            # Final ensemble prediction\n",
    "            _, predicted = torch.max(ensemble_output, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "# Main execution\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_ensemble_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Ensemble models saved to: {output_dir}\")\n",
    "\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultiScaleDataset(X_train, y_train, augment=True)\n",
    "test_dataset = MultiScaleDataset(X_test, y_test, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SMALL DATA STRATEGY: MIXUP + MULTI-SCALE + ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Approach: Conservative training + Mixup synthetic data\")\n",
    "\n",
    "# Train multiple models for ensemble\n",
    "model_configs = [\n",
    "    ('densenet169', 'DenseNet169'),\n",
    "    ('resnext50_32x4d', 'ResNeXt50'),\n",
    "    ('densenet201', 'DenseNet201'),\n",
    "]\n",
    "\n",
    "trained_models = []\n",
    "individual_scores = []\n",
    "\n",
    "for model_timm_name, display_name in model_configs:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Training {display_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    try:\n",
    "        model = create_conservative_model(model_timm_name)\n",
    "        trained_model, accuracy = train_with_mixup_and_multiscale(\n",
    "            model, train_loader, test_loader, display_name\n",
    "        )\n",
    "        \n",
    "        # Save individual model\n",
    "        acc_str = f\"{accuracy:.1f}\".replace('.', 'p')\n",
    "        model_filename = f\"{display_name}_{acc_str}pct.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': display_name,\n",
    "            'timm_name': model_timm_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        trained_models.append(trained_model)\n",
    "        individual_scores.append(accuracy)\n",
    "        \n",
    "        print(f\"{display_name}: {accuracy:.1f}% - Saved\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {display_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Ensemble evaluation\n",
    "if len(trained_models) > 1:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"ENSEMBLE EVALUATION\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    ensemble_accuracy = ensemble_predict(trained_models, test_loader)\n",
    "    \n",
    "    print(\"INDIVIDUAL MODEL RESULTS:\")\n",
    "    for i, (score, config) in enumerate(zip(individual_scores, model_configs)):\n",
    "        print(f\"  {config[1]}: {score:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nENSEMBLE RESULT: {ensemble_accuracy:.1f}%\")\n",
    "    \n",
    "    if ensemble_accuracy >= 75.0:\n",
    "        print(\"SUCCESS: 75% target achieved!\")\n",
    "    else:\n",
    "        gap = 75.0 - ensemble_accuracy\n",
    "        print(f\"Gap to 75%: {gap:.1f}%\")\n",
    "        \n",
    "        if ensemble_accuracy > max(individual_scores):\n",
    "            improvement = ensemble_accuracy - max(individual_scores)\n",
    "            print(f\"Ensemble improvement: +{improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nAll models saved in: {output_dir}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d49ddb-fc22-461c-87fc-db647028a0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Mixed Precision: Enabled\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 287\n",
      "Comprehensive results saved to: deer_age_comprehensive_20250801_075228\n",
      "Loading images...\n",
      "Total images: 466\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Train: 372, Test: 94\n",
      "\n",
      "================================================================================\n",
      "PHASE 1: ADVANCED ARCHITECTURE SURVEY\n",
      "================================================================================\n",
      "Added Vision Transformer\n",
      "Added ConvNeXt\n",
      "Added EfficientNetV2\n",
      "\n",
      "--- Testing vit_base ---\n",
      "Self-supervised pretraining...\n",
      "  Pretraining epoch 0: 23.3%\n",
      "  Pretraining epoch 10: 23.1%\n",
      "  Pretraining epoch 20: 24.1%\n",
      "Pretraining complete\n",
      "Training vit_base with ALL techniques\n",
      "  Epoch   0: Train 23.7%, Test+TTA 19.1%\n",
      "  Epoch  25: Train 25.0%, Test+TTA 27.7%\n",
      "  Epoch  50: Train 23.7%, Test+TTA 25.5%\n",
      "  Epoch  61: Train 24.7%, Test+TTA 24.5%\n",
      "  Early stopping at epoch 61\n",
      "vit_base with pretraining: 27.7%\n",
      "\n",
      "--- Testing convnext_tiny ---\n",
      "Self-supervised pretraining...\n",
      "  Pretraining epoch 0: 25.6%\n",
      "  Pretraining epoch 10: 23.2%\n",
      "  Pretraining epoch 20: 24.0%\n",
      "Pretraining complete\n",
      "Training convnext_tiny with ALL techniques\n",
      "  Epoch   0: Train 19.9%, Test+TTA 18.1%\n",
      "  Epoch  25: Train 25.3%, Test+TTA 25.5%\n",
      "  Epoch  42: Train 25.5%, Test+TTA 23.4%\n",
      "  Early stopping at epoch 42\n",
      "convnext_tiny with pretraining: 25.5%\n",
      "\n",
      "--- Testing efficientnet_v2_s ---\n",
      "Self-supervised pretraining...\n",
      "  Pretraining epoch 0: 70.1%\n",
      "  Pretraining epoch 10: 76.6%\n",
      "  Pretraining epoch 20: 76.9%\n",
      "Pretraining complete\n",
      "Training efficientnet_v2_s with ALL techniques\n",
      "  Epoch   0: Train 29.3%, Test+TTA 28.7%\n",
      "  Epoch  25: Train 89.2%, Test+TTA 53.2%\n",
      "  Epoch  50: Train 88.7%, Test+TTA 56.4%\n",
      "  Epoch  58: Train 88.7%, Test+TTA 58.5%\n",
      "  Early stopping at epoch 58\n",
      "efficientnet_v2_s with pretraining: 60.6%\n",
      "\n",
      "--- Testing densenet169 ---\n",
      "Self-supervised pretraining...\n",
      "  Pretraining epoch 0: 67.2%\n",
      "  Pretraining epoch 10: 73.7%\n",
      "  Pretraining epoch 20: 78.0%\n",
      "Pretraining complete\n",
      "Training densenet169 with ALL techniques\n",
      "  Epoch   0: Train 23.9%, Test+TTA 33.0%\n",
      "  Epoch  25: Train 79.6%, Test+TTA 54.3%\n",
      "  Epoch  50: Train 92.5%, Test+TTA 56.4%\n",
      "  Epoch  75: Train 97.3%, Test+TTA 56.4%\n",
      "  Epoch  77: Train 90.3%, Test+TTA 56.4%\n",
      "  Early stopping at epoch 77\n",
      "densenet169 with pretraining: 59.6%\n",
      "\n",
      "--- Testing resnext50 ---\n",
      "Self-supervised pretraining...\n",
      "  Pretraining epoch 0: 67.1%\n",
      "  Pretraining epoch 10: 78.0%\n",
      "  Pretraining epoch 20: 81.2%\n",
      "Pretraining complete\n",
      "Training resnext50 with ALL techniques\n",
      "  Epoch   0: Train 26.1%, Test+TTA 28.7%\n",
      "  Epoch  25: Train 87.4%, Test+TTA 61.7%\n",
      "  Epoch  50: Train 84.7%, Test+TTA 57.4%\n",
      "  Epoch  62: Train 99.7%, Test+TTA 61.7%\n",
      "  Early stopping at epoch 62\n",
      "resnext50 with pretraining: 62.8%\n",
      "\n",
      "--- Testing densenet201 ---\n",
      "Self-supervised pretraining...\n",
      "  Pretraining epoch 0: 65.5%\n",
      "  Pretraining epoch 10: 78.4%\n",
      "  Pretraining epoch 20: 78.2%\n",
      "Pretraining complete\n",
      "Training densenet201 with ALL techniques\n",
      "  Epoch   0: Train 21.2%, Test+TTA 28.7%\n",
      "  Epoch  25: Train 85.2%, Test+TTA 52.1%\n",
      "  Epoch  50: Train 91.4%, Test+TTA 48.9%\n",
      "  Epoch  75: Train 97.0%, Test+TTA 52.1%\n",
      "  Epoch 100: Train 80.9%, Test+TTA 56.4%\n",
      "  Epoch 116: Train 89.5%, Test+TTA 58.5%\n",
      "  Early stopping at epoch 116\n",
      "densenet201 with pretraining: 59.6%\n",
      "\n",
      "================================================================================\n",
      "PHASE 2: PROGRESSIVE TRAINING\n",
      "================================================================================\n",
      "\n",
      "--- Progressive training densenet169 ---\n",
      "Progressive training for densenet169\n",
      "  Progressive epoch 0: 24.5%\n",
      "  Progressive epoch 10: 30.9%\n",
      "  Progressive epoch 20: 33.0%\n",
      "  Progressive epoch 30: 33.0%\n",
      "  Progressive epoch 40: 38.3%\n",
      "densenet169 progressive: 40.4%\n",
      "\n",
      "--- Progressive training resnext50_32x4d ---\n",
      "Progressive training for resnext50_32x4d\n",
      "  Progressive epoch 0: 40.4%\n",
      "  Progressive epoch 10: 58.5%\n",
      "  Progressive epoch 20: 60.6%\n",
      "  Progressive epoch 30: 57.4%\n",
      "  Progressive epoch 40: 59.6%\n",
      "resnext50_32x4d progressive: 66.0%\n",
      "\n",
      "================================================================================\n",
      "PHASE 3: HYBRID CNN + TRADITIONAL ML\n",
      "================================================================================\n",
      "Using resnext50 for feature extraction...\n",
      "Training RandomForest on CNN features...\n",
      "CNN + RandomForest: 23.4%\n",
      "Training XGBoost on CNN features...\n",
      "CNN + XGBoost: 21.3%\n",
      "Training SVM on CNN features...\n",
      "CNN + SVM: 25.5%\n",
      "\n",
      "================================================================================\n",
      "PHASE 4: ORDINAL REGRESSION\n",
      "================================================================================\n",
      "Training ordinal regression model...\n",
      "Error with ordinal regression: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (372,) + inhomogeneous part.\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE RESULTS SUMMARY\n",
      "================================================================================\n",
      "PHASE 1 - ADVANCED ARCHITECTURES + PRETRAINING:\n",
      "  vit_base                  - 27.7%\n",
      "  convnext_tiny             - 25.5%\n",
      "  efficientnet_v2_s         - 60.6%\n",
      "  densenet169               - 59.6%\n",
      "  resnext50                 - 62.8%\n",
      "  densenet201               - 59.6%\n",
      "\n",
      "PHASE 2 - PROGRESSIVE TRAINING:\n",
      "  densenet169_progressive   - 40.4%\n",
      "  resnext50_32x4d_progressive - 66.0%\n",
      "\n",
      "PHASE 3 - HYBRID CNN + TRADITIONAL ML:\n",
      "  CNN+RandomForest          - 23.4%\n",
      "  CNN+XGBoost               - 21.3%\n",
      "  CNN+SVM                   - 25.5%\n",
      "\n",
      "PHASE 4 - ORDINAL REGRESSION:\n",
      "\n",
      "================================================================================\n",
      "OVERALL BEST RESULTS:\n",
      " 1. resnext50_32x4d_progressive - 66.0% - 9.0% to go\n",
      " 2. resnext50                 - 62.8% - 12.2% to go\n",
      " 3. efficientnet_v2_s         - 60.6% - 14.4% to go\n",
      " 4. densenet169               - 59.6% - 15.4% to go\n",
      " 5. densenet201               - 59.6% - 15.4% to go\n",
      " 6. densenet169_progressive   - 40.4% - 34.6% to go\n",
      " 7. vit_base                  - 27.7% - 47.3% to go\n",
      " 8. convnext_tiny             - 25.5% - 49.5% to go\n",
      " 9. CNN+SVM                   - 25.5% - 49.5% to go\n",
      "10. CNN+RandomForest          - 23.4% - 51.6% to go\n",
      "\n",
      "BEST OVERALL: resnext50_32x4d_progressive - 66.0%\n",
      "Best effort with 466 images: 9.0% short of 75% target\n",
      "Consider multi-fold ensemble if this is insufficient\n",
      "\n",
      "All models and results saved in: deer_age_comprehensive_20250801_075228\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Third attempt at model families\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "else:\n",
    "    use_amp = False\n",
    "\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def age_to_ordinal(age):\n",
    "    \"\"\"Convert age to ordinal targets for ordinal regression\"\"\"\n",
    "    class_idx = age_to_class(age)\n",
    "    if class_idx is None:\n",
    "        return None\n",
    "    # Create ordinal targets: [1,1,1,0,0] for class 2, [1,1,1,1,0] for class 3, etc.\n",
    "    ordinal = [1 if i <= class_idx else 0 for i in range(5)]\n",
    "    return ordinal\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    \"\"\"CutMix augmentation\"\"\"\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    \n",
    "    W, H = x.size(2), x.size(3)\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    \n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    \n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    \n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "    \n",
    "    return x, y, y[index], lam\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "def advanced_augment(image):\n",
    "    \"\"\"Comprehensive augmentation suite\"\"\"\n",
    "    # Random horizontal flip\n",
    "    if random.random() < 0.6:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Random rotation with scaling\n",
    "    if random.random() < 0.8:\n",
    "        angle = random.uniform(-20, 20)\n",
    "        scale = random.uniform(0.9, 1.1)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, scale)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Color jittering\n",
    "    if random.random() < 0.9:\n",
    "        alpha = random.uniform(0.8, 1.2)\n",
    "        beta = random.randint(-20, 20)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gaussian noise\n",
    "    if random.random() < 0.4:\n",
    "        noise = np.random.normal(0, random.uniform(3, 8), image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    # Random erasing\n",
    "    if random.random() < 0.3:\n",
    "        h, w, c = image.shape\n",
    "        area = h * w\n",
    "        target_area = random.uniform(0.02, 0.1) * area\n",
    "        aspect_ratio = random.uniform(0.3, 3.3)\n",
    "        \n",
    "        h_erase = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        w_erase = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "        \n",
    "        if h_erase < h and w_erase < w:\n",
    "            x1 = random.randint(0, h - h_erase)\n",
    "            y1 = random.randint(0, w - w_erase)\n",
    "            image[x1:x1+h_erase, y1:y1+w_erase, :] = random.randint(0, 255)\n",
    "    \n",
    "    return image\n",
    "\n",
    "class AdvancedDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False, progressive_size=None, ordinal=False):\n",
    "        self.X = X\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.augment = augment\n",
    "        self.progressive_size = progressive_size or 224\n",
    "        self.ordinal = ordinal\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].copy()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Progressive resizing\n",
    "        if self.progressive_size != 224:\n",
    "            image = cv2.resize(image, (self.progressive_size, self.progressive_size))\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        if self.augment:\n",
    "            image = advanced_augment(image)\n",
    "        \n",
    "        image = torch.FloatTensor(image)\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        if self.ordinal:\n",
    "            # Convert to ordinal targets\n",
    "            ordinal_targets = torch.FloatTensor([1 if i <= label.item() else 0 for i in range(4)])\n",
    "            return image, ordinal_targets\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "class OrdinalLoss(nn.Module):\n",
    "    \"\"\"Ordinal regression loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super(OrdinalLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        return F.binary_cross_entropy_with_logits(predictions, targets)\n",
    "\n",
    "class SelfSupervisedPretrainer:\n",
    "    \"\"\"Self-supervised pretraining on the deer images\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        # Replace final layer for rotation prediction (4 classes: 0, 90, 180, 270)\n",
    "        if hasattr(model, 'classifier'):\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, 4)\n",
    "        elif hasattr(model, 'fc'):\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "    \n",
    "    def create_rotation_dataset(self, images):\n",
    "        \"\"\"Create rotation prediction dataset\"\"\"\n",
    "        rotation_images = []\n",
    "        rotation_labels = []\n",
    "        \n",
    "        for img in images:\n",
    "            for rotation in range(4):\n",
    "                rotated = np.rot90(img, k=rotation, axes=(0, 1))\n",
    "                rotation_images.append(rotated)\n",
    "                rotation_labels.append(rotation)\n",
    "        \n",
    "        return np.array(rotation_images), np.array(rotation_labels)\n",
    "    \n",
    "    def pretrain(self, images, epochs=50):\n",
    "        \"\"\"Self-supervised pretraining\"\"\"\n",
    "        print(\"Self-supervised pretraining...\")\n",
    "        \n",
    "        rot_images, rot_labels = self.create_rotation_dataset(images)\n",
    "        dataset = AdvancedDataset(rot_images, rot_labels, augment=True)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        \n",
    "        # Ensure model is on correct device\n",
    "        self.model = self.model.to(device)\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images_batch, labels_batch in loader:\n",
    "                # Ensure tensors are on correct device\n",
    "                images_batch = images_batch.to(device)\n",
    "                labels_batch = labels_batch.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = self.model(images_batch)\n",
    "                        loss = criterion(outputs, labels_batch)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = self.model(images_batch)\n",
    "                    loss = criterion(outputs, labels_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels_batch.size(0)\n",
    "                correct += (predicted == labels_batch).sum().item()\n",
    "                \n",
    "                # Memory cleanup\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                acc = 100 * correct / total\n",
    "                print(f\"  Pretraining epoch {epoch}: {acc:.1f}%\")\n",
    "        \n",
    "        print(\"Pretraining complete\")\n",
    "        return self.model\n",
    "\n",
    "def create_diverse_models():\n",
    "    \"\"\"Create diverse model architectures\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    # Vision Transformers\n",
    "    try:\n",
    "        models['vit_base'] = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=5)\n",
    "        print(\"Added Vision Transformer\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ConvNeXt\n",
    "    try:\n",
    "        models['convnext_tiny'] = timm.create_model('convnext_tiny', pretrained=True, num_classes=5)\n",
    "        print(\"Added ConvNeXt\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # EfficientNet variants\n",
    "    try:\n",
    "        models['efficientnet_v2_s'] = timm.create_model('tf_efficientnetv2_s', pretrained=True, num_classes=5)\n",
    "        print(\"Added EfficientNetV2\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # RegNet\n",
    "    try:\n",
    "        models['regnet_y_800mf'] = timm.create_model('regnetx_800mf', pretrained=True, num_classes=5)\n",
    "        print(\"Added RegNet\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to proven architectures\n",
    "    models['densenet169'] = timm.create_model('densenet169', pretrained=True, num_classes=5)\n",
    "    models['resnext50'] = timm.create_model('resnext50_32x4d', pretrained=True, num_classes=5)\n",
    "    models['densenet201'] = timm.create_model('densenet201', pretrained=True, num_classes=5)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def train_with_all_techniques(model, train_loader, test_loader, model_name, epochs=150):\n",
    "    \"\"\"Training with every technique combined\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    \n",
    "    # Different optimizers for different models\n",
    "    if 'vit' in model_name.lower():\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=0.3)\n",
    "    elif 'convnext' in model_name.lower():\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.05)\n",
    "    else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "    \n",
    "    # Advanced scheduler with warm restarts\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=30, T_mult=2, eta_min=1e-7\n",
    "    )\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 40\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"Training {model_name} with ALL techniques\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Random choice of augmentation technique\n",
    "            aug_choice = random.choice(['mixup', 'cutmix', 'normal'])\n",
    "            \n",
    "            if aug_choice == 'mixup' and random.random() < 0.4:\n",
    "                # Mixup\n",
    "                lam = np.random.beta(0.4, 0.4)\n",
    "                batch_size = images.size(0)\n",
    "                index = torch.randperm(batch_size).to(device)\n",
    "                mixed_images = lam * images + (1 - lam) * images[index, :]\n",
    "                y_a, y_b = labels, labels[index]\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(mixed_images)\n",
    "                        loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(mixed_images)\n",
    "                    loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == y_a).sum().item()\n",
    "                \n",
    "            elif aug_choice == 'cutmix' and random.random() < 0.4:\n",
    "                # CutMix\n",
    "                mixed_images, y_a, y_b, lam = cutmix_data(images, labels, alpha=1.0)\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(mixed_images)\n",
    "                        loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(mixed_images)\n",
    "                    loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == y_a).sum().item()\n",
    "                \n",
    "            else:\n",
    "                # Normal training\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Advanced TTA evaluation\n",
    "        test_acc = evaluate_with_advanced_tta(model, test_loader)\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 25 == 0 or patience_counter >= patience:\n",
    "            print(f\"  Epoch {epoch:3d}: Train {train_acc:.1f}%, Test+TTA {test_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "def evaluate_with_advanced_tta(model, test_loader, num_tta=6):\n",
    "    \"\"\"Advanced TTA with multiple techniques\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            tta_outputs = []\n",
    "            \n",
    "            # Original\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            tta_outputs.append(F.softmax(outputs, dim=1))\n",
    "            \n",
    "            # Horizontal flip\n",
    "            flipped = torch.flip(images, [3])\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(flipped)\n",
    "            else:\n",
    "                outputs = model(flipped)\n",
    "            tta_outputs.append(F.softmax(outputs, dim=1))\n",
    "            \n",
    "            # Multiple scales\n",
    "            for scale in [0.9, 1.1]:\n",
    "                scaled = F.interpolate(images, scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "                scaled = F.interpolate(scaled, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(scaled)\n",
    "                else:\n",
    "                    outputs = model(scaled)\n",
    "                tta_outputs.append(F.softmax(outputs, dim=1))\n",
    "            \n",
    "            # Crop variants\n",
    "            for crop_factor in [0.85, 0.95]:\n",
    "                size = int(224 * crop_factor)\n",
    "                start = (224 - size) // 2\n",
    "                cropped = images[:, :, start:start+size, start:start+size]\n",
    "                cropped = F.interpolate(cropped, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(cropped)\n",
    "                else:\n",
    "                    outputs = model(cropped)\n",
    "                tta_outputs.append(F.softmax(outputs, dim=1))\n",
    "            \n",
    "            # Average all predictions\n",
    "            avg_output = torch.stack(tta_outputs).mean(0)\n",
    "            _, predicted = torch.max(avg_output, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "def extract_features_for_ml(model, images):\n",
    "    \"\"\"Extract CNN features for traditional ML\"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    \n",
    "    dataset = AdvancedDataset(images, np.zeros(len(images)), augment=False)\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, _ in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            # Remove final classification layer\n",
    "            if hasattr(model, 'classifier'):\n",
    "                feat = model.features(imgs)\n",
    "                feat = F.adaptive_avg_pool2d(feat, (1, 1))\n",
    "                feat = feat.view(feat.size(0), -1)\n",
    "            elif hasattr(model, 'fc'):\n",
    "                feat = model.forward_head(imgs, pre_logits=True)\n",
    "            else:\n",
    "                # For ViT and other models\n",
    "                feat = model.forward_features(imgs)\n",
    "                if len(feat.shape) > 2:\n",
    "                    feat = feat.mean(dim=1)\n",
    "            \n",
    "            features.append(feat.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(features)\n",
    "\n",
    "def progressive_training(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"Progressive training: easy distinctions first\"\"\"\n",
    "    print(f\"Progressive training for {model_name}\")\n",
    "    \n",
    "    # Phase 1: Binary young vs old (classes 0,1,2 vs 3,4)\n",
    "    y_binary_train = np.array([0 if y <= 2 else 1 for y in y_train])\n",
    "    y_binary_test = np.array([0 if y <= 2 else 1 for y in y_test])\n",
    "    \n",
    "    # Modify model for binary classification\n",
    "    if hasattr(model, 'classifier'):\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
    "    elif hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Train binary classifier\n",
    "    binary_dataset_train = AdvancedDataset(X_train, y_binary_train, augment=True)\n",
    "    binary_dataset_test = AdvancedDataset(X_test, y_binary_test, augment=False)\n",
    "    binary_loader_train = DataLoader(binary_dataset_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "    binary_loader_test = DataLoader(binary_dataset_test, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(30):\n",
    "        for images, labels in binary_loader_train:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    # Phase 2: Modify for 5-class and fine-tune\n",
    "    if hasattr(model, 'classifier'):\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 5)\n",
    "    elif hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, 5)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Fine-tune on all classes\n",
    "    full_dataset_train = AdvancedDataset(X_train, y_train, augment=True)\n",
    "    full_dataset_test = AdvancedDataset(X_test, y_test, augment=False)\n",
    "    full_loader_train = DataLoader(full_dataset_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "    full_loader_test = DataLoader(full_dataset_test, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Lower learning rate for fine-tuning\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0002, weight_decay=0.01)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for images, labels in full_loader_train:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        test_acc = evaluate_with_advanced_tta(model, full_loader_test)\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"  Progressive epoch {epoch}: {test_acc:.1f}%\")\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "# Main comprehensive pipeline\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_comprehensive_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Comprehensive results saved to: {output_dir}\")\n",
    "\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# PHASE 1: Advanced Architecture Survey\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1: ADVANCED ARCHITECTURE SURVEY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "diverse_models = create_diverse_models()\n",
    "phase1_results = []\n",
    "\n",
    "for model_name, model_template in diverse_models.items():\n",
    "    print(f\"\\n--- Testing {model_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Self-supervised pretraining\n",
    "        pretrainer = SelfSupervisedPretrainer(model_template.to(device))\n",
    "        pretrained_model = pretrainer.pretrain(X_train, epochs=30)\n",
    "        \n",
    "        # Reset for main task\n",
    "        if hasattr(pretrained_model, 'classifier'):\n",
    "            pretrained_model.classifier = nn.Linear(pretrained_model.classifier.in_features, 5)\n",
    "        elif hasattr(pretrained_model, 'fc'):\n",
    "            pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, 5)\n",
    "        \n",
    "        pretrained_model = pretrained_model.to(device)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = AdvancedDataset(X_train, y_train, augment=True)\n",
    "        test_dataset = AdvancedDataset(X_test, y_test, augment=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Train with all techniques\n",
    "        trained_model, accuracy = train_with_all_techniques(\n",
    "            pretrained_model, train_loader, test_loader, model_name, epochs=120\n",
    "        )\n",
    "        \n",
    "        # Save model\n",
    "        acc_str = f\"{accuracy:.1f}\".replace('.', 'p')\n",
    "        model_filename = f\"{model_name}_pretrained_{acc_str}pct.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5,\n",
    "            'pretrained': True\n",
    "        }, model_path)\n",
    "        \n",
    "        phase1_results.append({\n",
    "            'model': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'filename': model_filename,\n",
    "            'trained_model': trained_model\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name} with pretraining: {accuracy:.1f}%\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# PHASE 2: Progressive Training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2: PROGRESSIVE TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "phase2_results = []\n",
    "for model_name in ['densenet169', 'resnext50_32x4d']:\n",
    "    print(f\"\\n--- Progressive training {model_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=5)\n",
    "        trained_model, accuracy = progressive_training(\n",
    "            model, X_train, y_train, X_test, y_test, model_name\n",
    "        )\n",
    "        \n",
    "        acc_str = f\"{accuracy:.1f}\".replace('.', 'p')\n",
    "        model_filename = f\"{model_name}_progressive_{acc_str}pct.pth\"\n",
    "        model_path = os.path.join(output_dir, model_filename)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': trained_model.state_dict(),\n",
    "            'model_name': f\"{model_name}_progressive\",\n",
    "            'accuracy': accuracy,\n",
    "            'num_classes': 5\n",
    "        }, model_path)\n",
    "        \n",
    "        phase2_results.append({\n",
    "            'model': f\"{model_name}_progressive\",\n",
    "            'accuracy': accuracy,\n",
    "            'filename': model_filename,\n",
    "            'trained_model': trained_model\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name} progressive: {accuracy:.1f}%\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with progressive {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# PHASE 3: CNN Feature Extraction + Traditional ML\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 3: HYBRID CNN + TRADITIONAL ML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "phase3_results = []\n",
    "if phase1_results:\n",
    "    # Use best CNN model for feature extraction\n",
    "    best_cnn = max(phase1_results, key=lambda x: x['accuracy'])\n",
    "    print(f\"Using {best_cnn['model']} for feature extraction...\")\n",
    "    \n",
    "    # Extract features\n",
    "    train_features = extract_features_for_ml(best_cnn['trained_model'], X_train)\n",
    "    test_features = extract_features_for_ml(best_cnn['trained_model'], X_test)\n",
    "    \n",
    "    # Traditional ML models\n",
    "    ml_models = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "        'XGBoost': XGBClassifier(n_estimators=200, max_depth=6, random_state=42),\n",
    "        'SVM': SVC(kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "    }\n",
    "    \n",
    "    for ml_name, ml_model in ml_models.items():\n",
    "        try:\n",
    "            print(f\"Training {ml_name} on CNN features...\")\n",
    "            ml_model.fit(train_features, y_train)\n",
    "            ml_predictions = ml_model.predict(test_features)\n",
    "            ml_accuracy = accuracy_score(y_test, ml_predictions) * 100\n",
    "            \n",
    "            phase3_results.append({\n",
    "                'model': f\"CNN+{ml_name}\",\n",
    "                'accuracy': ml_accuracy,\n",
    "                'type': 'hybrid'\n",
    "            })\n",
    "            \n",
    "            print(f\"CNN + {ml_name}: {ml_accuracy:.1f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {ml_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "# PHASE 4: Ordinal Regression\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 4: ORDINAL REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "phase4_results = []\n",
    "try:\n",
    "    print(\"Training ordinal regression model...\")\n",
    "    \n",
    "    # Create ordinal targets\n",
    "    y_train_ordinal = np.array([age_to_ordinal(y_train[i]*0.5 + 1.5) for i in range(len(y_train))])\n",
    "    y_test_ordinal = np.array([age_to_ordinal(y_test[i]*0.5 + 1.5) for i in range(len(y_test))])\n",
    "    \n",
    "    # Remove None values\n",
    "    valid_train = [i for i, val in enumerate(y_train_ordinal) if val is not None]\n",
    "    valid_test = [i for i, val in enumerate(y_test_ordinal) if val is not None]\n",
    "    \n",
    "    if valid_train and valid_test:\n",
    "        X_train_ord = X_train[valid_train]\n",
    "        y_train_ord = np.array([y_train_ordinal[i] for i in valid_train])\n",
    "        X_test_ord = X_test[valid_test]\n",
    "        y_test_ord = np.array([y_test_ordinal[i] for i in valid_test])\n",
    "        \n",
    "        # Create ordinal model\n",
    "        ordinal_model = timm.create_model('densenet169', pretrained=True, num_classes=4)\n",
    "        ordinal_model = ordinal_model.to(device)\n",
    "        \n",
    "        # Replace classifier for ordinal regression\n",
    "        if hasattr(ordinal_model, 'classifier'):\n",
    "            ordinal_model.classifier = nn.Linear(ordinal_model.classifier.in_features, 4)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_ord_dataset = AdvancedDataset(X_train_ord, np.zeros(len(X_train_ord)), augment=True, ordinal=True)\n",
    "        test_ord_dataset = AdvancedDataset(X_test_ord, np.zeros(len(X_test_ord)), augment=False, ordinal=True)\n",
    "        train_ord_loader = DataLoader(train_ord_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "        test_ord_loader = DataLoader(test_ord_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Train ordinal model\n",
    "        ordinal_criterion = OrdinalLoss()\n",
    "        ordinal_optimizer = optim.AdamW(ordinal_model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        \n",
    "        best_ordinal_acc = 0.0\n",
    "        for epoch in range(50):\n",
    "            ordinal_model.train()\n",
    "            for images, targets in train_ord_loader:\n",
    "                images = images.to(device)\n",
    "                # Reconstruct ordinal targets from y_train_ord\n",
    "                batch_targets = torch.FloatTensor([y_train_ord[i % len(y_train_ord)] for i in range(len(images))]).to(device)\n",
    "                \n",
    "                ordinal_optimizer.zero_grad()\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = ordinal_model(images)\n",
    "                        loss = ordinal_criterion(outputs, batch_targets)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(ordinal_optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = ordinal_model(images)\n",
    "                    loss = ordinal_criterion(outputs, batch_targets)\n",
    "                    loss.backward()\n",
    "                    ordinal_optimizer.step()\n",
    "            \n",
    "            # Evaluate ordinal model (convert back to class predictions)\n",
    "            ordinal_model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, _ in test_ord_loader:\n",
    "                    images = images.to(device)\n",
    "                    outputs = torch.sigmoid(ordinal_model(images))\n",
    "                    # Convert ordinal predictions back to classes\n",
    "                    predicted_classes = (outputs > 0.5).sum(dim=1)\n",
    "                    \n",
    "                    batch_true_classes = torch.LongTensor([y_test[valid_test[i % len(valid_test)]] for i in range(len(images))]).to(device)\n",
    "                    \n",
    "                    total += len(images)\n",
    "                    correct += (predicted_classes == batch_true_classes).sum().item()\n",
    "            \n",
    "            ordinal_acc = 100 * correct / total\n",
    "            if ordinal_acc > best_ordinal_acc:\n",
    "                best_ordinal_acc = ordinal_acc\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"  Ordinal epoch {epoch}: {ordinal_acc:.1f}%\")\n",
    "        \n",
    "        phase4_results.append({\n",
    "            'model': 'Ordinal_Regression',\n",
    "            'accuracy': best_ordinal_acc,\n",
    "            'type': 'ordinal'\n",
    "        })\n",
    "        \n",
    "        print(f\"Ordinal regression: {best_ordinal_acc:.1f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error with ordinal regression: {e}\")\n",
    "\n",
    "# FINAL RESULTS COMPILATION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = []\n",
    "all_results.extend(phase1_results)\n",
    "all_results.extend(phase2_results)\n",
    "all_results.extend(phase3_results)\n",
    "all_results.extend(phase4_results)\n",
    "\n",
    "all_results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "print(\"PHASE 1 - ADVANCED ARCHITECTURES + PRETRAINING:\")\n",
    "for result in phase1_results:\n",
    "    print(f\"  {result['model']:25s} - {result['accuracy']:.1f}%\")\n",
    "\n",
    "print(\"\\nPHASE 2 - PROGRESSIVE TRAINING:\")\n",
    "for result in phase2_results:\n",
    "    print(f\"  {result['model']:25s} - {result['accuracy']:.1f}%\")\n",
    "\n",
    "print(\"\\nPHASE 3 - HYBRID CNN + TRADITIONAL ML:\")\n",
    "for result in phase3_results:\n",
    "    print(f\"  {result['model']:25s} - {result['accuracy']:.1f}%\")\n",
    "\n",
    "print(\"\\nPHASE 4 - ORDINAL REGRESSION:\")\n",
    "for result in phase4_results:\n",
    "    print(f\"  {result['model']:25s} - {result['accuracy']:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"OVERALL BEST RESULTS:\")\n",
    "for i, result in enumerate(all_results[:10], 1):\n",
    "    status = \"TARGET ACHIEVED\" if result['accuracy'] >= 75.0 else f\"{75.0-result['accuracy']:.1f}% to go\"\n",
    "    print(f\"{i:2d}. {result['model']:25s} - {result['accuracy']:.1f}% - {status}\")\n",
    "\n",
    "if all_results:\n",
    "    best_overall = all_results[0]\n",
    "    print(f\"\\nBEST OVERALL: {best_overall['model']} - {best_overall['accuracy']:.1f}%\")\n",
    "    \n",
    "    if best_overall['accuracy'] >= 75.0:\n",
    "        print(\"SUCCESS: 75% TARGET ACHIEVED!\")\n",
    "    else:\n",
    "        gap = 75.0 - best_overall['accuracy']\n",
    "        print(f\"Best effort with 466 images: {gap:.1f}% short of 75% target\")\n",
    "        print(\"Consider multi-fold ensemble if this is insufficient\")\n",
    "\n",
    "print(f\"\\nAll models and results saved in: {output_dir}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d54b84-ad86-44ac-bbd2-5e459bb2897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Mixed Precision: Enabled\n",
      "Multi-fold ensemble results saved to: deer_age_multifold_20250801_223542\n",
      "Loading images...\n",
      "Total images: 466\n",
      "Class distribution: Counter({np.int64(4): 118, np.int64(2): 111, np.int64(3): 89, np.int64(1): 82, np.int64(0): 66})\n",
      "Training pool: 372, Final test: 94\n",
      "\n",
      "================================================================================\n",
      "MULTI-FOLD ENSEMBLE: 5 FOLDS x 3 MODELS\n",
      "================================================================================\n",
      "Training strategy: Conservative to minimize overfitting\n",
      "Total models to train: 30\n",
      "Estimated time: 4-6 hours\n",
      "\n",
      "============================================================\n",
      "FOLD 1/5\n",
      "============================================================\n",
      "Fold 1: Train 297, Val 75\n",
      "Train distribution: Counter({np.int64(4): 75, np.int64(2): 71, np.int64(3): 57, np.int64(1): 52, np.int64(0): 42})\n",
      "Val distribution: Counter({np.int64(4): 19, np.int64(2): 18, np.int64(3): 14, np.int64(1): 13, np.int64(0): 11})\n",
      "\n",
      "--- ResNeXt50 ---\n",
      "  Regular training...\n",
      "    Training ResNeXt50 - Fold 1\n",
      "      Epoch  0: Train 22.2%, Val 22.7%\n",
      "      Epoch 15: Train 85.2%, Val 53.3%\n",
      "      Epoch 30: Train 90.2%, Val 57.3%\n",
      "      Epoch 45: Train 91.9%, Val 54.7%\n",
      "      Epoch 46: Train 81.5%, Val 57.3%\n",
      "      Early stopping at epoch 46\n",
      "    ResNeXt50 regular: 62.7%\n",
      "  Progressive training...\n",
      "    Progressive training resnext50_32x4d - Fold 1\n",
      "    Training resnext50_32x4d - Fold 1\n",
      "      Epoch  0: Train 39.7%, Val 41.3%\n",
      "      Epoch 15: Train 90.2%, Val 53.3%\n",
      "      Epoch 24: Train 89.2%, Val 57.3%\n",
      "      Early stopping at epoch 24\n",
      "    ResNeXt50 progressive: 60.0%\n",
      "\n",
      "--- EfficientNetV2 ---\n",
      "  Regular training...\n",
      "    Training EfficientNetV2 - Fold 1\n",
      "      Epoch  0: Train 17.2%, Val 24.0%\n",
      "      Epoch 15: Train 23.2%, Val 24.0%\n",
      "      Epoch 27: Train 27.9%, Val 24.0%\n",
      "      Early stopping at epoch 27\n",
      "    EfficientNetV2 regular: 29.3%\n",
      "  Progressive training...\n",
      "    Progressive training tf_efficientnetv2_s - Fold 1\n",
      "    Training tf_efficientnetv2_s - Fold 1\n",
      "      Epoch  0: Train 40.1%, Val 37.3%\n",
      "      Epoch 15: Train 88.9%, Val 62.7%\n",
      "      Epoch 30: Train 99.3%, Val 69.3%\n",
      "      Epoch 45: Train 93.6%, Val 68.0%\n",
      "    EfficientNetV2 progressive: 73.3%\n",
      "\n",
      "--- DenseNet169 ---\n",
      "  Regular training...\n",
      "    Training DenseNet169 - Fold 1\n",
      "      Epoch  0: Train 26.3%, Val 42.7%\n",
      "      Epoch 15: Train 97.3%, Val 58.7%\n",
      "      Epoch 30: Train 88.6%, Val 58.7%\n",
      "      Early stopping at epoch 30\n",
      "    DenseNet169 regular: 66.7%\n",
      "  Progressive training...\n",
      "    Progressive training densenet169 - Fold 1\n",
      "    Training densenet169 - Fold 1\n",
      "      Epoch  0: Train 21.5%, Val 24.0%\n",
      "      Epoch 15: Train 27.3%, Val 22.7%\n",
      "      Epoch 30: Train 38.4%, Val 29.3%\n",
      "      Epoch 45: Train 54.2%, Val 46.7%\n",
      "    DenseNet169 progressive: 52.0%\n",
      "\n",
      "Fold 1 average: 57.3%\n",
      "\n",
      "============================================================\n",
      "FOLD 2/5\n",
      "============================================================\n",
      "Fold 2: Train 297, Val 75\n",
      "Train distribution: Counter({np.int64(4): 75, np.int64(2): 71, np.int64(3): 57, np.int64(1): 52, np.int64(0): 42})\n",
      "Val distribution: Counter({np.int64(4): 19, np.int64(2): 18, np.int64(3): 14, np.int64(1): 13, np.int64(0): 11})\n",
      "\n",
      "--- ResNeXt50 ---\n",
      "  Regular training...\n",
      "    Training ResNeXt50 - Fold 2\n",
      "      Epoch  0: Train 20.5%, Val 24.0%\n",
      "      Epoch 15: Train 78.8%, Val 52.0%\n",
      "      Epoch 30: Train 86.2%, Val 53.3%\n",
      "      Epoch 38: Train 90.2%, Val 54.7%\n",
      "      Early stopping at epoch 38\n",
      "    ResNeXt50 regular: 57.3%\n",
      "  Progressive training...\n",
      "    Progressive training resnext50_32x4d - Fold 2\n",
      "    Training resnext50_32x4d - Fold 2\n",
      "      Epoch  0: Train 37.0%, Val 40.0%\n",
      "      Epoch 15: Train 94.3%, Val 56.0%\n",
      "      Epoch 30: Train 99.7%, Val 57.3%\n",
      "      Epoch 45: Train 93.9%, Val 53.3%\n",
      "      Epoch 46: Train 94.3%, Val 54.7%\n",
      "      Early stopping at epoch 46\n",
      "    ResNeXt50 progressive: 60.0%\n",
      "\n",
      "--- EfficientNetV2 ---\n",
      "  Regular training...\n",
      "    Training EfficientNetV2 - Fold 2\n",
      "      Epoch  0: Train 22.9%, Val 16.0%\n",
      "      Epoch 15: Train 19.5%, Val 18.7%\n",
      "      Epoch 24: Train 22.9%, Val 21.3%\n",
      "      Early stopping at epoch 24\n",
      "    EfficientNetV2 regular: 21.3%\n",
      "  Progressive training...\n",
      "    Progressive training tf_efficientnetv2_s - Fold 2\n",
      "    Training tf_efficientnetv2_s - Fold 2\n",
      "      Epoch  0: Train 40.7%, Val 37.3%\n",
      "      Epoch 15: Train 98.0%, Val 61.3%\n",
      "      Epoch 30: Train 95.6%, Val 61.3%\n",
      "      Epoch 34: Train 95.3%, Val 57.3%\n",
      "      Early stopping at epoch 34\n",
      "    EfficientNetV2 progressive: 65.3%\n",
      "\n",
      "--- DenseNet169 ---\n",
      "  Regular training...\n",
      "    Training DenseNet169 - Fold 2\n",
      "      Epoch  0: Train 26.6%, Val 29.3%\n",
      "      Epoch 15: Train 94.3%, Val 52.0%\n",
      "      Epoch 30: Train 87.5%, Val 49.3%\n",
      "      Epoch 39: Train 77.8%, Val 50.7%\n",
      "      Early stopping at epoch 39\n",
      "    DenseNet169 regular: 54.7%\n",
      "  Progressive training...\n",
      "    Progressive training densenet169 - Fold 2\n",
      "    Training densenet169 - Fold 2\n",
      "      Epoch  0: Train 24.6%, Val 18.7%\n",
      "      Epoch 15: Train 36.4%, Val 28.0%\n",
      "      Epoch 30: Train 44.8%, Val 37.3%\n",
      "      Epoch 45: Train 70.7%, Val 50.7%\n",
      "    DenseNet169 progressive: 52.0%\n",
      "\n",
      "Fold 2 average: 51.8%\n",
      "\n",
      "============================================================\n",
      "FOLD 3/5\n",
      "============================================================\n",
      "Fold 3: Train 298, Val 74\n",
      "Train distribution: Counter({np.int64(4): 75, np.int64(2): 71, np.int64(3): 57, np.int64(1): 52, np.int64(0): 43})\n",
      "Val distribution: Counter({np.int64(4): 19, np.int64(2): 18, np.int64(3): 14, np.int64(1): 13, np.int64(0): 10})\n",
      "\n",
      "--- ResNeXt50 ---\n",
      "  Regular training...\n",
      "    Training ResNeXt50 - Fold 3\n",
      "      Epoch  0: Train 23.2%, Val 27.0%\n",
      "      Epoch 15: Train 92.6%, Val 54.1%\n",
      "      Epoch 30: Train 84.9%, Val 54.1%\n",
      "      Epoch 45: Train 93.6%, Val 54.1%\n",
      "      Epoch 56: Train 96.0%, Val 54.1%\n",
      "      Early stopping at epoch 56\n",
      "    ResNeXt50 regular: 59.5%\n",
      "  Progressive training...\n",
      "    Progressive training resnext50_32x4d - Fold 3\n",
      "    Training resnext50_32x4d - Fold 3\n",
      "      Epoch  0: Train 40.6%, Val 32.4%\n",
      "      Epoch 15: Train 95.3%, Val 48.6%\n",
      "      Epoch 30: Train 86.9%, Val 47.3%\n",
      "      Epoch 31: Train 89.6%, Val 44.6%\n",
      "      Early stopping at epoch 31\n",
      "    ResNeXt50 progressive: 50.0%\n",
      "\n",
      "--- EfficientNetV2 ---\n",
      "  Regular training...\n",
      "    Training EfficientNetV2 - Fold 3\n",
      "      Epoch  0: Train 19.5%, Val 18.9%\n",
      "      Epoch 15: Train 22.1%, Val 16.2%\n",
      "      Epoch 20: Train 22.8%, Val 13.5%\n",
      "      Early stopping at epoch 20\n",
      "    EfficientNetV2 regular: 18.9%\n",
      "  Progressive training...\n",
      "    Progressive training tf_efficientnetv2_s - Fold 3\n",
      "    Training tf_efficientnetv2_s - Fold 3\n",
      "      Epoch  0: Train 36.2%, Val 39.2%\n",
      "      Epoch 15: Train 95.3%, Val 54.1%\n",
      "      Epoch 30: Train 87.9%, Val 56.8%\n",
      "      Epoch 45: Train 95.3%, Val 52.7%\n",
      "      Epoch 51: Train 100.0%, Val 51.4%\n",
      "      Early stopping at epoch 51\n",
      "    EfficientNetV2 progressive: 60.8%\n",
      "\n",
      "--- DenseNet169 ---\n",
      "  Regular training...\n",
      "    Training DenseNet169 - Fold 3\n",
      "      Epoch  0: Train 20.1%, Val 31.1%\n",
      "      Epoch 15: Train 97.7%, Val 50.0%\n",
      "      Epoch 30: Train 85.6%, Val 56.8%\n",
      "      Epoch 40: Train 89.9%, Val 51.4%\n",
      "      Early stopping at epoch 40\n",
      "    DenseNet169 regular: 56.8%\n",
      "  Progressive training...\n",
      "    Progressive training densenet169 - Fold 3\n",
      "    Training densenet169 - Fold 3\n",
      "      Epoch  0: Train 22.5%, Val 14.9%\n",
      "      Epoch 15: Train 33.6%, Val 23.0%\n",
      "      Epoch 30: Train 65.8%, Val 29.7%\n",
      "      Epoch 45: Train 80.5%, Val 45.9%\n",
      "    DenseNet169 progressive: 50.0%\n",
      "\n",
      "Fold 3 average: 49.3%\n",
      "\n",
      "============================================================\n",
      "FOLD 4/5\n",
      "============================================================\n",
      "Fold 4: Train 298, Val 74\n",
      "Train distribution: Counter({np.int64(4): 75, np.int64(2): 71, np.int64(3): 57, np.int64(1): 52, np.int64(0): 43})\n",
      "Val distribution: Counter({np.int64(4): 19, np.int64(2): 18, np.int64(3): 14, np.int64(1): 13, np.int64(0): 10})\n",
      "\n",
      "--- ResNeXt50 ---\n",
      "  Regular training...\n",
      "    Training ResNeXt50 - Fold 4\n",
      "      Epoch  0: Train 22.5%, Val 28.4%\n",
      "      Epoch 15: Train 77.2%, Val 51.4%\n",
      "      Epoch 30: Train 90.6%, Val 45.9%\n",
      "      Epoch 31: Train 90.3%, Val 47.3%\n",
      "      Early stopping at epoch 31\n",
      "    ResNeXt50 regular: 55.4%\n",
      "  Progressive training...\n",
      "    Progressive training resnext50_32x4d - Fold 4\n",
      "    Training resnext50_32x4d - Fold 4\n",
      "      Epoch  0: Train 37.9%, Val 35.1%\n",
      "      Epoch 15: Train 95.0%, Val 47.3%\n",
      "      Epoch 30: Train 95.6%, Val 52.7%\n",
      "      Epoch 45: Train 90.9%, Val 55.4%\n",
      "    ResNeXt50 progressive: 58.1%\n",
      "\n",
      "--- EfficientNetV2 ---\n",
      "  Regular training...\n",
      "    Training EfficientNetV2 - Fold 4\n",
      "      Epoch  0: Train 19.1%, Val 18.9%\n",
      "      Epoch 15: Train 22.1%, Val 27.0%\n",
      "      Epoch 21: Train 21.1%, Val 18.9%\n",
      "      Early stopping at epoch 21\n",
      "    EfficientNetV2 regular: 27.0%\n",
      "  Progressive training...\n",
      "    Progressive training tf_efficientnetv2_s - Fold 4\n",
      "    Training tf_efficientnetv2_s - Fold 4\n",
      "      Epoch  0: Train 41.6%, Val 33.8%\n",
      "      Epoch 15: Train 89.3%, Val 51.4%\n",
      "      Epoch 30: Train 91.3%, Val 56.8%\n",
      "      Epoch 41: Train 97.0%, Val 51.4%\n",
      "      Early stopping at epoch 41\n",
      "    EfficientNetV2 progressive: 58.1%\n",
      "\n",
      "--- DenseNet169 ---\n",
      "  Regular training...\n",
      "    Training DenseNet169 - Fold 4\n",
      "      Epoch  0: Train 25.8%, Val 44.6%\n",
      "      Epoch 15: Train 87.2%, Val 50.0%\n",
      "      Epoch 25: Train 73.8%, Val 45.9%\n",
      "      Early stopping at epoch 25\n",
      "    DenseNet169 regular: 56.8%\n",
      "  Progressive training...\n",
      "    Progressive training densenet169 - Fold 4\n",
      "    Training densenet169 - Fold 4\n",
      "      Epoch  0: Train 22.5%, Val 24.3%\n",
      "      Epoch 15: Train 54.7%, Val 32.4%\n",
      "      Epoch 30: Train 88.3%, Val 40.5%\n",
      "      Epoch 45: Train 97.7%, Val 43.2%\n",
      "    DenseNet169 progressive: 45.9%\n",
      "\n",
      "Fold 4 average: 50.2%\n",
      "\n",
      "============================================================\n",
      "FOLD 5/5\n",
      "============================================================\n",
      "Fold 5: Train 298, Val 74\n",
      "Train distribution: Counter({np.int64(4): 76, np.int64(2): 72, np.int64(3): 56, np.int64(1): 52, np.int64(0): 42})\n",
      "Val distribution: Counter({np.int64(4): 18, np.int64(2): 17, np.int64(3): 15, np.int64(1): 13, np.int64(0): 11})\n",
      "\n",
      "--- ResNeXt50 ---\n",
      "  Regular training...\n",
      "    Training ResNeXt50 - Fold 5\n",
      "      Epoch  0: Train 18.5%, Val 28.4%\n",
      "      Epoch 15: Train 85.6%, Val 55.4%\n",
      "      Epoch 30: Train 94.0%, Val 55.4%\n",
      "      Epoch 45: Train 88.6%, Val 54.1%\n",
      "      Epoch 57: Train 95.6%, Val 54.1%\n",
      "      Early stopping at epoch 57\n",
      "    ResNeXt50 regular: 60.8%\n",
      "  Progressive training...\n",
      "    Progressive training resnext50_32x4d - Fold 5\n",
      "    Training resnext50_32x4d - Fold 5\n",
      "      Epoch  0: Train 36.9%, Val 33.8%\n",
      "      Epoch 15: Train 86.6%, Val 52.7%\n",
      "      Epoch 30: Train 96.3%, Val 50.0%\n",
      "      Epoch 32: Train 95.6%, Val 51.4%\n",
      "      Early stopping at epoch 32\n",
      "    ResNeXt50 progressive: 55.4%\n",
      "\n",
      "--- EfficientNetV2 ---\n",
      "  Regular training...\n",
      "    Training EfficientNetV2 - Fold 5\n",
      "      Epoch  0: Train 23.5%, Val 20.3%\n",
      "      Epoch 15: Train 23.2%, Val 18.9%\n",
      "      Epoch 30: Train 21.1%, Val 17.6%\n",
      "      Epoch 45: Train 22.1%, Val 18.9%\n",
      "    EfficientNetV2 regular: 25.7%\n",
      "  Progressive training...\n",
      "    Progressive training tf_efficientnetv2_s - Fold 5\n",
      "    Training tf_efficientnetv2_s - Fold 5\n",
      "      Epoch  0: Train 36.9%, Val 39.2%\n",
      "      Epoch 15: Train 95.0%, Val 66.2%\n",
      "      Epoch 30: Train 87.6%, Val 66.2%\n",
      "      Epoch 35: Train 88.9%, Val 64.9%\n",
      "      Early stopping at epoch 35\n",
      "    EfficientNetV2 progressive: 66.2%\n",
      "\n",
      "--- DenseNet169 ---\n",
      "  Regular training...\n",
      "    Training DenseNet169 - Fold 5\n",
      "      Epoch  0: Train 26.2%, Val 33.8%\n",
      "      Epoch 15: Train 84.6%, Val 51.4%\n",
      "      Epoch 29: Train 91.9%, Val 55.4%\n",
      "      Early stopping at epoch 29\n",
      "    DenseNet169 regular: 59.5%\n",
      "  Progressive training...\n",
      "    Progressive training densenet169 - Fold 5\n",
      "    Training densenet169 - Fold 5\n",
      "      Epoch  0: Train 21.1%, Val 27.0%\n",
      "      Epoch 15: Train 33.9%, Val 27.0%\n",
      "      Epoch 30: Train 51.3%, Val 24.3%\n",
      "      Epoch 45: Train 70.5%, Val 47.3%\n",
      "    DenseNet169 progressive: 51.4%\n",
      "\n",
      "Fold 5 average: 53.2%\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS\n",
      "================================================================================\n",
      "Fold averages:\n",
      "  Fold 1: 57.3%\n",
      "  Fold 2: 51.8%\n",
      "  Fold 3: 49.3%\n",
      "  Fold 4: 50.2%\n",
      "  Fold 5: 53.2%\n",
      "\n",
      "CV Mean: 52.4% Â± 2.8%\n",
      "\n",
      "================================================================================\n",
      "FINAL ENSEMBLE EVALUATION\n",
      "================================================================================\n",
      "Evaluating ensemble on held-out test set...\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "Cross-validation: 52.4% Â± 2.8%\n",
      "Final ensemble test accuracy: 59.6%\n",
      "Total models in ensemble: 30\n",
      "\n",
      "Final result: 15.4% short of 75% target\n",
      "The dataset size appears to be the fundamental limiting factor.\n",
      "\n",
      "Ensemble saved: deer_age_multifold_20250801_223542\\multifold_ensemble_59.6pct.pth\n",
      "================================================================================\n",
      "Detailed results saved to: deer_age_multifold_20250801_223542\\results_summary.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if MIXED_PRECISION_AVAILABLE:\n",
    "        scaler = GradScaler()\n",
    "        use_amp = True\n",
    "        print(\"Mixed Precision: Enabled\")\n",
    "    else:\n",
    "        use_amp = False\n",
    "else:\n",
    "    use_amp = False\n",
    "\n",
    "color_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\"\n",
    "grayscale_path = r\"G:\\Dropbox\\AI Projects\\buck\\images\\squared\\grayscale\"\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        age_str = parts[3]\n",
    "        try:\n",
    "            age = float(age_str.replace('p', '.'))\n",
    "            if age > 5.5:\n",
    "                age = 5.5\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def age_to_class(age):\n",
    "    age_mapping = {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
    "    return age_mapping.get(age, None)\n",
    "\n",
    "def load_images(color_path, grayscale_path, img_size=(224, 224)):\n",
    "    images = []\n",
    "    ages = []\n",
    "    \n",
    "    if os.path.exists(color_path):\n",
    "        for filename in os.listdir(color_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(color_path, filename)\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                            img_resized = cv2.resize(img_gray, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    if os.path.exists(grayscale_path):\n",
    "        for filename in os.listdir(grayscale_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                age = parse_filename(filename)\n",
    "                if age is not None:\n",
    "                    class_idx = age_to_class(age)\n",
    "                    if class_idx is not None:\n",
    "                        img_path = os.path.join(grayscale_path, filename)\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, img_size)\n",
    "                            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
    "                            images.append(img_rgb)\n",
    "                            ages.append(class_idx)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    ages = np.array(ages)\n",
    "    \n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    print(f\"Class distribution: {Counter(ages)}\")\n",
    "    \n",
    "    return images, ages\n",
    "\n",
    "def conservative_augment(image):\n",
    "    \"\"\"Conservative augmentation to reduce overfitting\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        angle = random.uniform(-10, 10)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.6:\n",
    "        alpha = random.uniform(0.9, 1.1)\n",
    "        beta = random.randint(-15, 15)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.2:\n",
    "        noise = np.random.normal(0, 4, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "class ConservativeDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False):\n",
    "        self.X = X\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.augment = augment\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].copy()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if self.augment:\n",
    "            image = conservative_augment(image)\n",
    "        \n",
    "        image = torch.FloatTensor(image)\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_conservative_model(model_name, num_classes=5):\n",
    "    \"\"\"Create model with heavy regularization to combat overfitting\"\"\"\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=0.6)\n",
    "    \n",
    "    # Aggressive freezing to reduce overfitting\n",
    "    if 'densenet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('denseblock4' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'resnext' in model_name or 'resnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('layer4' in name or 'fc' in name):\n",
    "                param.requires_grad = False\n",
    "    elif 'efficientnet' in model_name:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not ('blocks.6' in name or 'blocks.7' in name or 'classifier' in name):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def train_conservative_model(model, train_loader, val_loader, model_name, fold_num):\n",
    "    \"\"\"Conservative training to minimize overfitting\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
    "    \n",
    "    # Low learning rate and high weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=0.1)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=60, eta_min=1e-7)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(f\"    Training {model_name} - Fold {fold_num}\")\n",
    "    \n",
    "    for epoch in range(60):  # Shorter training to reduce overfitting\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Light mixup occasionally\n",
    "            if random.random() < 0.2:\n",
    "                lam = np.random.beta(0.2, 0.2)\n",
    "                batch_size = images.size(0)\n",
    "                index = torch.randperm(batch_size).to(device)\n",
    "                mixed_images = lam * images + (1 - lam) * images[index, :]\n",
    "                y_a, y_b = labels, labels[index]\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(mixed_images)\n",
    "                        loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(mixed_images)\n",
    "                    loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == y_a).sum().item()\n",
    "            else:\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 15 == 0 or patience_counter >= patience:\n",
    "            print(f\"      Epoch {epoch:2d}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"      Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_val_acc\n",
    "\n",
    "def progressive_train_fold(X_fold_train, y_fold_train, X_fold_val, y_fold_val, model_name, fold_num):\n",
    "    \"\"\"Progressive training for a single fold\"\"\"\n",
    "    print(f\"    Progressive training {model_name} - Fold {fold_num}\")\n",
    "    \n",
    "    # Phase 1: Binary classification\n",
    "    y_binary_train = np.array([0 if y <= 2 else 1 for y in y_fold_train])\n",
    "    y_binary_val = np.array([0 if y <= 2 else 1 for y in y_fold_val])\n",
    "    \n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=2, drop_rate=0.5)\n",
    "    if hasattr(model, 'classifier'):\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 2)\n",
    "    elif hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Binary training\n",
    "    binary_train_dataset = ConservativeDataset(X_fold_train, y_binary_train, augment=True)\n",
    "    binary_val_dataset = ConservativeDataset(X_fold_val, y_binary_val, augment=False)\n",
    "    binary_train_loader = DataLoader(binary_train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    binary_val_loader = DataLoader(binary_val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.05)\n",
    "    \n",
    "    for epoch in range(25):\n",
    "        model.train()\n",
    "        for images, labels in binary_train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    # Phase 2: 5-class fine-tuning\n",
    "    if hasattr(model, 'classifier'):\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 5)\n",
    "    elif hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, 5)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 5-class datasets\n",
    "    full_train_dataset = ConservativeDataset(X_fold_train, y_fold_train, augment=True)\n",
    "    full_val_dataset = ConservativeDataset(X_fold_val, y_fold_val, augment=False)\n",
    "    full_train_loader = DataLoader(full_train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    full_val_loader = DataLoader(full_val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Fine-tune with lower learning rate\n",
    "    trained_model, val_acc = train_conservative_model(model, full_train_loader, full_val_loader, model_name, fold_num)\n",
    "    \n",
    "    return trained_model, val_acc\n",
    "\n",
    "def evaluate_with_tta(model, test_loader):\n",
    "    \"\"\"Simple TTA evaluation\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Original\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs1 = model(images)\n",
    "            else:\n",
    "                outputs1 = model(images)\n",
    "            \n",
    "            # Horizontal flip\n",
    "            flipped = torch.flip(images, [3])\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs2 = model(flipped)\n",
    "            else:\n",
    "                outputs2 = model(flipped)\n",
    "            \n",
    "            # Average predictions\n",
    "            avg_outputs = (F.softmax(outputs1, dim=1) + F.softmax(outputs2, dim=1)) / 2\n",
    "            _, predicted = torch.max(avg_outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "def ensemble_evaluate(all_models, test_loader):\n",
    "    \"\"\"Evaluate ensemble of all models from all folds\"\"\"\n",
    "    for models_list in all_models:\n",
    "        for model in models_list:\n",
    "            model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            ensemble_output = torch.zeros(images.size(0), 5).to(device)\n",
    "            model_count = 0\n",
    "            \n",
    "            # Collect predictions from all models\n",
    "            for models_list in all_models:\n",
    "                for model in models_list:\n",
    "                    # TTA for each model\n",
    "                    if use_amp:\n",
    "                        with autocast():\n",
    "                            outputs1 = model(images)\n",
    "                            outputs2 = model(torch.flip(images, [3]))\n",
    "                    else:\n",
    "                        outputs1 = model(images)\n",
    "                        outputs2 = model(torch.flip(images, [3]))\n",
    "                    \n",
    "                    avg_model_output = (F.softmax(outputs1, dim=1) + F.softmax(outputs2, dim=1)) / 2\n",
    "                    ensemble_output += avg_model_output\n",
    "                    model_count += 1\n",
    "            \n",
    "            # Average across all models\n",
    "            ensemble_output /= model_count\n",
    "            _, predicted = torch.max(ensemble_output, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "# Main Multi-Fold Ensemble Pipeline\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"deer_age_multifold_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Multi-fold ensemble results saved to: {output_dir}\")\n",
    "\n",
    "print(\"Loading images...\")\n",
    "X, y = load_images(color_path, grayscale_path)\n",
    "\n",
    "# Reserve test set\n",
    "X_train_all, X_test_final, y_train_all, y_test_final = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training pool: {len(X_train_all)}, Final test: {len(X_test_final)}\")\n",
    "\n",
    "# Model configurations based on best performers\n",
    "model_configs = [\n",
    "    ('resnext50_32x4d', 'ResNeXt50'),\n",
    "    ('tf_efficientnetv2_s', 'EfficientNetV2'),\n",
    "    ('densenet169', 'DenseNet169')\n",
    "]\n",
    "\n",
    "# 5-fold cross-validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"MULTI-FOLD ENSEMBLE: {n_folds} FOLDS x {len(model_configs)} MODELS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"Training strategy: Conservative to minimize overfitting\")\n",
    "print(\"Total models to train:\", n_folds * len(model_configs) * 2)  # x2 for regular + progressive\n",
    "print(\"Estimated time: 4-6 hours\")\n",
    "\n",
    "all_trained_models = []\n",
    "all_fold_scores = []\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_all, y_train_all)):\n",
    "    fold_num = fold + 1\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold_num}/{n_folds}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X_fold_train = X_train_all[train_idx]\n",
    "    y_fold_train = y_train_all[train_idx]\n",
    "    X_fold_val = X_train_all[val_idx]\n",
    "    y_fold_val = y_train_all[val_idx]\n",
    "    \n",
    "    print(f\"Fold {fold_num}: Train {len(X_fold_train)}, Val {len(X_fold_val)}\")\n",
    "    print(f\"Train distribution: {Counter(y_fold_train)}\")\n",
    "    print(f\"Val distribution: {Counter(y_fold_val)}\")\n",
    "    \n",
    "    fold_models = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    for model_timm_name, display_name in model_configs:\n",
    "        print(f\"\\n--- {display_name} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Regular training\n",
    "            print(f\"  Regular training...\")\n",
    "            model = create_conservative_model(model_timm_name)\n",
    "            \n",
    "            train_dataset = ConservativeDataset(X_fold_train, y_fold_train, augment=True)\n",
    "            val_dataset = ConservativeDataset(X_fold_val, y_fold_val, augment=False)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=14, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=14, shuffle=False, num_workers=0)\n",
    "            \n",
    "            trained_model, val_acc = train_conservative_model(\n",
    "                model, train_loader, val_loader, display_name, fold_num\n",
    "            )\n",
    "            \n",
    "            fold_models.append(trained_model)\n",
    "            fold_scores.append(val_acc)\n",
    "            \n",
    "            print(f\"    {display_name} regular: {val_acc:.1f}%\")\n",
    "            \n",
    "            # Progressive training\n",
    "            print(f\"  Progressive training...\")\n",
    "            prog_model, prog_acc = progressive_train_fold(\n",
    "                X_fold_train, y_fold_train, X_fold_val, y_fold_val, \n",
    "                model_timm_name, fold_num\n",
    "            )\n",
    "            \n",
    "            fold_models.append(prog_model)\n",
    "            fold_scores.append(prog_acc)\n",
    "            \n",
    "            print(f\"    {display_name} progressive: {prog_acc:.1f}%\")\n",
    "            \n",
    "            # Memory cleanup\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error with {display_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    all_trained_models.append(fold_models)\n",
    "    all_fold_scores.append(fold_scores)\n",
    "    \n",
    "    fold_avg = np.mean(fold_scores) if fold_scores else 0\n",
    "    fold_results.append(fold_avg)\n",
    "    print(f\"\\nFold {fold_num} average: {fold_avg:.1f}%\")\n",
    "\n",
    "# Cross-validation results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "cv_mean = np.mean(fold_results)\n",
    "cv_std = np.std(fold_results)\n",
    "\n",
    "print(\"Fold averages:\")\n",
    "for i, score in enumerate(fold_results, 1):\n",
    "    print(f\"  Fold {i}: {score:.1f}%\")\n",
    "\n",
    "print(f\"\\nCV Mean: {cv_mean:.1f}% Â± {cv_std:.1f}%\")\n",
    "\n",
    "# Final ensemble evaluation on held-out test set\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL ENSEMBLE EVALUATION\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "test_dataset = ConservativeDataset(X_test_final, y_test_final, augment=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Evaluating ensemble on held-out test set...\")\n",
    "final_ensemble_accuracy = ensemble_evaluate(all_trained_models, test_loader)\n",
    "\n",
    "# Save ensemble\n",
    "ensemble_save_path = os.path.join(output_dir, f\"multifold_ensemble_{final_ensemble_accuracy:.1f}pct.pth\")\n",
    "torch.save({\n",
    "    'all_models_state_dicts': [\n",
    "        [model.state_dict() for model in fold_models] \n",
    "        for fold_models in all_trained_models\n",
    "    ],\n",
    "    'model_configs': model_configs,\n",
    "    'fold_scores': all_fold_scores,\n",
    "    'cv_mean': cv_mean,\n",
    "    'cv_std': cv_std,\n",
    "    'final_test_accuracy': final_ensemble_accuracy,\n",
    "    'n_folds': n_folds,\n",
    "    'total_models': sum(len(fold) for fold in all_trained_models)\n",
    "}, ensemble_save_path)\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"Cross-validation: {cv_mean:.1f}% Â± {cv_std:.1f}%\")\n",
    "print(f\"Final ensemble test accuracy: {final_ensemble_accuracy:.1f}%\")\n",
    "print(f\"Total models in ensemble: {sum(len(fold) for fold in all_trained_models)}\")\n",
    "\n",
    "if final_ensemble_accuracy >= 75.0:\n",
    "    print(\"\\nSUCCESS: 75% TARGET ACHIEVED!\")\n",
    "    print(\"The multi-fold ensemble approach worked!\")\n",
    "else:\n",
    "    gap = 75.0 - final_ensemble_accuracy\n",
    "    print(f\"\\nFinal result: {gap:.1f}% short of 75% target\")\n",
    "    if final_ensemble_accuracy >= 70.0:\n",
    "        print(\"Very close! This is likely the ceiling with 466 images.\")\n",
    "    else:\n",
    "        print(\"The dataset size appears to be the fundamental limiting factor.\")\n",
    "\n",
    "print(f\"\\nEnsemble saved: {ensemble_save_path}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save detailed results\n",
    "results_summary = {\n",
    "    'timestamp': timestamp,\n",
    "    'total_images': len(X),\n",
    "    'train_images': len(X_train_all),\n",
    "    'test_images': len(X_test_final),\n",
    "    'n_folds': n_folds,\n",
    "    'model_configs': model_configs,\n",
    "    'fold_results': fold_results,\n",
    "    'cv_mean': float(cv_mean),\n",
    "    'cv_std': float(cv_std),\n",
    "    'final_test_accuracy': float(final_ensemble_accuracy),\n",
    "    'target_achieved': final_ensemble_accuracy >= 75.0,\n",
    "    'total_models': sum(len(fold) for fold in all_trained_models)\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'results_summary.json'), 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"Detailed results saved to: {os.path.join(output_dir, 'results_summary.json')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
