{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e3eb0f-fc0c-4f79-bbd0-64a5fe58961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357 images found:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from buck.analysis.basics import ingest_images\n",
    "\n",
    "# Your existing ingestion\n",
    "fpath = \"C:\\\\Users\\\\aaron\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*.png\"\n",
    "images, ages = ingest_images(fpath)\n",
    "print(len(images),'images found:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2e9606-63d3-422f-8f58-21a2e4ef579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 288, 288, 3) (57, 288, 288, 3) (72, 288, 288, 3)\n"
     ]
    }
   ],
   "source": [
    "from buck.analysis.basics import split_data\n",
    "\n",
    "Xtr_og, ytr_og, Xval, yval, Xte, yte_onehot, ages, l_map = split_data(images, ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4eec27e-965b-411c-8296-27762189ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 0 (Age 1.5): 37 → 1120 samples\n",
      "  Class 1 (Age 2.5): 42 → 1120 samples\n",
      "  Class 2 (Age 3.5): 46 → 1120 samples\n",
      "  Class 3 (Age 4.5): 47 → 1120 samples\n",
      "  Class 4 (Age 5.5): 56 → 1120 samples\n"
     ]
    }
   ],
   "source": [
    "from buck.analysis.basics import homogenize_data\n",
    "\n",
    "augment_multiplier = 20\n",
    "X_train, y_train, X_test, y_true, label_mapping, num_classes = homogenize_data(Xtr_og, ytr_og, Xte,yte_onehot, l_map, augment_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee743d90-6e1e-457d-9fc3-2067e1fb8880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from albumentations) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: PyYAML in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from albumentations) (6.0.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-3.12.5-cp311-cp311-win_amd64.whl.metadata (81 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.4.7-cp311-cp311-win_amd64.whl.metadata (67 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 13.9/39.4 MB 67.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.4 MB 82.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 80.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 58.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.4.7-cp311-cp311-win_amd64.whl (94 kB)\n",
      "Downloading stringzilla-3.12.5-cp311-cp311-win_amd64.whl (80 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: stringzilla, simsimd, typing-inspection, pydantic-core, opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "\n",
      "   ---------------------------------------- 0/9 [stringzilla]\n",
      "   ---------------------------------------- 0/9 [stringzilla]\n",
      "   ---- ----------------------------------- 1/9 [simsimd]\n",
      "   ------------- -------------------------- 3/9 [pydantic-core]\n",
      "   ------------- -------------------------- 3/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [opencv-python-headless]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~onttools (G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~onttools (G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\buck-env\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e2dad4-961a-479e-9619-1a78b5561d12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CosineAnnealingWarmRestarts, ReduceLROnPlateau\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01malbumentations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mA\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01malbumentations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToTensorV2\n\u001b[32m     19\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedDeerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    IMPROVED Dataset with better augmentation and stability\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, transform=None, is_training=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # IMPROVED AUGMENTATION using Albumentations\n",
    "        if is_training:\n",
    "            self.transform = A.Compose([\n",
    "                # Geometric transforms\n",
    "                A.Resize(384, 384),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Flip(p=0.5),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.1, \n",
    "                    scale_limit=0.2, \n",
    "                    rotate_limit=15, \n",
    "                    p=0.7,\n",
    "                    border_mode=0\n",
    "                ),\n",
    "                \n",
    "                # Photometric transforms\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.2, \n",
    "                    contrast_limit=0.2, \n",
    "                    p=0.6\n",
    "                ),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=10, \n",
    "                    sat_shift_limit=20, \n",
    "                    val_shift_limit=15, \n",
    "                    p=0.5\n",
    "                ),\n",
    "                A.GaussNoise(var_limit=(0.0, 0.01), p=0.3),\n",
    "                A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=3, p=1.0),\n",
    "                    A.GaussianBlur(blur_limit=3, p=1.0),\n",
    "                ], p=0.2),\n",
    "                \n",
    "                # Cutout/Erasing\n",
    "                A.CoarseDropout(\n",
    "                    max_holes=8, \n",
    "                    max_height=32, \n",
    "                    max_width=32, \n",
    "                    p=0.3\n",
    "                ),\n",
    "                \n",
    "                # Normalize to 0-1\n",
    "                A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        else:\n",
    "            # Validation - minimal transforms\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(384, 384),\n",
    "                A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        \n",
    "        print(f\"Dataset: {len(X)} samples, training={is_training}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].astype(np.float32)\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image_tensor = augmented['image']\n",
    "        else:\n",
    "            # Fallback\n",
    "            image_tensor = torch.FloatTensor(image).permute(2, 0, 1)\n",
    "        \n",
    "        return image_tensor, torch.LongTensor([label]).squeeze()\n",
    "\n",
    "class ImprovedDeerAgeEfficientNet:\n",
    "    \"\"\"\n",
    "    IMPROVED EfficientNet with better training stability and performance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Create improved model\n",
    "        self.create_improved_model()\n",
    "        \n",
    "    def create_improved_model(self):\n",
    "        \"\"\"\n",
    "        Create IMPROVED EfficientNet model\n",
    "        \"\"\"\n",
    "        # Try EfficientNet-B3 for better speed/accuracy balance\n",
    "        self.model = timm.create_model(\n",
    "            'efficientnet_b3',  # Changed from B4 to B3 for stability\n",
    "            pretrained=True,\n",
    "            num_classes=self.num_classes,\n",
    "            drop_rate=0.4,      # Increased dropout\n",
    "            drop_path_rate=0.3  # Increased stochastic depth\n",
    "        )\n",
    "        \n",
    "        # IMPROVED classifier with better regularization\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"✅ EfficientNet-B3 created:\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    def prepare_improved_data_loaders(self, X_train, y_train, X_val, y_val, batch_size=32):\n",
    "        \"\"\"\n",
    "        Create IMPROVED data loaders with better augmentation\n",
    "        \"\"\"\n",
    "        print(\"🔄 Preparing IMPROVED data loaders...\")\n",
    "        \n",
    "        # Create datasets with improved augmentation\n",
    "        train_dataset = ImprovedDeerDataset(X_train, y_train, is_training=True)\n",
    "        val_dataset = ImprovedDeerDataset(X_val, y_val, is_training=False)\n",
    "        \n",
    "        # IMPROVED data loaders with better settings\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            drop_last=True  # Consistent batch sizes\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Training loader: {len(train_loader)} batches (batch size: {batch_size})\")\n",
    "        print(f\"✅ Validation loader: {len(val_loader)} batches\")\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def train_improved_model(self, train_loader, val_loader, epochs=100, learning_rate=3e-4):\n",
    "        \"\"\"\n",
    "        IMPROVED training with better stability and performance\n",
    "        \"\"\"\n",
    "        print(f\"🚀 Starting IMPROVED training for {epochs} epochs...\")\n",
    "        \n",
    "        # IMPROVED OPTIMIZER with better settings\n",
    "        optimizer = optim.AdamW(\n",
    "            self.model.parameters(), \n",
    "            lr=learning_rate, \n",
    "            weight_decay=0.02,  # Increased weight decay\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # IMPROVED SCHEDULER with warm restarts\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer, \n",
    "            T_0=20,      # Restart every 20 epochs\n",
    "            T_mult=2,    # Double the period after each restart\n",
    "            eta_min=1e-7 # Minimum learning rate\n",
    "        )\n",
    "        \n",
    "        # LABEL SMOOTHING for better generalization\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 25  # Increased patience\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # GRADIENT ACCUMULATION for larger effective batch size\n",
    "        accumulation_steps = 2\n",
    "        \n",
    "        print(f\"📋 Training Configuration:\")\n",
    "        print(f\"   Optimizer: AdamW (lr={learning_rate}, weight_decay=0.02)\")\n",
    "        print(f\"   Scheduler: CosineAnnealingWarmRestarts (T_0=20)\")\n",
    "        print(f\"   Label smoothing: 0.1\")\n",
    "        print(f\"   Gradient accumulation: {accumulation_steps} steps\")\n",
    "        print(f\"   Patience: {patience} epochs\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Scale loss for accumulation\n",
    "                loss = loss / accumulation_steps\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient accumulation\n",
    "                if ((batch_idx + 1) % accumulation_steps == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                # Statistics\n",
    "                train_loss += loss.item() * accumulation_steps  # Unscale for logging\n",
    "                _, predicted = outputs.max(1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Progress update\n",
    "                if batch_idx % 10 == 0:\n",
    "                    current_acc = 100. * train_correct / train_total\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    print(f'Epoch {epoch+1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | '\n",
    "                          f'Loss: {loss.item()*accumulation_steps:.4f} | Acc: {current_acc:.1f}% | LR: {current_lr:.2e}')\n",
    "            \n",
    "            # Validation phase\n",
    "            val_loss, val_acc = self._validate_improved(val_loader, criterion)\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Update history\n",
    "            train_acc = 100. * train_correct / train_total\n",
    "            train_loss = train_loss / len(train_loader)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['learning_rate'].append(current_lr)\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f'\\n📊 Epoch {epoch+1}/{epochs} Results:')\n",
    "            print(f'   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'   Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "            print(f'   Learning Rate: {current_lr:.2e}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(self.model.state_dict(), 'best_deer_efficientnet_improved.pth')\n",
    "                patience_counter = 0\n",
    "                print(f'   🎯 NEW BEST MODEL! Validation Accuracy: {val_acc:.2f}%')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f'   Patience: {patience_counter}/{patience}')\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f'\\n⏰ Early stopping after {epoch+1} epochs')\n",
    "                break\n",
    "            \n",
    "            print('-' * 80)\n",
    "        \n",
    "        # Load best model\n",
    "        self.model.load_state_dict(torch.load('best_deer_efficientnet_improved.pth'))\n",
    "        print(f'\\n🏆 IMPROVED training completed!')\n",
    "        print(f'   Best validation accuracy: {best_val_acc:.2f}%')\n",
    "        print(f'   Target: 70%+ test accuracy')\n",
    "        \n",
    "        return history, best_val_acc\n",
    "    \n",
    "    def _validate_improved(self, val_loader, criterion):\n",
    "        \"\"\"\n",
    "        IMPROVED validation function\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        return val_loss, val_acc\n",
    "    \n",
    "    def plot_improved_training_history(self, history):\n",
    "        \"\"\"\n",
    "        Plot IMPROVED training curves with learning rate\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss curves\n",
    "        axes[0,0].plot(history['train_loss'], label='Training Loss', linewidth=2)\n",
    "        axes[0,0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "        axes[0,0].set_title('Model Loss', fontsize=14)\n",
    "        axes[0,0].set_xlabel('Epoch')\n",
    "        axes[0,0].set_ylabel('Loss')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Accuracy curves\n",
    "        axes[0,1].plot(history['train_acc'], label='Training Accuracy', linewidth=2)\n",
    "        axes[0,1].plot(history['val_acc'], label='Validation Accuracy', linewidth=2)\n",
    "        axes[0,1].axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Target 70%')\n",
    "        axes[0,1].set_title('Model Accuracy', fontsize=14)\n",
    "        axes[0,1].set_xlabel('Epoch')\n",
    "        axes[0,1].set_ylabel('Accuracy (%)')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Learning rate\n",
    "        axes[1,0].plot(history['learning_rate'], linewidth=2, color='green')\n",
    "        axes[1,0].set_title('Learning Rate Schedule', fontsize=14)\n",
    "        axes[1,0].set_xlabel('Epoch')\n",
    "        axes[1,0].set_ylabel('Learning Rate')\n",
    "        axes[1,0].set_yscale('log')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Validation accuracy smoothed\n",
    "        if len(history['val_acc']) > 10:\n",
    "            # Simple moving average\n",
    "            window = min(5, len(history['val_acc'])//5)\n",
    "            val_acc_smooth = np.convolve(history['val_acc'], np.ones(window)/window, mode='valid')\n",
    "            axes[1,1].plot(history['val_acc'], alpha=0.3, label='Raw Val Acc')\n",
    "            axes[1,1].plot(range(window-1, len(history['val_acc'])), val_acc_smooth, \n",
    "                          linewidth=2, label='Smoothed Val Acc')\n",
    "            axes[1,1].axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Target 70%')\n",
    "            axes[1,1].set_title('Smoothed Validation Accuracy', fontsize=14)\n",
    "            axes[1,1].set_xlabel('Epoch')\n",
    "            axes[1,1].set_ylabel('Accuracy (%)')\n",
    "            axes[1,1].legend()\n",
    "            axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print final stats\n",
    "        final_val_acc = max(history['val_acc'])\n",
    "        print(f\"📈 IMPROVED Training Summary:\")\n",
    "        print(f\"   Best Validation Accuracy: {final_val_acc:.2f}%\")\n",
    "        print(f\"   Target for publication: 70%+\")\n",
    "        if final_val_acc >= 70:\n",
    "            print(f\"   🎉 TARGET ACHIEVED! Ready for publication!\")\n",
    "        else:\n",
    "            print(f\"   📈 Progress: {final_val_acc:.1f}% / 70% ({final_val_acc-70:+.1f}%)\")\n",
    "\n",
    "def run_improved_training(X_train, y_train, X_val, y_val, X_test, y_test, label_mapping):\n",
    "    \"\"\"\n",
    "    Run IMPROVED training pipeline for 70%+ test accuracy\n",
    "    \"\"\"\n",
    "    print(\"🦌 IMPROVED DEER AGE CLASSIFICATION TRAINING\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🎯 TARGET: 70%+ test accuracy for publication\")\n",
    "    print(\"🔧 IMPROVEMENTS:\")\n",
    "    print(\"   ✅ Better data augmentation (Albumentations)\")\n",
    "    print(\"   ✅ EfficientNet-B3 for stability\")\n",
    "    print(\"   ✅ Improved classifier with BatchNorm\")\n",
    "    print(\"   ✅ Label smoothing (0.1)\")\n",
    "    print(\"   ✅ CosineAnnealingWarmRestarts scheduler\")\n",
    "    print(\"   ✅ Gradient accumulation\")\n",
    "    print(\"   ✅ Better regularization\")\n",
    "    print(\"   ✅ Increased patience (25 epochs)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Convert one-hot to class indices if needed\n",
    "    if len(y_train.shape) == 2:\n",
    "        print(f\"Converting y_train from one-hot {y_train.shape} to class indices\")\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "    \n",
    "    if len(y_val.shape) == 2:\n",
    "        print(f\"Converting y_val from one-hot {y_val.shape} to class indices\") \n",
    "        y_val = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    if len(y_test.shape) == 2:\n",
    "        print(f\"Converting y_test from one-hot {y_test.shape} to class indices\")\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Initialize IMPROVED classifier\n",
    "    classifier = ImprovedDeerAgeEfficientNet(num_classes=len(label_mapping))\n",
    "    \n",
    "    # Prepare IMPROVED data loaders\n",
    "    train_loader, val_loader = classifier.prepare_improved_data_loaders(\n",
    "        X_train, y_train, X_val, y_val, batch_size=32  # Larger batch size\n",
    "    )\n",
    "    \n",
    "    # Train IMPROVED model\n",
    "    history, best_val_acc = classifier.train_improved_model(\n",
    "        train_loader, val_loader, epochs=100, learning_rate=3e-4\n",
    "    )\n",
    "    \n",
    "    # Plot IMPROVED training history\n",
    "    classifier.plot_improved_training_history(history)\n",
    "    \n",
    "    print(f\"\\n🎯 FINAL RESULT: Best validation accuracy = {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return classifier, history, best_val_acc\n",
    "\n",
    "# Run the IMPROVED training\n",
    "classifier_improved, history_improved, best_val_acc = run_improved_training(X_train, y_train, Xval, yval, X_test, y_true, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0acd6f-d97b-407a-859f-c400767d63d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aaron\\AppData\\Local\\Temp\\ipykernel_4056\\3192201940.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦌 DEER AGE CLASSIFICATION: GRAD-CAM FEATURE ANALYSIS\n",
      "======================================================================\n",
      "🔄 Loading trained model from best_deer_efficientnet.pth...\n",
      "✅ Model loaded successfully on cuda\n",
      "\n",
      "📸 Generating Grad-CAM visualizations...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer features.8.2.block.2 not found in model",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 327\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# USAGE: Run this after training to analyze your saved model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m model = \u001b[43mrun_gradcam_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_deer_efficientnet.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 312\u001b[39m, in \u001b[36mrun_gradcam_analysis\u001b[39m\u001b[34m(X_test, y_test, label_mapping, model_path)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# Run Grad-CAM visualization\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📸 Generating Grad-CAM visualizations...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m \u001b[43mvisualize_deer_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_images\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# Analyze patterns by age group\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔍 Analyzing feature patterns by age group...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 146\u001b[39m, in \u001b[36mvisualize_deer_features\u001b[39m\u001b[34m(model, X_test, y_test, label_mapping, num_images)\u001b[39m\n\u001b[32m    143\u001b[39m class_to_age = {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m label_mapping.items()}\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# Initialize Grad-CAM (target the last convolutional layer)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m grad_cam = \u001b[43mGradCAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_layer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeatures.8.2.block.2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Select random test images\u001b[39;00m\n\u001b[32m    149\u001b[39m indices = np.random.choice(\u001b[38;5;28mlen\u001b[39m(X_test), num_images, replace=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mGradCAM.__init__\u001b[39m\u001b[34m(self, model, target_layer_name)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.activations = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Register hooks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregister_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mGradCAM.register_hooks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.target_layer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Register hooks\u001b[39;00m\n\u001b[32m     43\u001b[39m target_layer.register_forward_hook(forward_hook)\n",
      "\u001b[31mValueError\u001b[39m: Layer features.8.2.block.2 not found in model"
     ]
    }
   ],
   "source": [
    "# Imaging where the model is looking\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import timm\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Grad-CAM implementation for visualizing what features the model focuses on\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer_name):\n",
    "        self.model = model\n",
    "        self.target_layer_name = target_layer_name\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        self.register_hooks()\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        \"\"\"Register forward and backward hooks to capture gradients and activations\"\"\"\n",
    "        \n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]\n",
    "        \n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "        \n",
    "        # Find the target layer\n",
    "        target_layer = None\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.target_layer_name:\n",
    "                target_layer = module\n",
    "                break\n",
    "        \n",
    "        if target_layer is None:\n",
    "            raise ValueError(f\"Layer {self.target_layer_name} not found in model\")\n",
    "        \n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(forward_hook)\n",
    "        target_layer.register_backward_hook(backward_hook)\n",
    "    \n",
    "    def generate_cam(self, image_tensor, class_idx=None):\n",
    "        \"\"\"\n",
    "        Generate Grad-CAM for a given image\n",
    "        \n",
    "        Args:\n",
    "            image_tensor: Input image tensor (1, 3, H, W)\n",
    "            class_idx: Target class index (if None, uses predicted class)\n",
    "        \n",
    "        Returns:\n",
    "            cam: Grad-CAM heatmap\n",
    "            prediction: Model prediction\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        output = self.model(image_tensor)\n",
    "        \n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        target = output[0][class_idx]\n",
    "        target.backward()\n",
    "        \n",
    "        # Get gradients and activations\n",
    "        gradients = self.gradients[0]  # (C, H, W)\n",
    "        activations = self.activations[0]  # (C, H, W)\n",
    "        \n",
    "        # Calculate weights (global average pooling of gradients)\n",
    "        weights = torch.mean(gradients, dim=(1, 2))  # (C,)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "        \n",
    "        # Apply ReLU and normalize\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam / cam.max() if cam.max() > 0 else cam\n",
    "        \n",
    "        return cam.detach().cpu().numpy(), output.detach().cpu().numpy()\n",
    "\n",
    "def load_trained_model(model_path='best_deer_efficientnet.pth', num_classes=5):\n",
    "    \"\"\"\n",
    "    Load the saved deer age classification model\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to saved model weights\n",
    "        num_classes: Number of age classes\n",
    "    \n",
    "    Returns:\n",
    "        model: Loaded model ready for inference\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Loading trained model from {model_path}...\")\n",
    "    \n",
    "    # Recreate the model architecture (same as in training)\n",
    "    model = timm.create_model(\n",
    "        'efficientnet_b4',\n",
    "        pretrained=False,  # Don't download pretrained weights\n",
    "        num_classes=num_classes,\n",
    "        drop_rate=0.3,\n",
    "        drop_path_rate=0.2\n",
    "    )\n",
    "    \n",
    "    # Replace classifier (same as in training)\n",
    "    in_features = model.classifier.in_features\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(p=0.4, inplace=True),\n",
    "        torch.nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Load the saved weights\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✅ Model loaded successfully on {device}\")\n",
    "    return model\n",
    "\n",
    "def visualize_deer_features(model, X_test, y_test, label_mapping, num_images=6):\n",
    "    \"\"\"\n",
    "    Visualize which features the model focuses on for deer age prediction\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded trained model\n",
    "        X_test: Test images\n",
    "        y_test: True labels (as class indices, not one-hot)\n",
    "        label_mapping: Age to class mapping\n",
    "        num_images: Number of images to visualize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert one-hot to class indices if needed\n",
    "    if len(y_test.shape) == 2:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Create reverse mapping\n",
    "    class_to_age = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Initialize Grad-CAM (target the last convolutional layer)\n",
    "    grad_cam = GradCAM(model, target_layer_name='features.8.2.block.2')\n",
    "    \n",
    "    # Select random test images\n",
    "    indices = np.random.choice(len(X_test), num_images, replace=False)\n",
    "    \n",
    "    # Create custom colormap for heatmap\n",
    "    colors = ['blue', 'cyan', 'yellow', 'orange', 'red']\n",
    "    n_bins = 256\n",
    "    cmap = LinearSegmentedColormap.from_list('grad_cam', colors, N=n_bins)\n",
    "    \n",
    "    # Create subplot\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(20, 8))\n",
    "    if num_images == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Prepare image\n",
    "        original_image = X_test[idx]\n",
    "        true_age = class_to_age[y_test[idx]]\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        image_tensor = torch.FloatTensor(original_image).permute(2, 0, 1).unsqueeze(0)\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        \n",
    "        # Resize to model input size (384x384 for EfficientNet-B4)\n",
    "        image_tensor = F.interpolate(image_tensor, size=(384, 384), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Normalize (ImageNet normalization)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
    "        image_tensor = (image_tensor - mean) / std\n",
    "        \n",
    "        # Generate Grad-CAM\n",
    "        cam, prediction = grad_cam.generate_cam(image_tensor)\n",
    "        predicted_class = np.argmax(prediction[0])\n",
    "        predicted_age = class_to_age[predicted_class]\n",
    "        confidence = F.softmax(torch.tensor(prediction[0]), dim=0)[predicted_class].item()\n",
    "        \n",
    "        # Resize CAM to original image size\n",
    "        cam_resized = cv2.resize(cam, (original_image.shape[1], original_image.shape[0]))\n",
    "        \n",
    "        # Display original image\n",
    "        axes[0, i].imshow(original_image)\n",
    "        axes[0, i].set_title(f'Original Image\\nTrue Age: {true_age} years', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Display Grad-CAM overlay\n",
    "        axes[1, i].imshow(original_image)\n",
    "        axes[1, i].imshow(cam_resized, cmap=cmap, alpha=0.5, vmin=0, vmax=1)\n",
    "        axes[1, i].set_title(f'Predicted: {predicted_age} years\\nConfidence: {confidence:.2%}', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        print(f\"Image {i+1}: True={true_age}y, Predicted={predicted_age}y, Confidence={confidence:.1%}\")\n",
    "    \n",
    "    plt.suptitle('Deer Age Classification: Feature Importance Visualization', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a colorbar legend\n",
    "    fig, ax = plt.subplots(figsize=(8, 1))\n",
    "    gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "    ax.imshow(gradient, aspect='auto', cmap=cmap)\n",
    "    ax.set_xlim(0, 256)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([0, 64, 128, 192, 256])\n",
    "    ax.set_xticklabels(['Low', 'Medium-Low', 'Medium', 'Medium-High', 'High'])\n",
    "    ax.set_xlabel('Feature Importance for Age Prediction')\n",
    "    ax.set_title('Grad-CAM Heatmap Legend: Red = High Importance, Blue = Low Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_feature_patterns(model, X_test, y_test, label_mapping, samples_per_age=3):\n",
    "    \"\"\"\n",
    "    Analyze what features the model focuses on for each age group\n",
    "    \"\"\"\n",
    "    # Convert one-hot to class indices if needed\n",
    "    if len(y_test.shape) == 2:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    class_to_age = {v: k for k, v in label_mapping.items()}\n",
    "    grad_cam = GradCAM(model, target_layer_name='features.8.2.block.2')\n",
    "    \n",
    "    print(\"🔍 ANALYZING FEATURE PATTERNS BY AGE GROUP\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Group images by age\n",
    "    age_groups = {}\n",
    "    for i, label in enumerate(y_test):\n",
    "        age = class_to_age[label]\n",
    "        if age not in age_groups:\n",
    "            age_groups[age] = []\n",
    "        age_groups[age].append(i)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    for age in sorted(age_groups.keys()):\n",
    "        print(f\"\\n📊 AGE GROUP: {age} YEARS\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Sample images from this age group\n",
    "        indices = np.random.choice(age_groups[age], min(samples_per_age, len(age_groups[age])), replace=False)\n",
    "        \n",
    "        cam_averages = []\n",
    "        \n",
    "        for idx in indices:\n",
    "            # Prepare image\n",
    "            original_image = X_test[idx]\n",
    "            image_tensor = torch.FloatTensor(original_image).permute(2, 0, 1).unsqueeze(0)\n",
    "            image_tensor = image_tensor.to(device)\n",
    "            image_tensor = F.interpolate(image_tensor, size=(384, 384), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Normalize\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
    "            image_tensor = (image_tensor - mean) / std\n",
    "            \n",
    "            # Generate CAM\n",
    "            cam, prediction = grad_cam.generate_cam(image_tensor)\n",
    "            predicted_class = np.argmax(prediction[0])\n",
    "            predicted_age = class_to_age[predicted_class]\n",
    "            confidence = F.softmax(torch.tensor(prediction[0]), dim=0)[predicted_class].item()\n",
    "            \n",
    "            cam_averages.append(cam)\n",
    "            \n",
    "            print(f\"   Sample {len(cam_averages)}: Predicted {predicted_age}y (confidence: {confidence:.1%})\")\n",
    "        \n",
    "        # Calculate average attention pattern for this age group\n",
    "        avg_cam = np.mean(cam_averages, axis=0)\n",
    "        \n",
    "        # Analyze where the model focuses\n",
    "        height, width = avg_cam.shape\n",
    "        \n",
    "        # Divide image into regions and calculate average attention\n",
    "        regions = {\n",
    "            'Top (Head/Antlers)': avg_cam[:height//3, :].mean(),\n",
    "            'Middle (Body)': avg_cam[height//3:2*height//3, :].mean(), \n",
    "            'Bottom (Legs)': avg_cam[2*height//3:, :].mean(),\n",
    "            'Left Side': avg_cam[:, :width//2].mean(),\n",
    "            'Right Side': avg_cam[:, width//2:].mean(),\n",
    "            'Center': avg_cam[height//4:3*height//4, width//4:3*width//4].mean()\n",
    "        }\n",
    "        \n",
    "        print(f\"   🎯 Key focus areas:\")\n",
    "        for region, attention in sorted(regions.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"      {region}: {attention:.3f}\")\n",
    "\n",
    "def run_gradcam_analysis(X_test, y_test, label_mapping, model_path='best_deer_efficientnet.pth'):\n",
    "    \"\"\"\n",
    "    Complete pipeline to load model and run Grad-CAM analysis\n",
    "    \n",
    "    Args:\n",
    "        X_test: Test images\n",
    "        y_test: True labels\n",
    "        label_mapping: Age to class mapping dict\n",
    "        model_path: Path to saved model weights\n",
    "    \"\"\"\n",
    "    print(\"🦌 DEER AGE CLASSIFICATION: GRAD-CAM FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = load_trained_model(model_path, num_classes=len(label_mapping))\n",
    "    \n",
    "    # Run Grad-CAM visualization\n",
    "    print(\"\\n📸 Generating Grad-CAM visualizations...\")\n",
    "    visualize_deer_features(model, X_test, y_test, label_mapping, num_images=6)\n",
    "    \n",
    "    # Analyze patterns by age group\n",
    "    print(\"\\n🔍 Analyzing feature patterns by age group...\")\n",
    "    analyze_feature_patterns(model, X_test, y_test, label_mapping, samples_per_age=3)\n",
    "    \n",
    "    print(\"\\n✅ Grad-CAM analysis complete!\")\n",
    "    print(\"\\nKey insights to look for:\")\n",
    "    print(\"🔍 Young deer (1.5-2.5y): Model may focus on body size, facial features\")\n",
    "    print(\"🔍 Middle-aged (3.5y): Model may focus on antler development, body mass\")  \n",
    "    print(\"🔍 Older deer (4.5-5.5y): Model may focus on antler size, body structure\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# USAGE: Run this after training to analyze your saved model\n",
    "model = run_gradcam_analysis(X_test, y_true, label_mapping, 'best_deer_efficientnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d069baa4-1877-4af5-af40-80130e7a3711",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦌 DEER AGE CLASSIFICATION: CORRECTED MODEL EVALUATION\n",
      "======================================================================\n",
      "🔧 Using CORRECT preprocessing (no ImageNet normalization)\n",
      "   This matches what your model was actually trained on!\n",
      "🔄 Loading trained model from best_deer_efficientnet.pth...\n",
      "✅ Model loaded successfully on cuda\n",
      "🎯 EVALUATING MODEL ON TEST SET - CORRECTED PREPROCESSING\n",
      "============================================================\n",
      "Test set size: 72 images\n",
      "Number of classes: 5\n",
      "Age mapping: {np.float64(1.5): 0, np.float64(2.5): 1, np.float64(3.5): 2, np.float64(4.5): 3, np.float64(5.5): 4}\n",
      "Class to age: {0: np.float64(1.5), 1: np.float64(2.5), 2: np.float64(3.5), 3: np.float64(4.5), 4: np.float64(5.5)}\n",
      "\n",
      "🔄 Making predictions with CORRECT preprocessing...\n",
      "   ✅ Using raw 0-1 normalized pixels (NO ImageNet normalization)\n",
      "   Processed 16/72 images...\n",
      "✅ Predictions complete!\n",
      "\n",
      "📊 CALCULATING METRICS\n",
      "------------------------------\n",
      "🎯 Test Accuracy: 0.5556 (55.56%)\n",
      "📈 F1 Score (Macro): 0.5487\n",
      "📈 F1 Score (Weighted): 0.5449\n",
      "📈 F1 Score (Micro): 0.5556\n",
      "\n",
      "📋 DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   1.5 years       0.71      0.45      0.56        11\n",
      "   2.5 years       0.62      0.77      0.69        13\n",
      "   3.5 years       0.56      0.33      0.42        15\n",
      "   4.5 years       0.75      0.40      0.52        15\n",
      "   5.5 years       0.44      0.78      0.56        18\n",
      "\n",
      "    accuracy                           0.56        72\n",
      "   macro avg       0.62      0.55      0.55        72\n",
      "weighted avg       0.60      0.56      0.54        72\n",
      "\n",
      "\n",
      "🔍 CONFUSION MATRIX:\n",
      "Predicted →\n",
      "True ↓     1.5   2.5   3.5   4.5   5.5\n",
      " 1.5        5    3    1    0    2\n",
      " 2.5        1   10    0    0    2\n",
      " 3.5        1    2    5    0    7\n",
      " 4.5        0    0    2    6    7\n",
      " 5.5        0    1    1    2   14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🦌 AGE-SPECIFIC ANALYSIS:\n",
      "------------------------------\n",
      "Age 1.5 years (11 samples):\n",
      "   Accuracy: 0.455 (45.5%)\n",
      "   Precision: 0.714\n",
      "   Recall: 0.455\n",
      "   F1-Score: 0.556\n",
      "Age 2.5 years (13 samples):\n",
      "   Accuracy: 0.769 (76.9%)\n",
      "   Precision: 0.625\n",
      "   Recall: 0.769\n",
      "   F1-Score: 0.690\n",
      "Age 3.5 years (15 samples):\n",
      "   Accuracy: 0.333 (33.3%)\n",
      "   Precision: 0.556\n",
      "   Recall: 0.333\n",
      "   F1-Score: 0.417\n",
      "Age 4.5 years (15 samples):\n",
      "   Accuracy: 0.400 (40.0%)\n",
      "   Precision: 0.750\n",
      "   Recall: 0.400\n",
      "   F1-Score: 0.522\n",
      "Age 5.5 years (18 samples):\n",
      "   Accuracy: 0.778 (77.8%)\n",
      "   Precision: 0.438\n",
      "   Recall: 0.778\n",
      "   F1-Score: 0.560\n",
      "\n",
      "🎯 TOLERANCE-BASED ACCURACY:\n",
      "------------------------------\n",
      "Exact age accuracy: 0.556 (55.6%)\n",
      "Within ±1 year accuracy: 0.792 (79.2%)\n",
      "\n",
      "📊 PREDICTION DISTRIBUTION:\n",
      "------------------------------\n",
      "   Predicted 1.5 years: 7 times (9.7%)\n",
      "   Predicted 2.5 years: 16 times (22.2%)\n",
      "   Predicted 3.5 years: 9 times (12.5%)\n",
      "   Predicted 4.5 years: 8 times (11.1%)\n",
      "   Predicted 5.5 years: 32 times (44.4%)\n",
      "\n",
      "🔍 SAMPLE PREDICTIONS:\n",
      "------------------------------\n",
      "✅ Sample 1: True 5.5y → Predicted 5.5y (confidence: 100.00%)\n",
      "✅ Sample 2: True 5.5y → Predicted 5.5y (confidence: 100.00%)\n",
      "❌ Sample 3: True 4.5y → Predicted 5.5y (confidence: 67.31%)\n",
      "❌ Sample 4: True 3.5y → Predicted 5.5y (confidence: 99.75%)\n",
      "❌ Sample 5: True 4.5y → Predicted 5.5y (confidence: 87.34%)\n",
      "❌ Sample 6: True 3.5y → Predicted 2.5y (confidence: 88.21%)\n",
      "✅ Sample 7: True 4.5y → Predicted 4.5y (confidence: 84.91%)\n",
      "✅ Sample 8: True 1.5y → Predicted 1.5y (confidence: 100.00%)\n",
      "❌ Sample 9: True 4.5y → Predicted 5.5y (confidence: 99.95%)\n",
      "✅ Sample 10: True 4.5y → Predicted 4.5y (confidence: 100.00%)\n",
      "✅ Sample 11: True 1.5y → Predicted 1.5y (confidence: 99.98%)\n",
      "✅ Sample 12: True 5.5y → Predicted 5.5y (confidence: 85.33%)\n",
      "❌ Sample 13: True 4.5y → Predicted 3.5y (confidence: 98.99%)\n",
      "✅ Sample 14: True 5.5y → Predicted 5.5y (confidence: 100.00%)\n",
      "❌ Sample 15: True 4.5y → Predicted 5.5y (confidence: 99.99%)\n",
      "\n",
      "✅ CORRECTED EVALUATION COMPLETE!\n",
      "📊 Final Results Summary:\n",
      "   Test Accuracy: 0.556 (55.6%)\n",
      "   F1 Score (Macro): 0.549\n",
      "   F1 Score (Weighted): 0.545\n",
      "   Exact Age Accuracy: 0.556 (55.6%)\n",
      "   Within ±1 Year Accuracy: 0.792 (79.2%)\n"
     ]
    }
   ],
   "source": [
    "# Corrected model test\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_trained_model(model_path='best_deer_efficientnet.pth', num_classes=5):\n",
    "    \"\"\"\n",
    "    Load the saved deer age classification model\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Loading trained model from {model_path}...\")\n",
    "    \n",
    "    # Recreate the model architecture (same as in training)\n",
    "    model = timm.create_model(\n",
    "        'efficientnet_b4',\n",
    "        pretrained=False,  # Don't download pretrained weights\n",
    "        num_classes=num_classes,\n",
    "        drop_rate=0.3,\n",
    "        drop_path_rate=0.2\n",
    "    )\n",
    "    \n",
    "    # Replace classifier (same as in training)\n",
    "    in_features = model.classifier.in_features\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(p=0.4, inplace=True),\n",
    "        torch.nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Load the saved weights\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✅ Model loaded successfully on {device}\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model_correct_preprocessing(model, X_test, y_test, label_mapping):\n",
    "    \"\"\"\n",
    "    Evaluate model with CORRECT preprocessing (no ImageNet normalization)\n",
    "    \"\"\"\n",
    "    print(\"🎯 EVALUATING MODEL ON TEST SET - CORRECTED PREPROCESSING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Convert one-hot to class indices if needed\n",
    "    if len(y_test.shape) == 2:\n",
    "        print(f\"Converting one-hot labels {y_test.shape} to class indices...\")\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        print(f\"✅ Labels now: {y_test.shape}\")\n",
    "    \n",
    "    # Create reverse mapping\n",
    "    class_to_age = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    print(f\"Test set size: {len(X_test)} images\")\n",
    "    print(f\"Number of classes: {len(label_mapping)}\")\n",
    "    print(f\"Age mapping: {label_mapping}\")\n",
    "    print(f\"Class to age: {class_to_age}\")\n",
    "    \n",
    "    # Get device\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    print(\"\\n🔄 Making predictions with CORRECT preprocessing...\")\n",
    "    print(\"   ✅ Using raw 0-1 normalized pixels (NO ImageNet normalization)\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Process in batches to avoid memory issues\n",
    "        batch_size = 16\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_end = min(i + batch_size, len(X_test))\n",
    "            batch_images = X_test[i:batch_end]\n",
    "            \n",
    "            # Convert to tensor - same as training\n",
    "            batch_tensor = torch.FloatTensor(batch_images).permute(0, 3, 1, 2).to(device)\n",
    "            \n",
    "            # Resize to model input size (384x384 for EfficientNet-B4)\n",
    "            batch_tensor = F.interpolate(batch_tensor, size=(384, 384), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # ✅ NO IMAGENET NORMALIZATION - just use raw 0-1 pixel values\n",
    "            # This matches what your model was actually trained on!\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = model(batch_tensor)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            predicted_classes = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            # Convert to Python lists\n",
    "            all_predictions.extend(predicted_classes.tolist())\n",
    "            all_probabilities.extend(probabilities.tolist())\n",
    "            \n",
    "            if i % (batch_size * 5) == 0:\n",
    "                print(f\"   Processed {batch_end}/{len(X_test)} images...\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_pred = np.array(all_predictions)\n",
    "    y_proba = np.array(all_probabilities)\n",
    "    \n",
    "    print(f\"✅ Predictions complete!\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"\\n📊 CALCULATING METRICS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"🎯 Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # F1 Scores\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    print(f\"📈 F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"📈 F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "    print(f\"📈 F1 Score (Micro): {f1_micro:.4f}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    print(f\"\\n📋 DETAILED CLASSIFICATION REPORT:\")\n",
    "    age_labels = [class_to_age[i] for i in range(len(label_mapping))]\n",
    "    target_names = [f\"{age} years\" for age in age_labels]\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(f\"\\n🔍 CONFUSION MATRIX:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"Predicted →\")\n",
    "    print(\"True ↓   \", \"  \".join([f\"{age:4.1f}\" for age in age_labels]))\n",
    "    for i, age in enumerate(age_labels):\n",
    "        row_str = \" \".join([f\"{cm[i][j]:4d}\" for j in range(len(age_labels))])\n",
    "        print(f\"{age:4.1f}     {row_str}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[f\"{age}y\" for age in age_labels],\n",
    "                yticklabels=[f\"{age}y\" for age in age_labels])\n",
    "    plt.title('Confusion Matrix - Deer Age Classification (Corrected)')\n",
    "    plt.xlabel('Predicted Age')\n",
    "    plt.ylabel('True Age')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Age-based accuracy analysis\n",
    "    print(f\"\\n🦌 AGE-SPECIFIC ANALYSIS:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for class_idx in range(len(label_mapping)):\n",
    "        age = class_to_age[class_idx]\n",
    "        \n",
    "        # Get indices for this age class\n",
    "        true_class_mask = (y_test == class_idx)\n",
    "        if np.sum(true_class_mask) > 0:\n",
    "            class_accuracy = np.sum((y_test == class_idx) & (y_pred == class_idx)) / np.sum(true_class_mask)\n",
    "            class_count = np.sum(true_class_mask)\n",
    "            class_f1 = report[f\"{age} years\"]['f1-score']\n",
    "            class_precision = report[f\"{age} years\"]['precision']\n",
    "            class_recall = report[f\"{age} years\"]['recall']\n",
    "            \n",
    "            print(f\"Age {age} years ({class_count} samples):\")\n",
    "            print(f\"   Accuracy: {class_accuracy:.3f} ({class_accuracy*100:.1f}%)\")\n",
    "            print(f\"   Precision: {class_precision:.3f}\")\n",
    "            print(f\"   Recall: {class_recall:.3f}\")\n",
    "            print(f\"   F1-Score: {class_f1:.3f}\")\n",
    "    \n",
    "    # Tolerance-based accuracy\n",
    "    print(f\"\\n🎯 TOLERANCE-BASED ACCURACY:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Convert class indices back to actual ages\n",
    "    y_test_ages = [class_to_age[idx] for idx in y_test]\n",
    "    y_pred_ages = [class_to_age[idx] for idx in y_pred]\n",
    "    \n",
    "    exact_matches = sum(1 for true, pred in zip(y_test_ages, y_pred_ages) if true == pred)\n",
    "    within_1_year = sum(1 for true, pred in zip(y_test_ages, y_pred_ages) if abs(true - pred) <= 1.0)\n",
    "    \n",
    "    exact_accuracy = exact_matches / len(y_test_ages)\n",
    "    tolerance_accuracy = within_1_year / len(y_test_ages)\n",
    "    \n",
    "    print(f\"Exact age accuracy: {exact_accuracy:.3f} ({exact_accuracy*100:.1f}%)\")\n",
    "    print(f\"Within ±1 year accuracy: {tolerance_accuracy:.3f} ({tolerance_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    # Show prediction distribution\n",
    "    print(f\"\\n📊 PREDICTION DISTRIBUTION:\")\n",
    "    print(\"-\" * 30)\n",
    "    pred_counts = {}\n",
    "    for pred in y_pred:\n",
    "        age = class_to_age[pred]\n",
    "        pred_counts[age] = pred_counts.get(age, 0) + 1\n",
    "    \n",
    "    for age in sorted(pred_counts.keys()):\n",
    "        count = pred_counts[age]\n",
    "        print(f\"   Predicted {age} years: {count} times ({count/len(y_pred)*100:.1f}%)\")\n",
    "    \n",
    "    # Show some example predictions\n",
    "    print(f\"\\n🔍 SAMPLE PREDICTIONS:\")\n",
    "    print(\"-\" * 30)\n",
    "    for i in range(min(15, len(y_test))):\n",
    "        true_age = y_test_ages[i]\n",
    "        pred_age = y_pred_ages[i]\n",
    "        confidence = max(y_proba[i])\n",
    "        status = \"✅\" if true_age == pred_age else \"❌\"\n",
    "        print(f\"{status} Sample {i+1}: True {true_age}y → Predicted {pred_age}y (confidence: {confidence:.2%})\")\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_micro': f1_micro,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_proba,\n",
    "        'exact_accuracy': exact_accuracy,\n",
    "        'tolerance_accuracy': tolerance_accuracy\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_corrected_evaluation(X_test, y_test, label_mapping, model_path='best_deer_efficientnet.pth'):\n",
    "    \"\"\"\n",
    "    Complete corrected evaluation pipeline\n",
    "    \"\"\"\n",
    "    print(\"🦌 DEER AGE CLASSIFICATION: CORRECTED MODEL EVALUATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🔧 Using CORRECT preprocessing (no ImageNet normalization)\")\n",
    "    print(\"   This matches what your model was actually trained on!\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = load_trained_model(model_path, num_classes=len(label_mapping))\n",
    "    \n",
    "    # Evaluate the model with correct preprocessing\n",
    "    results = evaluate_model_correct_preprocessing(model, X_test, y_test, label_mapping)\n",
    "    \n",
    "    print(\"\\n✅ CORRECTED EVALUATION COMPLETE!\")\n",
    "    print(f\"📊 Final Results Summary:\")\n",
    "    print(f\"   Test Accuracy: {results['accuracy']:.3f} ({results['accuracy']*100:.1f}%)\")\n",
    "    print(f\"   F1 Score (Macro): {results['f1_macro']:.3f}\")\n",
    "    print(f\"   F1 Score (Weighted): {results['f1_weighted']:.3f}\")\n",
    "    print(f\"   Exact Age Accuracy: {results['exact_accuracy']:.3f} ({results['exact_accuracy']*100:.1f}%)\")\n",
    "    print(f\"   Within ±1 Year Accuracy: {results['tolerance_accuracy']:.3f} ({results['tolerance_accuracy']*100:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the CORRECTED evaluation\n",
    "results = run_corrected_evaluation(X_test, y_true, label_mapping, 'best_deer_efficientnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502ac84-f86f-49be-8aec-250cb172d572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from buck.classifiers.autotune import optimize_all\n",
    "\n",
    "optimize_all(X_train, y_train, X_test, y_true, cycles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7cf56a3-aa39-4b27-8b8f-5d331b384397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df423936-fa42-4599-9dfd-ee63284ba61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
