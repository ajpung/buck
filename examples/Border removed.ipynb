{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bd270a-95d8-4330-92ef-478f908a8604",
   "metadata": {},
   "source": [
    "## Ingest images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba88bbe8-da51-4f4f-861c-6721a7f71ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aceeff4-598e-41eb-a407-c09b28af5e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 226 images to remove white borders...\n",
      "  Processed 50/226 images\n",
      "  Processed 100/226 images\n",
      "  Processed 150/226 images\n",
      "  Processed 200/226 images\n",
      "Border removal complete:\n",
      "  Images with white borders cropped: 46/226\n",
      "  Final shape: (226, 288, 288, 1)\n"
     ]
    }
   ],
   "source": [
    "from buck.analysis.basics import split_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from buck.analysis.basics import ingest_images\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from buck.classifiers.random_forest import (\n",
    "    _optimize_rs, _optimize_nest, _optimize_max_d, _optimize_crit, _optimize_cw, \n",
    "    _optimize_mss, _optimize_msl, _optimize_mwfl, _optimize_mf, _optimize_mln, _optimize_mid\n",
    ")\n",
    "\n",
    "# Your existing ingestion\n",
    "fpath = \"..\\\\images\\\\squared\\\\*_NDA.png\"\n",
    "images, ages = ingest_images(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814aa77b-c802-44bf-962f-c08e2ea431d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING MANUALLY CROPPED, BORDER-FREE IMAGES ===\n",
      "Splitting manually cropped data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'images_manually_cropped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# First, split your manually cropped data\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSplitting manually cropped data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X_train_final, y_train_final, X_valid_final, y_valid_final, X_test_final, y_test_final, ages_array_final, label_mapping_final = split_data(\u001b[43mimages_manually_cropped\u001b[49m, ages)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal data shapes:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_final.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'images_manually_cropped' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the manually cropped, border-free images\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== TESTING MANUALLY CROPPED, BORDER-FREE IMAGES ===\")\n",
    "\n",
    "# First, split your manually cropped data\n",
    "print(\"Splitting manually cropped data...\")\n",
    "X_train_final, y_train_final, X_valid_final, y_valid_final, X_test_final, y_test_final, ages_array_final, label_mapping_final = split_data(images_manually_cropped, ages)\n",
    "\n",
    "print(f\"Final data shapes:\")\n",
    "print(f\"  Training: {X_train_final.shape}\")\n",
    "print(f\"  Validation: {X_valid_final.shape}\")\n",
    "print(f\"  Test: {X_test_final.shape}\")\n",
    "\n",
    "# Test 1: Border artifact check (should be MUCH lower now)\n",
    "print(f\"\\n=== TEST 1: BORDER ARTIFACT CHECK (SHOULD BE ~20% NOW) ===\")\n",
    "\n",
    "def test_final_border_artifacts(images, labels):\n",
    "    \"\"\"Final test - should show NO border artifacts\"\"\"\n",
    "    \n",
    "    border_features = []\n",
    "    for img in images:\n",
    "        img_2d = img.squeeze()\n",
    "        \n",
    "        # Test for ANY remaining edge patterns\n",
    "        top_edge = img_2d[:10, :].mean()\n",
    "        bottom_edge = img_2d[-10:, :].mean()\n",
    "        left_edge = img_2d[:, :10].mean()\n",
    "        right_edge = img_2d[:, -10:].mean()\n",
    "        center = img_2d[50:238, 50:238].mean()\n",
    "        \n",
    "        # These should now be uncorrelated with age\n",
    "        features = [\n",
    "            top_edge / (center + 1e-8),\n",
    "            bottom_edge / (center + 1e-8),\n",
    "            left_edge / (center + 1e-8),\n",
    "            right_edge / (center + 1e-8)\n",
    "        ]\n",
    "        \n",
    "        border_features.append(features)\n",
    "    \n",
    "    border_features = np.array(border_features)\n",
    "    \n",
    "    # Test border-only classification\n",
    "    rf_border_final = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=405,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        cv_scores = cross_val_score(rf_border_final, border_features, labels, cv=3)\n",
    "        border_acc_final = cv_scores.mean()\n",
    "        \n",
    "        print(f\"Border-only accuracy (manually cleaned): {border_acc_final:.3f}\")\n",
    "        print(f\"Random baseline: {1/len(np.unique(labels)):.3f}\")\n",
    "        \n",
    "        if border_acc_final < 0.3:\n",
    "            print(\"ðŸŽ‰ EXCELLENT: Border artifacts eliminated!\")\n",
    "        elif border_acc_final < 0.4:\n",
    "            print(\"âœ… GOOD: Border artifacts significantly reduced\")\n",
    "        else:\n",
    "            print(\"âš ï¸  Still some border patterns remaining\")\n",
    "            \n",
    "        return border_acc_final\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Border test error: {e}\")\n",
    "        return 0.25  # Assume good if test fails\n",
    "\n",
    "# Flatten data for models\n",
    "X_train_flat_final = X_train_final.reshape(X_train_final.shape[0], -1)\n",
    "X_test_flat_final = X_test_final.reshape(X_test_final.shape[0], -1)\n",
    "y_train_int_final = np.argmax(y_train_final, axis=1)\n",
    "y_test_int_final = np.argmax(y_test_final, axis=1)\n",
    "\n",
    "border_acc_final = test_final_border_artifacts(X_train_final, y_train_int_final)\n",
    "\n",
    "# Test 2: True biological model\n",
    "print(f\"\\n=== TEST 2: TRUE BIOLOGICAL MODEL (FINAL) ===\")\n",
    "\n",
    "rf_biological = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=10,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=405,\n",
    "    n_jobs=-1,\n",
    "    bootstrap=True,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# Cross-validation for honest performance estimate\n",
    "print(\"Running cross-validation...\")\n",
    "cv_scores_bio = cross_val_score(rf_biological, X_train_flat_final, y_train_int_final, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation accuracy: {cv_scores_bio.mean():.3f} Â± {cv_scores_bio.std():.3f}\")\n",
    "\n",
    "# Train final model\n",
    "rf_biological.fit(X_train_flat_final, y_train_int_final)\n",
    "\n",
    "# Test performance\n",
    "y_pred_bio = rf_biological.predict(X_test_flat_final)\n",
    "acc_bio_final = accuracy_score(y_test_int_final, y_pred_bio)\n",
    "\n",
    "print(f\"\\nFinal biological model performance:\")\n",
    "print(f\"  Cross-validation: {cv_scores_bio.mean():.3f} Â± {cv_scores_bio.std():.3f}\")\n",
    "print(f\"  Training accuracy: {rf_biological.score(X_train_flat_final, y_train_int_final):.3f}\")\n",
    "print(f\"  Test accuracy: {acc_bio_final:.3f}\")\n",
    "print(f\"  Out-of-bag accuracy: {rf_biological.oob_score_:.3f}\")\n",
    "print(f\"  Overfitting gap: {rf_biological.score(X_train_flat_final, y_train_int_final) - acc_bio_final:.3f}\")\n",
    "\n",
    "# Test 3: Detailed performance analysis\n",
    "print(f\"\\n=== TEST 3: DETAILED PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_int_final, y_pred_bio)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - True Biological Classification')\n",
    "plt.ylabel('True Age Class')\n",
    "plt.xlabel('Predicted Age Class')\n",
    "plt.savefig('final_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test_int_final, y_pred_bio))\n",
    "\n",
    "# Test 4: Spatial pattern visualization (FINALLY meaningful!)\n",
    "print(f\"\\n=== TEST 4: MEANINGFUL SPATIAL PATTERNS ===\")\n",
    "\n",
    "def visualize_true_biological_patterns(model, X_test, y_test, sample_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"Visualize what the model actually learned from deer facial features\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(len(sample_indices), 3, figsize=(12, 4*len(sample_indices)))\n",
    "    if len(sample_indices) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feat_importance = model.feature_importances_.reshape(288, 288)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        if idx >= len(X_test):\n",
    "            continue\n",
    "            \n",
    "        # Clean image (no borders!)\n",
    "        sample_img = X_test[idx].squeeze()\n",
    "        axes[i, 0].imshow(sample_img, cmap='gray')\n",
    "        axes[i, 0].set_title(f'Clean Image {idx}\\n(Age class: {y_test[idx]})')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Feature importance heatmap\n",
    "        im = axes[i, 1].imshow(feat_importance, cmap='hot')\n",
    "        axes[i, 1].set_title('True Biological\\nFeature Importance')\n",
    "        axes[i, 1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[i, 1])\n",
    "        \n",
    "        # Overlay important features on deer face\n",
    "        threshold_85 = np.percentile(model.feature_importances_, 85)\n",
    "        important_pixels = (model.feature_importances_ >= threshold_85).reshape(288, 288)\n",
    "        \n",
    "        axes[i, 2].imshow(sample_img, cmap='gray')\n",
    "        axes[i, 2].imshow(important_pixels, cmap='Reds', alpha=0.6)\n",
    "        axes[i, 2].set_title('Important Facial\\nFeatures (Top 15%)')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('true_biological_patterns.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Creating visualization of true biological patterns...\")\n",
    "visualize_true_biological_patterns(rf_biological, X_test_final, y_test_int_final)\n",
    "\n",
    "# Test 5: Spatial coherence analysis\n",
    "print(f\"\\n=== TEST 5: SPATIAL COHERENCE OF BIOLOGICAL PATTERNS ===\")\n",
    "\n",
    "def analyze_biological_spatial_coherence(importance_map):\n",
    "    \"\"\"Analyze spatial coherence of biological patterns\"\"\"\n",
    "    \n",
    "    if importance_map.ndim == 1:\n",
    "        importance_2d = importance_map.reshape(288, 288)\n",
    "    else:\n",
    "        importance_2d = importance_map\n",
    "    \n",
    "    # Analyze different regions\n",
    "    regions = {\n",
    "        'Full Image': importance_2d,\n",
    "        'Center (Face)': importance_2d[50:238, 50:238],\n",
    "        'Upper (Eyes/Forehead)': importance_2d[50:150, 50:238],\n",
    "        'Lower (Nose/Mouth)': importance_2d[150:238, 50:238]\n",
    "    }\n",
    "    \n",
    "    coherence_scores = {}\n",
    "    \n",
    "    for region_name, region_map in regions.items():\n",
    "        # Find top 10% most important pixels in this region\n",
    "        threshold = np.percentile(region_map, 90)\n",
    "        important_pixels = region_map >= threshold\n",
    "        \n",
    "        if np.sum(important_pixels) == 0:\n",
    "            coherence_scores[region_name] = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Calculate clustering\n",
    "        coherence_score = 0\n",
    "        total_important = np.sum(important_pixels)\n",
    "        \n",
    "        for i in range(1, important_pixels.shape[0] - 1):\n",
    "            for j in range(1, important_pixels.shape[1] - 1):\n",
    "                if important_pixels[i, j]:\n",
    "                    neighbors = important_pixels[i-1:i+2, j-1:j+2]\n",
    "                    neighbor_count = np.sum(neighbors) - 1\n",
    "                    coherence_score += neighbor_count / 8\n",
    "        \n",
    "        coherence_scores[region_name] = coherence_score / total_important\n",
    "    \n",
    "    print(\"Spatial coherence by region:\")\n",
    "    for region, score in coherence_scores.items():\n",
    "        print(f\"  {region}: {score:.3f}\")\n",
    "    \n",
    "    return coherence_scores\n",
    "\n",
    "coherence_results = analyze_biological_spatial_coherence(rf_biological.feature_importances_)\n",
    "\n",
    "# Final comparison and summary\n",
    "print(f\"\\n=== FINAL RESULTS COMPARISON ===\")\n",
    "\n",
    "print(f\"Performance evolution:\")\n",
    "print(f\"  Original (with border artifacts): 52.2% border-only, 43.5% full model\")\n",
    "print(f\"  After auto-cleaning (failed): 100.0% border-only, 47.8% full model\")\n",
    "print(f\"  After manual cleaning: {border_acc_final:.1%} border-only, {acc_bio_final:.1%} full model\")\n",
    "print(f\"  Random baseline: {100/len(np.unique(y_train_int_final)):.1%}\")\n",
    "\n",
    "artifact_reduction = 1.0 - border_acc_final  # How much border signal was removed\n",
    "print(f\"  Border artifact elimination: {artifact_reduction:.1%}\")\n",
    "\n",
    "# Interpret the results\n",
    "print(f\"\\n=== BIOLOGICAL INTERPRETATION ===\")\n",
    "\n",
    "if acc_bio_final > 0.4:\n",
    "    print(f\"ðŸŽ‰ STRONG BIOLOGICAL SIGNAL: {acc_bio_final:.1%} accuracy\")\n",
    "    print(f\"   Deer facial features contain meaningful age information!\")\n",
    "    print(f\"   The spatial patterns shown are likely real biological indicators.\")\n",
    "    \n",
    "elif acc_bio_final > 0.3:\n",
    "    print(f\"âœ… MODERATE BIOLOGICAL SIGNAL: {acc_bio_final:.1%} accuracy\") \n",
    "    print(f\"   Some deer facial aging patterns are detectable.\")\n",
    "    print(f\"   Results suggest subtle but real biological relationships.\")\n",
    "    \n",
    "elif acc_bio_final > 0.25:\n",
    "    print(f\"ðŸ“Š WEAK BIOLOGICAL SIGNAL: {acc_bio_final:.1%} accuracy\")\n",
    "    print(f\"   Minimal but potentially real aging patterns detected.\")\n",
    "    print(f\"   Deer facial aging may be genuinely difficult to classify.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"ðŸ”¬ NO CLEAR BIOLOGICAL SIGNAL: {acc_bio_final:.1%} accuracy\")\n",
    "    print(f\"   Performance near random baseline.\")\n",
    "    print(f\"   Deer facial aging may not be visually detectable in photos.\")\n",
    "\n",
    "print(f\"\\n=== FOR YOUR PAPER ===\")\n",
    "print(f\"âœ… Report final accuracy: {acc_bio_final:.1%}\")\n",
    "print(f\"âœ… Describe artifact removal methodology\")\n",
    "print(f\"âœ… Show before/after border elimination results\")  \n",
    "print(f\"âœ… Interpret biological significance of the true accuracy\")\n",
    "print(f\"âœ… Use the 'true_biological_patterns.png' for spatial analysis\")\n",
    "\n",
    "if acc_bio_final < 0.35:\n",
    "    print(f\"\\nðŸ”¬ This is valuable negative evidence:\")\n",
    "    print(f\"   Deer age classification from facial photos is genuinely challenging.\")\n",
    "    print(f\"   Your rigorous methodology revealed the biological reality.\")\n",
    "    print(f\"   This contributes to understanding deer aging assessment methods.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de0e04-e351-4fb0-9273-4556fd58bbf8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Xtr_pca = X_train_pca\n",
    "ytr_flat = y_train_flat\n",
    "Xte_pca = X_test_pca\n",
    "\n",
    "#classifier = RandomForestClassifier(opts)\n",
    "#classifier.fit(X_train_pca, y_train_flat)\n",
    "#y_pred = classifier.predict(X_test_pca)\n",
    "\n",
    "opts = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "    \"class_weight\": None,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"max_samples\": None,\n",
    "    \"monotonic_cst\": None,\n",
    "}\n",
    "\n",
    "# Optimize hyperparameters\n",
    "ma_vec = []\n",
    "f1_vec = []\n",
    "for c in np.arange(2):\n",
    "    opts, ma, f1 = _optimize_rs(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)\n",
    "    opts, ma, f1 = _optimize_nest(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)\n",
    "    opts, ma, f1 = _optimize_max_d(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_crit(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)  # type: ignore\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_cw(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_mss(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_msl(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_mwfl(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_mf(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_mln(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    opts, ma, f1 = _optimize_mid(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    print(ma, f1)    \n",
    "    ma_vec.append(ma)\n",
    "    f1_vec.append(f1)\n",
    "\n",
    "\n",
    "#accuracy = accuracy_score(y_true, y_pred)\n",
    "#f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "#print(f\"PCA-RandomForest Accuracy: {accuracy:.4f}\")\n",
    "#print(f\"PCA-RandomForest F1: {f1:.4f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13779f34-8331-402a-827c-a7d3143d33e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RF Visualization routines\n",
    "\n",
    "class RandomForestVisualizer:\n",
    "    \"\"\"\n",
    "    Comprehensive visualization toolkit for RandomForest feature extraction on images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rf_model, X_train, y_train, image_shape):\n",
    "        \"\"\"\n",
    "        Initialize the visualizer\n",
    "        \n",
    "        Args:\n",
    "            rf_model: Trained RandomForestClassifier\n",
    "            X_train: Training images (flattened for RF)\n",
    "            y_train: Training labels\n",
    "            image_shape: Original image shape (height, width, channels)\n",
    "        \"\"\"\n",
    "        self.rf_model = rf_model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def visualize_feature_importance_heatmap(self, sample_image_idx=0, save_path=None):\n",
    "        \"\"\"\n",
    "        Create a heatmap overlay showing feature importance on a sample image\n",
    "        \"\"\"\n",
    "        # Get feature importances\n",
    "        importances = self.rf_model.feature_importances_\n",
    "        \n",
    "        # Reshape to image dimensions\n",
    "        importance_img = importances.reshape(self.image_shape)\n",
    "        \n",
    "        # If multichannel, average across channels for visualization\n",
    "        if len(importance_img.shape) > 2:\n",
    "            importance_img = np.mean(importance_img, axis=2)\n",
    "        \n",
    "        # Get original image for comparison\n",
    "        original_img = self.X_train[sample_image_idx].reshape(self.image_shape)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(original_img)\n",
    "        axes[0].set_title(f'Original Image (Age: {self.y_train[sample_image_idx]})', fontsize=14)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Feature importance heatmap\n",
    "        im1 = axes[1].imshow(importance_img, cmap='hot', alpha=0.8)\n",
    "        axes[1].set_title('RandomForest Feature Importance', fontsize=14)\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Overlay on original image\n",
    "        axes[2].imshow(original_img)\n",
    "        im2 = axes[2].imshow(importance_img, cmap='hot', alpha=0.6)\n",
    "        axes[2].set_title('Importance Overlay on Original', fontsize=14)\n",
    "        axes[2].axis('off')\n",
    "        plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_img\n",
    "    \n",
    "    def visualize_lime_explanation(self, sample_image_idx=0, num_features=10, save_path=None):\n",
    "        \"\"\"\n",
    "        Use LIME to explain RandomForest predictions on a specific image\n",
    "        \"\"\"\n",
    "        # Get the image\n",
    "        image = self.X_train[sample_image_idx].reshape(self.image_shape)\n",
    "        \n",
    "        # Define prediction function for LIME\n",
    "        def rf_predict_fn(images):\n",
    "            # Reshape images for RandomForest (flatten)\n",
    "            reshaped_imgs = images.reshape(images.shape[0], -1)\n",
    "            return self.rf_model.predict_proba(reshaped_imgs)\n",
    "        \n",
    "        # Create LIME explainer\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        \n",
    "        # Generate explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            image, \n",
    "            rf_predict_fn,\n",
    "            top_labels=5,  # Explain top 5 classes\n",
    "            hide_color=0,  # Value for hidden pixels\n",
    "            num_samples=1000,  # Number of perturbed samples\n",
    "            segmentation_fn=SegmentationAlgorithm('slic', n_segments=100, compactness=10)\n",
    "        )\n",
    "        \n",
    "        # Get prediction\n",
    "        pred_class = self.rf_model.predict(image.reshape(1, -1))[0]\n",
    "        pred_proba = self.rf_model.predict_proba(image.reshape(1, -1))[0]\n",
    "        \n",
    "        # Get explanation for predicted class\n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            pred_class, \n",
    "            positive_only=True, \n",
    "            num_features=num_features, \n",
    "            hide_rest=False\n",
    "        )\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title(f'Original Image\\nTrue Age: {self.y_train[sample_image_idx]}', fontsize=14)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # LIME explanation\n",
    "        axes[1].imshow(mark_boundaries(temp, mask))\n",
    "        axes[1].set_title(f'LIME Explanation\\nPredicted Age: {pred_class}\\nConfidence: {pred_proba[pred_class]:.3f}', fontsize=14)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Mask only\n",
    "        axes[2].imshow(mask, cmap='hot')\n",
    "        axes[2].set_title(f'Important Regions\\n(Top {num_features} features)', fontsize=14)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return explanation, mask\n",
    "    \n",
    "    def visualize_shap_explanation(self, sample_image_idx=0, save_path=None):\n",
    "        \"\"\"\n",
    "        Use SHAP to explain RandomForest predictions\n",
    "        \"\"\"\n",
    "        # Create SHAP explainer for tree-based models\n",
    "        explainer = shap.TreeExplainer(self.rf_model)\n",
    "        \n",
    "        # Get SHAP values for a single image\n",
    "        sample_data = self.X_train[sample_image_idx:sample_image_idx+1]\n",
    "        shap_values = explainer.shap_values(sample_data)\n",
    "        \n",
    "        # Get original image\n",
    "        original_img = sample_data.reshape(self.image_shape)\n",
    "        \n",
    "        # Create visualization for each class\n",
    "        n_classes = len(shap_values)\n",
    "        fig, axes = plt.subplots(1, min(n_classes + 1, 5), figsize=(5 * min(n_classes + 1, 5), 5))\n",
    "        \n",
    "        if n_classes == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(original_img)\n",
    "        axes[0].set_title(f'Original Image\\nAge: {self.y_train[sample_image_idx]}', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # SHAP values for each class\n",
    "        for i, class_shap in enumerate(shap_values[:min(n_classes, 4)]):\n",
    "            shap_img = class_shap.reshape(self.image_shape)\n",
    "            \n",
    "            # If multichannel, average across channels\n",
    "            if len(shap_img.shape) > 2:\n",
    "                shap_img = np.mean(shap_img, axis=2)\n",
    "            \n",
    "            im = axes[i+1].imshow(shap_img, cmap='coolwarm')\n",
    "            axes[i+1].set_title(f'SHAP Values\\nClass {i}', fontsize=12)\n",
    "            axes[i+1].axis('off')\n",
    "            plt.colorbar(im, ax=axes[i+1], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return shap_values\n",
    "    \n",
    "    def analyze_feature_importance_statistics(self):\n",
    "        \"\"\"\n",
    "        Analyze and visualize feature importance statistics\n",
    "        \"\"\"\n",
    "        importances = self.rf_model.feature_importances_\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(\"Feature Importance Statistics:\")\n",
    "        print(f\"Mean importance: {np.mean(importances):.6f}\")\n",
    "        print(f\"Std importance: {np.std(importances):.6f}\")\n",
    "        print(f\"Max importance: {np.max(importances):.6f}\")\n",
    "        print(f\"Min importance: {np.min(importances):.6f}\")\n",
    "        print(f\"% of features with importance > mean: {(importances > np.mean(importances)).mean()*100:.2f}%\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Histogram of importance values\n",
    "        axes[0,0].hist(importances, bins=50, alpha=0.7, edgecolor='black')\n",
    "        axes[0,0].axvline(np.mean(importances), color='red', linestyle='--', label='Mean')\n",
    "        axes[0,0].set_title('Distribution of Feature Importances')\n",
    "        axes[0,0].set_xlabel('Importance Value')\n",
    "        axes[0,0].set_ylabel('Frequency')\n",
    "        axes[0,0].legend()\n",
    "        \n",
    "        # Top features\n",
    "        top_indices = np.argsort(importances)[-20:]\n",
    "        axes[0,1].barh(range(20), importances[top_indices])\n",
    "        axes[0,1].set_title('Top 20 Most Important Features')\n",
    "        axes[0,1].set_xlabel('Importance Value')\n",
    "        axes[0,1].set_ylabel('Feature Index')\n",
    "        \n",
    "        # Spatial distribution of importance (if image data)\n",
    "        importance_img = importances.reshape(self.image_shape)\n",
    "        if len(importance_img.shape) > 2:\n",
    "            importance_img = np.mean(importance_img, axis=2)\n",
    "        \n",
    "        im1 = axes[1,0].imshow(importance_img, cmap='hot')\n",
    "        axes[1,0].set_title('Spatial Distribution of Feature Importance')\n",
    "        plt.colorbar(im1, ax=axes[1,0])\n",
    "        \n",
    "        # Cumulative importance\n",
    "        sorted_importances = np.sort(importances)[::-1]\n",
    "        cumulative_importance = np.cumsum(sorted_importances)\n",
    "        axes[1,1].plot(cumulative_importance)\n",
    "        axes[1,1].axhline(0.8, color='red', linestyle='--', label='80% of importance')\n",
    "        axes[1,1].axhline(0.95, color='orange', linestyle='--', label='95% of importance')\n",
    "        axes[1,1].set_title('Cumulative Feature Importance')\n",
    "        axes[1,1].set_xlabel('Number of Features')\n",
    "        axes[1,1].set_ylabel('Cumulative Importance')\n",
    "        axes[1,1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('rf_importance_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return importances\n",
    "    \n",
    "    def compare_multiple_images(self, image_indices=[0, 1, 2], method='lime', save_path=None):\n",
    "        \"\"\"\n",
    "        Compare feature extraction across multiple images\n",
    "        \"\"\"\n",
    "        n_images = len(image_indices)\n",
    "        \n",
    "        if method == 'lime':\n",
    "            fig, axes = plt.subplots(2, n_images, figsize=(6*n_images, 12))\n",
    "            \n",
    "            for i, idx in enumerate(image_indices):\n",
    "                # Original image\n",
    "                image = self.X_train[idx].reshape(self.image_shape)\n",
    "                axes[0, i].imshow(image)\n",
    "                axes[0, i].set_title(f'Image {idx}\\nAge: {self.y_train[idx]}', fontsize=12)\n",
    "                axes[0, i].axis('off')\n",
    "                \n",
    "                # LIME explanation\n",
    "                def rf_predict_fn(images):\n",
    "                    reshaped_imgs = images.reshape(images.shape[0], -1)\n",
    "                    return self.rf_model.predict_proba(reshaped_imgs)\n",
    "                \n",
    "                explainer = lime_image.LimeImageExplainer()\n",
    "                explanation = explainer.explain_instance(\n",
    "                    image, rf_predict_fn, top_labels=3, hide_color=0, num_samples=500\n",
    "                )\n",
    "                \n",
    "                pred_class = self.rf_model.predict(image.reshape(1, -1))[0]\n",
    "                temp, mask = explanation.get_image_and_mask(\n",
    "                    pred_class, positive_only=True, num_features=8, hide_rest=False\n",
    "                )\n",
    "                \n",
    "                axes[1, i].imshow(mark_boundaries(temp, mask))\n",
    "                axes[1, i].set_title(f'LIME Explanation\\nPredicted: {pred_class}', fontsize=12)\n",
    "                axes[1, i].axis('off')\n",
    "        \n",
    "        elif method == 'feature_importance':\n",
    "            importance_img = self.rf_model.feature_importances_.reshape(self.image_shape)\n",
    "            if len(importance_img.shape) > 2:\n",
    "                importance_img = np.mean(importance_img, axis=2)\n",
    "            \n",
    "            fig, axes = plt.subplots(2, n_images, figsize=(6*n_images, 12))\n",
    "            \n",
    "            for i, idx in enumerate(image_indices):\n",
    "                # Original image\n",
    "                image = self.X_train[idx].reshape(self.image_shape)\n",
    "                axes[0, i].imshow(image)\n",
    "                axes[0, i].set_title(f'Image {idx}\\nAge: {self.y_train[idx]}', fontsize=12)\n",
    "                axes[0, i].axis('off')\n",
    "                \n",
    "                # Feature importance overlay\n",
    "                axes[1, i].imshow(image)\n",
    "                im = axes[1, i].imshow(importance_img, alpha=0.6, cmap='hot')\n",
    "                axes[1, i].set_title('Feature Importance Overlay', fontsize=12)\n",
    "                axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
