{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2dad4-961a-479e-9619-1a78b5561d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAUNCHING COMPLETE DEER AGING PIPELINE...\n",
      "================================================================================\n",
      "Testing data loading before starting pipeline...\n",
      "TESTING DATA LOADING\n",
      "==================================================\n",
      "Current working directory: G:\\Dropbox\\AI Projects\\buck\\examples\n",
      "\n",
      "Testing path: G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\\*_NDA.png\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 89\n",
      "   Files found: 197\n",
      "   First few files: ['G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\111009_111009_KY_2p5_NDA.png', 'G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\171220_171220_MO_2p5_NDA.png', 'G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\171220_171220_MO_3p5_NDA.png']\n",
      "   This path works!\n",
      "\n",
      "Successfully imported buck.analysis.basics\n",
      "\n",
      "Testing ingest_images with: G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\\*_NDA.png\n",
      "ingest_images returned: 196 images, 196 ages\n",
      "Sample ages: [2.5, 2.5, 3.5, 2.5, 3.5]\n",
      "Age range: 1.5 to 12.5\n",
      "Unique ages: [1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 8.5, 12.5]\n",
      "Data loading test passed!\n",
      "\n",
      "Starting main pipeline...\n",
      "LAUNCHING COMPLETE DEER AGING PIPELINE\n",
      "================================================================================\n",
      "PIPELINE STEPS:\n",
      "   1. Load original 357 images\n",
      "   2. Create train/val/test splits\n",
      "   3. Balance and augment training data\n",
      "   4. Test all architectures (starting from EfficientNet-B5)\n",
      "   5. Save results and create leaderboard\n",
      "================================================================================\n",
      "CRASH RECOVERY: Progress saved after each model!\n",
      "Look for 'deer_aging_progress_*.txt' files for latest results\n",
      "JSON/pickle backups: 'deer_aging_backup_*.json/.pkl'\n",
      "================================================================================\n",
      "LOADING ORIGINAL DATA\n",
      "==================================================\n",
      "   Trying primary path: G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\\*_NDA.png\n",
      "   SUCCESS: Loaded 196 original images from: G:\\Dropbox\\AI Projects\\buck\\images\\squared\\color\\*_NDA.png\n",
      "   Grouping ages: 5.5+ -> 5.5\n",
      "   Original age distribution: {2.5: 36, 3.5: 35, 4.5: 52, 5.5: 32, 12.5: 1, 1.5: 30, 6.5: 6, 8.5: 4}\n",
      "   Grouped age distribution: {2.5: 36, 3.5: 35, 4.5: 52, 5.5: 43, 1.5: 30}\n",
      "\n",
      "CREATING TRAIN/VAL/TEST SPLIT\n",
      "==================================================\n",
      "   Age distribution: {np.float64(2.5): 36, np.float64(3.5): 35, np.float64(4.5): 52, np.float64(5.5): 43, np.float64(1.5): 30}\n",
      "   Minimum class size: 30\n",
      "   Can use stratified split: True\n",
      "   Train: 126 samples\n",
      "   Val: 30 samples\n",
      "   Test: 40 samples\n",
      "   Label mapping: {np.float64(1.5): 0, np.float64(2.5): 1, np.float64(3.5): 2, np.float64(4.5): 3, np.float64(5.5): 4}\n",
      "   Number of classes: 5\n",
      "   Train distribution: Counter({np.int64(3): 33, np.int64(4): 28, np.int64(2): 23, np.int64(1): 23, np.int64(0): 19})\n",
      "   Val distribution: Counter({np.int64(3): 8, np.int64(1): 6, np.int64(4): 6, np.int64(2): 5, np.int64(0): 5})\n",
      "   Test distribution: Counter({np.int64(3): 11, np.int64(4): 9, np.int64(1): 7, np.int64(2): 7, np.int64(0): 6})\n",
      "\n",
      "BALANCING AND AUGMENTING DATA\n",
      "==================================================\n",
      "   Target: 40x augmentation per class\n",
      "   Original distribution: {np.int64(4): 28, np.int64(2): 23, np.int64(3): 33, np.int64(0): 19, np.int64(1): 23}\n",
      "   Target samples per class: 1320\n",
      "   Class 0: 19 -> 1320 samples\n",
      "   Class 1: 23 -> 1320 samples\n",
      "   Class 2: 23 -> 1320 samples\n",
      "   Class 3: 33 -> 1320 samples\n",
      "   Class 4: 28 -> 1320 samples\n",
      "   Augmentation complete: 6600 total samples\n",
      "   Final distribution: Counter({np.int64(0): 1320, np.int64(1): 1320, np.int64(2): 1320, np.int64(3): 1320, np.int64(4): 1320})\n",
      "COMPLETE DEER AGE TRAINER\n",
      "   Device: cpu (CUDA not available)\n",
      "   Classes: 5\n",
      "   Max Parallel Models: 2\n",
      "   Mixed Precision: Disabled\n",
      "COMPLETE DEER AGING PIPELINE\n",
      "================================================================================\n",
      "Starting from EfficientNet-B5 onwards\n",
      "All results will be saved automatically\n",
      "================================================================================\n",
      "OPTIMIZATIONS:\n",
      "   Optimal batch size: 8\n",
      "   Num workers: 0\n",
      "   Pin memory: False\n",
      "   Max parallel models: 2\n",
      "Data ready: 6600 train, 30 val, 40 test\n",
      "\n",
      "COMPLETE ARCHITECTURE ARSENAL (28 models)\n",
      "================================================================================\n",
      "FALLBACK STRATEGY: Pretrained -> Alternative Names -> Random Init\n",
      "ALL models will be tested regardless of pretrained weight availability\n",
      "ResNeXt (2 models): ResNeXt-50, ResNeXt-101\n",
      "Wide-ResNet (2 models): Wide-ResNet-50, Wide-ResNet-101\n",
      "MobileNet (3 models): MobileNetV2, MobileNetV3-Small, MobileNetV3-Large\n",
      "RegNet (4 models): RegNetX-400MF, RegNetX-800MF, RegNetY-400MF, RegNetY-800MF\n",
      "ConvNeXt (3 models): ConvNeXt-Tiny, ConvNeXt-Small, ConvNeXt-Base\n",
      "Swin (2 models): Swin-Tiny, Swin-Small\n",
      "VGG (2 models): VGG-16, VGG-19\n",
      "DeiT (3 models): DeiT-Tiny, DeiT-Small, DeiT-Base\n",
      "EfficientNet (3 models): EfficientNet-ES, EfficientNet-EM, EfficientNet-EL\n",
      "ResNet (2 models): ResNet-26, ResNet-26d\n",
      "SEResNet (1 models): SEResNet-50\n",
      "SEResNeXt (1 models): SEResNeXt-50\n",
      "\n",
      "ULTRA AGGRESSIVE TESTING: 28 ARCHITECTURES\n",
      "================================================================================\n",
      "PARALLEL PROCESSING: 2 models at once\n",
      "\n",
      "PARALLEL BATCH: ['ResNeXt-50', 'ResNeXt-101']\n",
      "      FROZEN BACKBONE STRATEGY:      FROZEN BACKBONE STRATEGY:\n",
      "      Creating ResNeXt-101...\n",
      "         Trying pretrained: resnext101_32x8d\n",
      "\n",
      "      Creating ResNeXt-50...\n",
      "         Trying pretrained: resnext50_32x4d\n",
      "         SUCCESS with pretrained weights!\n",
      "         Freezing backbone layers...\n",
      "         Loaded: 22,990,149 total, 10,245 trainable (pretrained)\n",
      "      ULTRA AGGRESSIVE TRAINING: ResNeXt-50 (frozen)...\n",
      "         ULTRA SETUP: 50 epochs, LR=0.01, patience=25\n",
      "         Mixed Precision: Disabled\n",
      "         SUCCESS with pretrained weights!\n",
      "         Freezing backbone layers...\n",
      "         Loaded: 86,752,581 total, 10,245 trainable (pretrained)\n",
      "      ULTRA AGGRESSIVE TRAINING: ResNeXt-101 (frozen)...\n",
      "         ULTRA SETUP: 50 epochs, LR=0.01, patience=25\n",
      "         Mixed Precision: Disabled\n",
      "         Epoch   0: Train 20.5%, Val 6.7% (gap: +13.8%), LR: 1.00e-02 BEST\n",
      "           Batch 200/825: 21.8%"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import queue\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU OPTIMIZATION: Enable mixed precision training if available\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "\n",
    "# Fix Windows multiprocessing issues\n",
    "def fix_windows_multiprocessing():\n",
    "    if hasattr(mp, 'set_start_method'):\n",
    "        try:\n",
    "            mp.set_start_method('spawn', force=True)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "    \n",
    "    import torch.multiprocessing as tmp\n",
    "    tmp.set_sharing_strategy('file_system')\n",
    "\n",
    "def load_original_data():\n",
    "    \"\"\"Load the original 357 images\"\"\"\n",
    "    print(\"LOADING ORIGINAL DATA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        from buck.analysis.basics import ingest_images\n",
    "        \n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "        print(f\"   Trying primary path: {fpath}\")\n",
    "        \n",
    "        images, ages = ingest_images(fpath)\n",
    "        \n",
    "        print(f\"   SUCCESS: Loaded {len(images)} original images from: {fpath}\")\n",
    "        \n",
    "        print(\"   Grouping ages: 5.5+ -> 5.5\")\n",
    "        ages_grouped = []\n",
    "        for age in ages:\n",
    "            if age >= 5.5:\n",
    "                ages_grouped.append(5.5)\n",
    "            else:\n",
    "                ages_grouped.append(age)\n",
    "        \n",
    "        if len(ages_grouped) == 0:\n",
    "            print(\"   ERROR: No ages remaining after grouping\")\n",
    "            raise ValueError(\"No ages remaining after grouping\")\n",
    "        \n",
    "        print(f\"   Original age distribution: {dict(Counter(ages))}\")\n",
    "        print(f\"   Grouped age distribution: {dict(Counter(ages_grouped))}\")\n",
    "        \n",
    "        return images, ages_grouped\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"   ERROR: Cannot import buck.analysis.basics: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_train_val_test_split(images, ages, test_size=0.2, val_size=0.15, random_state=42):\n",
    "    \"\"\"Create train/validation/test split\"\"\"\n",
    "    print(\"\\nCREATING TRAIN/VAL/TEST SPLIT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(images) == 0 or len(ages) == 0:\n",
    "        print(f\"   ERROR: Empty input data - images: {len(images)}, ages: {len(ages)}\")\n",
    "        raise ValueError(\"Input data is empty\")\n",
    "    \n",
    "    if len(images) != len(ages):\n",
    "        print(f\"   ERROR: Mismatched data lengths - images: {len(images)}, ages: {len(ages)}\")\n",
    "        raise ValueError(\"Images and ages must have the same length\")\n",
    "    \n",
    "    if not isinstance(images, np.ndarray):\n",
    "        images = np.array(images)\n",
    "    if not isinstance(ages, np.ndarray):\n",
    "        ages = np.array(ages)\n",
    "    \n",
    "    age_counts = Counter(ages)\n",
    "    \n",
    "    if len(age_counts) == 0:\n",
    "        print(f\"   ERROR: No age data found\")\n",
    "        raise ValueError(\"Age counter is empty\")\n",
    "    \n",
    "    min_count = min(age_counts.values())\n",
    "    can_stratify = min_count >= 2\n",
    "    \n",
    "    print(f\"   Age distribution: {dict(age_counts)}\")\n",
    "    print(f\"   Minimum class size: {min_count}\")\n",
    "    print(f\"   Can use stratified split: {can_stratify}\")\n",
    "    \n",
    "    if can_stratify:\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            images, ages, test_size=test_size, random_state=random_state, stratify=ages\n",
    "        )\n",
    "        \n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_size_adjusted, random_state=random_state, stratify=y_temp\n",
    "        )\n",
    "    else:\n",
    "        print(\"   WARNING: Using random split (some classes too small for stratification)\")\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            images, ages, test_size=test_size, random_state=random_state, shuffle=True\n",
    "        )\n",
    "        \n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_size_adjusted, random_state=random_state, shuffle=True\n",
    "        )\n",
    "    \n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    reverse_mapping = {i: age for age, i in label_mapping.items()}\n",
    "    \n",
    "    print(f\"   Train: {len(X_train)} samples\")\n",
    "    print(f\"   Val: {len(X_val)} samples\") \n",
    "    print(f\"   Test: {len(X_test)} samples\")\n",
    "    print(f\"   Label mapping: {label_mapping}\")\n",
    "    print(f\"   Number of classes: {len(unique_ages)}\")\n",
    "    \n",
    "    y_train_indices = np.array([label_mapping[age] for age in y_train])\n",
    "    y_val_indices = np.array([label_mapping[age] for age in y_val])\n",
    "    y_test_indices = np.array([label_mapping[age] for age in y_test])\n",
    "    \n",
    "    print(f\"   Train distribution: {Counter(y_train_indices)}\")\n",
    "    print(f\"   Val distribution: {Counter(y_val_indices)}\")\n",
    "    print(f\"   Test distribution: {Counter(y_test_indices)}\")\n",
    "    \n",
    "    return (X_train, y_train_indices, X_val, y_val_indices, X_test, y_test_indices, \n",
    "            label_mapping, reverse_mapping)\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Apply random augmentation to an image\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        alpha = random.uniform(0.8, 1.2)\n",
    "        beta = random.randint(-20, 20)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 5, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def balance_and_augment_data(X_train, y_train, augment_multiplier=40, num_classes=5):\n",
    "    \"\"\"Balance classes and augment training data\"\"\"\n",
    "    print(f\"\\nBALANCING AND AUGMENTING DATA\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"   Target: {augment_multiplier}x augmentation per class\")\n",
    "    \n",
    "    class_counts = Counter(y_train)\n",
    "    print(f\"   Original distribution: {dict(class_counts)}\")\n",
    "    \n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max_count * augment_multiplier\n",
    "    print(f\"   Target samples per class: {target_count}\")\n",
    "    \n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        class_labels = y_train[class_mask]\n",
    "        \n",
    "        current_count = len(class_images)\n",
    "        needed_count = target_count\n",
    "        \n",
    "        print(f\"   Class {class_idx}: {current_count} -> {needed_count} samples\")\n",
    "        \n",
    "        X_augmented.extend(class_images)\n",
    "        y_augmented.extend(class_labels)\n",
    "        \n",
    "        augmented_needed = needed_count - current_count\n",
    "        \n",
    "        for i in range(augmented_needed):\n",
    "            original_idx = random.randint(0, current_count - 1)\n",
    "            original_image = class_images[original_idx].copy()\n",
    "            \n",
    "            augmented_image = augment_image(original_image)\n",
    "            \n",
    "            X_augmented.append(augmented_image)\n",
    "            y_augmented.append(class_idx)\n",
    "    \n",
    "    X_augmented = np.array(X_augmented)\n",
    "    y_augmented = np.array(y_augmented)\n",
    "    \n",
    "    print(f\"   Augmentation complete: {len(X_augmented)} total samples\")\n",
    "    print(f\"   Final distribution: {Counter(y_augmented)}\")\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    \"\"\"Dataset for deer aging with preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, transform=True):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            self.X = torch.FloatTensor(X)\n",
    "        else:\n",
    "            self.X = torch.FloatTensor(np.array(X))\n",
    "            \n",
    "        if isinstance(y, np.ndarray):\n",
    "            self.y = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.y = torch.LongTensor(np.array(y))\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != (224, 224):\n",
    "            image = image.unsqueeze(0)\n",
    "            image = F.interpolate(image, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            image = image.squeeze(0)\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def get_optimal_batch_size(device):\n",
    "    \"\"\"Determine optimal batch size based on device\"\"\"\n",
    "    if device.type == 'cuda':\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        if gpu_memory >= 16:\n",
    "            return 64\n",
    "        elif gpu_memory >= 8:\n",
    "            return 32\n",
    "        elif gpu_memory >= 4:\n",
    "            return 24\n",
    "        else:\n",
    "            return 16\n",
    "    else:\n",
    "        import psutil\n",
    "        ram_gb = psutil.virtual_memory().total / 1e9\n",
    "        print(f\"   System RAM: {ram_gb:.1f} GB\")\n",
    "        \n",
    "        if ram_gb >= 32:\n",
    "            return 16\n",
    "        elif ram_gb >= 16:\n",
    "            return 12\n",
    "        else:\n",
    "            return 8\n",
    "\n",
    "def get_optimal_num_workers():\n",
    "    \"\"\"Get optimal number of workers for data loading\"\"\"\n",
    "    import platform\n",
    "    num_cores = mp.cpu_count()\n",
    "    \n",
    "    if platform.system() == \"Windows\":\n",
    "        return min(4, max(1, num_cores // 2))\n",
    "    else:\n",
    "        return min(8, max(1, int(num_cores * 0.75)))\n",
    "\n",
    "class CompleteDeerAgeTrainer:\n",
    "    \"\"\"Complete deer age trainer with parallelization\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=5, max_parallel_models=2):\n",
    "        self.num_classes = num_classes\n",
    "        self.max_parallel_models = max_parallel_models\n",
    "        \n",
    "        # Fix Windows multiprocessing\n",
    "        fix_windows_multiprocessing()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "            print(f\"COMPLETE DEER AGE TRAINER\")\n",
    "            print(f\"   Device: {self.device} ({torch.cuda.get_device_name(0)})\")\n",
    "            print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "            print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "            \n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            print(f\"COMPLETE DEER AGE TRAINER\")\n",
    "            print(f\"   Device: {self.device} (CUDA not available)\")\n",
    "        \n",
    "        print(f\"   Classes: {num_classes}\")\n",
    "        print(f\"   Max Parallel Models: {max_parallel_models}\")\n",
    "        self.all_results = []\n",
    "        \n",
    "        if MIXED_PRECISION_AVAILABLE and self.device.type == 'cuda':\n",
    "            self.scaler = GradScaler()\n",
    "            self.use_mixed_precision = True\n",
    "            print(f\"   Mixed Precision: Enabled\")\n",
    "        else:\n",
    "            self.scaler = None\n",
    "            self.use_mixed_precision = False\n",
    "            print(f\"   Mixed Precision: Disabled\")\n",
    "    \n",
    "    def get_all_architectures_with_fallback(self):\n",
    "        \"\"\"Get ALL architectures with graceful fallback for missing pretrained weights\"\"\"\n",
    "        \n",
    "        architectures = {\n",
    "            # ResNeXt\n",
    "            'ResNeXt-50': {'model_name': 'resnext50_32x4d', 'family': 'ResNeXt'},\n",
    "            'ResNeXt-101': {'model_name': 'resnext101_32x8d', 'family': 'ResNeXt'},\n",
    "            \n",
    "            # Wide ResNet\n",
    "            'Wide-ResNet-50': {'model_name': 'wide_resnet50_2', 'family': 'Wide-ResNet'},\n",
    "            'Wide-ResNet-101': {'model_name': 'wide_resnet101_2', 'family': 'Wide-ResNet'},\n",
    "            \n",
    "            # MobileNet Family\n",
    "            'MobileNetV2': {'model_name': 'mobilenetv2_100', 'family': 'MobileNet'},\n",
    "            'MobileNetV3-Small': {'model_name': 'mobilenetv3_small_100', 'family': 'MobileNet'},\n",
    "            'MobileNetV3-Large': {'model_name': 'mobilenetv3_large_100', 'family': 'MobileNet'},\n",
    "            \n",
    "            # RegNet Family\n",
    "            'RegNetX-400MF': {'model_name': 'regnetx_400mf', 'family': 'RegNet', 'alternatives': ['regnetx_002', 'regnetx_004']},\n",
    "            'RegNetX-800MF': {'model_name': 'regnetx_800mf', 'family': 'RegNet', 'alternatives': ['regnetx_004', 'regnetx_006']},\n",
    "            'RegNetY-400MF': {'model_name': 'regnety_400mf', 'family': 'RegNet', 'alternatives': ['regnety_002', 'regnety_004']},\n",
    "            'RegNetY-800MF': {'model_name': 'regnety_800mf', 'family': 'RegNet', 'alternatives': ['regnety_004', 'regnety_006']},\n",
    "            \n",
    "            # ConvNeXt Family\n",
    "            'ConvNeXt-Tiny': {'model_name': 'convnext_tiny', 'family': 'ConvNeXt', 'alternatives': ['convnext_tiny_in22ft1k']},\n",
    "            'ConvNeXt-Small': {'model_name': 'convnext_small', 'family': 'ConvNeXt', 'alternatives': ['convnext_small_in22ft1k']},\n",
    "            'ConvNeXt-Base': {'model_name': 'convnext_base', 'family': 'ConvNeXt', 'alternatives': ['convnext_base_in22ft1k']},\n",
    "            \n",
    "            # Vision Transformer variants\n",
    "            'Swin-Tiny': {'model_name': 'swin_tiny_patch4_window7_224', 'family': 'Swin', 'alternatives': ['swin_tiny_patch4_window7_224_in22k']},\n",
    "            'Swin-Small': {'model_name': 'swin_small_patch4_window7_224', 'family': 'Swin', 'alternatives': ['swin_small_patch4_window7_224_in22k']},\n",
    "            \n",
    "            # VGG (classic)\n",
    "            'VGG-16': {'model_name': 'vgg16', 'family': 'VGG'},\n",
    "            'VGG-19': {'model_name': 'vgg19', 'family': 'VGG'},\n",
    "            \n",
    "            # Vision Transformers\n",
    "            'DeiT-Tiny': {'model_name': 'deit_tiny_patch16_224', 'family': 'DeiT'},\n",
    "            'DeiT-Small': {'model_name': 'deit_small_patch16_224', 'family': 'DeiT'},\n",
    "            'DeiT-Base': {'model_name': 'deit_base_patch16_224', 'family': 'DeiT'},\n",
    "            \n",
    "            # Additional EfficientNet variants\n",
    "            'EfficientNet-ES': {'model_name': 'efficientnet_es', 'family': 'EfficientNet'},\n",
    "            'EfficientNet-EM': {'model_name': 'efficientnet_em', 'family': 'EfficientNet'},\n",
    "            'EfficientNet-EL': {'model_name': 'efficientnet_el', 'family': 'EfficientNet'},\n",
    "            \n",
    "            # Additional strong architectures\n",
    "            'ResNet-26': {'model_name': 'resnet26', 'family': 'ResNet'},\n",
    "            'ResNet-26d': {'model_name': 'resnet26d', 'family': 'ResNet'},\n",
    "            'SEResNet-50': {'model_name': 'seresnet50', 'family': 'SEResNet'},\n",
    "            'SEResNeXt-50': {'model_name': 'seresnext50_32x4d', 'family': 'SEResNeXt'},\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nCOMPLETE ARCHITECTURE ARSENAL ({len(architectures)} models)\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"FALLBACK STRATEGY: Pretrained -> Alternative Names -> Random Init\")\n",
    "        print(\"ALL models will be tested regardless of pretrained weight availability\")\n",
    "        \n",
    "        families = {}\n",
    "        for arch_name, arch_info in architectures.items():\n",
    "            family = arch_info['family']\n",
    "            if family not in families:\n",
    "                families[family] = []\n",
    "            families[family].append(arch_name)\n",
    "        \n",
    "        for family, models in families.items():\n",
    "            print(f\"{family} ({len(models)} models): {', '.join(models)}\")\n",
    "        \n",
    "        return architectures\n",
    "    \n",
    "    def create_model_with_fallback(self, arch_name, arch_info, freeze_strategy='none'):\n",
    "        \"\"\"Create model with graceful fallback for missing pretrained weights\"\"\"\n",
    "        model_name = arch_info['model_name']\n",
    "        alternatives = arch_info.get('alternatives', [])\n",
    "        \n",
    "        print(f\"      Creating {arch_name}...\")\n",
    "        \n",
    "        try:\n",
    "            print(f\"         Trying pretrained: {model_name}\")\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=self.num_classes)\n",
    "            initialization_type = \"pretrained\"\n",
    "            final_model_name = model_name\n",
    "            print(f\"         SUCCESS with pretrained weights!\")\n",
    "        except Exception as e1:\n",
    "            print(f\"         Pretrained failed: {str(e1)[:50]}...\")\n",
    "            \n",
    "            model = None\n",
    "            for alt_name in alternatives:\n",
    "                try:\n",
    "                    print(f\"         Trying alternative pretrained: {alt_name}\")\n",
    "                    model = timm.create_model(alt_name, pretrained=True, num_classes=self.num_classes)\n",
    "                    initialization_type = \"pretrained_alt\"\n",
    "                    final_model_name = alt_name\n",
    "                    print(f\"         SUCCESS with alternative pretrained weights!\")\n",
    "                    break\n",
    "                except Exception as e2:\n",
    "                    print(f\"         Alternative {alt_name} failed: {str(e2)[:30]}...\")\n",
    "                    continue\n",
    "            \n",
    "            if model is None:\n",
    "                try:\n",
    "                    print(f\"         Falling back to random initialization: {model_name}\")\n",
    "                    model = timm.create_model(model_name, pretrained=False, num_classes=self.num_classes)\n",
    "                    initialization_type = \"random\"\n",
    "                    final_model_name = model_name\n",
    "                    print(f\"         SUCCESS with random initialization!\")\n",
    "                except Exception as e3:\n",
    "                    for alt_name in alternatives:\n",
    "                        try:\n",
    "                            print(f\"         Trying alternative random: {alt_name}\")\n",
    "                            model = timm.create_model(alt_name, pretrained=False, num_classes=self.num_classes)\n",
    "                            initialization_type = \"random_alt\"\n",
    "                            final_model_name = alt_name\n",
    "                            print(f\"         SUCCESS with alternative random initialization!\")\n",
    "                            break\n",
    "                        except Exception as e4:\n",
    "                            continue\n",
    "                    \n",
    "                    if model is None:\n",
    "                        print(f\"         COMPLETE FAILURE: All strategies failed\")\n",
    "                        return None, None, None\n",
    "        \n",
    "        if freeze_strategy == 'backbone':\n",
    "            print(f\"         Freezing backbone layers...\")\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'classifier' not in name and 'head' not in name and 'fc' not in name:\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            print(f\"         Loaded: {total_params:,} total, {trainable_params:,} trainable ({initialization_type})\")\n",
    "        \n",
    "        elif freeze_strategy == 'partial':\n",
    "            print(f\"         Partial freeze (last 30% unfrozen)...\")\n",
    "            all_params = list(model.named_parameters())\n",
    "            total_layers = len(all_params)\n",
    "            freeze_until = int(total_layers * 0.7)\n",
    "            \n",
    "            for i, (name, param) in enumerate(all_params):\n",
    "                if i < freeze_until and 'classifier' not in name and 'head' not in name and 'fc' not in name:\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            print(f\"         Loaded: {total_params:,} total, {trainable_params:,} trainable ({initialization_type})\")\n",
    "        \n",
    "        else:\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            print(f\"         Loaded: {total_params:,} parameters (all trainable, {initialization_type})\")\n",
    "        \n",
    "        model = model.to(self.device)\n",
    "        \n",
    "        if hasattr(torch, 'compile') and self.device.type == 'cuda':\n",
    "            try:\n",
    "                model = torch.compile(model)\n",
    "                print(f\"         Model compiled for optimization\")\n",
    "            except Exception as e:\n",
    "                print(f\"         Model compilation failed (continuing without): {str(e)[:30]}\")\n",
    "        \n",
    "        return model, initialization_type, final_model_name\n",
    "    \n",
    "    def ultra_aggressive_training(self, model, arch_name, train_loader, val_loader, test_loader, strategy='unfrozen'):\n",
    "        \"\"\"Ultra aggressive training with enhanced error handling\"\"\"\n",
    "        print(f\"      ULTRA AGGRESSIVE TRAINING: {arch_name} ({strategy})...\")\n",
    "        \n",
    "        try:\n",
    "            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "            \n",
    "            if strategy == 'frozen':\n",
    "                lr = 0.01\n",
    "                max_epochs = 50 if self.device.type == 'cpu' else 100\n",
    "                patience = 25 if self.device.type == 'cpu' else 50\n",
    "            elif strategy == 'partial':\n",
    "                lr = 0.005\n",
    "                max_epochs = 50 if self.device.type == 'cpu' else 100\n",
    "                patience = 25 if self.device.type == 'cpu' else 50\n",
    "            else:\n",
    "                lr = 0.001\n",
    "                max_epochs = 50 if self.device.type == 'cpu' else 100\n",
    "                patience = 25 if self.device.type == 'cpu' else 50\n",
    "            \n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=lr,\n",
    "                weight_decay=0.01,\n",
    "                betas=(0.9, 0.999)\n",
    "            )\n",
    "            \n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "            \n",
    "            best_val_acc = 0.0\n",
    "            patience_counter = 0\n",
    "            \n",
    "            print(f\"         ULTRA SETUP: {max_epochs} epochs, LR={lr}, patience={patience}\")\n",
    "            if self.use_mixed_precision and self.device.type == 'cuda':\n",
    "                print(f\"         Mixed Precision: Enabled\")\n",
    "            else:\n",
    "                print(f\"         Mixed Precision: Disabled\")\n",
    "            \n",
    "            successful_epochs = 0\n",
    "            \n",
    "            for epoch in range(max_epochs):\n",
    "                try:\n",
    "                    model.train()\n",
    "                    train_correct = 0\n",
    "                    train_total = 0\n",
    "                    train_loss = 0.0\n",
    "                    \n",
    "                    batch_count = 0\n",
    "                    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                        try:\n",
    "                            if self.device.type == 'cuda':\n",
    "                                images = images.to(self.device, non_blocking=True)\n",
    "                                labels = labels.to(self.device, non_blocking=True)\n",
    "                            else:\n",
    "                                images = images.to(self.device)\n",
    "                                labels = labels.to(self.device)\n",
    "                            \n",
    "                            optimizer.zero_grad()\n",
    "                            \n",
    "                            if self.use_mixed_precision and self.device.type == 'cuda':\n",
    "                                with autocast():\n",
    "                                    outputs = model(images)\n",
    "                                    loss = criterion(outputs, labels)\n",
    "                                \n",
    "                                self.scaler.scale(loss).backward()\n",
    "                                self.scaler.unscale_(optimizer)\n",
    "                                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                                self.scaler.step(optimizer)\n",
    "                                self.scaler.update()\n",
    "                            else:\n",
    "                                outputs = model(images)\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                loss.backward()\n",
    "                                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                                optimizer.step()\n",
    "                            \n",
    "                            train_loss += loss.item()\n",
    "                            _, predicted = torch.max(outputs.data, 1)\n",
    "                            train_total += labels.size(0)\n",
    "                            train_correct += (predicted == labels).sum().item()\n",
    "                            \n",
    "                            batch_count += 1\n",
    "                            \n",
    "                            if self.device.type == 'cpu' and batch_count % 50 == 0:\n",
    "                                current_acc = 100 * train_correct / train_total if train_total > 0 else 0\n",
    "                                print(f\"           Batch {batch_count}/{len(train_loader)}: {current_acc:.1f}%\", end='\\r')\n",
    "                        \n",
    "                        except Exception as batch_error:\n",
    "                            print(f\"         Batch {batch_idx} failed: {str(batch_error)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    if train_total == 0:\n",
    "                        print(f\"         Epoch {epoch}: No training data processed - skipping\")\n",
    "                        continue\n",
    "                    \n",
    "                    train_acc = 100 * train_correct / train_total\n",
    "                    \n",
    "                    model.eval()\n",
    "                    val_correct = 0\n",
    "                    val_total = 0\n",
    "                    val_loss = 0.0\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        for images, labels in val_loader:\n",
    "                            try:\n",
    "                                if self.device.type == 'cuda':\n",
    "                                    images = images.to(self.device, non_blocking=True)\n",
    "                                    labels = labels.to(self.device, non_blocking=True)\n",
    "                                else:\n",
    "                                    images = images.to(self.device)\n",
    "                                    labels = labels.to(self.device)\n",
    "                                \n",
    "                                if self.use_mixed_precision and self.device.type == 'cuda':\n",
    "                                    with autocast():\n",
    "                                        outputs = model(images)\n",
    "                                        loss = criterion(outputs, labels)\n",
    "                                else:\n",
    "                                    outputs = model(images)\n",
    "                                    loss = criterion(outputs, labels)\n",
    "                                \n",
    "                                val_loss += loss.item()\n",
    "                                _, predicted = torch.max(outputs.data, 1)\n",
    "                                val_total += labels.size(0)\n",
    "                                val_correct += (predicted == labels).sum().item()\n",
    "                            \n",
    "                            except Exception as val_batch_error:\n",
    "                                print(f\"         Validation batch failed: {str(val_batch_error)}\")\n",
    "                                continue\n",
    "                    \n",
    "                    if val_total == 0:\n",
    "                        print(f\"         Epoch {epoch}: No validation data processed - skipping\")\n",
    "                        continue\n",
    "                    \n",
    "                    val_acc = 100 * val_correct / val_total\n",
    "                    scheduler.step()\n",
    "                    current_lr = scheduler.get_last_lr()[0]\n",
    "                    \n",
    "                    successful_epochs += 1\n",
    "                    \n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = val_acc\n",
    "                        patience_counter = 0\n",
    "                        best_model_state = model.state_dict().copy()\n",
    "                        improvement = \"BEST\"\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        improvement = \"\"\n",
    "                    \n",
    "                    if epoch % 5 == 0 or epoch < 10 or improvement or epoch > max_epochs - 10:\n",
    "                        gap = train_acc - val_acc\n",
    "                        print(f\"         Epoch {epoch:3d}: Train {train_acc:.1f}%, Val {val_acc:.1f}% (gap: {gap:+.1f}%), LR: {current_lr:.2e} {improvement}\")\n",
    "                    \n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"         Early stopping at epoch {epoch} (patience={patience})\")\n",
    "                        break\n",
    "                        \n",
    "                except Exception as epoch_error:\n",
    "                    print(f\"         Epoch {epoch} failed completely: {str(epoch_error)}\")\n",
    "                    continue\n",
    "            \n",
    "            if successful_epochs == 0:\n",
    "                print(f\"         TRAINING FAILED: No epochs completed successfully\")\n",
    "                return 0.0, 0.0\n",
    "            \n",
    "            if 'best_model_state' in locals():\n",
    "                model.load_state_dict(best_model_state)\n",
    "            \n",
    "            model.eval()\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    try:\n",
    "                        if self.device.type == 'cuda':\n",
    "                            images = images.to(self.device, non_blocking=True)\n",
    "                            labels = labels.to(self.device, non_blocking=True)\n",
    "                        else:\n",
    "                            images = images.to(self.device)\n",
    "                            labels = labels.to(self.device)\n",
    "                        \n",
    "                        if self.use_mixed_precision and self.device.type == 'cuda':\n",
    "                            with autocast():\n",
    "                                outputs = model(images)\n",
    "                        else:\n",
    "                            outputs = model(images)\n",
    "                        \n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        test_total += labels.size(0)\n",
    "                        test_correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    except Exception as test_batch_error:\n",
    "                        print(f\"         Test batch failed: {str(test_batch_error)}\")\n",
    "                        continue\n",
    "            \n",
    "            if test_total == 0:\n",
    "                print(f\"         TEST FAILED: No test data processed\")\n",
    "                return best_val_acc, 0.0\n",
    "            \n",
    "            test_acc = 100 * test_correct / test_total\n",
    "            \n",
    "            print(f\"         {arch_name} ({strategy}) FINAL: Val {best_val_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "            \n",
    "            return best_val_acc, test_acc\n",
    "            \n",
    "        except Exception as training_error:\n",
    "            print(f\"         TRAINING COMPLETELY FAILED: {str(training_error)}\")\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        finally:\n",
    "            if self.device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    def train_architecture_worker(self, arch_info, train_loader, val_loader, test_loader):\n",
    "        \"\"\"Worker function to train a single architecture\"\"\"\n",
    "        arch_name, arch_details = arch_info\n",
    "        try:\n",
    "            results = self.test_architecture_with_multiple_strategies(\n",
    "                arch_name, arch_details, train_loader, val_loader, test_loader\n",
    "            )\n",
    "            return (arch_name, results)\n",
    "        except Exception as e:\n",
    "            print(f\"         Architecture {arch_name} failed: {str(e)}\")\n",
    "            return (arch_name, [])\n",
    "    \n",
    "    def test_architecture_with_multiple_strategies(self, arch_name, arch_info, train_loader, val_loader, test_loader):\n",
    "        \"\"\"Test architecture with multiple training strategies\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        print(f\"      FROZEN BACKBONE STRATEGY:\")\n",
    "        model_frozen, init_type_frozen, final_name_frozen = self.create_model_with_fallback(arch_name, arch_info, freeze_strategy='backbone')\n",
    "        if model_frozen is not None:\n",
    "            try:\n",
    "                val_acc_frozen, test_acc_frozen = self.ultra_aggressive_training(\n",
    "                    model_frozen, arch_name, train_loader, val_loader, test_loader, strategy='frozen'\n",
    "                )\n",
    "                results.append({\n",
    "                    'name': f\"{arch_name}-Frozen\",\n",
    "                    'strategy': 'frozen',\n",
    "                    'val_accuracy': val_acc_frozen,\n",
    "                    'test_accuracy': test_acc_frozen,\n",
    "                    'family': arch_info['family'],\n",
    "                    'initialization': init_type_frozen,\n",
    "                    'final_model_name': final_name_frozen,\n",
    "                    'original_model_name': arch_info['model_name']\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"         Frozen strategy failed: {str(e)[:50]}...\")\n",
    "            finally:\n",
    "                del model_frozen\n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        if results and results[-1]['val_accuracy'] > 35:\n",
    "            print(f\"      PARTIAL FREEZE STRATEGY:\")\n",
    "            model_partial, init_type_partial, final_name_partial = self.create_model_with_fallback(arch_name, arch_info, freeze_strategy='partial')\n",
    "            if model_partial is not None:\n",
    "                try:\n",
    "                    val_acc_partial, test_acc_partial = self.ultra_aggressive_training(\n",
    "                        model_partial, arch_name, train_loader, val_loader, test_loader, strategy='partial'\n",
    "                    )\n",
    "                    results.append({\n",
    "                        'name': f\"{arch_name}-Partial\",\n",
    "                        'strategy': 'partial',\n",
    "                        'val_accuracy': val_acc_partial,\n",
    "                        'test_accuracy': test_acc_partial,\n",
    "                        'family': arch_info['family'],\n",
    "                        'initialization': init_type_partial,\n",
    "                        'final_model_name': final_name_partial,\n",
    "                        'original_model_name': arch_info['model_name']\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"         Partial strategy failed: {str(e)[:50]}...\")\n",
    "                finally:\n",
    "                    del model_partial\n",
    "                    if self.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "        if results and max(r['val_accuracy'] for r in results) > 45:\n",
    "            print(f\"      FULL UNFROZEN STRATEGY:\")\n",
    "            model_unfrozen, init_type_unfrozen, final_name_unfrozen = self.create_model_with_fallback(arch_name, arch_info, freeze_strategy='none')\n",
    "            if model_unfrozen is not None:\n",
    "                try:\n",
    "                    val_acc_unfrozen, test_acc_unfrozen = self.ultra_aggressive_training(\n",
    "                        model_unfrozen, arch_name, train_loader, val_loader, test_loader, strategy='unfrozen'\n",
    "                    )\n",
    "                    results.append({\n",
    "                        'name': f\"{arch_name}-Unfrozen\",\n",
    "                        'strategy': 'unfrozen',\n",
    "                        'val_accuracy': val_acc_unfrozen,\n",
    "                        'test_accuracy': test_acc_unfrozen,\n",
    "                        'family': arch_info['family'],\n",
    "                        'initialization': init_type_unfrozen,\n",
    "                        'final_model_name': final_name_unfrozen,\n",
    "                        'original_model_name': arch_info['model_name']\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"         Unfrozen strategy failed: {str(e)[:50]}...\")\n",
    "                finally:\n",
    "                    del model_unfrozen\n",
    "                    if self.device.type == 'cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def run_complete_pipeline(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "        \"\"\"Run the complete pipeline with parallelization\"\"\"\n",
    "        print(\"COMPLETE DEER AGING PIPELINE\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"Starting from EfficientNet-B5 onwards\")\n",
    "        print(\"All results will be saved automatically\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        train_dataset = DeerDataset(X_train, y_train)\n",
    "        val_dataset = DeerDataset(X_val, y_val)\n",
    "        test_dataset = DeerDataset(X_test, y_test)\n",
    "        \n",
    "        if self.device.type == 'cpu':\n",
    "            optimal_batch_size = 8\n",
    "            optimal_num_workers = 0\n",
    "        else:\n",
    "            optimal_batch_size = get_optimal_batch_size(self.device)\n",
    "            optimal_num_workers = get_optimal_num_workers()\n",
    "        \n",
    "        print(f\"OPTIMIZATIONS:\")\n",
    "        print(f\"   Optimal batch size: {optimal_batch_size}\")\n",
    "        print(f\"   Num workers: {optimal_num_workers}\")\n",
    "        print(f\"   Pin memory: {self.device.type == 'cuda'}\")\n",
    "        print(f\"   Max parallel models: {self.max_parallel_models}\")\n",
    "        \n",
    "        # Create data loaders with proper multiprocessing context\n",
    "        loader_kwargs = {\n",
    "            'batch_size': optimal_batch_size,\n",
    "            'num_workers': optimal_num_workers,\n",
    "            'pin_memory': (self.device.type == 'cuda'),\n",
    "            'persistent_workers': (optimal_num_workers > 0),\n",
    "        }\n",
    "        \n",
    "        if optimal_num_workers > 0:\n",
    "            loader_kwargs['multiprocessing_context'] = mp.get_context('spawn')\n",
    "            loader_kwargs['worker_init_fn'] = lambda worker_id: np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, **loader_kwargs)\n",
    "        val_loader = DataLoader(val_dataset, shuffle=False, **loader_kwargs)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=False, **loader_kwargs)\n",
    "        \n",
    "        print(f\"Data ready: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_dataset)} test\")\n",
    "        \n",
    "        architectures = self.get_all_architectures_with_fallback()\n",
    "        \n",
    "        total_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nULTRA AGGRESSIVE TESTING: {len(architectures)} ARCHITECTURES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Process architectures in parallel batches\n",
    "        arch_items = list(architectures.items())\n",
    "        \n",
    "        if self.max_parallel_models > 1:\n",
    "            print(f\"PARALLEL PROCESSING: {self.max_parallel_models} models at once\")\n",
    "            \n",
    "            for i in range(0, len(arch_items), self.max_parallel_models):\n",
    "                batch = arch_items[i:i + self.max_parallel_models]\n",
    "                batch_start_time = time.time()\n",
    "                \n",
    "                print(f\"\\nPARALLEL BATCH: {[item[0] for item in batch]}\")\n",
    "                \n",
    "                with ThreadPoolExecutor(max_workers=self.max_parallel_models) as executor:\n",
    "                    future_to_arch = {\n",
    "                        executor.submit(self.train_architecture_worker, arch_item, \n",
    "                                       train_loader, val_loader, test_loader): arch_item[0]\n",
    "                        for arch_item in batch\n",
    "                    }\n",
    "                    \n",
    "                    for future in as_completed(future_to_arch):\n",
    "                        arch_name = future_to_arch[future]\n",
    "                        try:\n",
    "                            arch_name_result, results = future.result()\n",
    "                            \n",
    "                            for result in results:\n",
    "                                result['architecture_family'] = arch_name_result\n",
    "                                result['training_time'] = time.time() - batch_start_time\n",
    "                                result['timestamp'] = datetime.now().isoformat()\n",
    "                                self.all_results.append(result)\n",
    "                            \n",
    "                            if results:\n",
    "                                best_arch_result = max(results, key=lambda x: x['test_accuracy'])\n",
    "                                print(f\"      Best {arch_name_result}: {best_arch_result['name']} ({best_arch_result['test_accuracy']:.1f}%)\")\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"      Error collecting {arch_name}: {str(e)}\")\n",
    "                \n",
    "                print(f\"PARALLEL BATCH COMPLETED: {time.time() - batch_start_time:.1f}s\")\n",
    "                \n",
    "                # Save progress\n",
    "                elapsed_time = time.time() - total_start_time\n",
    "                progress_file = self.save_progress_text_file(i//self.max_parallel_models + 1, \n",
    "                                                           len(arch_items)//self.max_parallel_models + 1, \n",
    "                                                           f\"Batch-{i//self.max_parallel_models + 1}\", \n",
    "                                                           [], elapsed_time)\n",
    "                json_file, pkl_file = self.save_backup_files(i//self.max_parallel_models + 1)\n",
    "                print(f\"      Backups: {json_file}, {pkl_file}\")\n",
    "        \n",
    "        else:\n",
    "            # Sequential processing\n",
    "            for i, (arch_name, arch_info) in enumerate(arch_items, 1):\n",
    "                print(f\"\\n[{i}/{len(arch_items)}] ULTRA AGGRESSIVE {arch_name}\")\n",
    "                print(\"-\" * 70)\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                arch_results = self.test_architecture_with_multiple_strategies(\n",
    "                    arch_name, arch_info, train_loader, val_loader, test_loader\n",
    "                )\n",
    "                \n",
    "                for result in arch_results:\n",
    "                    result['architecture_family'] = arch_info['family']\n",
    "                    result['training_time'] = time.time() - start_time\n",
    "                    result['timestamp'] = datetime.now().isoformat()\n",
    "                    self.all_results.append(result)\n",
    "                \n",
    "                if arch_results:\n",
    "                    best_arch_result = max(arch_results, key=lambda x: x['test_accuracy'])\n",
    "                    print(f\"      Best {arch_name}: {best_arch_result['name']} ({best_arch_result['test_accuracy']:.1f}%)\")\n",
    "                \n",
    "                print(f\"      Total time for {arch_name}: {time.time() - start_time:.1f}s\")\n",
    "                \n",
    "                elapsed_time = time.time() - total_start_time\n",
    "                progress_file = self.save_progress_text_file(i, len(arch_items), arch_name, arch_results, elapsed_time)\n",
    "                json_file, pkl_file = self.save_backup_files(i)\n",
    "                \n",
    "                print(f\"      Backups: {json_file}, {pkl_file}\")\n",
    "                \n",
    "                if i % 3 == 0:\n",
    "                    self.show_intermediate_leaderboard(i)\n",
    "        \n",
    "        total_time = time.time() - total_start_time\n",
    "        \n",
    "        self.save_final_results(total_time)\n",
    "        self.show_final_leaderboard(total_time)\n",
    "        \n",
    "        return self.all_results\n",
    "    \n",
    "    def save_progress_text_file(self, completed_count, total_count, arch_name, arch_results, total_time_so_far):\n",
    "        \"\"\"Save human-readable progress text file after each architecture\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f'deer_aging_progress_{timestamp}.txt'\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"DEER AGING PIPELINE - PROGRESS REPORT\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Runtime so far: {total_time_so_far/3600:.2f} hours\\n\")\n",
    "            f.write(f\"Progress: {completed_count}/{total_count} architectures completed\\n\")\n",
    "            f.write(f\"Device: {self.device}\\n\")\n",
    "            f.write(f\"Classes: {self.num_classes}\\n\")\n",
    "            f.write(f\"Mixed Precision: {self.use_mixed_precision}\\n\")\n",
    "            f.write(f\"Max Parallel Models: {self.max_parallel_models}\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            if arch_results:\n",
    "                f.write(f\"JUST COMPLETED: {arch_name}\\n\")\n",
    "                f.write(\"-\"*50 + \"\\n\")\n",
    "                for result in arch_results:\n",
    "                    init_type = result.get('initialization', 'unknown')\n",
    "                    f.write(f\"   {result['name']:30} | {result['strategy']:8} | {init_type:12} | Val: {result['val_accuracy']:5.1f}% | Test: {result['test_accuracy']:5.1f}%\\n\")\n",
    "                \n",
    "                best_arch = max(arch_results, key=lambda x: x['test_accuracy'])\n",
    "                f.write(f\"   Best: {best_arch['name']} ({best_arch['test_accuracy']:.1f}%)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            sorted_results = sorted(self.all_results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "            f.write(f\"CURRENT TOP 10 LEADERBOARD\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            f.write(f\"{'Rank':<4} {'Model':<30} {'Strategy':<10} {'Init':<12} {'Val%':<8} {'Test%':<8}\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            for i, result in enumerate(sorted_results[:10], 1):\n",
    "                init_type = result.get('initialization', 'unknown')\n",
    "                if init_type == 'pretrained':\n",
    "                    init_display = \"Pretrained\"\n",
    "                elif init_type == 'pretrained_alt':\n",
    "                    init_display = \"Alt-Pre\"\n",
    "                elif init_type == 'random':\n",
    "                    init_display = \"Random\"\n",
    "                elif init_type == 'random_alt':\n",
    "                    init_display = \"Alt-Rand\"\n",
    "                else:\n",
    "                    init_display = \"Unknown\"\n",
    "                \n",
    "                f.write(f\"{i:<4} {result['name']:<30} {result['strategy']:<10} {init_display:<12} {result['val_accuracy']:<7.1f} {result['test_accuracy']:<7.1f}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            if sorted_results:\n",
    "                best_overall = sorted_results[0]\n",
    "                breakthrough_count = sum(1 for r in sorted_results if r['test_accuracy'] > 54.2)\n",
    "                excellent_count = sum(1 for r in sorted_results if r['test_accuracy'] >= 65.0)\n",
    "                \n",
    "                f.write(f\"SUMMARY STATISTICS\\n\")\n",
    "                f.write(\"-\"*50 + \"\\n\")\n",
    "                f.write(f\"Current Best: {best_overall['name']} ({best_overall['test_accuracy']:.1f}%)\\n\")\n",
    "                f.write(f\"Models beating 54.2% baseline: {breakthrough_count}/{len(sorted_results)}\\n\")\n",
    "                f.write(f\"Models achieving 65%+: {excellent_count}\\n\")\n",
    "                f.write(f\"Total models tested: {len(sorted_results)}\\n\")\n",
    "                \n",
    "                f.write(f\"\\nBY INITIALIZATION TYPE:\\n\")\n",
    "                init_groups = {}\n",
    "                for result in sorted_results:\n",
    "                    init_type = result.get('initialization', 'unknown')\n",
    "                    if init_type not in init_groups:\n",
    "                        init_groups[init_type] = []\n",
    "                    init_groups[init_type].append(result)\n",
    "                \n",
    "                for init_type, group in init_groups.items():\n",
    "                    avg_test = sum(r['test_accuracy'] for r in group) / len(group)\n",
    "                    best_test = max(r['test_accuracy'] for r in group)\n",
    "                    f.write(f\"   {init_type:15}: {len(group):2d} models, avg: {avg_test:.1f}%, best: {best_test:.1f}%\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "            f.write(f\"REMAINING: {total_count - completed_count} architectures to test\\n\")\n",
    "            estimated_time_remaining = (total_time_so_far / completed_count) * (total_count - completed_count) if completed_count > 0 else 0\n",
    "            f.write(f\"Estimated time remaining: {estimated_time_remaining/3600:.1f} hours\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(f\"This file: {filename}\\n\")\n",
    "            f.write(f\"Auto-saved at: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "        \n",
    "        print(f\"      Progress saved: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    def save_backup_files(self, completed_count):\n",
    "        \"\"\"Save JSON/pickle backup files after each architecture\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        json_file = f'deer_aging_backup_{completed_count}_{timestamp}.json'\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(self.all_results, f, indent=2)\n",
    "        \n",
    "        pkl_file = f'deer_aging_backup_{completed_count}_{timestamp}.pkl'\n",
    "        with open(pkl_file, 'wb') as f:\n",
    "            pickle.dump(self.all_results, f)\n",
    "        \n",
    "        return json_file, pkl_file\n",
    "    \n",
    "    def save_final_results(self, total_time):\n",
    "        \"\"\"Save comprehensive final results\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        final_data = {\n",
    "            'experiment_info': {\n",
    "                'timestamp': timestamp,\n",
    "                'total_runtime_hours': total_time / 3600,\n",
    "                'total_models_tested': len(self.all_results),\n",
    "                'device': str(self.device),\n",
    "                'num_classes': self.num_classes,\n",
    "                'mixed_precision': self.use_mixed_precision,\n",
    "                'max_parallel_models': self.max_parallel_models\n",
    "            },\n",
    "            'results': self.all_results,\n",
    "            'leaderboard': sorted(self.all_results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "        }\n",
    "        \n",
    "        with open(f'deer_aging_final_results_{timestamp}.json', 'w') as f:\n",
    "            json.dump(final_data, f, indent=2)\n",
    "        \n",
    "        with open(f'deer_aging_final_results_{timestamp}.pkl', 'wb') as f:\n",
    "            pickle.dump(final_data, f)\n",
    "        \n",
    "        print(f\"\\nRESULTS SAVED:\")\n",
    "        print(f\"   deer_aging_final_results_{timestamp}.json\")\n",
    "        print(f\"   deer_aging_final_results_{timestamp}.pkl\")\n",
    "    \n",
    "    def show_intermediate_leaderboard(self, completed_count):\n",
    "        \"\"\"Show intermediate leaderboard\"\"\"\n",
    "        current_best = sorted(self.all_results, key=lambda x: x['test_accuracy'], reverse=True)[:5]\n",
    "        print(f\"\\nCURRENT TOP 5 (after {completed_count} architectures):\")\n",
    "        for j, result in enumerate(current_best, 1):\n",
    "            print(f\"   {j}. {result['name']}: {result['test_accuracy']:.1f}%\")\n",
    "        print()\n",
    "    \n",
    "    def show_final_leaderboard(self, total_time):\n",
    "        \"\"\"Show comprehensive final leaderboard\"\"\"\n",
    "        sorted_results = sorted(self.all_results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nFINAL COMPREHENSIVE RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Total testing time: {total_time/3600:.1f} hours\")\n",
    "        print(f\"Models tested: {len(self.all_results)}\")\n",
    "        print(f\"Parallelization: {self.max_parallel_models} concurrent models\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{'Rank':<4} {'Model':<30} {'Strategy':<10} {'Init':<12} {'Val%':<8} {'Test%':<8} {'Status'}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, result in enumerate(sorted_results, 1):\n",
    "            val_acc = result['val_accuracy']\n",
    "            test_acc = result['test_accuracy']\n",
    "            strategy = result['strategy']\n",
    "            init_type = result.get('initialization', 'unknown')\n",
    "            \n",
    "            if init_type == 'pretrained':\n",
    "                init_display = \"Pretrained\"\n",
    "            elif init_type == 'pretrained_alt':\n",
    "                init_display = \"Alt-Pre\"\n",
    "            elif init_type == 'random':\n",
    "                init_display = \"Random\"\n",
    "            elif init_type == 'random_alt':\n",
    "                init_display = \"Alt-Rand\"\n",
    "            else:\n",
    "                init_display = \"Unknown\"\n",
    "            \n",
    "            if test_acc >= 75.0:\n",
    "                status = \"BREAKTHROUGH!\"\n",
    "            elif test_acc >= 65.0:\n",
    "                status = \"EXCELLENT!\"\n",
    "            elif test_acc > 54.2:\n",
    "                status = \"NEW BEST!\"\n",
    "            elif test_acc > 45.0:\n",
    "                status = \"Good\"\n",
    "            else:\n",
    "                status = \"Weak\"\n",
    "            \n",
    "            print(f\"{i:<4} {result['name']:<30} {strategy:<10} {init_display:<12} {val_acc:<7.1f} {test_acc:<7.1f} {status}\")\n",
    "        \n",
    "        print(f\"\\nANALYSIS BY INITIALIZATION:\")\n",
    "        init_groups = {}\n",
    "        for result in sorted_results:\n",
    "            init_type = result.get('initialization', 'unknown')\n",
    "            if init_type not in init_groups:\n",
    "                init_groups[init_type] = []\n",
    "            init_groups[init_type].append(result)\n",
    "        \n",
    "        for init_type, group in init_groups.items():\n",
    "            avg_test = sum(r['test_accuracy'] for r in group) / len(group)\n",
    "            best_test = max(r['test_accuracy'] for r in group)\n",
    "            print(f\"   {init_type:15}: {len(group):2d} models, avg: {avg_test:.1f}%, best: {best_test:.1f}%\")\n",
    "        \n",
    "        if sorted_results:\n",
    "            best = sorted_results[0]\n",
    "            breakthrough_count = sum(1 for r in sorted_results if r['test_accuracy'] > 54.2)\n",
    "            excellent_count = sum(1 for r in sorted_results if r['test_accuracy'] >= 65.0)\n",
    "            \n",
    "            print(f\"\\nFINAL SUMMARY:\")\n",
    "            print(f\"   ULTIMATE CHAMPION: {best['name']} ({best['test_accuracy']:.1f}%)\")\n",
    "            print(f\"   Beat 54.2% baseline: {breakthrough_count}/{len(sorted_results)} models\")\n",
    "            print(f\"   Achieved 65%+: {excellent_count} models\")\n",
    "            \n",
    "            if best['test_accuracy'] >= 75.0:\n",
    "                print(f\"   MISSION ACCOMPLISHED! Achieved 75%+ accuracy!\")\n",
    "            elif best['test_accuracy'] >= 65.0:\n",
    "                print(f\"   EXCELLENT! Found 65%+ architecture!\")\n",
    "            elif best['test_accuracy'] > 54.2:\n",
    "                improvement = best['test_accuracy'] - 54.2\n",
    "                print(f\"   SUCCESS! Improved by +{improvement:.1f}% over baseline!\")\n",
    "            \n",
    "            best_pretrained = max([r for r in sorted_results if r.get('initialization', '').startswith('pretrained')], \n",
    "                                key=lambda x: x['test_accuracy'], default=None)\n",
    "            best_random = max([r for r in sorted_results if r.get('initialization', '').startswith('random')], \n",
    "                            key=lambda x: x['test_accuracy'], default=None)\n",
    "            \n",
    "            if best_pretrained and best_random:\n",
    "                print(f\"   Best Pretrained: {best_pretrained['name']} ({best_pretrained['test_accuracy']:.1f}%)\")\n",
    "                print(f\"   Best Random Init: {best_random['name']} ({best_random['test_accuracy']:.1f}%)\")\n",
    "                if best_random['test_accuracy'] > best_pretrained['test_accuracy']:\n",
    "                    print(f\"   SURPRISE! Random initialization outperformed pretrained!\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "\n",
    "def run_complete_deer_aging_pipeline():\n",
    "    \"\"\"Run the complete deer aging pipeline from start to finish\"\"\"\n",
    "    print(\"LAUNCHING COMPLETE DEER AGING PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"PIPELINE STEPS:\")\n",
    "    print(\"   1. Load original 357 images\")\n",
    "    print(\"   2. Create train/val/test splits\")\n",
    "    print(\"   3. Balance and augment training data\")\n",
    "    print(\"   4. Test all architectures (starting from EfficientNet-B5)\")\n",
    "    print(\"   5. Save results and create leaderboard\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"CRASH RECOVERY: Progress saved after each model!\")\n",
    "    print(\"Look for 'deer_aging_progress_*.txt' files for latest results\")\n",
    "    print(\"JSON/pickle backups: 'deer_aging_backup_*.json/.pkl'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        X_train, y_train, X_val, y_val, X_test, y_test, label_mapping, reverse_mapping = create_train_val_test_split(images, ages)\n",
    "        \n",
    "        X_train_aug, y_train_aug = balance_and_augment_data(X_train, y_train, augment_multiplier=40, num_classes=len(label_mapping))\n",
    "        \n",
    "        trainer = CompleteDeerAgeTrainer(num_classes=len(label_mapping), max_parallel_models=2)\n",
    "        results = trainer.run_complete_pipeline(X_train_aug, y_train_aug, X_val, y_val, X_test, y_test)\n",
    "        \n",
    "        print(\"\\nPIPELINE COMPLETE!\")\n",
    "        print(\"All results saved with timestamps\")\n",
    "        print(\"Check the final leaderboard above\")\n",
    "        \n",
    "        return results, label_mapping, reverse_mapping\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nINTERRUPTED BY USER\")\n",
    "        print(\"Check latest 'deer_aging_progress_*.txt' file for current results\")\n",
    "        print(\"Backup files saved as 'deer_aging_backup_*.json/.pkl'\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"\\nPIPELINE CRASHED: {str(e)}\")\n",
    "        print(\"Check latest 'deer_aging_progress_*.txt' file for results up to crash\")\n",
    "        print(\"Backup files saved as 'deer_aging_backup_*.json/.pkl'\")\n",
    "        print(\"You can manually load the pickle files to recover results\")\n",
    "        raise\n",
    "\n",
    "def test_data_loading():\n",
    "    \"\"\"Test function to debug data loading issues\"\"\"\n",
    "    print(\"TESTING DATA LOADING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    test_paths = [\n",
    "        \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\",\n",
    "    ]\n",
    "    \n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    \n",
    "    for fpath in test_paths:\n",
    "        print(f\"\\nTesting path: {fpath}\")\n",
    "        files = glob.glob(fpath)\n",
    "        print(f\"   Files found: {len(files)}\")\n",
    "        \n",
    "        if len(files) > 0:\n",
    "            print(f\"   First few files: {files[:3]}\")\n",
    "            print(f\"   This path works!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"   No files found at this path\")\n",
    "      \n",
    "    try:\n",
    "        from buck.analysis.basics import ingest_images\n",
    "        print(\"\\nSuccessfully imported buck.analysis.basics\")\n",
    "    except ImportError as e:\n",
    "        print(f\"\\nCannot import buck.analysis.basics: {e}\")\n",
    "        print(\"Possible solutions:\")\n",
    "        print(\"   1. Make sure you're in the right directory\")\n",
    "        print(\"   2. Add buck to Python path: sys.path.append('/path/to/buck')\")\n",
    "        print(\"   3. Install buck package if it's a separate package\")\n",
    "        return False\n",
    "    \n",
    "    for fpath in test_paths:\n",
    "        files = glob.glob(fpath)\n",
    "        if len(files) > 0:\n",
    "            try:\n",
    "                print(f\"\\nTesting ingest_images with: {fpath}\")\n",
    "                images, ages = ingest_images(fpath)\n",
    "                print(f\"ingest_images returned: {len(images)} images, {len(ages)} ages\")\n",
    "                if len(ages) > 0:\n",
    "                    print(f\"Sample ages: {ages[:5]}\")\n",
    "                    print(f\"Age range: {min(ages)} to {max(ages)}\")\n",
    "                    print(f\"Unique ages: {sorted(set(ages))}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"ingest_images failed: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "def load_latest_results():\n",
    "    \"\"\"Load the most recent backup results (for crash recovery)\"\"\"\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    print(\"CRASH RECOVERY MODE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    pickle_files = glob.glob('deer_aging_backup_*.pkl')\n",
    "    if not pickle_files:\n",
    "        print(\"No backup files found!\")\n",
    "        return None\n",
    "    \n",
    "    latest_pickle = max(pickle_files, key=os.path.getctime)\n",
    "    print(f\"Loading latest backup: {latest_pickle}\")\n",
    "    \n",
    "    with open(latest_pickle, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    print(f\"Loaded {len(results)} results\")\n",
    "    \n",
    "    if results:\n",
    "        sorted_results = sorted(results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "        print(f\"Best model: {sorted_results[0]['name']} ({sorted_results[0]['test_accuracy']:.1f}%)\")\n",
    "        print(f\"Models tested: {len(results)}\")\n",
    "        \n",
    "        progress_files = glob.glob('deer_aging_progress_*.txt')\n",
    "        if progress_files:\n",
    "            latest_progress = max(progress_files, key=os.path.getctime)\n",
    "            print(f\"Latest progress report: {latest_progress}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    \n",
    "    print(\"LAUNCHING COMPLETE DEER AGING PIPELINE...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"Testing data loading before starting pipeline...\")\n",
    "    if not test_data_loading():\n",
    "        print(\"\\nDATA LOADING FAILED!\")\n",
    "        print(\"Please fix the data loading issue before running the pipeline\")\n",
    "        print(\"Run test_data_loading() to debug the issue\")\n",
    "    else:\n",
    "        print(\"Data loading test passed!\")\n",
    "        print(\"\\nStarting main pipeline...\")\n",
    "        final_results, final_label_mapping, final_reverse_mapping = run_complete_deer_aging_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e0bfa-336e-4d66-843d-108f9bb85e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
