{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4375fc31-89a0-4ace-b2b8-de0ff579d62e",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "This notebook is better organized so that unlike the original ResNet-18 notebook, you only need to change parameters at the top of the second cell; the first cell still validates if CUDA is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e7a989-f872-4a6b-94d8-d60f6225e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7f717-95ca-4ef8-aa66-78473ba082d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable Ensemble Training, Analysis, and Visualization Pipeline\n",
    "# Change model architecture in ONE place below!\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ===========================\n",
    "# CONFIGURATION - CHANGE ONLY HERE!\n",
    "# ===========================\n",
    "\n",
    "# Choose your model architecture here - just change this one line!\n",
    "MODEL_ARCHITECTURE = 'efficientnet_b0'  # Options: resnet18, resnet34, resnet50, efficientnet_b0, efficientnet_b1, etc.\n",
    "\n",
    "# Model-specific configurations\n",
    "MODEL_CONFIGS = {\n",
    "    'resnet18': {\n",
    "        'frozen_layers': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3'],\n",
    "        'dropout': 0.3,\n",
    "        'classifier_attr': 'fc',\n",
    "        'target_layer_path': 'layer4.-1.conv2',  # For GradCAM\n",
    "        'lr_backbone': 0.0003,\n",
    "        'lr_classifier': 0.001,\n",
    "        'weight_decay': 0.03\n",
    "    },\n",
    "    'resnet34': {\n",
    "        'frozen_layers': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3'],\n",
    "        'dropout': 0.3,\n",
    "        'classifier_attr': 'fc',\n",
    "        'target_layer_path': 'layer4.-1.conv2',\n",
    "        'lr_backbone': 0.0002,\n",
    "        'lr_classifier': 0.0008,\n",
    "        'weight_decay': 0.03\n",
    "    },\n",
    "    'resnet50': {\n",
    "        'frozen_layers': ['conv1', 'bn1', 'layer1', 'layer2'],\n",
    "        'dropout': 0.4,\n",
    "        'classifier_attr': 'fc',\n",
    "        'target_layer_path': 'layer4.-1.conv3',\n",
    "        'lr_backbone': 0.0002,\n",
    "        'lr_classifier': 0.0008,\n",
    "        'weight_decay': 0.04\n",
    "    },\n",
    "    'efficientnet_b0': {\n",
    "        'frozen_layers': ['conv_stem', 'bn1', 'blocks.0', 'blocks.1', 'blocks.2'],\n",
    "        'dropout': 0.2,\n",
    "        'classifier_attr': 'classifier',\n",
    "        'target_layer_path': 'blocks.-1.conv_pwl',\n",
    "        'lr_backbone': 0.0001,\n",
    "        'lr_classifier': 0.0005,\n",
    "        'weight_decay': 0.02\n",
    "    },\n",
    "    'efficientnet_b1': {\n",
    "        'frozen_layers': ['conv_stem', 'bn1', 'blocks.0', 'blocks.1', 'blocks.2'],\n",
    "        'dropout': 0.25,\n",
    "        'classifier_attr': 'classifier',\n",
    "        'target_layer_path': 'blocks.-1.conv_pwl',\n",
    "        'lr_backbone': 0.00008,\n",
    "        'lr_classifier': 0.0004,\n",
    "        'weight_decay': 0.025\n",
    "    },\n",
    "    'densenet121': {\n",
    "        'frozen_layers': ['features.conv0', 'features.norm0', 'features.denseblock1'],\n",
    "        'dropout': 0.3,\n",
    "        'classifier_attr': 'classifier',\n",
    "        'target_layer_path': 'features.denseblock4.denselayer16.conv2',\n",
    "        'lr_backbone': 0.0002,\n",
    "        'lr_classifier': 0.0008,\n",
    "        'weight_decay': 0.03\n",
    "    }\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'max_epochs': 80,\n",
    "    'patience': 20,\n",
    "    'augmentation_multiplier': 15,\n",
    "    'batch_size': 16,\n",
    "    'num_folds': 5,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Data configuration\n",
    "DATA_CONFIG = {\n",
    "    'path': \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\",\n",
    "    'image_size': (448, 224),  # (width, height)\n",
    "    'min_samples_per_class': 3\n",
    "}\n",
    "\n",
    "# ===========================\n",
    "# END CONFIGURATION\n",
    "# ===========================\n",
    "\n",
    "# Get current model config\n",
    "if MODEL_ARCHITECTURE not in MODEL_CONFIGS:\n",
    "    raise ValueError(f\"Model {MODEL_ARCHITECTURE} not configured. Available: {list(MODEL_CONFIGS.keys())}\")\n",
    "\n",
    "CURRENT_MODEL_CONFIG = MODEL_CONFIGS[MODEL_ARCHITECTURE]\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = DATA_CONFIG['path']\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img_resized = cv2.resize(img, DATA_CONFIG['image_size'])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= DATA_CONFIG['min_samples_per_class']}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train, multiplier=None):\n",
    "    if multiplier is None:\n",
    "        multiplier = TRAINING_CONFIG['augmentation_multiplier']\n",
    "    \n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max_count * multiplier\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        self.target_size = (DATA_CONFIG['image_size'][1], DATA_CONFIG['image_size'][0])  # H, W\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != self.target_size:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=self.target_size, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "def get_target_layer(model, target_layer_path):\n",
    "    \"\"\"Get target layer for GradCAM based on path\"\"\"\n",
    "    try:\n",
    "        # Parse path like 'layer4.-1.conv2' -> model.layer4[-1].conv2\n",
    "        parts = target_layer_path.split('.')\n",
    "        layer = model\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.startswith('-') and part[1:].isdigit():\n",
    "                # Handle negative indices like -1\n",
    "                layer = layer[int(part)]\n",
    "            elif part.isdigit():\n",
    "                # Handle positive indices\n",
    "                layer = layer[int(part)]\n",
    "            else:\n",
    "                # Handle attribute names\n",
    "                layer = getattr(layer, part)\n",
    "        \n",
    "        return layer\n",
    "    except Exception as e:\n",
    "        print(f\"Could not find target layer {target_layer_path}: {e}\")\n",
    "        # Fallback to last conv layer\n",
    "        last_conv = None\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                last_conv = module\n",
    "        return last_conv\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.handles = []\n",
    "        \n",
    "        handle1 = self.target_layer.register_forward_hook(self.forward_hook)\n",
    "        handle2 = self.target_layer.register_backward_hook(self.backward_hook)\n",
    "        self.handles.extend([handle1, handle2])\n",
    "    \n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "        self.handles = []\n",
    "    \n",
    "    def generate_cam(self, input_image, class_idx):\n",
    "        self.model.eval()\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        input_image = input_image.to(device)\n",
    "        \n",
    "        input_image.requires_grad_()\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        class_score = output[:, class_idx]\n",
    "        class_score.backward()\n",
    "        \n",
    "        if self.gradients is None or self.activations is None:\n",
    "            return np.zeros(DATA_CONFIG['image_size'][::-1])  # H, W\n",
    "        \n",
    "        gradients = self.gradients[0].to(device)\n",
    "        activations = self.activations[0].to(device)\n",
    "        \n",
    "        weights = torch.mean(gradients, dim=(1, 2))\n",
    "        \n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32, device=device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "        \n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        if cam.max() > 0:\n",
    "            cam = cam / cam.max()\n",
    "        \n",
    "        return cam.detach().cpu().numpy()\n",
    "\n",
    "class EnsembleTrainer:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model_name = MODEL_ARCHITECTURE\n",
    "        self.config = CURRENT_MODEL_CONFIG\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "    \n",
    "    def create_model(self):\n",
    "        model = timm.create_model(self.model_name, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Freeze specified layers\n",
    "        for name, param in model.named_parameters():\n",
    "            for frozen_layer in self.config['frozen_layers']:\n",
    "                if name.startswith(frozen_layer):\n",
    "                    param.requires_grad = False\n",
    "                    break\n",
    "        \n",
    "        # Replace classifier\n",
    "        classifier_attr = self.config['classifier_attr']\n",
    "        \n",
    "        if hasattr(model, classifier_attr):\n",
    "            original_classifier = getattr(model, classifier_attr)\n",
    "            \n",
    "            if hasattr(original_classifier, 'in_features'):\n",
    "                in_features = original_classifier.in_features\n",
    "            else:\n",
    "                # Find the last linear layer to get input features\n",
    "                last_linear = None\n",
    "                for module in original_classifier.modules():\n",
    "                    if isinstance(module, nn.Linear):\n",
    "                        last_linear = module\n",
    "                if last_linear:\n",
    "                    in_features = last_linear.in_features\n",
    "                else:\n",
    "                    raise ValueError(f\"Could not determine input features for {self.model_name}\")\n",
    "            \n",
    "            new_classifier = nn.Sequential(\n",
    "                nn.Dropout(self.config['dropout']),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "            setattr(model, classifier_attr, new_classifier)\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        model = self.create_model()\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if self.config['classifier_attr'] in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': self.config['lr_backbone']},\n",
    "            {'params': classifier_params, 'lr': self.config['lr_classifier']}\n",
    "        ], weight_decay=self.config['weight_decay'])\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=TRAINING_CONFIG['max_epochs'], eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = TRAINING_CONFIG['max_epochs']\n",
    "        patience = TRAINING_CONFIG['patience']\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        # Track training history\n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # Clear intermediate tensors every few batches\n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    # Clear memory during validation too\n",
    "                    if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Record training history\n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            # Periodic GPU memory cleanup\n",
    "            if epoch % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history\n",
    "    \n",
    "    def train_ensemble(self, images, ages):\n",
    "        if not isinstance(images, np.ndarray):\n",
    "            images = np.array(images)\n",
    "        if not isinstance(ages, np.ndarray):\n",
    "            ages = np.array(ages)\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=TRAINING_CONFIG['num_folds'], shuffle=True, random_state=TRAINING_CONFIG['random_state'])\n",
    "        \n",
    "        trained_models = []\n",
    "        cv_scores = []\n",
    "        training_histories = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(images, y_indices)):\n",
    "            X_train_fold = images[train_idx]\n",
    "            y_train_fold = y_indices[train_idx]\n",
    "            X_val_fold = images[val_idx]\n",
    "            y_val_fold = y_indices[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            batch_size = TRAINING_CONFIG['batch_size']\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "            model, val_acc, history = self.train_single_fold(train_loader, val_loader, fold + 1)\n",
    "            \n",
    "            trained_models.append(model)\n",
    "            cv_scores.append(val_acc)\n",
    "            training_histories.append(history)\n",
    "            print(f\"Fold {fold + 1}/{TRAINING_CONFIG['num_folds']} completed: {val_acc:.1f}% validation accuracy\")\n",
    "            \n",
    "            # Clear GPU memory after each fold\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return trained_models, cv_scores, label_mapping, training_histories\n",
    "    \n",
    "    def evaluate_model_with_tta(self, model, test_loader):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "        all_labels = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                \n",
    "                avg_outputs = (outputs1 + outputs2) / 2\n",
    "                probs = F.softmax(avg_outputs, dim=1)\n",
    "                _, predicted = torch.max(avg_outputs, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_probabilities.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy, all_predictions, all_probabilities, all_labels\n",
    "    \n",
    "    def evaluate_ensemble(self, models, cv_scores, test_loader):\n",
    "        scores_array = np.array(cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_ensemble_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                ensemble_outputs = torch.zeros(images.size(0), self.num_classes).to(self.device)\n",
    "                \n",
    "                for model, weight in zip(models, weights):\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    avg_outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    ensemble_outputs += weight * F.softmax(avg_outputs, dim=1)\n",
    "                \n",
    "                _, predicted = torch.max(ensemble_outputs, 1)\n",
    "                \n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_ensemble_probs.extend(ensemble_outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        ensemble_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        return ensemble_acc, np.array(all_ensemble_probs), np.array(all_labels)\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, models, cv_scores, label_mapping, X_test, y_test, training_histories):\n",
    "        self.models = models\n",
    "        self.cv_scores = cv_scores\n",
    "        self.label_mapping = label_mapping\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.training_histories = training_histories\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.unique_ages = sorted(list(label_mapping.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        self.model_name = MODEL_ARCHITECTURE\n",
    "        \n",
    "        Path(\"analysis_plots\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def evaluate_individual_models(self):\n",
    "        test_dataset = OptimizedDataset(self.X_test, self.y_test, test_time_aug=True)\n",
    "        batch_size = TRAINING_CONFIG['batch_size']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trainer = EnsembleTrainer(self.num_classes)\n",
    "        individual_results = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            accuracy, preds, probs, labels = trainer.evaluate_model_with_tta(model, test_loader)\n",
    "            \n",
    "            individual_results.append({\n",
    "                'model_name': f'{MODEL_ARCHITECTURE}_Fold_{i+1}',\n",
    "                'accuracy': accuracy,\n",
    "                'cv_score': self.cv_scores[i],\n",
    "                'predictions': np.array(preds),\n",
    "                'probabilities': np.array(probs),\n",
    "                'true_labels': np.array(labels)\n",
    "            })\n",
    "        \n",
    "        return individual_results\n",
    "    \n",
    "    def evaluate_ensemble(self, individual_results):\n",
    "        test_dataset = OptimizedDataset(self.X_test, self.y_test, test_time_aug=True)\n",
    "        batch_size = TRAINING_CONFIG['batch_size']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trainer = EnsembleTrainer(self.num_classes)\n",
    "        ensemble_acc, ensemble_probs, true_labels = trainer.evaluate_ensemble(self.models, self.cv_scores, test_loader)\n",
    "        \n",
    "        ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'ensemble_accuracy': ensemble_acc,\n",
    "            'ensemble_predictions': ensemble_preds,\n",
    "            'ensemble_probabilities': ensemble_probs,\n",
    "            'true_labels': true_labels\n",
    "        }\n",
    "    \n",
    "    def calculate_metrics(self, individual_results, ensemble_result):\n",
    "        metrics = {}\n",
    "        \n",
    "        for i, result in enumerate(individual_results):\n",
    "            preds = result['predictions']\n",
    "            true_labels = result['true_labels']\n",
    "            \n",
    "            accuracy = np.mean(preds == true_labels) * 100\n",
    "            f1_macro = f1_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            f1_weighted = f1_score(true_labels, preds, average='weighted', zero_division=0) * 100\n",
    "            precision = precision_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            recall = recall_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            \n",
    "            metrics[f'model_{i+1}'] = {\n",
    "                'accuracy': accuracy,\n",
    "                'f1_macro': f1_macro,\n",
    "                'f1_weighted': f1_weighted,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'cv_score': result['cv_score']\n",
    "            }\n",
    "        \n",
    "        if ensemble_result:\n",
    "            ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "            true_labels = ensemble_result['true_labels']\n",
    "            \n",
    "            ensemble_accuracy = np.mean(ensemble_preds == true_labels) * 100\n",
    "            ensemble_f1_macro = f1_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            ensemble_f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted', zero_division=0) * 100\n",
    "            ensemble_precision = precision_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            ensemble_recall = recall_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            \n",
    "            metrics['ensemble'] = {\n",
    "                'accuracy': ensemble_accuracy,\n",
    "                'f1_macro': ensemble_f1_macro,\n",
    "                'f1_weighted': ensemble_f1_weighted,\n",
    "                'precision': ensemble_precision,\n",
    "                'recall': ensemble_recall\n",
    "            }\n",
    "            \n",
    "            class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "            metrics['classification_report'] = classification_report(\n",
    "                true_labels, ensemble_preds,\n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "            metrics['class_names'] = class_names\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def create_performance_plots(self, individual_results, ensemble_result, metrics):\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        model_names = [f'Fold {i+1}' for i in range(len(individual_results))]\n",
    "        accuracies = [result['accuracy'] for result in individual_results]\n",
    "        cv_scores = [result['cv_score'] for result in individual_results]\n",
    "        \n",
    "        if ensemble_result:\n",
    "            model_names.append('Ensemble')\n",
    "            accuracies.append(ensemble_result['ensemble_accuracy'])\n",
    "            cv_scores.append(np.mean(cv_scores))\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(model_names)))\n",
    "        \n",
    "        bars = ax1.bar(model_names, accuracies, alpha=0.8, color=colors, edgecolor='black', linewidth=2)\n",
    "        ax1.axhline(y=70, color='red', linestyle='--', linewidth=2, label=\"Target: 70%\")\n",
    "        \n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        ax1.set_ylabel('Test Accuracy (%)')\n",
    "        ax1.set_title(f'{MODEL_ARCHITECTURE.upper()} Performance Comparison')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # CV vs Test comparison\n",
    "        test_accs = [result['accuracy'] for result in individual_results]\n",
    "        cv_accs = [result['cv_score'] for result in individual_results]\n",
    "        \n",
    "        ax2.scatter(cv_accs, test_accs, alpha=0.7, s=100, c=colors[:-1] if ensemble_result else colors)\n",
    "        \n",
    "        min_acc = min(min(cv_accs), min(test_accs)) - 5\n",
    "        max_acc = max(max(cv_accs), max(test_accs)) + 5\n",
    "        ax2.plot([min_acc, max_acc], [min_acc, max_acc], 'k--', alpha=0.5)\n",
    "        \n",
    "        ax2.set_xlabel('Cross-Validation Accuracy (%)')\n",
    "        ax2.set_ylabel('Test Accuracy (%)')\n",
    "        ax2.set_title('CV vs Test Performance')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # F1 Scores\n",
    "        f1_scores = [metrics[f'model_{i+1}']['f1_macro'] for i in range(len(individual_results))]\n",
    "        if ensemble_result and 'ensemble' in metrics:\n",
    "            f1_scores.append(metrics['ensemble']['f1_macro'])\n",
    "        \n",
    "        ax3.bar(model_names, f1_scores, alpha=0.7, color='lightgreen', edgecolor='darkgreen')\n",
    "        ax3.set_ylabel('F1 Score (%)')\n",
    "        ax3.set_title('F1 Score (Macro) Comparison')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Class distribution\n",
    "        if ensemble_result:\n",
    "            true_labels = ensemble_result['true_labels']\n",
    "            ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "            class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "            \n",
    "            true_dist = [np.sum(true_labels == i) for i in range(len(class_names))]\n",
    "            pred_dist = [np.sum(ensemble_preds == i) for i in range(len(class_names))]\n",
    "            \n",
    "            x = np.arange(len(class_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax4.bar(x - width/2, true_dist, width, label='True Distribution', alpha=0.7, color='skyblue')\n",
    "            ax4.bar(x + width/2, pred_dist, width, label='Predicted Distribution', alpha=0.7, color='salmon')\n",
    "            \n",
    "            ax4.set_xlabel('Age Class')\n",
    "            ax4.set_ylabel('Number of Samples')\n",
    "            ax4.set_title('True vs Predicted Distribution')\n",
    "            ax4.set_xticks(x)\n",
    "            ax4.set_xticklabels(class_names)\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'analysis_plots/{MODEL_ARCHITECTURE}_performance_overview.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def create_confusion_matrix(self, ensemble_result):\n",
    "        if not ensemble_result:\n",
    "            return\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        true_labels = ensemble_result['true_labels']\n",
    "        ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "        class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "        \n",
    "        cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   cbar_kws={'label': 'Number of Samples'})\n",
    "        ax1.set_title(f'{MODEL_ARCHITECTURE.upper()} Confusion Matrix (Counts)')\n",
    "        ax1.set_xlabel('Predicted Age Class')\n",
    "        ax1.set_ylabel('True Age Class')\n",
    "        \n",
    "        cm_norm = confusion_matrix(true_labels, ensemble_preds, normalize='true')\n",
    "        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Greens', ax=ax2,\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   cbar_kws={'label': 'Proportion'})\n",
    "        ax2.set_title(f'{MODEL_ARCHITECTURE.upper()} Confusion Matrix (Normalized)')\n",
    "        ax2.set_xlabel('Predicted Age Class')\n",
    "        ax2.set_ylabel('True Age Class')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'analysis_plots/{MODEL_ARCHITECTURE}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def create_training_curves(self):\n",
    "        fig, axes = plt.subplots(1, TRAINING_CONFIG['num_folds'], figsize=(4*TRAINING_CONFIG['num_folds'], 4))\n",
    "        \n",
    "        if TRAINING_CONFIG['num_folds'] == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for fold, history in enumerate(self.training_histories):\n",
    "            ax = axes[fold]\n",
    "            epochs = range(1, len(history['train_accs']) + 1)\n",
    "            \n",
    "            ax.plot(epochs, history['train_accs'], 'b-', label='Training', linewidth=2, alpha=0.8)\n",
    "            ax.plot(epochs, history['val_accs'], 'r-', label='Validation', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Accuracy (%)')\n",
    "            ax.set_title(f'Fold {fold + 1} Training Curves')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'analysis_plots/{MODEL_ARCHITECTURE}_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def run_analysis(self):\n",
    "        individual_results = self.evaluate_individual_models()\n",
    "        ensemble_result = self.evaluate_ensemble(individual_results)\n",
    "        metrics = self.calculate_metrics(individual_results, ensemble_result)\n",
    "        \n",
    "        self.create_performance_plots(individual_results, ensemble_result, metrics)\n",
    "        self.create_confusion_matrix(ensemble_result)\n",
    "        self.create_training_curves()\n",
    "        \n",
    "        return individual_results, ensemble_result, metrics\n",
    "\n",
    "class GradCAMVisualizer:\n",
    "    def __init__(self, models, label_mapping, X_test, y_test):\n",
    "        self.models = models\n",
    "        self.label_mapping = label_mapping\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.unique_ages = sorted(list(label_mapping.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        self.model_name = MODEL_ARCHITECTURE\n",
    "        \n",
    "        Path(\"gradcam_visualizations\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.FloatTensor(image)\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        target_size = (DATA_CONFIG['image_size'][1], DATA_CONFIG['image_size'][0])  # H, W\n",
    "        if image.shape[-2:] != target_size:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=target_size, \n",
    "                                mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image = (image - mean) / std\n",
    "        \n",
    "        return image.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def overlay_heatmap(self, image, heatmap, alpha=0.6):\n",
    "        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "        \n",
    "        heatmap_colored = cv2.applyColorMap(\n",
    "            (heatmap_resized * 255).astype(np.uint8), \n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        heatmap_colored = heatmap_colored.astype(np.float32) / 255.0\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_display = image\n",
    "        else:\n",
    "            image_display = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        overlaid = alpha * heatmap_colored + (1 - alpha) * image_display\n",
    "        return overlaid\n",
    "    \n",
    "    def select_diverse_samples(self, num_samples):\n",
    "        selected_indices = []\n",
    "        \n",
    "        for class_idx in range(self.num_classes):\n",
    "            class_indices = np.where(np.array(self.y_test) == class_idx)[0]\n",
    "            if len(class_indices) > 0:\n",
    "                selected_indices.append(np.random.choice(class_indices))\n",
    "        \n",
    "        remaining_needed = num_samples - len(selected_indices)\n",
    "        if remaining_needed > 0:\n",
    "            available_indices = [i for i in range(len(self.y_test)) if i not in selected_indices]\n",
    "            additional = np.random.choice(available_indices, \n",
    "                                        min(remaining_needed, len(available_indices)), \n",
    "                                        replace=False)\n",
    "            selected_indices.extend(additional)\n",
    "        \n",
    "        return selected_indices[:num_samples]\n",
    "    \n",
    "    def visualize_model_attention(self, num_samples=6):\n",
    "        sample_indices = self.select_diverse_samples(num_samples)\n",
    "        \n",
    "        num_cols = 2 + len(self.models)\n",
    "        fig, axes = plt.subplots(num_samples, num_cols, figsize=(4*num_cols, 4*num_samples))\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        grad_cams = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            try:\n",
    "                target_layer = get_target_layer(model, CURRENT_MODEL_CONFIG['target_layer_path'])\n",
    "                grad_cam = GradCAM(model, target_layer)\n",
    "                grad_cams.append(grad_cam)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to setup GradCAM for model {i}: {e}\")\n",
    "                grad_cams.append(None)\n",
    "        \n",
    "        try:\n",
    "            for sample_idx, idx in enumerate(sample_indices):\n",
    "                original_image = self.X_test[idx]\n",
    "                true_label = self.y_test[idx]\n",
    "                true_age = self.unique_ages[true_label]\n",
    "                \n",
    "                input_tensor = self.preprocess_image(original_image.copy())\n",
    "                \n",
    "                if original_image.max() > 1.0:\n",
    "                    display_image = original_image.astype(np.float32) / 255.0\n",
    "                else:\n",
    "                    display_image = original_image.astype(np.float32)\n",
    "                \n",
    "                axes[sample_idx, 0].imshow(display_image)\n",
    "                axes[sample_idx, 0].set_title(f'Original\\nTrue: Age {true_age}', fontsize=10)\n",
    "                axes[sample_idx, 0].axis('off')\n",
    "                \n",
    "                model_heatmaps = []\n",
    "                \n",
    "                for model_idx, (model, grad_cam) in enumerate(zip(self.models, grad_cams)):\n",
    "                    if grad_cam is None:\n",
    "                        axes[sample_idx, model_idx + 1].text(0.5, 0.5, 'Failed', \n",
    "                                                           transform=axes[sample_idx, model_idx + 1].transAxes,\n",
    "                                                           ha='center', va='center')\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        with torch.no_grad():\n",
    "                            model_output = model(input_tensor)\n",
    "                            model_pred = torch.argmax(model_output, dim=1).item()\n",
    "                        \n",
    "                        heatmap = grad_cam.generate_cam(input_tensor.clone(), model_pred)\n",
    "                        model_heatmaps.append(heatmap)\n",
    "                        \n",
    "                        overlaid = self.overlay_heatmap(display_image, heatmap)\n",
    "                        \n",
    "                        axes[sample_idx, model_idx + 1].imshow(overlaid)\n",
    "                        axes[sample_idx, model_idx + 1].set_title(f'Fold {model_idx + 1}\\nPred: Age {self.unique_ages[model_pred]}', fontsize=9)\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing fold {model_idx + 1}: {e}\")\n",
    "                        axes[sample_idx, model_idx + 1].text(0.5, 0.5, 'Error', \n",
    "                                                           transform=axes[sample_idx, model_idx + 1].transAxes,\n",
    "                                                           ha='center', va='center')\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                \n",
    "                # Create ensemble heatmap\n",
    "                valid_heatmaps = [h for h in model_heatmaps if h is not None]\n",
    "                if valid_heatmaps:\n",
    "                    ensemble_heatmap = np.mean(valid_heatmaps, axis=0)\n",
    "                    ensemble_overlaid = self.overlay_heatmap(display_image, ensemble_heatmap)\n",
    "                    \n",
    "                    axes[sample_idx, -1].imshow(ensemble_overlaid)\n",
    "                    axes[sample_idx, -1].set_title(f'Ensemble\\nAverage', fontsize=10)\n",
    "                    axes[sample_idx, -1].axis('off')\n",
    "                else:\n",
    "                    axes[sample_idx, -1].text(0.5, 0.5, 'No Valid\\nHeatmaps', \n",
    "                                            transform=axes[sample_idx, -1].transAxes,\n",
    "                                            ha='center', va='center')\n",
    "                    axes[sample_idx, -1].axis('off')\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        finally:\n",
    "            for grad_cam in grad_cams:\n",
    "                if grad_cam is not None:\n",
    "                    grad_cam.remove_hooks()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'gradcam_visualizations/{MODEL_ARCHITECTURE}_ensemble_attention.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def run_gradcam_analysis(self):\n",
    "        self.visualize_model_attention(num_samples=6)\n",
    "\n",
    "def save_models_and_ensemble(models, cv_scores, label_mapping, ensemble_acc, training_histories):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_dir = f\"{MODEL_ARCHITECTURE}_ensemble_{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save individual models\n",
    "    for i, (model, score) in enumerate(zip(models, cv_scores)):\n",
    "        model_path = os.path.join(save_dir, f\"{MODEL_ARCHITECTURE}_fold_{i+1}_{score:.1f}pct.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': MODEL_ARCHITECTURE,\n",
    "            'fold': i+1,\n",
    "            'cv_score': score,\n",
    "            'num_classes': len(label_mapping),\n",
    "            'label_mapping': label_mapping,\n",
    "            'input_size': DATA_CONFIG['image_size'][::-1],  # H, W format\n",
    "            'model_config': CURRENT_MODEL_CONFIG\n",
    "        }, model_path)\n",
    "    \n",
    "    # Save ensemble\n",
    "    ensemble_path = os.path.join(save_dir, f\"{MODEL_ARCHITECTURE}_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': [MODEL_ARCHITECTURE] * len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': DATA_CONFIG['image_size'][::-1],\n",
    "        'model_config': CURRENT_MODEL_CONFIG\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    # Save data splits and training histories\n",
    "    with open(os.path.join(save_dir, \"training_histories.pkl\"), 'wb') as f:\n",
    "        pickle.dump(training_histories, f)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'timestamp': timestamp,\n",
    "        'architecture': MODEL_ARCHITECTURE,\n",
    "        'model_config': CURRENT_MODEL_CONFIG,\n",
    "        'training_config': TRAINING_CONFIG,\n",
    "        'data_config': DATA_CONFIG,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    return save_dir\n",
    "\n",
    "def main():\n",
    "    print(f\"{MODEL_ARCHITECTURE.upper()} Ensemble Training, Analysis, and Visualization Pipeline\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Model: {MODEL_ARCHITECTURE}\")\n",
    "    print(f\"Image Size: {DATA_CONFIG['image_size']} (W x H)\")\n",
    "    print(f\"Batch Size: {TRAINING_CONFIG['batch_size']}\")\n",
    "    print(f\"Augmentation: {TRAINING_CONFIG['augmentation_multiplier']}x\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = EnsembleTrainer(num_classes=len(set(ages)))\n",
    "        \n",
    "        # Train ensemble\n",
    "        print(\"Training ensemble...\")\n",
    "        models, cv_scores, label_mapping, training_histories = trainer.train_ensemble(images, ages)\n",
    "        \n",
    "        # Create test set\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "            images, y_indices, test_size=TRAINING_CONFIG['test_size'], \n",
    "            random_state=TRAINING_CONFIG['random_state'], stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "        batch_size = TRAINING_CONFIG['batch_size']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "        \n",
    "        # Save models\n",
    "        print(\"Saving models...\")\n",
    "        save_dir = save_models_and_ensemble(models, cv_scores, label_mapping, ensemble_acc, training_histories)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(f\"\\n{MODEL_ARCHITECTURE.upper()} Training Results:\")\n",
    "        print(f\"CV Scores: {[f'{score:.1f}%' for score in cv_scores]}\")\n",
    "        print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "        print(f\"Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "        print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"Models saved to: {save_dir}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        print(\"\\nRunning model analysis...\")\n",
    "        analyzer = ModelAnalyzer(models, cv_scores, label_mapping, X_test, y_test, training_histories)\n",
    "        individual_results, ensemble_result, metrics = analyzer.run_analysis()\n",
    "        \n",
    "        # Run Grad-CAM visualization\n",
    "        print(\"\\nRunning Grad-CAM visualization...\")\n",
    "        gradcam_viz = GradCAMVisualizer(models, label_mapping, X_test, y_test)\n",
    "        gradcam_viz.run_gradcam_analysis()\n",
    "        \n",
    "        print(\"\\nPipeline Complete!\")\n",
    "        print(\"Check 'analysis_plots/' for performance analysis\")\n",
    "        print(\"Check 'gradcam_visualizations/' for attention maps\")\n",
    "        \n",
    "        return {\n",
    "            'models': models,\n",
    "            'cv_scores': cv_scores,\n",
    "            'ensemble_score': ensemble_acc,\n",
    "            'save_directory': save_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ffe2c-08d5-4532-af7c-cfdacd263f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
