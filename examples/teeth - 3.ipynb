{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4375fc31-89a0-4ace-b2b8-de0ff579d62e",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "This notebook is better organized so that unlike the original ResNet-18 notebook, you only need to change parameters at the top of the second cell; the first cell still validates if CUDA is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e7a989-f872-4a6b-94d8-d60f6225e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7f717-95ca-4ef8-aa66-78473ba082d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Full multi-fold training\n",
    "#   Complete Multi-Architecture Ensemble Training, Analysis, and Visualization Pipeline\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIGURATION - Change model architectures here\n",
    "AVAILABLE_ARCHITECTURES = ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'mobilenetv3_large_100']\n",
    "AUGMENTATION_TARGET = 1200  # Target samples per class after augmentation\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 448)  # height, width\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train):\n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.handles = []\n",
    "        \n",
    "        handle1 = self.target_layer.register_forward_hook(self.forward_hook)\n",
    "        handle2 = self.target_layer.register_backward_hook(self.backward_hook)\n",
    "        self.handles.extend([handle1, handle2])\n",
    "    \n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "        self.handles = []\n",
    "    \n",
    "    def generate_cam(self, input_image, class_idx):\n",
    "        self.model.eval()\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        input_image = input_image.to(device)\n",
    "        \n",
    "        input_image.requires_grad_()\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        class_score = output[:, class_idx]\n",
    "        class_score.backward()\n",
    "        \n",
    "        if self.gradients is None or self.activations is None:\n",
    "            return np.zeros(IMAGE_SIZE)\n",
    "        \n",
    "        gradients = self.gradients[0].to(device)\n",
    "        activations = self.activations[0].to(device)\n",
    "        \n",
    "        weights = torch.mean(gradients, dim=(1, 2))\n",
    "        \n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32, device=device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "        \n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        if cam.max() > 0:\n",
    "            cam = cam / cam.max()\n",
    "        \n",
    "        return cam.detach().cpu().numpy()\n",
    "\n",
    "class MultiArchEnsembleTrainer:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        if 'resnet' in architecture:\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "            for name, param in model.named_parameters():\n",
    "                for frozen_layer in frozen_layers:\n",
    "                    if name.startswith(frozen_layer):\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'mobilenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.0' in name or 'features.1' in name or 'features.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "                model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_model(self, train_loader, val_loader, architecture):\n",
    "        model = self.create_model(architecture)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            if epoch % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history, architecture\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        best_model = None\n",
    "        best_acc = 0.0\n",
    "        best_history = None\n",
    "        best_arch = None\n",
    "        \n",
    "        for arch in AVAILABLE_ARCHITECTURES:\n",
    "            try:\n",
    "                print(f\"  Testing {arch}...\")\n",
    "                model, val_acc, history, architecture = self.train_single_model(train_loader, val_loader, arch)\n",
    "                \n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "                    best_arch = architecture\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to train {arch}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_model, best_acc, best_history, best_arch\n",
    "    \n",
    "    def train_ensemble(self, images, ages):\n",
    "        if not isinstance(images, np.ndarray):\n",
    "            images = np.array(images)\n",
    "        if not isinstance(ages, np.ndarray):\n",
    "            ages = np.array(ages)\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "        \n",
    "        trained_models = []\n",
    "        cv_scores = []\n",
    "        training_histories = []\n",
    "        architectures_used = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(images, y_indices)):\n",
    "            print(f\"Training Fold {fold + 1}/{NUM_FOLDS}\")\n",
    "            \n",
    "            X_train_fold = images[train_idx]\n",
    "            y_train_fold = y_indices[train_idx]\n",
    "            X_val_fold = images[val_idx]\n",
    "            y_val_fold = y_indices[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            batch_size = 16 if torch.cuda.is_available() else 8\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "            model, val_acc, history, best_arch = self.train_single_fold(train_loader, val_loader, fold + 1)\n",
    "            \n",
    "            if model is not None:\n",
    "                trained_models.append(model)\n",
    "                cv_scores.append(val_acc)\n",
    "                training_histories.append(history)\n",
    "                architectures_used.append(best_arch)\n",
    "                print(f\"Fold {fold + 1}/{NUM_FOLDS} completed: {val_acc:.1f}% with {best_arch}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return trained_models, cv_scores, label_mapping, training_histories, architectures_used\n",
    "    \n",
    "    def evaluate_model_with_tta(self, model, test_loader):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "        all_labels = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                \n",
    "                avg_outputs = (outputs1 + outputs2) / 2\n",
    "                probs = F.softmax(avg_outputs, dim=1)\n",
    "                _, predicted = torch.max(avg_outputs, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_probabilities.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy, all_predictions, all_probabilities, all_labels\n",
    "    \n",
    "    def evaluate_ensemble(self, models, cv_scores, test_loader):\n",
    "        scores_array = np.array(cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_ensemble_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                ensemble_outputs = torch.zeros(images.size(0), self.num_classes).to(self.device)\n",
    "                \n",
    "                for model, weight in zip(models, weights):\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    avg_outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    ensemble_outputs += weight * F.softmax(avg_outputs, dim=1)\n",
    "                \n",
    "                _, predicted = torch.max(ensemble_outputs, 1)\n",
    "                \n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_ensemble_probs.extend(ensemble_outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        ensemble_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        return ensemble_acc, np.array(all_ensemble_probs), np.array(all_labels)\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, models, cv_scores, label_mapping, X_test, y_test, training_histories, architectures_used):\n",
    "        self.models = models\n",
    "        self.cv_scores = cv_scores\n",
    "        self.label_mapping = label_mapping\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.training_histories = training_histories\n",
    "        self.architectures_used = architectures_used\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.unique_ages = sorted(list(label_mapping.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        \n",
    "        Path(\"analysis_plots\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def evaluate_individual_models(self):\n",
    "        test_dataset = OptimizedDataset(self.X_test, self.y_test, test_time_aug=True)\n",
    "        batch_size = 16 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(self.num_classes)\n",
    "        individual_results = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            accuracy, preds, probs, labels = trainer.evaluate_model_with_tta(model, test_loader)\n",
    "            \n",
    "            individual_results.append({\n",
    "                'model_name': f'{self.architectures_used[i]}_Fold_{i+1}',\n",
    "                'accuracy': accuracy,\n",
    "                'cv_score': self.cv_scores[i],\n",
    "                'architecture': self.architectures_used[i],\n",
    "                'predictions': np.array(preds),\n",
    "                'probabilities': np.array(probs),\n",
    "                'true_labels': np.array(labels)\n",
    "            })\n",
    "        \n",
    "        return individual_results\n",
    "    \n",
    "    def evaluate_ensemble(self, individual_results):\n",
    "        test_dataset = OptimizedDataset(self.X_test, self.y_test, test_time_aug=True)\n",
    "        batch_size = 16 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(self.num_classes)\n",
    "        ensemble_acc, ensemble_probs, true_labels = trainer.evaluate_ensemble(self.models, self.cv_scores, test_loader)\n",
    "        \n",
    "        ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'ensemble_accuracy': ensemble_acc,\n",
    "            'ensemble_predictions': ensemble_preds,\n",
    "            'ensemble_probabilities': ensemble_probs,\n",
    "            'true_labels': true_labels\n",
    "        }\n",
    "    \n",
    "    def calculate_metrics(self, individual_results, ensemble_result):\n",
    "        metrics = {}\n",
    "        \n",
    "        for i, result in enumerate(individual_results):\n",
    "            preds = result['predictions']\n",
    "            true_labels = result['true_labels']\n",
    "            \n",
    "            accuracy = np.mean(preds == true_labels) * 100\n",
    "            f1_macro = f1_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            f1_weighted = f1_score(true_labels, preds, average='weighted', zero_division=0) * 100\n",
    "            precision = precision_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            recall = recall_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            \n",
    "            metrics[f'model_{i+1}'] = {\n",
    "                'accuracy': accuracy,\n",
    "                'f1_macro': f1_macro,\n",
    "                'f1_weighted': f1_weighted,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'cv_score': result['cv_score'],\n",
    "                'architecture': result['architecture']\n",
    "            }\n",
    "        \n",
    "        if ensemble_result:\n",
    "            ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "            true_labels = ensemble_result['true_labels']\n",
    "            \n",
    "            ensemble_accuracy = np.mean(ensemble_preds == true_labels) * 100\n",
    "            ensemble_f1_macro = f1_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            ensemble_f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted', zero_division=0) * 100\n",
    "            ensemble_precision = precision_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            ensemble_recall = recall_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            \n",
    "            metrics['ensemble'] = {\n",
    "                'accuracy': ensemble_accuracy,\n",
    "                'f1_macro': ensemble_f1_macro,\n",
    "                'f1_weighted': ensemble_f1_weighted,\n",
    "                'precision': ensemble_precision,\n",
    "                'recall': ensemble_recall\n",
    "            }\n",
    "            \n",
    "            class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "            metrics['classification_report'] = classification_report(\n",
    "                true_labels, ensemble_preds,\n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "            metrics['class_names'] = class_names\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def create_performance_plots(self, individual_results, ensemble_result, metrics):\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        model_names = [f'{result[\"architecture\"]}\\n(Fold {i+1})' for i, result in enumerate(individual_results)]\n",
    "        accuracies = [result['accuracy'] for result in individual_results]\n",
    "        cv_scores = [result['cv_score'] for result in individual_results]\n",
    "        \n",
    "        if ensemble_result:\n",
    "            model_names.append('Ensemble')\n",
    "            accuracies.append(ensemble_result['ensemble_accuracy'])\n",
    "            cv_scores.append(np.mean(cv_scores))\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(model_names)))\n",
    "        \n",
    "        bars = ax1.bar(model_names, accuracies, alpha=0.8, color=colors, edgecolor='black', linewidth=2)\n",
    "        ax1.axhline(y=70, color='red', linestyle='--', linewidth=2, label=\"Target: 70%\")\n",
    "        \n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        ax1.set_ylabel('Test Accuracy (%)')\n",
    "        ax1.set_title('Model Performance Comparison')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        test_accs = [result['accuracy'] for result in individual_results]\n",
    "        cv_accs = [result['cv_score'] for result in individual_results]\n",
    "        \n",
    "        ax2.scatter(cv_accs, test_accs, alpha=0.7, s=100, c=colors[:-1] if ensemble_result else colors)\n",
    "        \n",
    "        min_acc = min(min(cv_accs), min(test_accs)) - 5\n",
    "        max_acc = max(max(cv_accs), max(test_accs)) + 5\n",
    "        ax2.plot([min_acc, max_acc], [min_acc, max_acc], 'k--', alpha=0.5)\n",
    "        \n",
    "        ax2.set_xlabel('Cross-Validation Accuracy (%)')\n",
    "        ax2.set_ylabel('Test Accuracy (%)')\n",
    "        ax2.set_title('CV vs Test Performance')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        f1_scores = [metrics[f'model_{i+1}']['f1_macro'] for i in range(len(individual_results))]\n",
    "        if ensemble_result and 'ensemble' in metrics:\n",
    "            f1_scores.append(metrics['ensemble']['f1_macro'])\n",
    "        \n",
    "        ax3.bar(model_names, f1_scores, alpha=0.7, color='lightgreen', edgecolor='darkgreen')\n",
    "        ax3.set_ylabel('F1 Score (%)')\n",
    "        ax3.set_title('F1 Score (Macro) Comparison')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        if ensemble_result:\n",
    "            true_labels = ensemble_result['true_labels']\n",
    "            ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "            class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "            \n",
    "            true_dist = [np.sum(true_labels == i) for i in range(len(class_names))]\n",
    "            pred_dist = [np.sum(ensemble_preds == i) for i in range(len(class_names))]\n",
    "            \n",
    "            x = np.arange(len(class_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax4.bar(x - width/2, true_dist, width, label='True Distribution', alpha=0.7, color='skyblue')\n",
    "            ax4.bar(x + width/2, pred_dist, width, label='Predicted Distribution', alpha=0.7, color='salmon')\n",
    "            \n",
    "            ax4.set_xlabel('Age Class')\n",
    "            ax4.set_ylabel('Number of Samples')\n",
    "            ax4.set_title('True vs Predicted Distribution')\n",
    "            ax4.set_xticks(x)\n",
    "            ax4.set_xticklabels(class_names)\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('analysis_plots/performance_overview.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def create_confusion_matrix(self, ensemble_result):\n",
    "        if not ensemble_result:\n",
    "            return\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        true_labels = ensemble_result['true_labels']\n",
    "        ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "        class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "        \n",
    "        cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   cbar_kws={'label': 'Number of Samples'})\n",
    "        ax1.set_title('Confusion Matrix (Counts)')\n",
    "        ax1.set_xlabel('Predicted Age Class')\n",
    "        ax1.set_ylabel('True Age Class')\n",
    "        \n",
    "        cm_norm = confusion_matrix(true_labels, ensemble_preds, normalize='true')\n",
    "        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Greens', ax=ax2,\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   cbar_kws={'label': 'Proportion'})\n",
    "        ax2.set_title('Confusion Matrix (Normalized)')\n",
    "        ax2.set_xlabel('Predicted Age Class')\n",
    "        ax2.set_ylabel('True Age Class')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('analysis_plots/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def create_training_curves(self):\n",
    "        fig, axes = plt.subplots(1, NUM_FOLDS, figsize=(4*NUM_FOLDS, 4))\n",
    "        if NUM_FOLDS == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for fold, history in enumerate(self.training_histories):\n",
    "            ax = axes[fold]\n",
    "            epochs = range(1, len(history['train_accs']) + 1)\n",
    "            \n",
    "            ax.plot(epochs, history['train_accs'], 'b-', label='Training', linewidth=2, alpha=0.8)\n",
    "            ax.plot(epochs, history['val_accs'], 'r-', label='Validation', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Accuracy (%)')\n",
    "            ax.set_title(f'Fold {fold + 1} ({self.architectures_used[fold]})')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('analysis_plots/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def run_analysis(self):\n",
    "        individual_results = self.evaluate_individual_models()\n",
    "        ensemble_result = self.evaluate_ensemble(individual_results)\n",
    "        metrics = self.calculate_metrics(individual_results, ensemble_result)\n",
    "        \n",
    "        self.create_performance_plots(individual_results, ensemble_result, metrics)\n",
    "        self.create_confusion_matrix(ensemble_result)\n",
    "        self.create_training_curves()\n",
    "        \n",
    "        return individual_results, ensemble_result, metrics\n",
    "\n",
    "class GradCAMVisualizer:\n",
    "    def __init__(self, models, label_mapping, X_test, y_test, architectures_used):\n",
    "        self.models = models\n",
    "        self.label_mapping = label_mapping\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.architectures_used = architectures_used\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.unique_ages = sorted(list(label_mapping.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        \n",
    "        Path(\"gradcam_visualizations\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.FloatTensor(image)\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, \n",
    "                                mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image = (image - mean) / std\n",
    "        \n",
    "        return image.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def get_target_layer(self, model, architecture):\n",
    "        if 'resnet' in architecture:\n",
    "            return model.layer4[-1].conv2\n",
    "        elif 'efficientnet' in architecture:\n",
    "            return model.features[-1]\n",
    "        elif 'mobilenet' in architecture:\n",
    "            return model.features[-1]\n",
    "        else:\n",
    "            return model.features[-1] if hasattr(model, 'features') else model.layer4[-1]\n",
    "    \n",
    "    def overlay_heatmap(self, image, heatmap, alpha=0.6):\n",
    "        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "        \n",
    "        heatmap_colored = cv2.applyColorMap(\n",
    "            (heatmap_resized * 255).astype(np.uint8), \n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        heatmap_colored = heatmap_colored.astype(np.float32) / 255.0\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_display = image\n",
    "        else:\n",
    "            image_display = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        overlaid = alpha * heatmap_colored + (1 - alpha) * image_display\n",
    "        return overlaid\n",
    "    \n",
    "    def select_diverse_samples(self, num_samples):\n",
    "        selected_indices = []\n",
    "        \n",
    "        for class_idx in range(self.num_classes):\n",
    "            class_indices = np.where(np.array(self.y_test) == class_idx)[0]\n",
    "            if len(class_indices) > 0:\n",
    "                selected_indices.append(np.random.choice(class_indices))\n",
    "        \n",
    "        remaining_needed = num_samples - len(selected_indices)\n",
    "        if remaining_needed > 0:\n",
    "            available_indices = [i for i in range(len(self.y_test)) if i not in selected_indices]\n",
    "            additional = np.random.choice(available_indices, \n",
    "                                        min(remaining_needed, len(available_indices)), \n",
    "                                        replace=False)\n",
    "            selected_indices.extend(additional)\n",
    "        \n",
    "        return selected_indices[:num_samples]\n",
    "    \n",
    "    def visualize_model_attention(self, num_samples=6):\n",
    "        sample_indices = self.select_diverse_samples(num_samples)\n",
    "        \n",
    "        num_cols = 2 + len(self.models)\n",
    "        fig, axes = plt.subplots(num_samples, num_cols, figsize=(4*num_cols, 4*num_samples))\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        grad_cams = []\n",
    "        \n",
    "        for i, (model, arch) in enumerate(zip(self.models, self.architectures_used)):\n",
    "            try:\n",
    "                target_layer = self.get_target_layer(model, arch)\n",
    "                grad_cam = GradCAM(model, target_layer)\n",
    "                grad_cams.append(grad_cam)\n",
    "            except Exception as e:\n",
    "                grad_cams.append(None)\n",
    "        \n",
    "        try:\n",
    "            for sample_idx, idx in enumerate(sample_indices):\n",
    "                original_image = self.X_test[idx]\n",
    "                true_label = self.y_test[idx]\n",
    "                true_age = self.unique_ages[true_label]\n",
    "                \n",
    "                input_tensor = self.preprocess_image(original_image.copy())\n",
    "                \n",
    "                if original_image.max() > 1.0:\n",
    "                    display_image = original_image.astype(np.float32) / 255.0\n",
    "                else:\n",
    "                    display_image = original_image.astype(np.float32)\n",
    "                \n",
    "                axes[sample_idx, 0].imshow(display_image)\n",
    "                axes[sample_idx, 0].set_title(f'Original\\nTrue: Age {true_age}', fontsize=10)\n",
    "                axes[sample_idx, 0].axis('off')\n",
    "                \n",
    "                model_heatmaps = []\n",
    "                \n",
    "                for model_idx, (model, grad_cam, arch) in enumerate(zip(self.models, grad_cams, self.architectures_used)):\n",
    "                    if grad_cam is None:\n",
    "                        axes[sample_idx, model_idx + 1].text(0.5, 0.5, 'Failed', \n",
    "                                                           transform=axes[sample_idx, model_idx + 1].transAxes,\n",
    "                                                           ha='center', va='center')\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        with torch.no_grad():\n",
    "                            model_output = model(input_tensor)\n",
    "                            model_pred = torch.argmax(model_output, dim=1).item()\n",
    "                        \n",
    "                        heatmap = grad_cam.generate_cam(input_tensor.clone(), model_pred)\n",
    "                        model_heatmaps.append(heatmap)\n",
    "                        \n",
    "                        overlaid = self.overlay_heatmap(display_image, heatmap)\n",
    "                        \n",
    "                        axes[sample_idx, model_idx + 1].imshow(overlaid)\n",
    "                        axes[sample_idx, model_idx + 1].set_title(f'{arch}\\nPred: Age {self.unique_ages[model_pred]}', fontsize=9)\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        axes[sample_idx, model_idx + 1].text(0.5, 0.5, 'Error', \n",
    "                                                           transform=axes[sample_idx, model_idx + 1].transAxes,\n",
    "                                                           ha='center', va='center')\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                \n",
    "                valid_heatmaps = [h for h in model_heatmaps if h is not None]\n",
    "                if valid_heatmaps:\n",
    "                    ensemble_heatmap = np.mean(valid_heatmaps, axis=0)\n",
    "                    ensemble_overlaid = self.overlay_heatmap(display_image, ensemble_heatmap)\n",
    "                    \n",
    "                    axes[sample_idx, -1].imshow(ensemble_overlaid)\n",
    "                    axes[sample_idx, -1].set_title(f'Ensemble\\nAverage', fontsize=10)\n",
    "                    axes[sample_idx, -1].axis('off')\n",
    "                else:\n",
    "                    axes[sample_idx, -1].text(0.5, 0.5, 'No Valid\\nHeatmaps', \n",
    "                                            transform=axes[sample_idx, -1].transAxes,\n",
    "                                            ha='center', va='center')\n",
    "                    axes[sample_idx, -1].axis('off')\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        finally:\n",
    "            for grad_cam in grad_cams:\n",
    "                if grad_cam is not None:\n",
    "                    grad_cam.remove_hooks()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gradcam_visualizations/multi_arch_ensemble_attention.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def run_gradcam_analysis(self):\n",
    "        self.visualize_model_attention(num_samples=6)\n",
    "\n",
    "def save_models_and_ensemble(models, cv_scores, label_mapping, ensemble_acc, training_histories, architectures_used):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_dir = f\"multi_arch_ensemble_{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for i, (model, score, arch) in enumerate(zip(models, cv_scores, architectures_used)):\n",
    "        model_path = os.path.join(save_dir, f\"{arch}_fold_{i+1}_{score:.1f}pct.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': arch,\n",
    "            'fold': i+1,\n",
    "            'cv_score': score,\n",
    "            'num_classes': len(label_mapping),\n",
    "            'label_mapping': label_mapping,\n",
    "            'input_size': IMAGE_SIZE\n",
    "        }, model_path)\n",
    "    \n",
    "    ensemble_path = os.path.join(save_dir, \"multi_arch_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': architectures_used,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"training_histories.pkl\"), 'wb') as f:\n",
    "        pickle.dump(training_histories, f)\n",
    "    \n",
    "    metadata = {\n",
    "        'timestamp': timestamp,\n",
    "        'architectures_used': architectures_used,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': f'{IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}',\n",
    "        'augmentation_target': AUGMENTATION_TARGET\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    return save_dir\n",
    "\n",
    "def main():\n",
    "    print(\"Multi-Architecture Ensemble Training, Analysis, and Visualization Pipeline\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Available architectures: {AVAILABLE_ARCHITECTURES}\")\n",
    "    print(f\"Number of folds: {NUM_FOLDS}\")\n",
    "    print(f\"Image size: {IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}\")\n",
    "    print(f\"Augmentation target: {AUGMENTATION_TARGET} samples per class\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(num_classes=len(set(ages)))\n",
    "        \n",
    "        print(\"Training ensemble...\")\n",
    "        models, cv_scores, label_mapping, training_histories, architectures_used = trainer.train_ensemble(images, ages)\n",
    "        \n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "        batch_size = 32 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "        \n",
    "        print(\"Saving models...\")\n",
    "        save_dir = save_models_and_ensemble(models, cv_scores, label_mapping, ensemble_acc, training_histories, architectures_used)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\nTraining Results:\")\n",
    "        for i, (score, arch) in enumerate(zip(cv_scores, architectures_used)):\n",
    "            print(f\"Fold {i+1}: {score:.1f}% ({arch})\")\n",
    "        print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "        print(f\"Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "        print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"Models saved to: {save_dir}\")\n",
    "        \n",
    "        print(\"\\nRunning model analysis...\")\n",
    "        analyzer = ModelAnalyzer(models, cv_scores, label_mapping, X_test, y_test, training_histories, architectures_used)\n",
    "        individual_results, ensemble_result, metrics = analyzer.run_analysis()\n",
    "        \n",
    "        print(\"\\nRunning Grad-CAM visualization...\")\n",
    "        gradcam_viz = GradCAMVisualizer(models, label_mapping, X_test, y_test, architectures_used)\n",
    "        gradcam_viz.run_gradcam_analysis()\n",
    "        \n",
    "        print(\"\\nPipeline Complete!\")\n",
    "        print(\"Check 'analysis_plots/' for performance analysis\")\n",
    "        print(\"Check 'gradcam_visualizations/' for attention maps\")\n",
    "        \n",
    "        return {\n",
    "            'models': models,\n",
    "            'cv_scores': cv_scores,\n",
    "            'ensemble_score': ensemble_acc,\n",
    "            'architectures_used': architectures_used,\n",
    "            'save_directory': save_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23ffe2c-08d5-4532-af7c-cfdacd263f49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Training Script\n",
      "==================================================\n",
      "Search result: save_dir=None, found 0 models\n",
      "No existing models found. Please run the main training script first.\n",
      "Looking for directories starting with 'multi_arch_ensemble_'\n",
      "Found directories: []\n"
     ]
    }
   ],
   "source": [
    "# Resume Training Script - Continue from where training stopped\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIGURATION - Should match your original training\n",
    "AVAILABLE_ARCHITECTURES = ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'mobilenetv3_large_100']\n",
    "AUGMENTATION_TARGET = 1200\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 448)\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 96\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train):\n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class MultiArchEnsembleTrainer:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        if 'resnet' in architecture:\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "            for name, param in model.named_parameters():\n",
    "                for frozen_layer in frozen_layers:\n",
    "                    if name.startswith(frozen_layer):\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'mobilenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.0' in name or 'features.1' in name or 'features.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "                model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_model(self, train_loader, val_loader, architecture):\n",
    "        model = self.create_model(architecture)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history, architecture\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        best_model = None\n",
    "        best_acc = 0.0\n",
    "        best_history = None\n",
    "        best_arch = None\n",
    "        \n",
    "        for arch in AVAILABLE_ARCHITECTURES:\n",
    "            try:\n",
    "                print(f\"  Testing {arch}...\")\n",
    "                model, val_acc, history, architecture = self.train_single_model(train_loader, val_loader, arch)\n",
    "                \n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "                    best_arch = architecture\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to train {arch}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_model, best_acc, best_history, best_arch\n",
    "\n",
    "def find_existing_models(save_dir=None):\n",
    "    \"\"\"Find existing model files from previous training\"\"\"\n",
    "    if save_dir is None:\n",
    "        # Find the most recent save directory\n",
    "        dirs = [d for d in os.listdir('.') if d.startswith('multi_arch_ensemble_')]\n",
    "        if not dirs:\n",
    "            return None, [], [], [], [], [], {}\n",
    "        save_dir = max(dirs, key=lambda x: os.path.getctime(x))\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        return None, [], [], [], [], [], {}\n",
    "    \n",
    "    print(f\"Found existing training directory: {save_dir}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(save_dir, \"metadata.json\")\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"Loaded metadata: {metadata}\")\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    # Find existing model files\n",
    "    model_files = glob.glob(os.path.join(save_dir, \"*_fold_*.pth\"))\n",
    "    model_files = [f for f in model_files if 'ensemble' not in f]\n",
    "    \n",
    "    models = []\n",
    "    cv_scores = []\n",
    "    architectures_used = []\n",
    "    training_histories = []\n",
    "    completed_folds = []\n",
    "    label_mapping = {}\n",
    "    \n",
    "    # Load training histories if available\n",
    "    history_path = os.path.join(save_dir, \"training_histories.pkl\")\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            training_histories = pickle.load(f)\n",
    "    \n",
    "    for model_file in sorted(model_files):\n",
    "        try:\n",
    "            checkpoint = torch.load(model_file, map_location='cpu')\n",
    "            fold_num = checkpoint['fold']\n",
    "            architecture = checkpoint['model_architecture']\n",
    "            cv_score = checkpoint['cv_score']\n",
    "            num_classes = checkpoint['num_classes']\n",
    "            model_label_mapping = checkpoint.get('label_mapping', {})\n",
    "            \n",
    "            # Use the first model's label mapping as reference\n",
    "            if not label_mapping and model_label_mapping:\n",
    "                label_mapping = model_label_mapping\n",
    "            \n",
    "            # Create and load model\n",
    "            trainer = MultiArchEnsembleTrainer(num_classes)\n",
    "            model = trainer.create_model(architecture)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            models.append(model)\n",
    "            cv_scores.append(cv_score)\n",
    "            architectures_used.append(architecture)\n",
    "            completed_folds.append(fold_num)\n",
    "            \n",
    "            print(f\"Loaded Fold {fold_num}: {cv_score:.1f}% ({architecture})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {model_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return save_dir, models, cv_scores, architectures_used, training_histories, completed_folds, label_mapping\n",
    "\n",
    "def resume_training():\n",
    "    print(\"Resume Training Script\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find existing models\n",
    "    try:\n",
    "        result = find_existing_models()\n",
    "        save_dir, models, cv_scores, architectures_used, training_histories, completed_folds, label_mapping = result\n",
    "        \n",
    "        print(f\"Search result: save_dir={save_dir}, found {len(models)} models\")\n",
    "        \n",
    "        if not models:\n",
    "            print(\"No existing models found. Please run the main training script first.\")\n",
    "            print(\"Looking for directories starting with 'multi_arch_ensemble_'\")\n",
    "            dirs = [d for d in os.listdir('.') if d.startswith('multi_arch_ensemble_')]\n",
    "            print(f\"Found directories: {dirs}\")\n",
    "            return\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error finding existing models: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(models)} completed folds: {completed_folds}\")\n",
    "    \n",
    "    # Determine which folds are missing\n",
    "    all_folds = set(range(1, NUM_FOLDS + 1))\n",
    "    missing_folds = all_folds - set(completed_folds)\n",
    "    \n",
    "    if not missing_folds:\n",
    "        print(\"All folds are complete! Proceeding with analysis...\")\n",
    "    else:\n",
    "        print(f\"Missing folds: {sorted(missing_folds)}\")\n",
    "        \n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        # Recreate label mapping if not available or empty\n",
    "        if not label_mapping:\n",
    "            unique_ages = sorted(list(set(ages)))\n",
    "            label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "            print(\"Recreated label mapping from data\")\n",
    "        else:\n",
    "            print(\"Using existing label mapping\")\n",
    "        \n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        # Recreate the same train/test split using the same random state\n",
    "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        # Recreate the same fold splits\n",
    "        skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "        fold_splits = list(skf.split(X_train_all, y_train_all))\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(len(label_mapping))\n",
    "        \n",
    "        # Train missing folds\n",
    "        for missing_fold in sorted(missing_folds):\n",
    "            print(f\"\\nTraining missing Fold {missing_fold}/{NUM_FOLDS}\")\n",
    "            \n",
    "            fold_idx = missing_fold - 1  # Convert to 0-based index\n",
    "            train_idx, val_idx = fold_splits[fold_idx]\n",
    "            \n",
    "            X_train_fold = X_train_all[train_idx]\n",
    "            y_train_fold = y_train_all[train_idx]\n",
    "            X_val_fold = X_train_all[val_idx]\n",
    "            y_val_fold = y_train_all[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=NUM_WORKERS)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=NUM_WORKERS)\n",
    "            \n",
    "            model, val_acc, history, best_arch = trainer.train_single_fold(train_loader, val_loader, missing_fold)\n",
    "            \n",
    "            if model is not None:\n",
    "                models.append(model)\n",
    "                cv_scores.append(val_acc)\n",
    "                architectures_used.append(best_arch)\n",
    "                training_histories.append(history)\n",
    "                completed_folds.append(missing_fold)\n",
    "                \n",
    "                # Save the new model immediately\n",
    "                model_path = os.path.join(save_dir, f\"{best_arch}_fold_{missing_fold}_{val_acc:.1f}pct.pth\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'model_architecture': best_arch,\n",
    "                    'fold': missing_fold,\n",
    "                    'cv_score': val_acc,\n",
    "                    'num_classes': len(label_mapping),\n",
    "                    'label_mapping': label_mapping,\n",
    "                    'input_size': IMAGE_SIZE\n",
    "                }, model_path)\n",
    "                \n",
    "                print(f\"Fold {missing_fold} completed: {val_acc:.1f}% with {best_arch}\")\n",
    "                print(f\"Saved to: {model_path}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Update training histories\n",
    "        history_path = os.path.join(save_dir, \"training_histories.pkl\")\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(training_histories, f)\n",
    "    \n",
    "    # Now proceed with ensemble evaluation and analysis\n",
    "    print(\"\\nAll folds complete! Running ensemble evaluation...\")\n",
    "    \n",
    "    # Load test data and ensure we have label mapping\n",
    "    images, ages = load_original_data()\n",
    "    \n",
    "    if not label_mapping:\n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        print(\"Recreated label mapping for final evaluation\")\n",
    "    \n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Create ensemble and evaluate\n",
    "    trainer = MultiArchEnsembleTrainer(len(label_mapping))\n",
    "    \n",
    "    test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "    \n",
    "    # Update and save ensemble\n",
    "    ensemble_path = os.path.join(save_dir, \"multi_arch_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': architectures_used,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    # Update metadata\n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        'architectures_used': architectures_used,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': f'{IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}',\n",
    "        'augmentation_target': AUGMENTATION_TARGET,\n",
    "        'completed': True\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    for i, (score, arch) in enumerate(zip(cv_scores, architectures_used)):\n",
    "        print(f\"Fold {i+1}: {score:.1f}% ({arch})\")\n",
    "    print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "    print(f\"Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "    print(f\"Results saved to: {save_dir}\")\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'architectures_used': architectures_used,\n",
    "        'save_directory': save_dir,\n",
    "        'label_mapping': label_mapping\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9498ba-7329-4caa-bfd0-608d5294290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Multi-Architecture Ensemble Training with Incremental Saving\n",
      "================================================================================\n",
      "Available architectures: ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'mobilenetv3_large_100']\n",
      "Number of folds: 5\n",
      "Image size: 448x224\n",
      "Augmentation target: 1200 samples per class\n",
      "Loading data...\n",
      "Results will be saved to: multi_arch_ensemble_20250720_083652\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "Training ensemble (with incremental saving)...\n",
      "Found existing folds: []\n",
      "Training Fold 1/5\n",
      "  Testing resnet18...\n",
      "  Testing resnet34...\n",
      "  Testing resnet50...\n",
      "  Testing efficientnet_b0...\n",
      "  Testing efficientnet_b1...\n",
      "  Testing efficientnet_b2...\n",
      "  Testing mobilenetv3_large_100...\n",
      "  Saved fold 1 to: multi_arch_ensemble_20250720_083652\\efficientnet_b1_fold_1_87.2pct.pth\n",
      "Fold 1/5 completed: 87.2% with efficientnet_b1\n",
      "Training Fold 2/5\n",
      "  Testing resnet18...\n",
      "  Testing resnet34...\n",
      "  Testing resnet50...\n",
      "  Testing efficientnet_b0...\n",
      "  Testing efficientnet_b1...\n",
      "  Testing efficientnet_b2...\n",
      "  Testing mobilenetv3_large_100...\n",
      "  Saved fold 2 to: multi_arch_ensemble_20250720_083652\\efficientnet_b0_fold_2_91.5pct.pth\n",
      "Fold 2/5 completed: 91.5% with efficientnet_b0\n",
      "Training Fold 3/5\n",
      "  Testing resnet18...\n",
      "  Testing resnet34...\n",
      "  Testing resnet50...\n",
      "  Testing efficientnet_b0...\n",
      "  Testing efficientnet_b1...\n",
      "  Testing efficientnet_b2...\n",
      "  Testing mobilenetv3_large_100...\n",
      "  Saved fold 3 to: multi_arch_ensemble_20250720_083652\\efficientnet_b2_fold_3_95.7pct.pth\n",
      "Fold 3/5 completed: 95.7% with efficientnet_b2\n",
      "Training Fold 4/5\n",
      "  Testing resnet18...\n",
      "  Testing resnet34...\n",
      "  Testing resnet50...\n",
      "  Testing efficientnet_b0...\n",
      "  Testing efficientnet_b1...\n",
      "  Testing efficientnet_b2...\n",
      "  Testing mobilenetv3_large_100...\n",
      "  Saved fold 4 to: multi_arch_ensemble_20250720_083652\\efficientnet_b1_fold_4_87.0pct.pth\n",
      "Fold 4/5 completed: 87.0% with efficientnet_b1\n",
      "Training Fold 5/5\n",
      "  Testing resnet18...\n",
      "  Testing resnet34...\n",
      "  Testing resnet50...\n"
     ]
    }
   ],
   "source": [
    "# Improved Multi-Architecture Ensemble Training with Incremental Saving\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIGURATION - Change model architectures here\n",
    "AVAILABLE_ARCHITECTURES = ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'mobilenetv3_large_100']\n",
    "AUGMENTATION_TARGET = 1200\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 448)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train):\n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class MultiArchEnsembleTrainer:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Create save directory at initialization\n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"multi_arch_ensemble_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        print(f\"Results will be saved to: {self.save_dir}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        if 'resnet' in architecture:\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "            for name, param in model.named_parameters():\n",
    "                for frozen_layer in frozen_layers:\n",
    "                    if name.startswith(frozen_layer):\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'mobilenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.0' in name or 'features.1' in name or 'features.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "                model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_model(self, train_loader, val_loader, architecture):\n",
    "        model = self.create_model(architecture)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # Clear intermediate tensors every few batches\n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    # Clear memory during validation too\n",
    "                    if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            # Periodic GPU memory cleanup\n",
    "            if epoch % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history, architecture\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        best_model = None\n",
    "        best_acc = 0.0\n",
    "        best_history = None\n",
    "        best_arch = None\n",
    "        \n",
    "        for arch in AVAILABLE_ARCHITECTURES:\n",
    "            try:\n",
    "                print(f\"  Testing {arch}...\")\n",
    "                model, val_acc, history, architecture = self.train_single_model(train_loader, val_loader, arch)\n",
    "                \n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "                    best_arch = architecture\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to train {arch}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_model, best_acc, best_history, best_arch\n",
    "    \n",
    "    def save_fold_immediately(self, model, fold_num, architecture, cv_score, label_mapping, history):\n",
    "        \"\"\"Save a single fold immediately after training\"\"\"\n",
    "        model_path = os.path.join(self.save_dir, f\"{architecture}_fold_{fold_num}_{cv_score:.1f}pct.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': architecture,\n",
    "            'fold': fold_num,\n",
    "            'cv_score': cv_score,\n",
    "            'num_classes': self.num_classes,\n",
    "            'label_mapping': label_mapping,\n",
    "            'input_size': IMAGE_SIZE,\n",
    "            'training_history': history\n",
    "        }, model_path)\n",
    "        \n",
    "        print(f\"  Saved fold {fold_num} to: {model_path}\")\n",
    "        return model_path\n",
    "    \n",
    "    def check_existing_folds(self):\n",
    "        \"\"\"Check which folds have already been completed\"\"\"\n",
    "        existing_files = glob.glob(os.path.join(self.save_dir, \"*_fold_*.pth\"))\n",
    "        completed_folds = []\n",
    "        \n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                checkpoint = torch.load(file_path, map_location='cpu')\n",
    "                fold_num = checkpoint.get('fold', None)\n",
    "                if fold_num is not None:\n",
    "                    completed_folds.append(fold_num)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return sorted(completed_folds)\n",
    "    \n",
    "    def load_existing_fold(self, fold_num):\n",
    "        \"\"\"Load an existing fold model\"\"\"\n",
    "        pattern = os.path.join(self.save_dir, f\"*_fold_{fold_num}_*.pth\")\n",
    "        matching_files = glob.glob(pattern)\n",
    "        \n",
    "        if not matching_files:\n",
    "            return None, None, None, None\n",
    "        \n",
    "        file_path = matching_files[0]  # Take first match\n",
    "        try:\n",
    "            checkpoint = torch.load(file_path, map_location='cpu')\n",
    "            \n",
    "            architecture = checkpoint.get('model_architecture', 'unknown')\n",
    "            cv_score = checkpoint.get('cv_score', 0.0)\n",
    "            history = checkpoint.get('training_history', {})\n",
    "            \n",
    "            model = self.create_model(architecture)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            print(f\"  Loaded existing Fold {fold_num}: {cv_score:.1f}% ({architecture})\")\n",
    "            return model, cv_score, history, architecture\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to load fold {fold_num}: {e}\")\n",
    "            return None, None, None, None\n",
    "    \n",
    "    def train_ensemble(self, images, ages):\n",
    "        if not isinstance(images, np.ndarray):\n",
    "            images = np.array(images)\n",
    "        if not isinstance(ages, np.ndarray):\n",
    "            ages = np.array(ages)\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        # Save label mapping immediately\n",
    "        with open(os.path.join(self.save_dir, \"label_mapping.json\"), 'w') as f:\n",
    "            json.dump(label_mapping, f, indent=2)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "        fold_splits = list(skf.split(images, y_indices))\n",
    "        \n",
    "        # Save fold splits for reproducibility\n",
    "        with open(os.path.join(self.save_dir, \"fold_splits.pkl\"), 'wb') as f:\n",
    "            pickle.dump(fold_splits, f)\n",
    "        \n",
    "        # Check for existing folds\n",
    "        completed_folds = self.check_existing_folds()\n",
    "        print(f\"Found existing folds: {completed_folds}\")\n",
    "        \n",
    "        trained_models = []\n",
    "        cv_scores = []\n",
    "        training_histories = []\n",
    "        architectures_used = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(fold_splits):\n",
    "            fold_num = fold_idx + 1\n",
    "            \n",
    "            # Check if this fold is already completed\n",
    "            if fold_num in completed_folds:\n",
    "                model, cv_score, history, arch = self.load_existing_fold(fold_num)\n",
    "                if model is not None:\n",
    "                    trained_models.append(model)\n",
    "                    cv_scores.append(cv_score)\n",
    "                    training_histories.append(history)\n",
    "                    architectures_used.append(arch)\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Training Fold {fold_num}/{NUM_FOLDS}\")\n",
    "            \n",
    "            X_train_fold = images[train_idx]\n",
    "            y_train_fold = y_indices[train_idx]\n",
    "            X_val_fold = images[val_idx]\n",
    "            y_val_fold = y_indices[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            batch_size = 16 if torch.cuda.is_available() else 8\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "            model, val_acc, history, best_arch = self.train_single_fold(train_loader, val_loader, fold_num)\n",
    "            \n",
    "            if model is not None:\n",
    "                # Save immediately after training each fold\n",
    "                self.save_fold_immediately(model, fold_num, best_arch, val_acc, label_mapping, history)\n",
    "                \n",
    "                trained_models.append(model)\n",
    "                cv_scores.append(val_acc)\n",
    "                training_histories.append(history)\n",
    "                architectures_used.append(best_arch)\n",
    "                print(f\"Fold {fold_num}/{NUM_FOLDS} completed: {val_acc:.1f}% with {best_arch}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return trained_models, cv_scores, label_mapping, training_histories, architectures_used\n",
    "    \n",
    "    def evaluate_ensemble(self, models, cv_scores, test_loader):\n",
    "        scores_array = np.array(cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_ensemble_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                ensemble_outputs = torch.zeros(images.size(0), self.num_classes).to(self.device)\n",
    "                \n",
    "                for model, weight in zip(models, weights):\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    avg_outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    ensemble_outputs += weight * F.softmax(avg_outputs, dim=1)\n",
    "                \n",
    "                _, predicted = torch.max(ensemble_outputs, 1)\n",
    "                \n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_ensemble_probs.extend(ensemble_outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        ensemble_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        return ensemble_acc, np.array(all_ensemble_probs), np.array(all_labels)\n",
    "\n",
    "def save_final_ensemble(trainer, models, cv_scores, label_mapping, ensemble_acc, training_histories, architectures_used):\n",
    "    \"\"\"Save the final ensemble and metadata\"\"\"\n",
    "    \n",
    "    ensemble_path = os.path.join(trainer.save_dir, \"multi_arch_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': architectures_used,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    with open(os.path.join(trainer.save_dir, \"training_histories.pkl\"), 'wb') as f:\n",
    "        pickle.dump(training_histories, f)\n",
    "    \n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        'architectures_used': architectures_used,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': f'{IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}',\n",
    "        'augmentation_target': AUGMENTATION_TARGET,\n",
    "        'completed': True\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(trainer.save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Final ensemble saved to: {ensemble_path}\")\n",
    "    return trainer.save_dir\n",
    "\n",
    "def main():\n",
    "    print(\"Improved Multi-Architecture Ensemble Training with Incremental Saving\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Available architectures: {AVAILABLE_ARCHITECTURES}\")\n",
    "    print(f\"Number of folds: {NUM_FOLDS}\")\n",
    "    print(f\"Image size: {IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}\")\n",
    "    print(f\"Augmentation target: {AUGMENTATION_TARGET} samples per class\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(num_classes=len(set(ages)))\n",
    "        \n",
    "        print(\"Training ensemble (with incremental saving)...\")\n",
    "        models, cv_scores, label_mapping, training_histories, architectures_used = trainer.train_ensemble(images, ages)\n",
    "        \n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "        batch_size = 32 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "        \n",
    "        print(\"Saving final ensemble...\")\n",
    "        save_dir = save_final_ensemble(trainer, models, cv_scores, label_mapping, ensemble_acc, training_histories, architectures_used)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\nTraining Results:\")\n",
    "        for i, (score, arch) in enumerate(zip(cv_scores, architectures_used)):\n",
    "            print(f\"Fold {i+1}: {score:.1f}% ({arch})\")\n",
    "        print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "        print(f\"Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "        print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"All results saved to: {save_dir}\")\n",
    "        \n",
    "        return {\n",
    "            'models': models,\n",
    "            'cv_scores': cv_scores,\n",
    "            'ensemble_score': ensemble_acc,\n",
    "            'architectures_used': architectures_used,\n",
    "            'save_directory': save_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb7bbf-6d90-43d5-b3d9-6e8bdd8e8a66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# \"improved\" resume script\n",
    "# Resume Training Script - Continue from where training stopped\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIGURATION - Should match your original training\n",
    "AVAILABLE_ARCHITECTURES = ['resnet18', 'resnet34', 'resnet50', 'efficientnet_b0', 'mobilenetv3_large_100']\n",
    "AUGMENTATION_TARGET = 1200\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 448)\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 96\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train):\n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class MultiArchEnsembleTrainer:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        if 'resnet' in architecture:\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "            for name, param in model.named_parameters():\n",
    "                for frozen_layer in frozen_layers:\n",
    "                    if name.startswith(frozen_layer):\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'mobilenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.0' in name or 'features.1' in name or 'features.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "                model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_model(self, train_loader, val_loader, architecture):\n",
    "        model = self.create_model(architecture)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history, architecture\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        best_model = None\n",
    "        best_acc = 0.0\n",
    "        best_history = None\n",
    "        best_arch = None\n",
    "        \n",
    "        for arch in AVAILABLE_ARCHITECTURES:\n",
    "            try:\n",
    "                print(f\"  Testing {arch}...\")\n",
    "                model, val_acc, history, architecture = self.train_single_model(train_loader, val_loader, arch)\n",
    "                \n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "                    best_arch = architecture\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to train {arch}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_model, best_acc, best_history, best_arch\n",
    "\n",
    "def find_existing_models(save_dir=None):\n",
    "    \"\"\"Find existing model files from previous training\"\"\"\n",
    "    if save_dir is None:\n",
    "        # Look for the exact directory pattern from the original script\n",
    "        dirs = [d for d in os.listdir('.') if d.startswith('multi_arch_ensemble_') and os.path.isdir(d)]\n",
    "        \n",
    "        if not dirs:\n",
    "            print(\"No 'multi_arch_ensemble_*' directories found.\")\n",
    "            print(\"This suggests the original training didn't complete and save models.\")\n",
    "            print(\"The original script only saves models after ALL folds complete.\")\n",
    "            return None, [], [], [], [], [], {}\n",
    "        \n",
    "        # Find the most recent one\n",
    "        save_dir = max(dirs, key=lambda x: os.path.getctime(x))\n",
    "        print(f\"Found directories: {dirs}\")\n",
    "        print(f\"Using most recent: {save_dir}\")\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        return None, [], [], [], [], [], {}\n",
    "    \n",
    "    print(f\"Found existing training directory: {save_dir}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(save_dir, \"metadata.json\")\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"Loaded metadata: {metadata}\")\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    # Find existing model files - look in save_dir and also current directory\n",
    "    model_files = []\n",
    "    \n",
    "    if save_dir:\n",
    "        model_files.extend(glob.glob(os.path.join(save_dir, \"*_fold_*.pth\")))\n",
    "    \n",
    "    # Also check current directory for model files\n",
    "    current_dir_files = glob.glob(\"*_fold_*.pth\")\n",
    "    model_files.extend(current_dir_files)\n",
    "    \n",
    "    # Remove duplicates and exclude ensemble files\n",
    "    model_files = list(set([f for f in model_files if 'ensemble' not in os.path.basename(f)]))\n",
    "    \n",
    "    print(f\"Found model files: {model_files}\")\n",
    "    \n",
    "    if not model_files:\n",
    "        return save_dir, [], [], [], [], [], {}\n",
    "    \n",
    "    models = []\n",
    "    cv_scores = []\n",
    "    architectures_used = []\n",
    "    training_histories = []\n",
    "    completed_folds = []\n",
    "    label_mapping = {}\n",
    "    \n",
    "    # Load training histories if available\n",
    "    history_path = os.path.join(save_dir, \"training_histories.pkl\")\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            training_histories = pickle.load(f)\n",
    "    \n",
    "    for model_file in sorted(model_files):\n",
    "        try:\n",
    "            print(f\"Attempting to load: {model_file}\")\n",
    "            checkpoint = torch.load(model_file, map_location='cpu')\n",
    "            \n",
    "            # Handle different checkpoint formats\n",
    "            fold_num = checkpoint.get('fold', None)\n",
    "            if fold_num is None:\n",
    "                # Try to extract fold number from filename\n",
    "                import re\n",
    "                match = re.search(r'fold[_\\s]*(\\d+)', os.path.basename(model_file), re.IGNORECASE)\n",
    "                if match:\n",
    "                    fold_num = int(match.group(1))\n",
    "                else:\n",
    "                    print(f\"Cannot determine fold number for {model_file}\")\n",
    "                    continue\n",
    "            \n",
    "            architecture = checkpoint.get('model_architecture', 'unknown')\n",
    "            cv_score = checkpoint.get('cv_score', 0.0)\n",
    "            num_classes = checkpoint.get('num_classes', None)\n",
    "            model_label_mapping = checkpoint.get('label_mapping', {})\n",
    "            \n",
    "            # Handle missing num_classes\n",
    "            if num_classes is None:\n",
    "                if model_label_mapping:\n",
    "                    num_classes = len(model_label_mapping)\n",
    "                else:\n",
    "                    print(f\"Cannot determine num_classes for {model_file}\")\n",
    "                    continue\n",
    "            \n",
    "            # Use the first model's label mapping as reference\n",
    "            if not label_mapping and model_label_mapping:\n",
    "                label_mapping = model_label_mapping\n",
    "            \n",
    "            # Create and load model\n",
    "            trainer = MultiArchEnsembleTrainer(num_classes)\n",
    "            model = trainer.create_model(architecture)\n",
    "            \n",
    "            # Handle different state dict keys\n",
    "            state_dict_key = 'model_state_dict'\n",
    "            if state_dict_key not in checkpoint:\n",
    "                # Maybe it's just the raw state dict\n",
    "                if any(key.startswith('conv') or key.startswith('fc') or key.startswith('layer') for key in checkpoint.keys()):\n",
    "                    model.load_state_dict(checkpoint)\n",
    "                else:\n",
    "                    print(f\"Cannot find state dict in {model_file}\")\n",
    "                    continue\n",
    "            else:\n",
    "                model.load_state_dict(checkpoint[state_dict_key])\n",
    "            \n",
    "            models.append(model)\n",
    "            cv_scores.append(cv_score)\n",
    "            architectures_used.append(architecture)\n",
    "            completed_folds.append(fold_num)\n",
    "            \n",
    "            print(f\"Successfully loaded Fold {fold_num}: {cv_score:.1f}% ({architecture})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {model_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    return save_dir, models, cv_scores, architectures_used, training_histories, completed_folds, label_mapping\n",
    "\n",
    "def resume_training():\n",
    "    print(\"Resume Training Script\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find existing models\n",
    "    try:\n",
    "        result = find_existing_models()\n",
    "        save_dir, models, cv_scores, architectures_used, training_histories, completed_folds, label_mapping = result\n",
    "        \n",
    "        print(f\"Search result: save_dir={save_dir}, found {len(models)} models\")\n",
    "        \n",
    "        if not models:\n",
    "            print(\"No existing models found. Please run the main training script first.\")\n",
    "            print(\"Looking for directories containing 'ensemble'\")\n",
    "            \n",
    "            # Show all directories for debugging\n",
    "            all_dirs = [d for d in os.listdir('.') if os.path.isdir(d)]\n",
    "            ensemble_dirs = [d for d in all_dirs if 'ensemble' in d.lower()]\n",
    "            \n",
    "            print(f\"All directories: {all_dirs}\")\n",
    "            print(f\"Ensemble directories found: {ensemble_dirs}\")\n",
    "            \n",
    "            # Also look for .pth files in current directory\n",
    "            pth_files = glob.glob(\"*.pth\")\n",
    "            print(f\"Model files in current directory: {pth_files}\")\n",
    "            \n",
    "            return\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error finding existing models: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(models)} completed folds: {completed_folds}\")\n",
    "    \n",
    "    # Determine which folds are missing\n",
    "    all_folds = set(range(1, NUM_FOLDS + 1))\n",
    "    missing_folds = all_folds - set(completed_folds)\n",
    "    \n",
    "    if not missing_folds:\n",
    "        print(\"All folds are complete! Proceeding with analysis...\")\n",
    "    else:\n",
    "        print(f\"Missing folds: {sorted(missing_folds)}\")\n",
    "        \n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        # Recreate label mapping if not available or empty\n",
    "        if not label_mapping:\n",
    "            unique_ages = sorted(list(set(ages)))\n",
    "            label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "            print(\"Recreated label mapping from data\")\n",
    "        else:\n",
    "            print(\"Using existing label mapping\")\n",
    "        \n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        # Recreate the same train/test split using the same random state\n",
    "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        # Recreate the same fold splits\n",
    "        skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "        fold_splits = list(skf.split(X_train_all, y_train_all))\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(len(label_mapping))\n",
    "        \n",
    "        # Train missing folds\n",
    "        for missing_fold in sorted(missing_folds):\n",
    "            print(f\"\\nTraining missing Fold {missing_fold}/{NUM_FOLDS}\")\n",
    "            \n",
    "            fold_idx = missing_fold - 1  # Convert to 0-based index\n",
    "            train_idx, val_idx = fold_splits[fold_idx]\n",
    "            \n",
    "            X_train_fold = X_train_all[train_idx]\n",
    "            y_train_fold = y_train_all[train_idx]\n",
    "            X_val_fold = X_train_all[val_idx]\n",
    "            y_val_fold = y_train_all[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=NUM_WORKERS)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=NUM_WORKERS)\n",
    "            \n",
    "            model, val_acc, history, best_arch = trainer.train_single_fold(train_loader, val_loader, missing_fold)\n",
    "            \n",
    "            if model is not None:\n",
    "                models.append(model)\n",
    "                cv_scores.append(val_acc)\n",
    "                architectures_used.append(best_arch)\n",
    "                training_histories.append(history)\n",
    "                completed_folds.append(missing_fold)\n",
    "                \n",
    "                # Save the new model immediately\n",
    "                model_path = os.path.join(save_dir, f\"{best_arch}_fold_{missing_fold}_{val_acc:.1f}pct.pth\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'model_architecture': best_arch,\n",
    "                    'fold': missing_fold,\n",
    "                    'cv_score': val_acc,\n",
    "                    'num_classes': len(label_mapping),\n",
    "                    'label_mapping': label_mapping,\n",
    "                    'input_size': IMAGE_SIZE\n",
    "                }, model_path)\n",
    "                \n",
    "                print(f\"Fold {missing_fold} completed: {val_acc:.1f}% with {best_arch}\")\n",
    "                print(f\"Saved to: {model_path}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Update training histories\n",
    "        history_path = os.path.join(save_dir, \"training_histories.pkl\")\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(training_histories, f)\n",
    "    \n",
    "    # Now proceed with ensemble evaluation and analysis\n",
    "    print(\"\\nAll folds complete! Running ensemble evaluation...\")\n",
    "    \n",
    "    # Load test data and ensure we have label mapping\n",
    "    images, ages = load_original_data()\n",
    "    \n",
    "    if not label_mapping:\n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        print(\"Recreated label mapping for final evaluation\")\n",
    "    \n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Create ensemble and evaluate\n",
    "    trainer = MultiArchEnsembleTrainer(len(label_mapping))\n",
    "    \n",
    "    test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "    \n",
    "    # Update and save ensemble\n",
    "    ensemble_path = os.path.join(save_dir, \"multi_arch_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': architectures_used,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    # Update metadata\n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        'architectures_used': architectures_used,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': f'{IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}',\n",
    "        'augmentation_target': AUGMENTATION_TARGET,\n",
    "        'completed': True\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    for i, (score, arch) in enumerate(zip(cv_scores, architectures_used)):\n",
    "        print(f\"Fold {i+1}: {score:.1f}% ({arch})\")\n",
    "    print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "    print(f\"Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "    print(f\"Results saved to: {save_dir}\")\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'architectures_used': architectures_used,\n",
    "        'save_directory': save_dir,\n",
    "        'label_mapping': label_mapping\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
