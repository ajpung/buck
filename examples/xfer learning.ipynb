{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e197dfc4-bdbe-4eab-b9a3-43ff7608e8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: absl-py in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (2.1.3)\n",
      "Requirement already satisfied: rich in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (0.0.9)\n",
      "Requirement already satisfied: h5py in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from optree->keras) (4.13.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in g:\\dropbox\\ai projects\\buck\\buck-env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7620144f-f327-42d2-9868-74c3f99e96b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 image files\n",
      "Converted grayscale to RGB: ..\\images\\squared\\241205_240927_TX_3p5_NDA.png\n",
      "Converted grayscale to RGB: ..\\images\\squared\\250501_241108_PA_8p5_NDA.png\n",
      "Loaded 225 images, all converted to RGB\n"
     ]
    }
   ],
   "source": [
    "# Image parsing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from buck.analysis.basics import ingest_images\n",
    "\n",
    "# Your existing ingestion\n",
    "fpath = \"..\\\\images\\\\squared\\\\*_NDA.png\"\n",
    "\n",
    "def read_images_convert_to_rgb(file_pattern):\n",
    "    \"\"\"\n",
    "    Read images and convert grayscale to RGB\n",
    "    \n",
    "    Args:\n",
    "        file_pattern: Pattern like \"..\\\\images\\\\squared\\\\*_NDA.png\"\n",
    "    \n",
    "    Returns:\n",
    "        images: List of RGB images (all have 3 channels)\n",
    "        file_paths: List of file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    file_paths = glob.glob(file_pattern)\n",
    "    print(f\"Found {len(file_paths)} image files\")\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        try:\n",
    "            # Load image in color\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not load {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Check if it's actually grayscale (all channels identical)\n",
    "            if np.allclose(img_rgb[:,:,0], img_rgb[:,:,1]) and np.allclose(img_rgb[:,:,1], img_rgb[:,:,2]):\n",
    "                print(f\"Converted grayscale to RGB: {file_path}\")\n",
    "            \n",
    "            # All images are now RGB regardless of original format\n",
    "            images.append(img_rgb)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images, all converted to RGB\")\n",
    "    \n",
    "    return images, file_paths[:len(images)]\n",
    "\n",
    "images, paths = read_images_convert_to_rgb(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856836c3-38a9-41c3-8957-725d361c01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ages from filenames...\n",
      "Skipping invalid age in: ..\\images\\squared\\250522_241221_IN_xpx_NDA.png\n",
      "Successfully processed 224 images\n",
      "Applying age grouping: ages 5.5+ -> 5.5\n",
      "Original age distribution:\n",
      "  Age 1.5: 31 images\n",
      "  Age 2.5: 39 images\n",
      "  Age 3.5: 47 images\n",
      "  Age 4.5: 54 images\n",
      "  Age 5.5: 41 images\n",
      "  Age 6.5: 6 images\n",
      "  Age 8.5: 5 images\n",
      "  Age 12.5: 1 images\n",
      "Grouped age distribution:\n",
      "  Age 1.5: 31 images\n",
      "  Age 2.5: 39 images\n",
      "  Age 3.5: 47 images\n",
      "  Age 4.5: 54 images\n",
      "  Age 5.5: 53 images\n",
      "Image array shape: (224, 224, 224, 3)\n",
      "Ages array shape: (224,)\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "Minimum class count: 31\n",
      "Using stratified splitting to maintain class balance.\n",
      "\n",
      "Data split completed:\n",
      "  Training set: 134 images\n",
      "  Validation set: 45 images\n",
      "  Test set: 45 images\n",
      "  Number of classes: 5\n",
      "\n",
      "Class distribution:\n",
      "  Train:\n",
      "    Age 1.5: 19 images\n",
      "    Age 2.5: 23 images\n",
      "    Age 3.5: 29 images\n",
      "    Age 4.5: 32 images\n",
      "    Age 5.5: 31 images\n",
      "  Val:\n",
      "    Age 1.5: 6 images\n",
      "    Age 2.5: 8 images\n",
      "    Age 3.5: 9 images\n",
      "    Age 4.5: 11 images\n",
      "    Age 5.5: 11 images\n",
      "  Test:\n",
      "    Age 1.5: 6 images\n",
      "    Age 2.5: 8 images\n",
      "    Age 3.5: 9 images\n",
      "    Age 4.5: 11 images\n",
      "    Age 5.5: 11 images\n"
     ]
    }
   ],
   "source": [
    "# Extract / combine dates\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "def extract_age_from_path(file_path):\n",
    "    \"\"\"\n",
    "    Extract age from file path using your exact working logic\n",
    "    \n",
    "    Args:\n",
    "        file_path: Full path to image file\n",
    "    \n",
    "    Returns:\n",
    "        age: Float age (e.g., 2.5 for \"2p5\") or None if invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        age_part = file_path.split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[3]\n",
    "        \n",
    "        # Skip invalid age parts like \"xpx\"\n",
    "        if 'x' in age_part or len(age_part) < 2:\n",
    "            return None\n",
    "            \n",
    "        age_float = float(age_part.replace(\"p\", \".\"))\n",
    "        \n",
    "        # Validate reasonable deer age\n",
    "        if 0.5 <= age_float <= 15.5:\n",
    "            return age_float\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except (IndexError, ValueError):\n",
    "        return None\n",
    "\n",
    "def split_images_with_ages(images, file_paths, target_size=(224, 224), test_size=0.2, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split images into train/test/validation sets and extract ages\n",
    "    \n",
    "    Args:\n",
    "        images: List of RGB images\n",
    "        file_paths: List of corresponding file paths\n",
    "        target_size: Resize all images to this size for uniform arrays\n",
    "        test_size: Fraction for test set (default 0.2 = 20%)\n",
    "        val_size: Fraction of remaining data for validation (default 0.2 = 20%)\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_val, X_test: Image arrays\n",
    "        y_train, y_val, y_test: Age labels (one-hot encoded)\n",
    "        label_mapping: Dictionary mapping class indices to ages\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting ages from filenames...\")\n",
    "    \n",
    "    # Extract ages and resize images\n",
    "    ages = []\n",
    "    resized_images = []\n",
    "    \n",
    "    for i, (image, file_path) in enumerate(zip(images, file_paths)):\n",
    "        try:\n",
    "            age = extract_age_from_path(file_path)\n",
    "            \n",
    "            if age is not None:\n",
    "                # Resize image to target size for uniform array\n",
    "                import cv2\n",
    "                resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "                \n",
    "                ages.append(age)\n",
    "                resized_images.append(resized_img)\n",
    "            else:\n",
    "                print(f\"Skipping invalid age in: {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {len(ages)} images\")\n",
    "    \n",
    "    # Group ages: all ages 5.5 and over become 5.5 (mature deer)\n",
    "    print(\"Applying age grouping: ages 5.5+ -> 5.5\")\n",
    "    original_ages = ages.copy()\n",
    "    ages_grouped = []\n",
    "    \n",
    "    for age in ages:\n",
    "        if age >= 5.5:\n",
    "            ages_grouped.append(5.5)\n",
    "        else:\n",
    "            ages_grouped.append(age)\n",
    "    \n",
    "    # Show original vs grouped distribution\n",
    "    print(\"Original age distribution:\")\n",
    "    unique_original = sorted(list(set(original_ages)))\n",
    "    for age in unique_original:\n",
    "        count = original_ages.count(age)\n",
    "        print(f\"  Age {age}: {count} images\")\n",
    "    \n",
    "    print(\"Grouped age distribution:\")\n",
    "    unique_ages = sorted(list(set(ages_grouped)))\n",
    "    for age in unique_ages:\n",
    "        count = ages_grouped.count(age)\n",
    "        print(f\"  Age {age}: {count} images\")\n",
    "    \n",
    "    # Use grouped ages for the rest of the process\n",
    "    ages = ages_grouped\n",
    "    \n",
    "    # Convert to numpy arrays (now all images have same size)\n",
    "    X = np.array(resized_images)\n",
    "    y_raw = np.array(ages)\n",
    "    \n",
    "    print(f\"Image array shape: {X.shape}\")\n",
    "    print(f\"Ages array shape: {y_raw.shape}\")\n",
    "    \n",
    "    # Create label mapping (age -> class index)\n",
    "    label_mapping = {age: idx for idx, age in enumerate(unique_ages)}\n",
    "    reverse_mapping = {idx: age for age, idx in label_mapping.items()}\n",
    "    \n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Convert ages to class indices\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    # Check class counts for stratification\n",
    "    unique_classes, class_counts = np.unique(y_indices, return_counts=True)\n",
    "    min_class_count = np.min(class_counts)\n",
    "    \n",
    "    print(f\"Minimum class count: {min_class_count}\")\n",
    "    \n",
    "    # If any class has fewer than 2 samples, we can't use stratification\n",
    "    if min_class_count < 2:\n",
    "        print(\"Warning: Some classes have only 1 sample. Cannot use stratified splitting.\")\n",
    "        print(\"Using random splitting instead.\")\n",
    "        \n",
    "        # First split: separate test set (no stratification)\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y_indices, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Second split: separate train and validation (no stratification)\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        print(\"Using stratified splitting to maintain class balance.\")\n",
    "        \n",
    "        # First split: separate test set (with stratification)\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y_indices, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        # Second split: separate train and validation (with stratification)\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=random_state,\n",
    "            stratify=y_temp\n",
    "        )\n",
    "    \n",
    "    # Convert to one-hot encoding\n",
    "    num_classes = len(unique_ages)\n",
    "    y_train_onehot = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val_onehot = keras.utils.to_categorical(y_val, num_classes)\n",
    "    y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print(f\"\\nData split completed:\")\n",
    "    print(f\"  Training set: {X_train.shape[0]} images\")\n",
    "    print(f\"  Validation set: {X_val.shape[0]} images\")\n",
    "    print(f\"  Test set: {X_test.shape[0]} images\")\n",
    "    print(f\"  Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Show class distribution in each set\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    for split_name, y_split in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "        print(f\"  {split_name}:\")\n",
    "        for class_idx in range(num_classes):\n",
    "            count = np.sum(y_split == class_idx)\n",
    "            age = reverse_mapping[class_idx]\n",
    "            print(f\"    Age {age}: {count} images\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train_onehot, y_val_onehot, y_test_onehot, label_mapping\n",
    "\n",
    "# Test usage:\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, mapping = split_images_with_ages(images, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53114930-d6b8-45a8-8a8b-6e8e5a666944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data augmentation and class balancing...\n",
      "Input data shape: (134, 224, 224, 3)\n",
      "Input labels shape: (134, 5)\n",
      "Current class distribution:\n",
      "  Class 0: 19 samples\n",
      "  Class 1: 23 samples\n",
      "  Class 2: 29 samples\n",
      "  Class 3: 32 samples\n",
      "  Class 4: 31 samples\n",
      "Target samples per class: 500\n",
      "\n",
      "Processing class 0...\n",
      "  Current samples: 19\n",
      "  Target samples: 500\n",
      "  Generating 481 augmented samples...\n",
      "    Generated 481/481 samples\n",
      "  Final samples for class 0: 500\n",
      "\n",
      "Processing class 1...\n",
      "  Current samples: 23\n",
      "  Target samples: 500\n",
      "  Generating 477 augmented samples...\n",
      "    Generated 477/477 samples\n",
      "  Final samples for class 1: 500\n",
      "\n",
      "Processing class 2...\n",
      "  Current samples: 29\n",
      "  Target samples: 500\n",
      "  Generating 471 augmented samples...\n",
      "    Generated 471/471 samples\n",
      "  Final samples for class 2: 500\n",
      "\n",
      "Processing class 3...\n",
      "  Current samples: 32\n",
      "  Target samples: 500\n",
      "  Generating 468 augmented samples...\n",
      "    Generated 468/468 samples\n",
      "  Final samples for class 3: 500\n",
      "\n",
      "Processing class 4...\n",
      "  Current samples: 31\n",
      "  Target samples: 500\n",
      "  Generating 469 augmented samples...\n",
      "    Generated 469/469 samples\n",
      "  Final samples for class 4: 500\n",
      "\n",
      "Combining all classes...\n",
      "Shuffling combined dataset...\n",
      "\n",
      "Final balanced dataset:\n",
      "  Shape: (2500, 224, 224, 3)\n",
      "  Labels shape: (2500, 5)\n",
      "Final class distribution:\n",
      "  Class 0: 500 samples\n",
      "  Class 1: 500 samples\n",
      "  Class 2: 500 samples\n",
      "  Class 3: 500 samples\n",
      "  Class 4: 500 samples\n",
      "Data augmentation and balancing functions loaded!\n",
      "Usage:\n",
      "X_train_balanced, y_train_balanced = augment_and_balance_data(X_train, y_train, target_samples_per_class=500)\n"
     ]
    }
   ],
   "source": [
    "# Homogenize data\n",
    "\n",
    "from buck.analysis.basics import homogenize_data\n",
    "\n",
    "#augment_multiplier = 40\n",
    "#X_train_pca, y_train_flat, X_test_pca, y_true, label_mapping, num_classes = homogenize_data(Xtr_og, ytr_og, Xte,yte_onehot, l_map, augment_multiplier)\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "\n",
    "def augment_and_balance_data(X_train, y_train, target_samples_per_class=None, augmentation_factor=5):\n",
    "    \"\"\"\n",
    "    Augment training data and balance classes to have equal representation\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training images array (N, H, W, 3)\n",
    "        y_train: Training labels (one-hot encoded)\n",
    "        target_samples_per_class: Target number of samples per class (if None, uses max class count * augmentation_factor)\n",
    "        augmentation_factor: Multiplier for the largest class to determine target size\n",
    "    \n",
    "    Returns:\n",
    "        X_train_balanced: Balanced and augmented training data\n",
    "        y_train_balanced: Corresponding balanced labels\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting data augmentation and class balancing...\")\n",
    "    print(f\"Input data shape: {X_train.shape}\")\n",
    "    print(f\"Input labels shape: {y_train.shape}\")\n",
    "    \n",
    "    # Convert one-hot to class indices\n",
    "    y_train_indices = np.argmax(y_train, axis=1)\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    # Count samples per class\n",
    "    unique_classes, class_counts = np.unique(y_train_indices, return_counts=True)\n",
    "    \n",
    "    print(\"Current class distribution:\")\n",
    "    for class_idx, count in zip(unique_classes, class_counts):\n",
    "        print(f\"  Class {class_idx}: {count} samples\")\n",
    "    \n",
    "    # Determine target samples per class\n",
    "    max_count = np.max(class_counts)\n",
    "    if target_samples_per_class is None:\n",
    "        target_samples_per_class = max_count * augmentation_factor\n",
    "    \n",
    "    print(f\"Target samples per class: {target_samples_per_class}\")\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,           # Rotate images up to 15 degrees\n",
    "        width_shift_range=0.1,       # Shift horizontally up to 10%\n",
    "        height_shift_range=0.1,      # Shift vertically up to 10%\n",
    "        shear_range=0.1,            # Shear transformation\n",
    "        zoom_range=0.1,             # Zoom in/out up to 10%\n",
    "        horizontal_flip=True,       # Random horizontal flips\n",
    "        brightness_range=[0.8, 1.2], # Brightness variation\n",
    "        fill_mode='nearest'         # Fill strategy for new pixels\n",
    "    )\n",
    "    \n",
    "    # Store augmented data\n",
    "    X_balanced_list = []\n",
    "    y_balanced_list = []\n",
    "    \n",
    "    # Process each class\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"\\nProcessing class {class_idx}...\")\n",
    "        \n",
    "        # Get all samples for this class\n",
    "        class_mask = y_train_indices == class_idx\n",
    "        X_class = X_train[class_mask]\n",
    "        current_count = len(X_class)\n",
    "        \n",
    "        print(f\"  Current samples: {current_count}\")\n",
    "        print(f\"  Target samples: {target_samples_per_class}\")\n",
    "        \n",
    "        if current_count == 0:\n",
    "            print(f\"  Warning: No samples for class {class_idx}\")\n",
    "            continue\n",
    "        \n",
    "        # Add original samples\n",
    "        X_class_augmented = list(X_class)\n",
    "        \n",
    "        # Calculate how many more samples we need\n",
    "        samples_needed = target_samples_per_class - current_count\n",
    "        \n",
    "        if samples_needed > 0:\n",
    "            print(f\"  Generating {samples_needed} augmented samples...\")\n",
    "            \n",
    "            # Normalize images for augmentation (0-255 -> 0-1)\n",
    "            X_class_norm = X_class.astype('float32') / 255.0\n",
    "            \n",
    "            # Generate augmented samples\n",
    "            augmented_count = 0\n",
    "            batch_size = min(32, current_count)  # Process in batches\n",
    "            \n",
    "            while augmented_count < samples_needed:\n",
    "                # How many samples to generate in this batch\n",
    "                batch_samples_needed = min(batch_size, samples_needed - augmented_count)\n",
    "                \n",
    "                # Randomly select source images for this batch\n",
    "                source_indices = np.random.choice(current_count, size=batch_samples_needed, replace=True)\n",
    "                X_batch = X_class_norm[source_indices]\n",
    "                \n",
    "                # Generate augmented images\n",
    "                aug_iter = datagen.flow(X_batch, batch_size=batch_samples_needed, shuffle=False)\n",
    "                X_aug_batch = next(aug_iter)\n",
    "                \n",
    "                # Convert back to 0-255 range\n",
    "                X_aug_batch = (X_aug_batch * 255).astype(np.uint8)\n",
    "                \n",
    "                # Add to our collection\n",
    "                for img in X_aug_batch:\n",
    "                    if augmented_count < samples_needed:\n",
    "                        X_class_augmented.append(img)\n",
    "                        augmented_count += 1\n",
    "                \n",
    "                # Progress update\n",
    "                if augmented_count % 100 == 0 or augmented_count >= samples_needed:\n",
    "                    print(f\"    Generated {augmented_count}/{samples_needed} samples\")\n",
    "        \n",
    "        elif samples_needed < 0:\n",
    "            # Randomly downsample if we have too many\n",
    "            print(f\"  Downsampling from {current_count} to {target_samples_per_class}\")\n",
    "            indices = np.random.choice(current_count, size=target_samples_per_class, replace=False)\n",
    "            X_class_augmented = [X_class[i] for i in indices]\n",
    "        \n",
    "        # Convert to numpy array and add to balanced dataset\n",
    "        X_class_final = np.array(X_class_augmented)\n",
    "        y_class_final = np.full(len(X_class_final), class_idx)\n",
    "        \n",
    "        X_balanced_list.append(X_class_final)\n",
    "        y_balanced_list.append(y_class_final)\n",
    "        \n",
    "        print(f\"  Final samples for class {class_idx}: {len(X_class_final)}\")\n",
    "        \n",
    "        # Clean up memory\n",
    "        del X_class_augmented, X_class_final\n",
    "        gc.collect()\n",
    "    \n",
    "    # Combine all classes\n",
    "    print(\"\\nCombining all classes...\")\n",
    "    X_train_balanced = np.concatenate(X_balanced_list, axis=0)\n",
    "    y_train_indices_balanced = np.concatenate(y_balanced_list, axis=0)\n",
    "    \n",
    "    # Convert back to one-hot encoding\n",
    "    from tensorflow import keras\n",
    "    y_train_balanced = keras.utils.to_categorical(y_train_indices_balanced, num_classes)\n",
    "    \n",
    "    # Shuffle the combined dataset\n",
    "    print(\"Shuffling combined dataset...\")\n",
    "    shuffle_indices = np.random.permutation(len(X_train_balanced))\n",
    "    X_train_balanced = X_train_balanced[shuffle_indices]\n",
    "    y_train_balanced = y_train_balanced[shuffle_indices]\n",
    "    \n",
    "    print(f\"\\nFinal balanced dataset:\")\n",
    "    print(f\"  Shape: {X_train_balanced.shape}\")\n",
    "    print(f\"  Labels shape: {y_train_balanced.shape}\")\n",
    "    \n",
    "    # Verify class balance\n",
    "    final_indices = np.argmax(y_train_balanced, axis=1)\n",
    "    final_unique, final_counts = np.unique(final_indices, return_counts=True)\n",
    "    \n",
    "    print(\"Final class distribution:\")\n",
    "    for class_idx, count in zip(final_unique, final_counts):\n",
    "        print(f\"  Class {class_idx}: {count} samples\")\n",
    "    \n",
    "    # Clean up memory\n",
    "    del X_balanced_list, y_balanced_list\n",
    "    gc.collect()\n",
    "    \n",
    "    return X_train_balanced, y_train_balanced\n",
    "\n",
    "def create_simple_augmentation(image):\n",
    "    \"\"\"\n",
    "    Simple augmentation function for individual images\n",
    "    \"\"\"\n",
    "    \n",
    "    # Random rotation (-10 to 10 degrees)\n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.uniform(-10, 10)\n",
    "        center = (image.shape[1]//2, image.shape[0]//2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Random horizontal flip\n",
    "    if np.random.random() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    if np.random.random() > 0.5:\n",
    "        brightness = np.random.uniform(0.8, 1.2)\n",
    "        image = np.clip(image * brightness, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Random zoom (scale between 0.9 and 1.1)\n",
    "    if np.random.random() > 0.5:\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        \n",
    "        if scale > 1:\n",
    "            # Zoom in - resize then crop center\n",
    "            resized = cv2.resize(image, (new_w, new_h))\n",
    "            start_x = (new_w - w) // 2\n",
    "            start_y = (new_h - h) // 2\n",
    "            image = resized[start_y:start_y+h, start_x:start_x+w]\n",
    "        else:\n",
    "            # Zoom out - resize then pad\n",
    "            resized = cv2.resize(image, (new_w, new_h))\n",
    "            # Create black canvas and place resized image in center\n",
    "            canvas = np.zeros_like(image)\n",
    "            start_x = (w - new_w) // 2\n",
    "            start_y = (h - new_h) // 2\n",
    "            canvas[start_y:start_y+new_h, start_x:start_x+new_w] = resized\n",
    "            image = canvas\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Test usage:\n",
    "X_train_balanced, y_train_balanced = augment_and_balance_data(X_train, y_train, target_samples_per_class=500)\n",
    "print(\"Data augmentation and balancing functions loaded!\")\n",
    "print(\"Usage:\")\n",
    "print(\"X_train_balanced, y_train_balanced = augment_and_balance_data(X_train, y_train, target_samples_per_class=500)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48858061-613d-4798-84fd-074cee953c42",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3042470459.py, line 567)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 567\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31melse:\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import (\n",
    "    ResNet50, ResNet101, EfficientNetB0, EfficientNetB3, EfficientNetB5,\n",
    "    DenseNet121, DenseNet169, ConvNeXtTiny, InceptionV3, VGG16\n",
    ")\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def create_body_morphology_model(base_model_name, input_shape, num_classes, architecture='multi_scale'):\n",
    "    \"\"\"\n",
    "    Create transfer learning models optimized for deer body morphology analysis\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: Pre-trained model ('ResNet50', 'EfficientNetB3', etc.)\n",
    "        input_shape: Input shape (224, 224, 3)\n",
    "        num_classes: Number of age classes\n",
    "        architecture: 'standard', 'multi_scale', 'attention', or 'boosted_attention'\n",
    "    \n",
    "    Returns:\n",
    "        model: Compiled Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model selection\n",
    "    base_models = {\n",
    "        'ResNet50': ResNet50,\n",
    "        'ResNet101': ResNet101,\n",
    "        'EfficientNetB0': EfficientNetB0,\n",
    "        'EfficientNetB3': EfficientNetB3,\n",
    "        'EfficientNetB5': EfficientNetB5,\n",
    "        'DenseNet121': DenseNet121,\n",
    "        'DenseNet169': DenseNet169,\n",
    "        'ConvNeXtTiny': ConvNeXtTiny,\n",
    "        'InceptionV3': InceptionV3,\n",
    "        'VGG16': VGG16\n",
    "    }\n",
    "    \n",
    "    if base_model_name not in base_models:\n",
    "        raise ValueError(f\"Unsupported model: {base_model_name}\")\n",
    "    \n",
    "    print(f\"Creating {base_model_name} model with {architecture} architecture...\")\n",
    "    \n",
    "    # BOOSTED DENSENET169 ATTENTION - Enhanced version\n",
    "    if architecture == 'boosted_attention' and base_model_name == 'DenseNet169':\n",
    "        print(\"ðŸš€ Creating BOOSTED DenseNet169 with enhanced attention mechanisms...\")\n",
    "        \n",
    "        # Load pre-trained DenseNet169\n",
    "        base_model = base_models[base_model_name](\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        inputs = base_model.input\n",
    "        base_features = base_model.output  # Shape: (batch, H, W, 1664)\n",
    "        \n",
    "        # ============ MULTI-SCALE ATTENTION ============\n",
    "        print(\"  Adding multi-scale attention for body parts...\")\n",
    "        \n",
    "        # Global attention (full body proportions)\n",
    "        global_attention = layers.Conv2D(1, 1, activation='sigmoid', name='global_body_attention')(base_features)\n",
    "        global_attended = layers.Multiply(name='global_body_focus')([base_features, global_attention])\n",
    "        \n",
    "        # Regional attention (body segments: head/neck, torso, legs)\n",
    "        regional_features = layers.AveragePooling2D(2, name='regional_pool')(base_features)\n",
    "        regional_attention = layers.Conv2D(1, 1, activation='sigmoid', name='regional_body_attention')(regional_features)\n",
    "        regional_attended = layers.Multiply(name='regional_body_focus')([regional_features, regional_attention])\n",
    "        regional_upsampled = layers.UpSampling2D(2, name='regional_upsample')(regional_attended)\n",
    "        \n",
    "        # Local attention (fine details: antler development, facial features)\n",
    "        local_features = layers.MaxPooling2D(4, name='local_pool')(base_features)\n",
    "        local_attention = layers.Conv2D(1, 1, activation='sigmoid', name='local_detail_attention')(local_features)\n",
    "        local_attended = layers.Multiply(name='local_detail_focus')([local_features, local_attention])\n",
    "        local_upsampled = layers.UpSampling2D(4, name='local_upsample')(local_attended)\n",
    "        \n",
    "        # Combine multi-scale attention\n",
    "        combined_attention = layers.Add(name='multi_scale_body_combine')([global_attended, regional_upsampled, local_upsampled])\n",
    "        \n",
    "        # ============ CHANNEL ATTENTION (SE Block) ============\n",
    "        print(\"  Adding Squeeze-and-Excitation for feature importance...\")\n",
    "        \n",
    "        def se_block(input_tensor, reduction=16, name_prefix='se'):\n",
    "            channels = input_tensor.shape[-1]\n",
    "            # Squeeze: Global average pooling\n",
    "            squeeze = layers.GlobalAveragePooling2D(name=f'{name_prefix}_squeeze')(input_tensor)\n",
    "            # Excitation: FC layers\n",
    "            excitation = layers.Dense(channels // reduction, activation='relu', name=f'{name_prefix}_fc1')(squeeze)\n",
    "            excitation = layers.Dense(channels, activation='sigmoid', name=f'{name_prefix}_fc2')(excitation)\n",
    "            # Reshape and multiply\n",
    "            excitation = layers.Reshape((1, 1, channels), name=f'{name_prefix}_reshape')(excitation)\n",
    "            scaled = layers.Multiply(name=f'{name_prefix}_scale')([input_tensor, excitation])\n",
    "            return scaled\n",
    "        \n",
    "        se_features = se_block(combined_attention, reduction=8, name_prefix='body_morphology_se')\n",
    "        \n",
    "        # ============ BODY PART SPECIFIC ATTENTION ============\n",
    "        print(\"  Adding deer-specific body part attention...\")\n",
    "        \n",
    "        def body_part_attention_block(features, part_name):\n",
    "            part_conv = layers.Conv2D(256, 3, padding='same', activation='relu', \n",
    "                                    name=f'{part_name}_analysis')(features)\n",
    "            part_attention = layers.Conv2D(1, 1, activation='sigmoid', \n",
    "                                         name=f'{part_name}_attention_map')(part_conv)\n",
    "            part_attended = layers.Multiply(name=f'{part_name}_focused_features')([features, part_attention])\n",
    "            return part_attended\n",
    "        \n",
    "        # Neck/head region (important for antler development)\n",
    "        neck_features = body_part_attention_block(se_features, 'neck_head')\n",
    "        # Torso/belly region (body condition indicator)\n",
    "        torso_features = body_part_attention_block(se_features, 'torso_belly')\n",
    "        # Legs region (proportional development)\n",
    "        legs_features = body_part_attention_block(se_features, 'legs')\n",
    "        \n",
    "        # Combine body part features\n",
    "        body_part_combined = layers.Add(name='body_parts_fusion')([neck_features, torso_features, legs_features])\n",
    "        \n",
    "        # ============ SPATIAL ATTENTION ============\n",
    "        print(\"  Adding spatial attention for anatomical regions...\")\n",
    "        \n",
    "        # Average and max pooling across channels for spatial focus\n",
    "        avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True), \n",
    "                               name='spatial_avg')(body_part_combined)\n",
    "        max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True), \n",
    "                               name='spatial_max')(body_part_combined)\n",
    "        \n",
    "        # Learn spatial attention map\n",
    "        spatial_concat = layers.Concatenate(axis=-1, name='spatial_concat')([avg_pool, max_pool])\n",
    "        spatial_attention = layers.Conv2D(1, 7, padding='same', activation='sigmoid', \n",
    "                                        name='spatial_attention_map')(spatial_concat)\n",
    "        \n",
    "        # Apply spatial attention\n",
    "        spatial_attended = layers.Multiply(name='spatially_focused_features')([body_part_combined, spatial_attention])\n",
    "        \n",
    "        # ============ ENHANCED FEATURE POOLING ============\n",
    "        print(\"  Adding enhanced feature extraction...\")\n",
    "        \n",
    "        # Multiple pooling strategies for comprehensive feature extraction\n",
    "        global_avg = layers.GlobalAveragePooling2D(name='comprehensive_global_avg')(spatial_attended)\n",
    "        global_max = layers.GlobalMaxPooling2D(name='comprehensive_global_max')(spatial_attended)\n",
    "        \n",
    "        # Adaptive pooling for spatial relationships\n",
    "        adaptive_pool = layers.AveragePooling2D(pool_size=2, name='adaptive_spatial_pool')(spatial_attended)\n",
    "        adaptive_flat = layers.Flatten(name='adaptive_spatial_flat')(adaptive_pool)\n",
    "        \n",
    "        # Combine all pooling strategies\n",
    "        combined_features = layers.Concatenate(name='comprehensive_feature_fusion')([global_avg, global_max, adaptive_flat])\n",
    "        \n",
    "        # ============ ENHANCED CLASSIFICATION HEAD ============\n",
    "        print(\"  Building enhanced classification layers...\")\n",
    "        \n",
    "        x = combined_features\n",
    "        \n",
    "        # Progressive dense layers with residual connections and high capacity\n",
    "        dense_sizes = [1536, 1024, 512, 256]\n",
    "        \n",
    "        for i, units in enumerate(dense_sizes):\n",
    "            # Main dense layer\n",
    "            main = layers.Dense(units, activation='relu', name=f'boosted_dense_{i+1}')(x)\n",
    "            main = layers.BatchNormalization(name=f'boosted_bn_{i+1}')(main)\n",
    "            main = layers.Dropout(0.4 + i*0.1, name=f'boosted_dropout_{i+1}')(main)  # Increasing dropout\n",
    "            \n",
    "            # Residual connection if dimensions allow\n",
    "            if x.shape[-1] == units:\n",
    "                x = layers.Add(name=f'boosted_residual_{i+1}')([x, main])\n",
    "            else:\n",
    "                x = main\n",
    "        \n",
    "        # Deer morphology understanding layer\n",
    "        x = layers.Dense(128, activation='relu', name='deer_morphology_understanding')(x)\n",
    "        x = layers.BatchNormalization(name='deer_morphology_bn')(x)\n",
    "        x = layers.Dropout(0.3, name='deer_morphology_dropout')(x)\n",
    "        \n",
    "        # Final age prediction\n",
    "        predictions = layers.Dense(num_classes, activation='softmax', name='enhanced_age_prediction')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=predictions, name='BoostedDenseNet169_SuperAttention')\n",
    "        \n",
    "        print(f\"âœ… Boosted DenseNet169 created with {model.count_params():,} parameters\")\n",
    "        return model\n",
    "    \n",
    "    # Load pre-trained base model for other architectures\n",
    "    base_model = base_models[base_model_name](\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    if architecture == 'multi_scale':\n",
    "        # Multi-scale approach for body parts analysis (neck, legs, belly)\n",
    "        base_features = base_model.output\n",
    "        \n",
    "        # Global features (overall body shape and proportions)\n",
    "        global_pool = layers.GlobalAveragePooling2D(name='global_body_shape')(base_features)\n",
    "        \n",
    "        # Local features (specific body parts: neck thickness, leg length, belly width)\n",
    "        local_pool = layers.GlobalMaxPooling2D(name='local_body_parts')(base_features)\n",
    "        \n",
    "        # Spatial features (preserve spatial relationships between body parts)\n",
    "        spatial_pool = layers.AveragePooling2D(pool_size=4, name='spatial_relationships')(base_features)\n",
    "        spatial_flat = layers.Flatten(name='flatten_spatial')(spatial_pool)\n",
    "        \n",
    "        # Combine all feature types for comprehensive body analysis\n",
    "        combined = layers.Concatenate(name='body_feature_fusion')([global_pool, local_pool, spatial_flat])\n",
    "        \n",
    "        # Body morphology analysis layers\n",
    "        x = layers.Dense(1024, activation='relu', name='morphology_analysis')(combined)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.4)(x)\n",
    "        \n",
    "        # Deer-specific body characteristics\n",
    "        x = layers.Dense(512, activation='relu', name='deer_body_features')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        # Age-related morphological features\n",
    "        x = layers.Dense(256, activation='relu', name='age_morphology')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        # Final age classification\n",
    "        predictions = layers.Dense(num_classes, activation='softmax', name='age_classification')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=base_model.input, outputs=predictions, name=f'{base_model_name}_MultiScale')\n",
    "        \n",
    "    elif architecture == 'attention':\n",
    "        # Attention mechanism to focus on important body regions\n",
    "        base_features = base_model.output\n",
    "        \n",
    "        # Spatial attention\n",
    "        attention_weights = layers.Conv2D(1, 1, activation='sigmoid', name='attention_map')(base_features)\n",
    "        attended_features = layers.Multiply(name='attended_features')([base_features, attention_weights])\n",
    "        \n",
    "        # Global pooling of attended features\n",
    "        global_features = layers.GlobalAveragePooling2D(name='attended_global')(attended_features)\n",
    "        \n",
    "        # Regular global features for comparison\n",
    "        regular_features = layers.GlobalAveragePooling2D(name='regular_global')(base_features)\n",
    "        \n",
    "        # Combine attended and regular features\n",
    "        combined = layers.Concatenate(name='attention_combined')([global_features, regular_features])\n",
    "        \n",
    "        # Classification layers\n",
    "        x = layers.Dense(512, activation='relu', name='attention_analysis')(combined)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.4)(x)\n",
    "        \n",
    "        x = layers.Dense(256, activation='relu', name='body_understanding')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        predictions = layers.Dense(num_classes, activation='softmax', name='age_prediction')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=base_model.input, outputs=predictions, name=f'{base_model_name}_Attention')\n",
    "        \n",
    "    else:  # 'standard'\n",
    "        # Standard approach\n",
    "        model = keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Dense(512, activation='relu', name='body_features'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.4),\n",
    "            \n",
    "            layers.Dense(256, activation='relu', name='morphology_features'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Dense(num_classes, activation='softmax', name='age_prediction')\n",
    "        ], name=f'{base_model_name}_Standard')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_preprocessing_function(model_name):\n",
    "    \"\"\"Get the appropriate preprocessing function for each model\"\"\"\n",
    "    \n",
    "    preprocessing_map = {\n",
    "        'ResNet50': tf.keras.applications.resnet50.preprocess_input,\n",
    "        'ResNet101': tf.keras.applications.resnet.preprocess_input,\n",
    "        'EfficientNetB0': tf.keras.applications.efficientnet.preprocess_input,\n",
    "        'EfficientNetB3': tf.keras.applications.efficientnet.preprocess_input,\n",
    "        'EfficientNetB5': tf.keras.applications.efficientnet.preprocess_input,\n",
    "        'DenseNet121': tf.keras.applications.densenet.preprocess_input,\n",
    "        'DenseNet169': tf.keras.applications.densenet.preprocess_input,\n",
    "        'ConvNeXtTiny': tf.keras.applications.convnext.preprocess_input,\n",
    "        'InceptionV3': tf.keras.applications.inception_v3.preprocess_input,\n",
    "        'VGG16': tf.keras.applications.vgg16.preprocess_input,\n",
    "    }\n",
    "    \n",
    "    return preprocessing_map.get(model_name, lambda x: x.astype('float32') / 255.0)\n",
    "\n",
    "def train_transfer_learning_model(model, X_train, y_train, X_val, y_val, model_name, \n",
    "                                  preprocessing_fn=None, epochs_phase1=15, epochs_phase2=10, \n",
    "                                  use_advanced_training=False):\n",
    "    \"\"\"\n",
    "    Two-phase training: frozen features then fine-tuning\n",
    "    Enhanced training for boosted models\n",
    "    \n",
    "    Args:\n",
    "        model: Keras model\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "        model_name: Name for logging\n",
    "        preprocessing_fn: Preprocessing function for the model\n",
    "        epochs_phase1: Epochs for phase 1 (frozen base)\n",
    "        epochs_phase2: Epochs for phase 2 (fine-tuning)\n",
    "        use_advanced_training: Use enhanced training for boosted models\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        history: Training history\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n=== TRAINING {model_name} ===\")\n",
    "    print(f\"Training data: {X_train.shape}\")\n",
    "    print(f\"Validation data: {X_val.shape}\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    if preprocessing_fn is not None:\n",
    "        print(\"Applying model-specific preprocessing...\")\n",
    "        X_train_prep = preprocessing_fn(X_train.astype('float32'))\n",
    "        X_val_prep = preprocessing_fn(X_val.astype('float32'))\n",
    "    else:\n",
    "        print(\"Using standard normalization...\")\n",
    "        X_train_prep = X_train.astype('float32') / 255.0\n",
    "        X_val_prep = X_val.astype('float32') / 255.0\n",
    "    \n",
    "    # Enhanced training for boosted models\n",
    "    if use_advanced_training and 'Boosted' in model_name:\n",
    "        print(\"ðŸš€ Using ADVANCED TRAINING for boosted model...\")\n",
    "        \n",
    "        # Apply label smoothing for better generalization\n",
    "        def apply_label_smoothing(y, smoothing=0.1):\n",
    "            num_classes = y.shape[1]\n",
    "            return y * (1 - smoothing) + smoothing / num_classes\n",
    "        \n",
    "        y_train_smooth = apply_label_smoothing(y_train, smoothing=0.1)\n",
    "        \n",
    "        # Apply mixup augmentation\n",
    "        def apply_mixup(X, y, alpha=0.2):\n",
    "            batch_size = X.shape[0]\n",
    "            lam = np.random.beta(alpha, alpha, batch_size)\n",
    "            lam = np.maximum(lam, 1 - lam)\n",
    "            \n",
    "            lam_img = lam.reshape(-1, 1, 1, 1)\n",
    "            lam_label = lam.reshape(-1, 1)\n",
    "            \n",
    "            indices = np.random.permutation(batch_size)\n",
    "            \n",
    "            X_mixed = lam_img * X + (1 - lam_img) * X[indices]\n",
    "            y_mixed = lam_label * y + (1 - lam_label) * y[indices]\n",
    "            \n",
    "            return X_mixed, y_mixed\n",
    "        \n",
    "        print(\"  Applying mixup augmentation...\")\n",
    "        X_train_mixed, y_train_mixed = apply_mixup(X_train_prep, y_train_smooth, alpha=0.2)\n",
    "        \n",
    "        # Use mixed data for training\n",
    "        X_train_final = X_train_mixed\n",
    "        y_train_final = y_train_mixed\n",
    "        \n",
    "        # Enhanced callbacks\n",
    "        callbacks_phase1 = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=8,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.3,\n",
    "                patience=3,\n",
    "                min_lr=1e-8,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        callbacks_phase2 = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=2,\n",
    "                min_lr=1e-9,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Use label smoothing loss\n",
    "        loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "        \n",
    "    else:\n",
    "        # Standard training\n",
    "        X_train_final = X_train_prep\n",
    "        y_train_final = y_train\n",
    "        loss_fn = 'categorical_crossentropy'\n",
    "        \n",
    "        callbacks_phase1 = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        callbacks_phase2 = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=7,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.3,\n",
    "                patience=3,\n",
    "                min_lr=1e-8,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # Phase 1: Train classifier head only\n",
    "    print(\"\\nPHASE 1: Training classifier head (base model frozen)...\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=loss_fn,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history_1 = model.fit(\n",
    "        X_train_final, y_train_final,\n",
    "        batch_size=16,\n",
    "        epochs=epochs_phase1,\n",
    "        validation_data=(X_val_prep, y_val),\n",
    "        callbacks=callbacks_phase1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Fine-tune top layers\n",
    "    print(\"\\nPHASE 2: Fine-tuning top layers...\")\n",
    "    \n",
    "    # Unfreeze top layers of base model\n",
    "    base_model = None\n",
    "    if hasattr(model, 'layers') and len(model.layers) > 0:\n",
    "        if hasattr(model.layers[0], 'layers'):  # Sequential or Functional model\n",
    "            base_model = model.layers[0]\n",
    "        else:\n",
    "            # Find the base model layer\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, 'layers') and len(layer.layers) > 10:\n",
    "                    base_model = layer\n",
    "                    break\n",
    "    \n",
    "    if base_model is not None and hasattr(base_model, 'layers'):\n",
    "        total_layers = len(base_model.layers)\n",
    "        \n",
    "        # More aggressive unfreezing for boosted models\n",
    "        if 'Boosted' in model_name:\n",
    "            unfreeze_from = int(total_layers * 0.7)  # Unfreeze top 30%\n",
    "        else:\n",
    "            unfreeze_from = int(total_layers * 0.8)  # Unfreeze top 20%\n",
    "        \n",
    "        for layer in base_model.layers[unfreeze_from:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        print(f\"Unfroze {total_layers - unfreeze_from} layers out of {total_layers}\")\n",
    "    else:\n",
    "        print(\"Could not find base model for fine-tuning\")\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    fine_tune_lr = 0.00005 if 'Boosted' in model_name else 0.0001\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "        loss=loss_fn,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Smaller batch size for fine-tuning stability\n",
    "    fine_tune_batch = 4 if 'Boosted' in model_name else 8\n",
    "    \n",
    "    history_2 = model.fit(\n",
    "        X_train_final, y_train_final,\n",
    "        batch_size=fine_tune_batch,\n",
    "        epochs=epochs_phase2,\n",
    "        validation_data=(X_val_prep, y_val),\n",
    "        callbacks=callbacks_phase2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Optional Phase 3 for boosted models\n",
    "    if use_advanced_training and 'Boosted' in model_name:\n",
    "        print(\"\\nPHASE 3: Ultra-fine-tuning (boosted model only)...\")\n",
    "        \n",
    "        # Unfreeze even more layers\n",
    "        if base_model is not None:\n",
    "            unfreeze_from_phase3 = int(total_layers * 0.5)  # Unfreeze top 50%\n",
    "            for layer in base_model.layers[unfreeze_from_phase3:]:\n",
    "                layer.trainable = True\n",
    "            print(f\"Phase 3: Unfroze {total_layers - unfreeze_from_phase3} layers out of {total_layers}\")\n",
    "        \n",
    "        # Very low learning rate\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.000005),\n",
    "            loss=loss_fn,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history_3 = model.fit(\n",
    "            X_train_final, y_train_final,\n",
    "            batch_size=2,\n",
    "            epochs=5,\n",
    "            validation_data=(X_val_prep, y_val),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "            ],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Combine histories\n",
    "        history = {\n",
    "            'phase1': history_1,\n",
    "            'phase2': history_2,\n",
    "            'phase3': history_3\n",
    "        }\n",
    "    else:\n",
    "        # Combine histories\n",
    "        history = {\n",
    "            'phase1': history_1,\n",
    "            'phase2': history_2\n",
    "        }\n",
    "    \n",
    "    # Preprocess data\n",
    "    if preprocessing_fn is not None:\n",
    "        print(\"Applying model-specific preprocessing...\")\n",
    "        X_train_prep = preprocessing_fn(X_train.astype('float32'))\n",
    "        X_val_prep = preprocessing_fn(X_val.astype('float32'))\n",
    "    else:\n",
    "        print(\"Using standard normalization...\")\n",
    "        X_train_prep = X_train.astype('float32') / 255.0\n",
    "        X_val_prep = X_val.astype('float32') / 255.0\n",
    "        X_val_prep = preprocessing_fn(X_val.astype('float32'))\n",
    "    else:\n",
    "        print(\"Using standard normalization...\")\n",
    "        X_train_prep = X_train.astype('float32') / 255.0\n",
    "        X_val_prep = X_val.astype('float32') / 255.0\n",
    "    \n",
    "    # Phase 1: Train classifier head only\n",
    "    print(\"\\nPHASE 1: Training classifier head (base model frozen)...\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks_phase1 = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history_1 = model.fit(\n",
    "        X_train_prep, y_train,\n",
    "        batch_size=16,\n",
    "        epochs=epochs_phase1,\n",
    "        validation_data=(X_val_prep, y_val),\n",
    "        callbacks=callbacks_phase1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Fine-tune top layers\n",
    "    print(\"\\nPHASE 2: Fine-tuning top layers...\")\n",
    "    \n",
    "    # Unfreeze top 20% of base model layers\n",
    "    base_model = None\n",
    "    if hasattr(model, 'layers') and len(model.layers) > 0:\n",
    "        if hasattr(model.layers[0], 'layers'):  # Sequential or Functional model\n",
    "            base_model = model.layers[0]\n",
    "        else:\n",
    "            # Find the base model layer\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, 'layers') and len(layer.layers) > 10:\n",
    "                    base_model = layer\n",
    "                    break\n",
    "    \n",
    "    if base_model is not None and hasattr(base_model, 'layers'):\n",
    "        total_layers = len(base_model.layers)\n",
    "        unfreeze_from = int(total_layers * 0.8)  # Unfreeze top 20%\n",
    "        \n",
    "        for layer in base_model.layers[unfreeze_from:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        print(f\"Unfroze {total_layers - unfreeze_from} layers out of {total_layers}\")\n",
    "    else:\n",
    "        print(\"Could not find base model for fine-tuning\")\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks_phase2 = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=7,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,\n",
    "            patience=3,\n",
    "            min_lr=1e-8,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history_2 = model.fit(\n",
    "        X_train_prep, y_train,\n",
    "        batch_size=8,  # Smaller batch for stability\n",
    "        epochs=epochs_phase2,\n",
    "        validation_data=(X_val_prep, y_val),\n",
    "        callbacks=callbacks_phase2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Combine histories\n",
    "    history = {\n",
    "        'phase1': history_1,\n",
    "        'phase2': history_2\n",
    "    }\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_mapping, model_name, preprocessing_fn=None):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test, y_test: Test data and labels\n",
    "        label_mapping: Dictionary mapping class indices to ages\n",
    "        model_name: Name for reporting\n",
    "        preprocessing_fn: Preprocessing function\n",
    "    \n",
    "    Returns:\n",
    "        results: Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n=== EVALUATING {model_name} ===\")\n",
    "    \n",
    "    # Preprocess test data\n",
    "    if preprocessing_fn is not None:\n",
    "        X_test_prep = preprocessing_fn(X_test.astype('float32'))\n",
    "    else:\n",
    "        X_test_prep = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Get predictions\n",
    "    test_loss, test_acc = model.evaluate(X_test_prep, y_test, verbose=0)\n",
    "    predictions = model.predict(X_test_prep, verbose=0)\n",
    "    \n",
    "    # Convert to class indices\n",
    "    y_test_indices = np.argmax(y_test, axis=1)\n",
    "    pred_indices = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Check class diversity\n",
    "    unique_preds, pred_counts = np.unique(pred_indices, return_counts=True)\n",
    "    unique_true, true_counts = np.unique(y_test_indices, return_counts=True)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    diversity_score = len(unique_preds) / len(unique_true)\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_acc:.3f} ({test_acc:.1%})\")\n",
    "    print(f\"Test Loss: {test_loss:.3f}\")\n",
    "    print(f\"Classes predicted: {len(unique_preds)}/{len(unique_true)}\")\n",
    "    print(f\"Diversity score: {diversity_score:.3f}\")\n",
    "    \n",
    "    # Show prediction distribution\n",
    "    reverse_mapping = {idx: age for age, idx in label_mapping.items()}\n",
    "    \n",
    "    print(\"Prediction distribution:\")\n",
    "    for class_idx, count in zip(unique_preds, pred_counts):\n",
    "        age = reverse_mapping.get(class_idx, f\"Class_{class_idx}\")\n",
    "        print(f\"  Age {age}: {count} predictions\")\n",
    "    \n",
    "    # Classification report\n",
    "    target_names = [f\"Age_{reverse_mapping.get(i, i)}\" for i in range(len(label_mapping))]\n",
    "    class_report = classification_report(y_test_indices, pred_indices, \n",
    "                                       target_names=target_names, \n",
    "                                       output_dict=True, zero_division=0)\n",
    "    \n",
    "    print(\"\\\\nClassification Report:\")\n",
    "    print(classification_report(y_test_indices, pred_indices, \n",
    "                              target_names=target_names, zero_division=0))\n",
    "    \n",
    "    # Success assessment\n",
    "    if test_acc > 0.467:  # Better than RandomForest baseline\n",
    "        status = \"âœ… BETTER than RandomForest (46.7%)\"\n",
    "    elif diversity_score >= 0.7:\n",
    "        status = \"ðŸ“Š Good diversity, reasonable performance\"\n",
    "    elif test_acc > 0.35:\n",
    "        status = \"ðŸ“ˆ Shows promise, needs improvement\"\n",
    "    else:\n",
    "        status = \"âš ï¸ Needs significant improvement\"\n",
    "    \n",
    "    print(f\"Assessment: {status}\")\n",
    "    \n",
    "    return {\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'diversity_score': diversity_score,\n",
    "        'predictions': pred_indices,\n",
    "        'classification_report': class_report,\n",
    "        'status': status\n",
    "    }\n",
    "\n",
    "def compare_transfer_learning_models(X_train, y_train, X_val, y_val, X_test, y_test, label_mapping):\n",
    "    \"\"\"\n",
    "    Compare multiple transfer learning models for deer body morphology\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_val, y_val: Validation data  \n",
    "        X_test, y_test: Test data\n",
    "        label_mapping: Class to age mapping\n",
    "    \n",
    "    Returns:\n",
    "        results: Dictionary with results for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== DEER BODY MORPHOLOGY TRANSFER LEARNING COMPARISON ===\")\n",
    "    print(f\"Training data: {X_train.shape}\")\n",
    "    print(f\"Validation data: {X_val.shape}\")\n",
    "    print(f\"Test data: {X_test.shape}\")\n",
    "    print(f\"Number of classes: {len(label_mapping)}\")\n",
    "    \n",
    "    # Models to test (optimized for body morphology)\n",
    "    models_to_test = {\n",
    "        'EfficientNetB3_MultiScale': ('EfficientNetB3', 'multi_scale'),\n",
    "        'ResNet50_MultiScale': ('ResNet50', 'multi_scale'),\n",
    "        'DenseNet169_Attention': ('DenseNet169', 'attention'),\n",
    "        'DenseNet169_BOOSTED': ('DenseNet169', 'boosted_attention'),  # ðŸš€ BOOSTED VERSION\n",
    "        'ConvNeXtTiny_Standard': ('ConvNeXtTiny', 'standard'),\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, (base_arch, architecture) in models_to_test.items():\n",
    "        try:\n",
    "            print(f\"\\\\n{'='*60}\")\n",
    "            print(f\"TESTING {model_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Create model\n",
    "            model = create_body_morphology_model(\n",
    "                base_arch, \n",
    "                (224, 224, 3), \n",
    "                len(label_mapping), \n",
    "                architecture\n",
    "            )\n",
    "            \n",
    "            # Get preprocessing function\n",
    "            preprocessing_fn = get_preprocessing_function(base_arch)\n",
    "            \n",
    "            # Train model\n",
    "            trained_model, history = train_transfer_learning_model(\n",
    "                model, X_train, y_train, X_val, y_val, \n",
    "                model_name, preprocessing_fn,\n",
    "                use_advanced_training=('BOOSTED' in model_name)  # Enhanced training for boosted models\n",
    "            )\n",
    "            \n",
    "            # Evaluate model\n",
    "            eval_results = evaluate_model(\n",
    "                trained_model, X_test, y_test, label_mapping, \n",
    "                model_name, preprocessing_fn\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            results[model_name] = {\n",
    "                'model': trained_model,\n",
    "                'history': history,\n",
    "                'evaluation': eval_results\n",
    "            }\n",
    "            \n",
    "            # Clean up memory\n",
    "            del model, trained_model\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Final comparison\n",
    "    print(f\"\\\\n{'='*60}\")\n",
    "    print(\"FINAL COMPARISON\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"RandomForest Baseline: 46.7%\")\n",
    "    \n",
    "    if results:\n",
    "        sorted_results = sorted(\n",
    "            results.items(), \n",
    "            key=lambda x: x[1]['evaluation']['test_accuracy'], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        best_acc = sorted_results[0][1]['evaluation']['test_accuracy']\n",
    "        \n",
    "        for model_name, result in sorted_results:\n",
    "            acc = result['evaluation']['test_accuracy']\n",
    "            diversity = result['evaluation']['diversity_score']\n",
    "            status = result['evaluation']['status']\n",
    "            \n",
    "            print(f\"{model_name}: {acc:.1%} (diversity: {diversity:.2f}) - {status}\")\n",
    "        \n",
    "        print(f\"\\\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "        if best_acc > 0.467:\n",
    "            print(f\"   âœ… Body morphology transfer learning SUCCESS!\")\n",
    "            print(f\"   ðŸŽ¯ Best model achieved {best_acc:.1%} vs RandomForest 46.7%\")\n",
    "            print(f\"   ðŸ† Transfer learning beats domain-specific features!\")\n",
    "            \n",
    "            # Check if boosted model won\n",
    "            best_model_name = sorted_results[0][0]\n",
    "            if 'BOOSTED' in best_model_name:\n",
    "                print(f\"   ðŸš€ BOOSTED DenseNet169 DOMINATED the competition!\")\n",
    "                print(f\"   ðŸ”¥ Enhanced attention mechanisms paid off!\")\n",
    "            \n",
    "        elif best_acc > 0.35:\n",
    "            print(f\"   ðŸ“ˆ Body morphology shows promise ({best_acc:.1%})\")\n",
    "            print(f\"   ðŸ”„ Consider more data or different architectures\")\n",
    "            \n",
    "            # Suggest boosted approach if not already used\n",
    "            if not any('BOOSTED' in name for name, _ in sorted_results):\n",
    "                print(f\"   ðŸ’¡ Try the BOOSTED DenseNet169 for better performance!\")\n",
    "        else:\n",
    "            print(f\"   ðŸ¤” Your RandomForest domain expertise still wins!\")\n",
    "            print(f\"   ðŸ“Š Transfer learning may not be ideal for this specific task\")\n",
    "            \n",
    "        print(f\"\\\\nðŸŽ¯ BOOSTED MODEL PERFORMANCE:\")\n",
    "        boosted_results = [r for r in sorted_results if 'BOOSTED' in r[0]]\n",
    "        if boosted_results:\n",
    "            boosted_name, boosted_result = boosted_results[0]\n",
    "            boosted_acc = boosted_result['evaluation']['test_accuracy']\n",
    "            boosted_diversity = boosted_result['evaluation']['diversity_score']\n",
    "            print(f\"   {boosted_name}: {boosted_acc:.1%} (diversity: {boosted_diversity:.2f})\")\n",
    "            \n",
    "            if boosted_acc > 0.467:\n",
    "                improvement = boosted_acc - 0.467\n",
    "                print(f\"   ðŸš€ Boosted model BEATS RandomForest by {improvement:.1%}!\")\n",
    "                print(f\"   ðŸ† Multi-scale + body-part + spatial attention = WINNER!\")\n",
    "            else:\n",
    "                print(f\"   ðŸ“Š Boosted model shows promise but needs more optimization\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ Boosted model not tested - try running again!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No models completed successfully\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage example:\n",
    "print(\"Transfer learning models for deer body morphology loaded!\")\n",
    "print(\"ðŸš€ NOW INCLUDES BOOSTED DenseNet169 with enhanced attention!\")\n",
    "print(\"\\\\nUsage:\")\n",
    "print(\"results = compare_transfer_learning_models(X_train_balanced, y_train_balanced, X_val, y_val, X_test, y_test, mapping)\")\n",
    "print(\"\\\\nðŸŽ¯ The boosted DenseNet169 includes:\")\n",
    "print(\"   â€¢ Multi-scale attention (global + regional + local)\")\n",
    "print(\"   â€¢ Squeeze-and-Excitation channel attention\")  \n",
    "print(\"   â€¢ Body-part specific attention (neck, torso, legs)\")\n",
    "print(\"   â€¢ Spatial attention for anatomical regions\")\n",
    "print(\"   â€¢ Enhanced training with label smoothing + mixup\")\n",
    "print(\"   â€¢ 3-phase progressive training\")\n",
    "print(\"\\\\nðŸ† Should significantly outperform the standard DenseNet169!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95341b1-8c7f-4863-b735-dc8f14fa5cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
