{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a96314-0633-40b4-b727-9ceef74d57af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 image files\n",
      "Converted grayscale to RGB: ..\\images\\squared\\241205_240927_TX_3p5_NDA.png\n",
      "Converted grayscale to RGB: ..\\images\\squared\\250501_241108_PA_8p5_NDA.png\n",
      "Loaded 225 images, all converted to RGB\n"
     ]
    }
   ],
   "source": [
    "# Read in images\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from buck.analysis.basics import ingest_images\n",
    "\n",
    "# Your existing ingestion\n",
    "fpath = \"..\\\\images\\\\squared\\\\*_NDA.png\"\n",
    "\n",
    "def read_images_convert_to_rgb(file_pattern):\n",
    "   \n",
    "    file_paths = glob.glob(file_pattern)\n",
    "    print(f\"Found {len(file_paths)} image files\")\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        try:\n",
    "            # Load image in color\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not load {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Check if it's actually grayscale (all channels identical)\n",
    "            if np.allclose(img_rgb[:,:,0], img_rgb[:,:,1]) and np.allclose(img_rgb[:,:,1], img_rgb[:,:,2]):\n",
    "                print(f\"Converted grayscale to RGB: {file_path}\")\n",
    "            \n",
    "            # All images are now RGB regardless of original format\n",
    "            images.append(img_rgb)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images, all converted to RGB\")\n",
    "    \n",
    "    return images, file_paths[:len(images)]\n",
    "\n",
    "images, paths = read_images_convert_to_rgb(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c789e1f-450c-4b8d-96e3-143aa81d94fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ages from filenames...\n",
      "Skipping invalid age in: ..\\images\\squared\\250522_241221_IN_xpx_NDA.png\n",
      "Successfully processed 224 images\n",
      "Applying age grouping: ages 5.5+ -> 5.5\n",
      "Original age distribution:\n",
      "  Age 1.5: 31 images\n",
      "  Age 2.5: 39 images\n",
      "  Age 3.5: 47 images\n",
      "  Age 4.5: 54 images\n",
      "  Age 5.5: 41 images\n",
      "  Age 6.5: 6 images\n",
      "  Age 8.5: 5 images\n",
      "  Age 12.5: 1 images\n",
      "Grouped age distribution:\n",
      "  Age 1.5: 31 images\n",
      "  Age 2.5: 39 images\n",
      "  Age 3.5: 47 images\n",
      "  Age 4.5: 54 images\n",
      "  Age 5.5: 53 images\n",
      "Image array shape: (224, 224, 224, 3)\n",
      "Ages array shape: (224,)\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "Minimum class count: 31\n",
      "Using stratified splitting to maintain class balance.\n",
      "\n",
      "Data split completed:\n",
      "  Training set: 134 images\n",
      "  Validation set: 45 images\n",
      "  Test set: 45 images\n",
      "  Number of classes: 5\n",
      "\n",
      "Class distribution:\n",
      "  Train:\n",
      "    Age 1.5: 19 images\n",
      "    Age 2.5: 23 images\n",
      "    Age 3.5: 29 images\n",
      "    Age 4.5: 32 images\n",
      "    Age 5.5: 31 images\n",
      "  Val:\n",
      "    Age 1.5: 6 images\n",
      "    Age 2.5: 8 images\n",
      "    Age 3.5: 9 images\n",
      "    Age 4.5: 11 images\n",
      "    Age 5.5: 11 images\n",
      "  Test:\n",
      "    Age 1.5: 6 images\n",
      "    Age 2.5: 8 images\n",
      "    Age 3.5: 9 images\n",
      "    Age 4.5: 11 images\n",
      "    Age 5.5: 11 images\n"
     ]
    }
   ],
   "source": [
    "# Extract / combine dates\n",
    "# X_train, X_val, X_test, y_train, y_val, y_test, mapping = split_images_with_ages(images, paths)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "def extract_age_from_path(file_path):\n",
    "    try:\n",
    "        age_part = file_path.split(\"\\\\\")[-1].split(\".\")[0].split(\"_\")[3]\n",
    "        \n",
    "        # Skip invalid age parts like \"xpx\"\n",
    "        if 'x' in age_part or len(age_part) < 2:\n",
    "            return None\n",
    "            \n",
    "        age_float = float(age_part.replace(\"p\", \".\"))\n",
    "        \n",
    "        # Validate reasonable deer age\n",
    "        if 0.5 <= age_float <= 15.5:\n",
    "            return age_float\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except (IndexError, ValueError):\n",
    "        return None\n",
    "\n",
    "def split_images_with_ages(images, file_paths, target_size=(224, 224), test_size=0.2, val_size=0.2, random_state=42):\n",
    "    print(\"Extracting ages from filenames...\")\n",
    "    \n",
    "    # Extract ages and resize images\n",
    "    ages = []\n",
    "    resized_images = []\n",
    "    \n",
    "    for i, (image, file_path) in enumerate(zip(images, file_paths)):\n",
    "        try:\n",
    "            age = extract_age_from_path(file_path)\n",
    "            \n",
    "            if age is not None:\n",
    "                # Resize image to target size for uniform array\n",
    "                import cv2\n",
    "                resized_img = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "                \n",
    "                ages.append(age)\n",
    "                resized_images.append(resized_img)\n",
    "            else:\n",
    "                print(f\"Skipping invalid age in: {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {len(ages)} images\")\n",
    "    \n",
    "    # Group ages: all ages 5.5 and over become 5.5 (mature deer)\n",
    "    print(\"Applying age grouping: ages 5.5+ -> 5.5\")\n",
    "    original_ages = ages.copy()\n",
    "    ages_grouped = []\n",
    "    \n",
    "    for age in ages:\n",
    "        if age >= 5.5:\n",
    "            ages_grouped.append(5.5)\n",
    "        else:\n",
    "            ages_grouped.append(age)\n",
    "    \n",
    "    # Show original vs grouped distribution\n",
    "    print(\"Original age distribution:\")\n",
    "    unique_original = sorted(list(set(original_ages)))\n",
    "    for age in unique_original:\n",
    "        count = original_ages.count(age)\n",
    "        print(f\"  Age {age}: {count} images\")\n",
    "    \n",
    "    print(\"Grouped age distribution:\")\n",
    "    unique_ages = sorted(list(set(ages_grouped)))\n",
    "    for age in unique_ages:\n",
    "        count = ages_grouped.count(age)\n",
    "        print(f\"  Age {age}: {count} images\")\n",
    "    \n",
    "    # Use grouped ages for the rest of the process\n",
    "    ages = ages_grouped\n",
    "    \n",
    "    # Convert to numpy arrays (now all images have same size)\n",
    "    X = np.array(resized_images)\n",
    "    y_raw = np.array(ages)\n",
    "    \n",
    "    print(f\"Image array shape: {X.shape}\")\n",
    "    print(f\"Ages array shape: {y_raw.shape}\")\n",
    "    \n",
    "    # Create label mapping (age -> class index)\n",
    "    label_mapping = {age: idx for idx, age in enumerate(unique_ages)}\n",
    "    reverse_mapping = {idx: age for age, idx in label_mapping.items()}\n",
    "    \n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Convert ages to class indices\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    # Check class counts for stratification\n",
    "    unique_classes, class_counts = np.unique(y_indices, return_counts=True)\n",
    "    min_class_count = np.min(class_counts)\n",
    "    \n",
    "    print(f\"Minimum class count: {min_class_count}\")\n",
    "    \n",
    "    # If any class has fewer than 2 samples, we can't use stratification\n",
    "    if min_class_count < 2:\n",
    "        print(\"Warning: Some classes have only 1 sample. Cannot use stratified splitting.\")\n",
    "        print(\"Using random splitting instead.\")\n",
    "        \n",
    "        # First split: separate test set (no stratification)\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y_indices, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Second split: separate train and validation (no stratification)\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        print(\"Using stratified splitting to maintain class balance.\")\n",
    "        \n",
    "        # First split: separate test set (with stratification)\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y_indices, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        # Second split: separate train and validation (with stratification)\n",
    "        val_size_adjusted = val_size / (1 - test_size)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=random_state,\n",
    "            stratify=y_temp\n",
    "        )\n",
    "    \n",
    "    # Convert to one-hot encoding\n",
    "    num_classes = len(unique_ages)\n",
    "    y_train_onehot = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val_onehot = keras.utils.to_categorical(y_val, num_classes)\n",
    "    y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print(f\"\\nData split completed:\")\n",
    "    print(f\"  Training set: {X_train.shape[0]} images\")\n",
    "    print(f\"  Validation set: {X_val.shape[0]} images\")\n",
    "    print(f\"  Test set: {X_test.shape[0]} images\")\n",
    "    print(f\"  Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Show class distribution in each set\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    for split_name, y_split in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "        print(f\"  {split_name}:\")\n",
    "        for class_idx in range(num_classes):\n",
    "            count = np.sum(y_split == class_idx)\n",
    "            age = reverse_mapping[class_idx]\n",
    "            print(f\"    Age {age}: {count} images\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train_onehot, y_val_onehot, y_test_onehot, label_mapping\n",
    "\n",
    "# Test usage:\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, mapping = split_images_with_ages(images, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbafb882-22a9-45ad-858f-decd4041dd0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data augmentation and class balancing...\n",
      "Input data shape: (134, 224, 224, 3)\n",
      "Input labels shape: (134, 5)\n",
      "Current class distribution:\n",
      "  Class 0: 19 samples\n",
      "  Class 1: 23 samples\n",
      "  Class 2: 29 samples\n",
      "  Class 3: 32 samples\n",
      "  Class 4: 31 samples\n",
      "Target samples per class: 500\n",
      "    Generated 481/481 samples\n",
      "  Final samples for class 0: 500\n",
      "    Generated 477/477 samples\n",
      "  Final samples for class 1: 500\n",
      "    Generated 471/471 samples\n",
      "  Final samples for class 2: 500\n",
      "    Generated 468/468 samples\n",
      "  Final samples for class 3: 500\n",
      "    Generated 469/469 samples\n",
      "  Final samples for class 4: 500\n",
      "\n",
      "Combining all classes...\n",
      "Shuffling combined dataset...\n",
      "\n",
      "Final balanced dataset:\n",
      "  Shape: (2500, 224, 224, 3)\n",
      "  Labels shape: (2500, 5)\n",
      "Final class distribution:\n",
      "  Class 0: 500 samples\n",
      "  Class 1: 500 samples\n",
      "  Class 2: 500 samples\n",
      "  Class 3: 500 samples\n",
      "  Class 4: 500 samples\n",
      "Data augmentation and balancing functions loaded!\n",
      "Usage:\n",
      "X_train_balanced, y_train_balanced = augment_and_balance_data(X_train, y_train, target_samples_per_class=500)\n"
     ]
    }
   ],
   "source": [
    "# Homogenize data\n",
    "\n",
    "from buck.analysis.basics import homogenize_data\n",
    "\n",
    "#augment_multiplier = 40\n",
    "#X_train_pca, y_train_flat, X_test_pca, y_true, label_mapping, num_classes = homogenize_data(Xtr_og, ytr_og, Xte,yte_onehot, l_map, augment_multiplier)\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "\n",
    "def augment_and_balance_data(X_train, y_train, target_samples_per_class=None, augmentation_factor=5):\n",
    "    \n",
    "    print(\"Starting data augmentation and class balancing...\")\n",
    "    print(f\"Input data shape: {X_train.shape}\")\n",
    "    print(f\"Input labels shape: {y_train.shape}\")\n",
    "    \n",
    "    # Convert one-hot to class indices\n",
    "    y_train_indices = np.argmax(y_train, axis=1)\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    # Count samples per class\n",
    "    unique_classes, class_counts = np.unique(y_train_indices, return_counts=True)\n",
    "    \n",
    "    print(\"Current class distribution:\")\n",
    "    for class_idx, count in zip(unique_classes, class_counts):\n",
    "        print(f\"  Class {class_idx}: {count} samples\")\n",
    "    \n",
    "    # Determine target samples per class\n",
    "    max_count = np.max(class_counts)\n",
    "    if target_samples_per_class is None:\n",
    "        target_samples_per_class = max_count * augmentation_factor\n",
    "    \n",
    "    print(f\"Target samples per class: {target_samples_per_class}\")\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,           # Rotate images up to 15 degrees\n",
    "        width_shift_range=0.1,       # Shift horizontally up to 10%\n",
    "        height_shift_range=0.1,      # Shift vertically up to 10%\n",
    "        shear_range=0.1,            # Shear transformation\n",
    "        zoom_range=0.1,             # Zoom in/out up to 10%\n",
    "        horizontal_flip=True,       # Random horizontal flips\n",
    "        brightness_range=[0.8, 1.2], # Brightness variation\n",
    "        fill_mode='nearest'         # Fill strategy for new pixels\n",
    "    )\n",
    "    \n",
    "    # Store augmented data\n",
    "    X_balanced_list = []\n",
    "    y_balanced_list = []\n",
    "    \n",
    "    # Process each class\n",
    "    for class_idx in range(num_classes):\n",
    "        # Get all samples for this class\n",
    "        class_mask = y_train_indices == class_idx\n",
    "        X_class = X_train[class_mask]\n",
    "        current_count = len(X_class)\n",
    "       \n",
    "        if current_count == 0:\n",
    "            print(f\"  Warning: No samples for class {class_idx}\")\n",
    "            continue\n",
    "        \n",
    "        # Add original samples\n",
    "        X_class_augmented = list(X_class)\n",
    "        \n",
    "        # Calculate how many more samples we need\n",
    "        samples_needed = target_samples_per_class - current_count\n",
    "        \n",
    "        if samples_needed > 0:\n",
    "            \n",
    "            # Normalize images for augmentation (0-255 -> 0-1)\n",
    "            X_class_norm = X_class.astype('float32') / 255.0\n",
    "            \n",
    "            # Generate augmented samples\n",
    "            augmented_count = 0\n",
    "            batch_size = min(32, current_count)  # Process in batches\n",
    "            \n",
    "            while augmented_count < samples_needed:\n",
    "                # How many samples to generate in this batch\n",
    "                batch_samples_needed = min(batch_size, samples_needed - augmented_count)\n",
    "                \n",
    "                # Randomly select source images for this batch\n",
    "                source_indices = np.random.choice(current_count, size=batch_samples_needed, replace=True)\n",
    "                X_batch = X_class_norm[source_indices]\n",
    "                \n",
    "                # Generate augmented images\n",
    "                aug_iter = datagen.flow(X_batch, batch_size=batch_samples_needed, shuffle=False)\n",
    "                X_aug_batch = next(aug_iter)\n",
    "                \n",
    "                # Convert back to 0-255 range\n",
    "                X_aug_batch = (X_aug_batch * 255).astype(np.uint8)\n",
    "                \n",
    "                # Add to our collection\n",
    "                for img in X_aug_batch:\n",
    "                    if augmented_count < samples_needed:\n",
    "                        X_class_augmented.append(img)\n",
    "                        augmented_count += 1\n",
    "                \n",
    "                # Progress update\n",
    "                if augmented_count % 100 == 0 or augmented_count >= samples_needed:\n",
    "                    print(f\"    Generated {augmented_count}/{samples_needed} samples\")\n",
    "        \n",
    "        elif samples_needed < 0:\n",
    "            # Randomly downsample if we have too many\n",
    "            print(f\"  Downsampling from {current_count} to {target_samples_per_class}\")\n",
    "            indices = np.random.choice(current_count, size=target_samples_per_class, replace=False)\n",
    "            X_class_augmented = [X_class[i] for i in indices]\n",
    "        \n",
    "        # Convert to numpy array and add to balanced dataset\n",
    "        X_class_final = np.array(X_class_augmented)\n",
    "        y_class_final = np.full(len(X_class_final), class_idx)\n",
    "        \n",
    "        X_balanced_list.append(X_class_final)\n",
    "        y_balanced_list.append(y_class_final)\n",
    "        \n",
    "        print(f\"  Final samples for class {class_idx}: {len(X_class_final)}\")\n",
    "        \n",
    "        # Clean up memory\n",
    "        del X_class_augmented, X_class_final\n",
    "        gc.collect()\n",
    "    \n",
    "    # Combine all classes\n",
    "    print(\"\\nCombining all classes...\")\n",
    "    X_train_balanced = np.concatenate(X_balanced_list, axis=0)\n",
    "    y_train_indices_balanced = np.concatenate(y_balanced_list, axis=0)\n",
    "    \n",
    "    # Convert back to one-hot encoding\n",
    "    from tensorflow import keras\n",
    "    y_train_balanced = keras.utils.to_categorical(y_train_indices_balanced, num_classes)\n",
    "    \n",
    "    # Shuffle the combined dataset\n",
    "    print(\"Shuffling combined dataset...\")\n",
    "    shuffle_indices = np.random.permutation(len(X_train_balanced))\n",
    "    X_train_balanced = X_train_balanced[shuffle_indices]\n",
    "    y_train_balanced = y_train_balanced[shuffle_indices]\n",
    "    \n",
    "    print(f\"\\nFinal balanced dataset:\")\n",
    "    print(f\"  Shape: {X_train_balanced.shape}\")\n",
    "    print(f\"  Labels shape: {y_train_balanced.shape}\")\n",
    "    \n",
    "    # Verify class balance\n",
    "    final_indices = np.argmax(y_train_balanced, axis=1)\n",
    "    final_unique, final_counts = np.unique(final_indices, return_counts=True)\n",
    "    \n",
    "    print(\"Final class distribution:\")\n",
    "    for class_idx, count in zip(final_unique, final_counts):\n",
    "        print(f\"  Class {class_idx}: {count} samples\")\n",
    "    \n",
    "    # Clean up memory\n",
    "    del X_balanced_list, y_balanced_list\n",
    "    gc.collect()\n",
    "    \n",
    "    return X_train_balanced, y_train_balanced\n",
    "\n",
    "def create_simple_augmentation(image):\n",
    "    \"\"\"\n",
    "    Simple augmentation function for individual images\n",
    "    \"\"\"\n",
    "    \n",
    "    # Random rotation (-10 to 10 degrees)\n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.uniform(-10, 10)\n",
    "        center = (image.shape[1]//2, image.shape[0]//2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Random horizontal flip\n",
    "    if np.random.random() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    if np.random.random() > 0.5:\n",
    "        brightness = np.random.uniform(0.8, 1.2)\n",
    "        image = np.clip(image * brightness, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Random zoom (scale between 0.9 and 1.1)\n",
    "    if np.random.random() > 0.5:\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        \n",
    "        if scale > 1:\n",
    "            # Zoom in - resize then crop center\n",
    "            resized = cv2.resize(image, (new_w, new_h))\n",
    "            start_x = (new_w - w) // 2\n",
    "            start_y = (new_h - h) // 2\n",
    "            image = resized[start_y:start_y+h, start_x:start_x+w]\n",
    "        else:\n",
    "            # Zoom out - resize then pad\n",
    "            resized = cv2.resize(image, (new_w, new_h))\n",
    "            # Create black canvas and place resized image in center\n",
    "            canvas = np.zeros_like(image)\n",
    "            start_x = (w - new_w) // 2\n",
    "            start_y = (h - new_h) // 2\n",
    "            canvas[start_y:start_y+new_h, start_x:start_x+new_w] = resized\n",
    "            image = canvas\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Test usage:\n",
    "X_train_balanced, y_train_balanced = augment_and_balance_data(X_train, y_train, target_samples_per_class=500)\n",
    "print(\"Data augmentation and balancing functions loaded!\")\n",
    "print(\"Usage:\")\n",
    "print(\"X_train_balanced, y_train_balanced = augment_and_balance_data(X_train, y_train, target_samples_per_class=500)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54486b36-c48f-4b93-9069-1faf2c1f0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image flattening functions loaded!\n",
      "\n",
      "Usage options:\n",
      "# Quick test (grayscale, subsampled):\n",
      "opts, ma, f1, ma_vec, f1_vec = quick_bagging_test(X_train_balanced, y_train_balanced, X_test, y_test, _optimize_bagging)\n",
      "\n",
      "# Full test (color, all pixels):\n",
      "opts, ma, f1, ma_vec, f1_vec = full_color_bagging_test(X_train_balanced, y_train_balanced, X_test, y_test, _optimize_bagging)\n",
      "\n",
      "# Manual control:\n",
      "X_train_flat, y_train_flat, X_test_flat, y_test_flat = prepare_images_for_bagging(X_train_balanced, y_train_balanced, X_test, y_test)\n",
      "opts, ma, f1, ma_vec, f1_vec = _optimize_bagging(X_train_flat, y_train_flat, X_test_flat, y_test_flat)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_images_for_bagging(X_train_balanced, y_train_balanced, X_test, y_test, \n",
    "                              convert_to_grayscale=False, normalize=True):\n",
    "    \"\"\"\n",
    "    Convert image arrays to format compatible with your bagging classifier\n",
    "    \n",
    "    Args:\n",
    "        X_train_balanced: Training images (N, H, W, 3) \n",
    "        y_train_balanced: Training labels (one-hot encoded)\n",
    "        X_test: Test images (N, H, W, 3)\n",
    "        y_test: Test labels (one-hot encoded)\n",
    "        convert_to_grayscale: Whether to convert RGB to grayscale first\n",
    "        normalize: Whether to normalize pixel values\n",
    "    \n",
    "    Returns:\n",
    "        X_train_flat: Flattened training features (N, features)\n",
    "        y_train_flat: Integer class labels\n",
    "        X_test_flat: Flattened test features (N, features)  \n",
    "        y_test_flat: Integer class labels\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== PREPARING IMAGES FOR BAGGING CLASSIFIER ===\")\n",
    "    print(f\"Input shapes: Train={X_train_balanced.shape}, Test={X_test.shape}\")\n",
    "    \n",
    "    # Convert one-hot labels to integers\n",
    "    y_train_flat = np.argmax(y_train_balanced, axis=1)\n",
    "    y_test_flat = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(f\"Label shapes: Train={y_train_flat.shape}, Test={y_test_flat.shape}\")\n",
    "    print(f\"Classes in training: {np.unique(y_train_flat)}\")\n",
    "    print(f\"Classes in test: {np.unique(y_test_flat)}\")\n",
    "    \n",
    "    # Process images\n",
    "    X_train_processed = X_train_balanced.copy()\n",
    "    X_test_processed = X_test.copy()\n",
    "    \n",
    "    # Convert to grayscale if requested (reduces features by 3x)\n",
    "    if convert_to_grayscale:\n",
    "        print(\"Converting RGB to grayscale...\")\n",
    "        \n",
    "        # RGB to grayscale conversion (standard weights)\n",
    "        X_train_gray = np.dot(X_train_processed[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "        X_test_gray = np.dot(X_test_processed[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "        \n",
    "        # Add channel dimension back\n",
    "        X_train_processed = np.expand_dims(X_train_gray, axis=-1)\n",
    "        X_test_processed = np.expand_dims(X_test_gray, axis=-1)\n",
    "        \n",
    "        print(f\"Grayscale shapes: Train={X_train_processed.shape}, Test={X_test_processed.shape}\")\n",
    "    \n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        print(\"Normalizing pixel values...\")\n",
    "        X_train_processed = X_train_processed.astype('float32') / 255.0\n",
    "        X_test_processed = X_test_processed.astype('float32') / 255.0\n",
    "    \n",
    "    # Flatten images to 1D feature vectors\n",
    "    print(\"Flattening images to feature vectors...\")\n",
    "    X_train_flat = X_train_processed.reshape(X_train_processed.shape[0], -1)\n",
    "    X_test_flat = X_test_processed.reshape(X_test_processed.shape[0], -1)\n",
    "    \n",
    "    print(f\"Final shapes: Train={X_train_flat.shape}, Test={X_test_flat.shape}\")\n",
    "    print(f\"Features per image: {X_train_flat.shape[1]}\")\n",
    "    \n",
    "    # Calculate memory usage\n",
    "    train_memory_mb = X_train_flat.nbytes / (1024**2)\n",
    "    test_memory_mb = X_test_flat.nbytes / (1024**2)\n",
    "    total_memory_mb = train_memory_mb + test_memory_mb\n",
    "    \n",
    "    print(f\"Memory usage: Train={train_memory_mb:.1f}MB, Test={test_memory_mb:.1f}MB, Total={total_memory_mb:.1f}MB\")\n",
    "    \n",
    "    # Show sample statistics\n",
    "    print(f\"Pixel value range: [{X_train_flat.min():.3f}, {X_train_flat.max():.3f}]\")\n",
    "    \n",
    "    return X_train_flat, y_train_flat, X_test_flat, y_test_flat\n",
    "\n",
    "def reduce_image_features(X_train_flat, X_test_flat, method='subsample', factor=4):\n",
    "    \"\"\"\n",
    "    Reduce the number of features if memory/computation becomes an issue\n",
    "    \n",
    "    Args:\n",
    "        X_train_flat, X_test_flat: Flattened image arrays\n",
    "        method: 'subsample', 'pca', or 'variance'\n",
    "        factor: Reduction factor\n",
    "    \n",
    "    Returns:\n",
    "        X_train_reduced, X_test_reduced: Reduced feature arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"=== REDUCING FEATURES USING {method.upper()} ===\")\n",
    "    print(f\"Original features: {X_train_flat.shape[1]}\")\n",
    "    \n",
    "    if method == 'subsample':\n",
    "        # Simple subsampling (every Nth pixel)\n",
    "        indices = np.arange(0, X_train_flat.shape[1], factor)\n",
    "        X_train_reduced = X_train_flat[:, indices]\n",
    "        X_test_reduced = X_test_flat[:, indices]\n",
    "        print(f\"Subsampled to every {factor}th pixel\")\n",
    "        \n",
    "    elif method == 'variance':\n",
    "        # Keep pixels with highest variance across training set\n",
    "        variances = np.var(X_train_flat, axis=0)\n",
    "        n_keep = X_train_flat.shape[1] // factor\n",
    "        top_indices = np.argsort(variances)[-n_keep:]\n",
    "        \n",
    "        X_train_reduced = X_train_flat[:, top_indices]\n",
    "        X_test_reduced = X_test_flat[:, top_indices]\n",
    "        print(f\"Kept {n_keep} highest variance pixels\")\n",
    "        \n",
    "    elif method == 'pca':\n",
    "        # PCA dimensionality reduction\n",
    "        from sklearn.decomposition import PCA\n",
    "        n_components = X_train_flat.shape[1] // factor\n",
    "        n_components = min(n_components, X_train_flat.shape[0] - 1)\n",
    "        \n",
    "        pca = PCA(n_components=n_components, random_state=42)\n",
    "        X_train_reduced = pca.fit_transform(X_train_flat)\n",
    "        X_test_reduced = pca.transform(X_test_flat)\n",
    "        \n",
    "        explained_var = np.sum(pca.explained_variance_ratio_)\n",
    "        print(f\"PCA to {n_components} components, explained variance: {explained_var:.3f}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    print(f\"Reduced features: {X_train_reduced.shape[1]} (reduction factor: {X_train_flat.shape[1] / X_train_reduced.shape[1]:.1f}x)\")\n",
    "    \n",
    "    return X_train_reduced, X_test_reduced\n",
    "\n",
    "# Example usage functions\n",
    "def quick_bagging_test(X_train_balanced, y_train_balanced, X_test, y_test, _optimize_bagging):\n",
    "    \"\"\"\n",
    "    Quick test with grayscale + subsampling for fast results\n",
    "    \"\"\"\n",
    "    print(\"=== QUICK BAGGING TEST (GRAYSCALE + SUBSAMPLED) ===\")\n",
    "    \n",
    "    # Convert to grayscale and flatten\n",
    "    X_train_flat, y_train_flat, X_test_flat, y_test_flat = prepare_images_for_bagging(\n",
    "        X_train_balanced, y_train_balanced, X_test, y_test, \n",
    "        convert_to_grayscale=True, normalize=True\n",
    "    )\n",
    "    \n",
    "    # Reduce features for faster computation\n",
    "    X_train_reduced, X_test_reduced = reduce_image_features(\n",
    "        X_train_flat, X_test_flat, method='subsample', factor=4\n",
    "    )\n",
    "    \n",
    "    # Run your bagging optimization\n",
    "    print(\"\\nRunning bagging optimization...\")\n",
    "    opts, ma, f1, ma_vec, f1_vec = _optimize_bagging(\n",
    "        X_train_reduced, y_train_flat, X_test_reduced, y_test_flat, cycles=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nQuick test results:\")\n",
    "    print(f\"  Accuracy: {ma:.3f} ({ma:.1%})\")\n",
    "    print(f\"  F1 Score: {f1:.3f}\")\n",
    "    \n",
    "    return opts, ma, f1, ma_vec, f1_vec\n",
    "\n",
    "def full_color_bagging_test(X_train_balanced, y_train_balanced, X_test, y_test, _optimize_bagging):\n",
    "    \"\"\"\n",
    "    Full test with color images (more features, slower but potentially better)\n",
    "    \"\"\"\n",
    "    print(\"=== FULL COLOR BAGGING TEST ===\")\n",
    "    \n",
    "    # Keep color, just flatten\n",
    "    X_train_flat, y_train_flat, X_test_flat, y_test_flat = prepare_images_for_bagging(\n",
    "        X_train_balanced, y_train_balanced, X_test, y_test, \n",
    "        convert_to_grayscale=False, normalize=True\n",
    "    )\n",
    "    \n",
    "    # Check if we need to reduce features due to memory\n",
    "    total_features = X_train_flat.shape[1]\n",
    "    if total_features > 150000:  # ~150k features might be too much\n",
    "        print(f\"Large feature count ({total_features}), applying variance-based reduction...\")\n",
    "        X_train_reduced, X_test_reduced = reduce_image_features(\n",
    "            X_train_flat, X_test_flat, method='variance', factor=2\n",
    "        )\n",
    "    else:\n",
    "        X_train_reduced, X_test_reduced = X_train_flat, X_test_flat\n",
    "    \n",
    "    # Run your bagging optimization\n",
    "    print(\"\\nRunning bagging optimization...\")\n",
    "    opts, ma, f1, ma_vec, f1_vec = _optimize_bagging(\n",
    "        X_train_reduced, y_train_flat, X_test_reduced, y_test_flat, cycles=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFull color results:\")\n",
    "    print(f\"  Accuracy: {ma:.3f} ({ma:.1%})\")\n",
    "    print(f\"  F1 Score: {f1:.3f}\")\n",
    "    \n",
    "    return opts, ma, f1, ma_vec, f1_vec\n",
    "\n",
    "print(\"Image flattening functions loaded!\")\n",
    "print(\"\\nUsage options:\")\n",
    "print(\"# Quick test (grayscale, subsampled):\")\n",
    "print(\"opts, ma, f1, ma_vec, f1_vec = quick_bagging_test(X_train_balanced, y_train_balanced, X_test, y_test, _optimize_bagging)\")\n",
    "print(\"\\n# Full test (color, all pixels):\")\n",
    "print(\"opts, ma, f1, ma_vec, f1_vec = full_color_bagging_test(X_train_balanced, y_train_balanced, X_test, y_test, _optimize_bagging)\")\n",
    "print(\"\\n# Manual control:\")\n",
    "print(\"X_train_flat, y_train_flat, X_test_flat, y_test_flat = prepare_images_for_bagging(X_train_balanced, y_train_balanced, X_test, y_test)\")\n",
    "print(\"opts, ma, f1, ma_vec, f1_vec = _optimize_bagging(X_train_flat, y_train_flat, X_test_flat, y_test_flat)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed687721-6224-4580-8c4d-159c05e8b198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARING IMAGES FOR BAGGING CLASSIFIER ===\n",
      "Input shapes: Train=(2500, 224, 224, 3), Test=(45, 224, 224, 3)\n",
      "Label shapes: Train=(2500,), Test=(45,)\n",
      "Classes in training: [0 1 2 3 4]\n",
      "Classes in test: [0 1 2 3 4]\n",
      "Converting RGB to grayscale...\n",
      "Grayscale shapes: Train=(2500, 224, 224, 1), Test=(45, 224, 224, 1)\n",
      "Normalizing pixel values...\n",
      "Flattening images to feature vectors...\n",
      "Final shapes: Train=(2500, 50176), Test=(45, 50176)\n",
      "Features per image: 50176\n",
      "Memory usage: Train=478.5MB, Test=8.6MB, Total=487.1MB\n",
      "Pixel value range: [0.000, 1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from buck.classifiers.random_forest import _optimize_random_forest\n",
    "\n",
    "# Convert your balanced data to the right format\n",
    "X_train_flat, y_train_flat, X_test_flat, y_test_flat = prepare_images_for_bagging(\n",
    "    X_train_balanced, y_train_balanced, X_test, y_test,\n",
    "    convert_to_grayscale=True,  # Reduces features 3x\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Now this will work with your bagging function\n",
    "results = _optimize_bagging(X_train_flat, y_train_flat, X_test_flat, y_test_flat, cycles=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415e8a2-4981-46df-9980-e2f0c35bd3a3",
   "metadata": {},
   "source": [
    "## Homogenize data across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c2ba6-9153-4ea4-a8f6-55201f91bb7b",
   "metadata": {},
   "source": [
    "## Optimize all classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6d11d-5762-40c8-947d-f66c4a4045f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "'''\n",
    "from buck.classifiers.ada_boost import (_optimize_rs, _optimize_nest, _optimize_lr)\n",
    "\n",
    "# Shorten parameters\n",
    "Xtr_pca = X_train_pca\n",
    "ytr_flat = y_train_flat\n",
    "Xte_pca = X_test_pca\n",
    "\n",
    "# Define optimals\n",
    "opts = {\n",
    "    \"random_state\": None,\n",
    "    \"estimator\": None,\n",
    "    \"n_estimators\": 50,\n",
    "    \"learning_rate\": 1.0,\n",
    "}\n",
    "\n",
    "# Adaboost\n",
    "opts, ma, ab_rs = _optimize_rs(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "opts, ma, ab_ne = _optimize_nest(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "opts, ma, ab_lr = _optimize_lr(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "print(ma)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19097c-4937-455b-8a3e-37c6097a33fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8aedc-fd21-4ced-b966-16b7008eedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from buck.classifiers.random_forest import (\n",
    "    _optimize_rs, _optimize_nest, _optimize_max_d, _optimize_crit, _optimize_cw, _optimize_mss, _optimize_msl, _optimize_mwfl, _optimize_mf, _optimize_mln, _optimize_mid\n",
    ")\n",
    "\n",
    "# Shorten parameters\n",
    "Xtr_pca = X_train_pca\n",
    "ytr_flat = y_train_flat\n",
    "Xte_pca = X_test_pca\n",
    "\n",
    "opts = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "    \"class_weight\": None,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"max_samples\": None,\n",
    "    \"monotonic_cst\": None,\n",
    "}\n",
    "\n",
    "# Optimize hyperparameters\n",
    "ma_vec = []\n",
    "f1_vec = []\n",
    "for c in np.arange(10):\n",
    "    opts, _, _ = _optimize_rs(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_nest(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_max_d(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_crit(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)  # type: ignore\n",
    "    opts, _, _ = _optimize_cw(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_mss(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_msl(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_mwfl(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_mf(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, _, _ = _optimize_mln(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    opts, ma, f1 = _optimize_mid(Xtr_pca, ytr_flat, Xte_pca, y_true, opts)\n",
    "    ma_vec.append(ma)\n",
    "    f1_vec.append(f1)\n",
    "    print(ma, f1)\n",
    "\n",
    "#Best: 0.7894736842105263\n",
    "#{'n_estimators': np.int64(127),\n",
    "# 'criterion': 'gini',\n",
    "# 'max_depth': None,\n",
    "# 'min_samples_split': np.int64(2),\n",
    "# 'min_samples_leaf': np.int64(1),\n",
    "# 'min_weight_fraction_leaf': np.float64(0.0),\n",
    "# 'max_features': 'log2',\n",
    "# 'max_leaf_nodes': None,\n",
    "# 'min_impurity_decrease': np.float64(0.0),\n",
    "# 'bootstrap': True,\n",
    "# 'oob_score': False,\n",
    "# 'n_jobs': -1,\n",
    "# 'random_state': np.int64(405),\n",
    "# 'verbose': 0,\n",
    "# 'warm_start': False,\n",
    "# 'class_weight': None,\n",
    "# 'ccp_alpha': 0.0,\n",
    "# 'max_samples': None,\n",
    "# 'monotonic_cst': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ababe7-a723-4cbd-92b3-597b6c4cde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Shorten parameters\n",
    "Xtr_pca = X_train_pca\n",
    "ytr_flat = y_train_flat\n",
    "Xte_pca = X_test_pca\n",
    "\n",
    "# Define optimals\n",
    "opts = {\n",
    "    \"hidden_layer_sizes\": (100,),\n",
    "    \"activation\": \"relu\",\n",
    "    \"solver\": \"adam\",\n",
    "    \"alpha\": 0.0001,\n",
    "    \"batch_size\": \"auto\",\n",
    "    \"learning_rate\": \"constant\",\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"power_t\": 0.5,\n",
    "    \"max_iter\": 20000,\n",
    "    \"shuffle\": True,\n",
    "    \"random_state\": None,\n",
    "    \"tol\": 0.01,\n",
    "    \"verbose\": False,\n",
    "    \"warm_start\": False,\n",
    "    \"momentum\": 0.9,\n",
    "    \"nesterovs_momentum\": True,\n",
    "    \"early_stopping\": False,\n",
    "    \"validation_fraction\": 0.1,\n",
    "    \"beta_1\": 0.9,\n",
    "    \"beta_2\": 0.999,\n",
    "    \"epsilon\": 1e-08,\n",
    "    \"n_iter_no_change\": 10,\n",
    "    \"max_fun\": 15000,\n",
    "}\n",
    "\n",
    "# Initialize variables\n",
    "ac_vec = []\n",
    "f1_vec = []\n",
    "max_acc = -np.inf\n",
    "max_idx = -1\n",
    "variable_array = np.arange(150)\n",
    "#best_val = variable_array[0]\n",
    "for i in np.arange(len(variable_array)):\n",
    "    v = variable_array[i]\n",
    "    # Define classifiers to test\n",
    "    classifier = MLPClassifier(\n",
    "        random_state=v,\n",
    "        hidden_layer_sizes=opts[\"hidden_layer_sizes\"],\n",
    "        activation=opts[\"activation\"],\n",
    "        solver=opts[\"solver\"],\n",
    "        alpha=opts[\"alpha\"],\n",
    "        batch_size=opts[\"batch_size\"],\n",
    "        learning_rate=opts[\"learning_rate\"],\n",
    "        learning_rate_init=opts[\"learning_rate_init\"],\n",
    "        power_t=opts[\"power_t\"],\n",
    "        max_iter=opts[\"max_iter\"],\n",
    "        shuffle=opts[\"shuffle\"],\n",
    "        tol=opts[\"tol\"],\n",
    "        verbose=opts[\"verbose\"],\n",
    "        warm_start=opts[\"warm_start\"],\n",
    "        momentum=opts[\"momentum\"],\n",
    "        nesterovs_momentum=opts[\"nesterovs_momentum\"],\n",
    "        early_stopping=opts[\"early_stopping\"],\n",
    "        validation_fraction=opts[\"validation_fraction\"],\n",
    "        beta_1=opts[\"beta_1\"],\n",
    "        beta_2=opts[\"beta_2\"],\n",
    "        epsilon=opts[\"epsilon\"],\n",
    "        n_iter_no_change=opts[\"n_iter_no_change\"],\n",
    "        max_fun=opts[\"max_fun\"],\n",
    "    )\n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train_pca, y_train_flat)\n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test_pca)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    ac_vec.append(accuracy)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1_vec.append(f1)\n",
    "    \n",
    "    # Return index\n",
    "    if accuracy >= max_acc:\n",
    "        max_acc = accuracy\n",
    "        print(max_acc)\n",
    "        best_val = v\n",
    "    \n",
    "    # Store best value\n",
    "    opts[\"random_state\"] = best_val\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8281d0-0684-46a1-9e1d-28fa603e6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from buck.classifiers.compare_models import compare_models\n",
    "#\n",
    "## Shorten parameters\n",
    "#Xtr_pca = X_train_pca\n",
    "#ytr_flat = y_train_flat\n",
    "#Xte_pca = X_test_pca\n",
    "#\n",
    "#compare_models(Xtr_pca, ytr_flat, Xte_pca, y_true, num_classes, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51182f6d-437a-4c77-96c0-0156ca6a648a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c450d8-7f37-4727-9223-1c3855193bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
