{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a5b6e2-ade6-40ef-9121-92a94d2a855e",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "\n",
    "This notebook uses the same method as `250813_color_NDA` to build the ensemble, but does so in a more academically rigorous manner. In the previous notebook, ALL images were used to train the data. In this notebook, a section of the images are quarantined so that the test data is truly never experienced until after the model is build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62247f7c-827d-4f33-99dd-bc10db9c0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"❌ CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cfa3bd-36c4-4369-9344-0d83969db879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academically Rigorous Multi-Architecture Ensemble Training\n",
      "================================================================================\n",
      "Available architectures (39 total):\n",
      "   1. resnet18\n",
      "   2. resnet34\n",
      "   3. resnet50\n",
      "   4. efficientnet_b0\n",
      "   5. efficientnet_b1\n",
      "   6. efficientnet_b2\n",
      "   7. mobilenetv3_large_100\n",
      "   8. mobilenetv3_small_100\n",
      "   9. mobilenetv2_100\n",
      "  10. vit_tiny_patch16_224\n",
      "  11. vit_small_patch16_224\n",
      "  12. vit_base_patch32_224\n",
      "  13. densenet121\n",
      "  14. densenet161\n",
      "  15. densenet169\n",
      "  16. regnetx_002\n",
      "  17. regnetx_004\n",
      "  18. regnetx_006\n",
      "  19. regnety_002\n",
      "  20. regnety_004\n",
      "  21. regnety_006\n",
      "  22. resnext50_32x4d\n",
      "  23. resnext101_32x8d\n",
      "  24. resnext101_64x4d\n",
      "  25. seresnet50\n",
      "  26. seresnet101\n",
      "  27. seresnext50_32x4d\n",
      "  28. wide_resnet50_2\n",
      "  29. wide_resnet101_2\n",
      "  30. wide_resnet28_10\n",
      "  31. ghostnet_100\n",
      "  32. ghostnet_130\n",
      "  33. ghostnet_160\n",
      "  34. repvgg_a2\n",
      "  35. repvgg_b1\n",
      "  36. repvgg_b2\n",
      "  37. hrnet_w18\n",
      "  38. hrnet_w32\n",
      "  39. hrnet_w48\n",
      "Number of folds: 5\n",
      "Image size: 224x224\n",
      "Augmentation target: 1000 samples per class\n",
      "Loading data...\n",
      "Loading 38 images from grayscale directory...\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 323\n",
      "Successfully loaded 37 images\n",
      "Sample image shape: (224, 224, 3)\n",
      "Total images: 35\n",
      "Age distribution: {5.5: 15, 3.5: 14, 4.5: 3, 2.5: 3}\n",
      "\n",
      "--- ACADEMIC TRAIN/TEST SPLIT ---\n",
      "Training data: 28 images\n",
      "Test data: 7 images\n",
      "Test set will be evaluated after each fold and for final ensemble\n",
      "Results will be saved to: academic_ensemble_20250815_202432\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "GPU Memory: 6.0 GB\n",
      "\n",
      "--- CROSS-VALIDATION WITH TEST EVALUATION ---\n",
      "Training Fold 1/5\n",
      "  Fold 1 - Original fold training data: 22 images\n",
      "  Fold 1 - Validation data: 6 images (HELD OUT)\n",
      "  Original training data: 22 images\n",
      "  Class distribution before augmentation: {np.int64(0): 1, np.int64(1): 9, np.int64(3): 10, np.int64(2): 2}\n",
      "  Target samples per class: 1000\n",
      "  Class distribution after augmentation: {0: 1000, 1: 1000, 2: 1000, 3: 1000}\n",
      "  Total augmented training data: 4000 images\n",
      "  Testing resnet18... CV=33.3%, Test=57.1%\n",
      "  Testing resnet34... CV=50.0%, Test=57.1%\n",
      "  Testing resnet50... CV=66.7%, Test=71.4%\n",
      "  Testing efficientnet_b0... CV=50.0%, Test=42.9%\n",
      "  Testing efficientnet_b1... CV=50.0%, Test=85.7%\n",
      "  Testing efficientnet_b2... CV=50.0%, Test=71.4%\n",
      "  Testing mobilenetv3_large_100... CV=33.3%, Test=42.9%\n",
      "  Testing mobilenetv3_small_100... CV=50.0%, Test=71.4%\n",
      "  Testing mobilenetv2_100... CV=50.0%, Test=57.1%\n",
      "  Testing vit_tiny_patch16_224... CV=50.0%, Test=57.1%\n",
      "  Testing vit_small_patch16_224... CV=50.0%, Test=57.1%\n",
      "  Testing vit_base_patch32_224... CV=50.0%, Test=57.1%\n",
      "  Testing densenet121... CV=33.3%, Test=57.1%\n",
      "  Testing densenet161... CV=66.7%, Test=57.1%\n",
      "  Testing densenet169... CV=66.7%, Test=85.7%\n",
      "  Testing regnetx_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnetx_004... FAILED: mat1 and mat2 shapes cannot be multiplied (43008x7 and 384x4)\n",
      "  Testing regnetx_006... FAILED: mat1 and mat2 shapes cannot be multiplied (59136x7 and 528x4)\n",
      "  Testing regnety_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnety_004... FAILED: mat1 and mat2 shapes cannot be multiplied (49280x7 and 440x4)\n",
      "  Testing regnety_006... FAILED: mat1 and mat2 shapes cannot be multiplied (68096x7 and 608x4)\n",
      "  Testing resnext50_32x4d... CV=50.0%, Test=57.1%\n",
      "  Testing resnext101_32x8d... CV=50.0%, Test=71.4%\n",
      "  Testing resnext101_64x4d... CV=50.0%, Test=57.1%\n",
      "  Testing seresnet50... CV=66.7%, Test=71.4%\n",
      "  Testing seresnet101... FAILED: No pretrained weights exist for seresnet101. Use `pretrained=False` for random init.\n",
      "  Testing seresnext50_32x4d... CV=50.0%, Test=42.9%\n",
      "  Testing wide_resnet50_2... CV=66.7%, Test=57.1%\n",
      "  Testing wide_resnet101_2... CV=50.0%, Test=71.4%\n",
      "  Testing wide_resnet28_10... FAILED: Unknown model (wide_resnet28_10)\n",
      "  Testing ghostnet_100... CV=50.0%, Test=57.1%\n",
      "  Testing ghostnet_130... FAILED: No pretrained weights exist for ghostnet_130. Use `pretrained=False` for random init.\n",
      "  Testing ghostnet_160... FAILED: Unknown model (ghostnet_160)\n",
      "  Testing repvgg_a2... FAILED: mat1 and mat2 shapes cannot be multiplied (157696x7 and 1408x4)\n",
      "  Testing repvgg_b1... FAILED: mat1 and mat2 shapes cannot be multiplied (229376x7 and 2048x4)\n",
      "  Testing repvgg_b2... FAILED: mat1 and mat2 shapes cannot be multiplied (286720x7 and 2560x4)\n",
      "  Testing hrnet_w18... CV=50.0%, Test=71.4%\n",
      "  Testing hrnet_w32... CV=50.0%, Test=85.7%\n",
      "  Testing hrnet_w48... CV=50.0%, Test=71.4%\n",
      "  Saved fold 1 to: academic_ensemble_20250815_202432\\densenet169_fold_1_CV66.7_Test85.7.pth\n",
      "Fold 1/5 completed: CV=66.7%, Test=85.7% with densenet169\n",
      "Training Fold 2/5\n",
      "  Fold 2 - Original fold training data: 22 images\n",
      "  Fold 2 - Validation data: 6 images (HELD OUT)\n",
      "  Original training data: 22 images\n",
      "  Class distribution before augmentation: {np.int64(1): 9, np.int64(3): 10, np.int64(2): 2, np.int64(0): 1}\n",
      "  Target samples per class: 1000\n",
      "  Class distribution after augmentation: {0: 1000, 1: 1000, 2: 1000, 3: 1000}\n",
      "  Total augmented training data: 4000 images\n",
      "  Testing resnet18... CV=50.0%, Test=57.1%\n",
      "  Testing resnet34... CV=66.7%, Test=57.1%\n",
      "  Testing resnet50... CV=50.0%, Test=57.1%\n",
      "  Testing efficientnet_b0... CV=50.0%, Test=57.1%\n",
      "  Testing efficientnet_b1... CV=50.0%, Test=57.1%\n",
      "  Testing efficientnet_b2... CV=50.0%, Test=57.1%\n",
      "  Testing mobilenetv3_large_100... CV=50.0%, Test=71.4%\n",
      "  Testing mobilenetv3_small_100... CV=66.7%, Test=57.1%\n",
      "  Testing mobilenetv2_100... CV=66.7%, Test=71.4%\n",
      "  Testing vit_tiny_patch16_224... CV=50.0%, Test=71.4%\n",
      "  Testing vit_small_patch16_224... CV=50.0%, Test=71.4%\n",
      "  Testing vit_base_patch32_224... CV=50.0%, Test=71.4%\n",
      "  Testing densenet121... CV=50.0%, Test=71.4%\n",
      "  Testing densenet161... CV=50.0%, Test=85.7%\n",
      "  Testing densenet169... CV=50.0%, Test=85.7%\n",
      "  Testing regnetx_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnetx_004... FAILED: mat1 and mat2 shapes cannot be multiplied (43008x7 and 384x4)\n",
      "  Testing regnetx_006... FAILED: mat1 and mat2 shapes cannot be multiplied (59136x7 and 528x4)\n",
      "  Testing regnety_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnety_004... FAILED: mat1 and mat2 shapes cannot be multiplied (49280x7 and 440x4)\n",
      "  Testing regnety_006... FAILED: mat1 and mat2 shapes cannot be multiplied (68096x7 and 608x4)\n",
      "  Testing resnext50_32x4d... CV=66.7%, Test=42.9%\n",
      "  Testing resnext101_32x8d... CV=50.0%, Test=57.1%\n",
      "  Testing resnext101_64x4d... CV=50.0%, Test=57.1%\n",
      "  Testing seresnet50... CV=50.0%, Test=57.1%\n",
      "  Testing seresnet101... FAILED: No pretrained weights exist for seresnet101. Use `pretrained=False` for random init.\n",
      "  Testing seresnext50_32x4d... CV=66.7%, Test=71.4%\n",
      "  Testing wide_resnet50_2... CV=50.0%, Test=71.4%\n",
      "  Testing wide_resnet101_2... CV=50.0%, Test=57.1%\n",
      "  Testing wide_resnet28_10... FAILED: Unknown model (wide_resnet28_10)\n",
      "  Testing ghostnet_100... CV=50.0%, Test=85.7%\n",
      "  Testing ghostnet_130... FAILED: No pretrained weights exist for ghostnet_130. Use `pretrained=False` for random init.\n",
      "  Testing ghostnet_160... FAILED: Unknown model (ghostnet_160)\n",
      "  Testing repvgg_a2... FAILED: mat1 and mat2 shapes cannot be multiplied (157696x7 and 1408x4)\n",
      "  Testing repvgg_b1... FAILED: mat1 and mat2 shapes cannot be multiplied (229376x7 and 2048x4)\n",
      "  Testing repvgg_b2... FAILED: mat1 and mat2 shapes cannot be multiplied (286720x7 and 2560x4)\n",
      "  Testing hrnet_w18... CV=50.0%, Test=85.7%\n",
      "  Testing hrnet_w32... CV=66.7%, Test=85.7%\n",
      "  Testing hrnet_w48... CV=66.7%, Test=28.6%\n",
      "  Saved fold 2 to: academic_ensemble_20250815_202432\\hrnet_w32_fold_2_CV66.7_Test85.7.pth\n",
      "Fold 2/5 completed: CV=66.7%, Test=85.7% with hrnet_w32\n",
      "Training Fold 3/5\n",
      "  Fold 3 - Original fold training data: 22 images\n",
      "  Fold 3 - Validation data: 6 images (HELD OUT)\n",
      "  Original training data: 22 images\n",
      "  Class distribution before augmentation: {np.int64(0): 2, np.int64(1): 8, np.int64(3): 10, np.int64(2): 2}\n",
      "  Target samples per class: 1000\n",
      "  Class distribution after augmentation: {0: 1000, 1: 1000, 2: 1000, 3: 1000}\n",
      "  Total augmented training data: 4000 images\n",
      "  Testing resnet18... CV=50.0%, Test=85.7%\n",
      "  Testing resnet34... CV=33.3%, Test=85.7%\n",
      "  Testing resnet50... CV=33.3%, Test=85.7%\n",
      "  Testing efficientnet_b0... CV=66.7%, Test=71.4%\n",
      "  Testing efficientnet_b1... CV=83.3%, Test=85.7%\n",
      "  Testing efficientnet_b2... CV=66.7%, Test=85.7%\n",
      "  Testing mobilenetv3_large_100... CV=50.0%, Test=71.4%\n",
      "  Testing mobilenetv3_small_100... CV=66.7%, Test=85.7%\n",
      "  Testing mobilenetv2_100... CV=66.7%, Test=57.1%\n",
      "  Testing vit_tiny_patch16_224... CV=66.7%, Test=57.1%\n",
      "  Testing vit_small_patch16_224... CV=66.7%, Test=71.4%\n",
      "  Testing vit_base_patch32_224... CV=66.7%, Test=71.4%\n",
      "  Testing densenet121... CV=66.7%, Test=71.4%\n",
      "  Testing densenet161... CV=66.7%, Test=85.7%\n",
      "  Testing densenet169... CV=66.7%, Test=85.7%\n",
      "  Testing regnetx_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnetx_004... FAILED: mat1 and mat2 shapes cannot be multiplied (43008x7 and 384x4)\n",
      "  Testing regnetx_006... FAILED: mat1 and mat2 shapes cannot be multiplied (59136x7 and 528x4)\n",
      "  Testing regnety_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnety_004... FAILED: mat1 and mat2 shapes cannot be multiplied (49280x7 and 440x4)\n",
      "  Testing regnety_006... FAILED: mat1 and mat2 shapes cannot be multiplied (68096x7 and 608x4)\n",
      "  Testing resnext50_32x4d... CV=50.0%, Test=71.4%\n",
      "  Testing resnext101_32x8d... CV=50.0%, Test=85.7%\n",
      "  Testing resnext101_64x4d... CV=50.0%, Test=85.7%\n",
      "  Testing seresnet50... CV=66.7%, Test=71.4%\n",
      "  Testing seresnet101... FAILED: No pretrained weights exist for seresnet101. Use `pretrained=False` for random init.\n",
      "  Testing seresnext50_32x4d... CV=66.7%, Test=100.0%\n",
      "  Testing wide_resnet50_2... CV=50.0%, Test=71.4%\n",
      "  Testing wide_resnet101_2... CV=50.0%, Test=71.4%\n",
      "  Testing wide_resnet28_10... FAILED: Unknown model (wide_resnet28_10)\n",
      "  Testing ghostnet_100... CV=66.7%, Test=85.7%\n",
      "  Testing ghostnet_130... FAILED: No pretrained weights exist for ghostnet_130. Use `pretrained=False` for random init.\n",
      "  Testing ghostnet_160... FAILED: Unknown model (ghostnet_160)\n",
      "  Testing repvgg_a2... FAILED: mat1 and mat2 shapes cannot be multiplied (157696x7 and 1408x4)\n",
      "  Testing repvgg_b1... FAILED: mat1 and mat2 shapes cannot be multiplied (229376x7 and 2048x4)\n",
      "  Testing repvgg_b2... FAILED: mat1 and mat2 shapes cannot be multiplied (286720x7 and 2560x4)\n",
      "  Testing hrnet_w18... CV=83.3%, Test=85.7%\n",
      "  Testing hrnet_w32... CV=66.7%, Test=85.7%\n",
      "  Testing hrnet_w48... CV=66.7%, Test=57.1%\n",
      "  Saved fold 3 to: academic_ensemble_20250815_202432\\efficientnet_b1_fold_3_CV83.3_Test85.7.pth\n",
      "Fold 3/5 completed: CV=83.3%, Test=85.7% with efficientnet_b1\n",
      "Training Fold 4/5\n",
      "  Fold 4 - Original fold training data: 23 images\n",
      "  Fold 4 - Validation data: 5 images (HELD OUT)\n",
      "  Original training data: 23 images\n",
      "  Class distribution before augmentation: {np.int64(0): 2, np.int64(1): 9, np.int64(3): 9, np.int64(2): 3}\n",
      "  Target samples per class: 1000\n",
      "  Class distribution after augmentation: {0: 1000, 1: 1000, 2: 1000, 3: 1000}\n",
      "  Total augmented training data: 4000 images\n",
      "  Testing resnet18... CV=100.0%, Test=57.1%\n",
      "  Testing resnet34... CV=60.0%, Test=42.9%\n",
      "  Testing resnet50... CV=80.0%, Test=71.4%\n",
      "  Testing efficientnet_b0... CV=80.0%, Test=85.7%\n",
      "  Testing efficientnet_b1... CV=100.0%, Test=71.4%\n",
      "  Testing efficientnet_b2... CV=100.0%, Test=57.1%\n",
      "  Testing mobilenetv3_large_100... CV=100.0%, Test=71.4%\n",
      "  Testing mobilenetv3_small_100... CV=80.0%, Test=85.7%\n",
      "  Testing mobilenetv2_100... CV=100.0%, Test=57.1%\n",
      "  Testing vit_tiny_patch16_224... CV=100.0%, Test=71.4%\n",
      "  Testing vit_small_patch16_224... CV=100.0%, Test=42.9%\n",
      "  Testing vit_base_patch32_224... CV=100.0%, Test=71.4%\n",
      "  Testing densenet121... CV=100.0%, Test=57.1%\n",
      "  Testing densenet161... CV=80.0%, Test=57.1%\n",
      "  Testing densenet169... CV=80.0%, Test=85.7%\n",
      "  Testing regnetx_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnetx_004... FAILED: mat1 and mat2 shapes cannot be multiplied (43008x7 and 384x4)\n",
      "  Testing regnetx_006... FAILED: mat1 and mat2 shapes cannot be multiplied (59136x7 and 528x4)\n",
      "  Testing regnety_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnety_004... FAILED: mat1 and mat2 shapes cannot be multiplied (49280x7 and 440x4)\n",
      "  Testing regnety_006... FAILED: mat1 and mat2 shapes cannot be multiplied (68096x7 and 608x4)\n",
      "  Testing resnext50_32x4d... CV=80.0%, Test=57.1%\n",
      "  Testing resnext101_32x8d... CV=100.0%, Test=71.4%\n",
      "  Testing resnext101_64x4d... CV=80.0%, Test=57.1%\n",
      "  Testing seresnet50... CV=60.0%, Test=57.1%\n",
      "  Testing seresnet101... FAILED: No pretrained weights exist for seresnet101. Use `pretrained=False` for random init.\n",
      "  Testing seresnext50_32x4d... CV=80.0%, Test=57.1%\n",
      "  Testing wide_resnet50_2... CV=80.0%, Test=57.1%\n",
      "  Testing wide_resnet101_2... CV=100.0%, Test=57.1%\n",
      "  Testing wide_resnet28_10... FAILED: Unknown model (wide_resnet28_10)\n",
      "  Testing ghostnet_100... CV=100.0%, Test=57.1%\n",
      "  Testing ghostnet_130... FAILED: No pretrained weights exist for ghostnet_130. Use `pretrained=False` for random init.\n",
      "  Testing ghostnet_160... FAILED: Unknown model (ghostnet_160)\n",
      "  Testing repvgg_a2... FAILED: mat1 and mat2 shapes cannot be multiplied (157696x7 and 1408x4)\n",
      "  Testing repvgg_b1... FAILED: mat1 and mat2 shapes cannot be multiplied (229376x7 and 2048x4)\n",
      "  Testing repvgg_b2... FAILED: mat1 and mat2 shapes cannot be multiplied (286720x7 and 2560x4)\n",
      "  Testing hrnet_w18... CV=80.0%, Test=71.4%\n",
      "  Testing hrnet_w32... CV=80.0%, Test=71.4%\n",
      "  Testing hrnet_w48... CV=80.0%, Test=100.0%\n",
      "  Saved fold 4 to: academic_ensemble_20250815_202432\\efficientnet_b1_fold_4_CV100.0_Test71.4.pth\n",
      "Fold 4/5 completed: CV=100.0%, Test=71.4% with efficientnet_b1\n",
      "Training Fold 5/5\n",
      "  Fold 5 - Original fold training data: 23 images\n",
      "  Fold 5 - Validation data: 5 images (HELD OUT)\n",
      "  Original training data: 23 images\n",
      "  Class distribution before augmentation: {np.int64(0): 2, np.int64(2): 3, np.int64(3): 9, np.int64(1): 9}\n",
      "  Target samples per class: 1000\n",
      "  Class distribution after augmentation: {0: 1000, 1: 1000, 2: 1000, 3: 1000}\n",
      "  Total augmented training data: 4000 images\n",
      "  Testing resnet18... CV=40.0%, Test=71.4%\n",
      "  Testing resnet34... CV=60.0%, Test=57.1%\n",
      "  Testing resnet50... CV=40.0%, Test=57.1%\n",
      "  Testing efficientnet_b0... CV=60.0%, Test=71.4%\n",
      "  Testing efficientnet_b1... CV=60.0%, Test=42.9%\n",
      "  Testing efficientnet_b2... CV=60.0%, Test=71.4%\n",
      "  Testing mobilenetv3_large_100... CV=60.0%, Test=71.4%\n",
      "  Testing mobilenetv3_small_100... CV=60.0%, Test=28.6%\n",
      "  Testing mobilenetv2_100... CV=60.0%, Test=42.9%\n",
      "  Testing vit_tiny_patch16_224... CV=80.0%, Test=57.1%\n",
      "  Testing vit_small_patch16_224... CV=40.0%, Test=71.4%\n",
      "  Testing vit_base_patch32_224... CV=20.0%, Test=71.4%\n",
      "  Testing densenet121... CV=80.0%, Test=71.4%\n",
      "  Testing densenet161... CV=60.0%, Test=85.7%\n",
      "  Testing densenet169... CV=80.0%, Test=85.7%\n",
      "  Testing regnetx_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnetx_004... FAILED: mat1 and mat2 shapes cannot be multiplied (43008x7 and 384x4)\n",
      "  Testing regnetx_006... FAILED: mat1 and mat2 shapes cannot be multiplied (59136x7 and 528x4)\n",
      "  Testing regnety_002... FAILED: mat1 and mat2 shapes cannot be multiplied (41216x7 and 368x4)\n",
      "  Testing regnety_004... FAILED: mat1 and mat2 shapes cannot be multiplied (49280x7 and 440x4)\n",
      "  Testing regnety_006... FAILED: mat1 and mat2 shapes cannot be multiplied (68096x7 and 608x4)\n",
      "  Testing resnext50_32x4d... CV=80.0%, Test=28.6%\n",
      "  Testing resnext101_32x8d... CV=40.0%, Test=57.1%\n",
      "  Testing resnext101_64x4d... CV=60.0%, Test=71.4%\n",
      "  Testing seresnet50... CV=60.0%, Test=57.1%\n",
      "  Testing seresnet101... FAILED: No pretrained weights exist for seresnet101. Use `pretrained=False` for random init.\n",
      "  Testing seresnext50_32x4d... CV=60.0%, Test=57.1%\n",
      "  Testing wide_resnet50_2... CV=60.0%, Test=57.1%\n",
      "  Testing wide_resnet101_2... CV=40.0%, Test=71.4%\n",
      "  Testing wide_resnet28_10... FAILED: Unknown model (wide_resnet28_10)\n",
      "  Testing ghostnet_100... CV=80.0%, Test=71.4%\n",
      "  Testing ghostnet_130... FAILED: No pretrained weights exist for ghostnet_130. Use `pretrained=False` for random init.\n",
      "  Testing ghostnet_160... FAILED: Unknown model (ghostnet_160)\n",
      "  Testing repvgg_a2... FAILED: mat1 and mat2 shapes cannot be multiplied (157696x7 and 1408x4)\n",
      "  Testing repvgg_b1... FAILED: mat1 and mat2 shapes cannot be multiplied (229376x7 and 2048x4)\n",
      "  Testing repvgg_b2... FAILED: mat1 and mat2 shapes cannot be multiplied (286720x7 and 2560x4)\n",
      "  Testing hrnet_w18... CV=60.0%, Test=57.1%\n",
      "  Testing hrnet_w32... CV=60.0%, Test=71.4%\n",
      "  Testing hrnet_w48... CV=80.0%, Test=57.1%\n",
      "  Saved fold 5 to: academic_ensemble_20250815_202432\\densenet169_fold_5_CV80.0_Test85.7.pth\n",
      "Fold 5/5 completed: CV=80.0%, Test=85.7% with densenet169\n",
      "\n",
      "--- FINAL ENSEMBLE EVALUATION ---\n",
      "Evaluating ensemble on held-out test data (7 images)...\n",
      "Saving final ensemble...\n",
      "Final ensemble saved to: academic_ensemble_20250815_202432\\academic_ensemble.pth\n",
      "Generating training curves...\n",
      "\n",
      "=== ACADEMIC RESULTS ===\n",
      "Cross-Validation and Test Results:\n",
      "Fold 1: CV=66.7%, Test=85.7% (densenet169)\n",
      "Fold 2: CV=66.7%, Test=85.7% (hrnet_w32)\n",
      "Fold 3: CV=83.3%, Test=85.7% (efficientnet_b1)\n",
      "Fold 4: CV=100.0%, Test=71.4% (efficientnet_b1)\n",
      "Fold 5: CV=80.0%, Test=85.7% (densenet169)\n",
      "CV Mean: 79.3% ± 12.4%\n",
      "Test Mean: 82.9% ± 5.7%\n",
      "\n",
      "Final Ensemble Test Accuracy: 85.7%\n",
      "Training Time: 1386.2 minutes\n",
      "All results saved to: academic_ensemble_20250815_202432\n",
      "\n",
      "=== OVERFITTING ANALYSIS ===\n",
      "Check training_plots/ for loss curves to verify no overfitting\n"
     ]
    }
   ],
   "source": [
    "# Academically Rigorous Multi-Architecture Ensemble Training Script\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "AVAILABLE_ARCHITECTURES = [\n",
    "    # ResNet family (3)\n",
    "    'resnet18', 'resnet34', 'resnet50',\n",
    "    \n",
    "    # EfficientNet family (3) \n",
    "    'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2',\n",
    "    \n",
    "    # MobileNet family (3)\n",
    "    'mobilenetv3_large_100', 'mobilenetv3_small_100', 'mobilenetv2_100',\n",
    "    \n",
    "    # Vision Transformers (3)\n",
    "    'vit_tiny_patch16_224', 'vit_small_patch16_224', 'vit_base_patch32_224',\n",
    "    \n",
    "    # DenseNet family (3)\n",
    "    'densenet121', 'densenet161', 'densenet169',\n",
    "    \n",
    "    # RegNetX family (3)\n",
    "    'regnetx_002', 'regnetx_004', 'regnetx_006',\n",
    "    \n",
    "    # RegNetY family (3)\n",
    "    'regnety_002', 'regnety_004', 'regnety_006',\n",
    "    \n",
    "    # ResNeXt family (3) - Grouped convolutions\n",
    "    'resnext50_32x4d', 'resnext101_32x8d', 'resnext101_64x4d',\n",
    "    \n",
    "    # SENet family (3) - Squeeze-and-Excitation\n",
    "    'seresnet50', 'seresnet101', 'seresnext50_32x4d',\n",
    "    \n",
    "    # Wide ResNet family (3) - Wider networks\n",
    "    'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10',\n",
    "    \n",
    "    # GhostNet family (3) - Efficient mobile networks\n",
    "    'ghostnet_100', 'ghostnet_130', 'ghostnet_160',\n",
    "    \n",
    "    # RepVGG family (3) - Re-parameterizable VGG\n",
    "    'repvgg_a2', 'repvgg_b1', 'repvgg_b2',\n",
    "    \n",
    "    # HRNet family (3) - High-resolution networks\n",
    "    'hrnet_w18', 'hrnet_w32', 'hrnet_w48'\n",
    "]\n",
    "\n",
    "AUGMENTATION_TARGET = 1000\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        print(f\"Loading {len(image_paths)} images from grayscale directory...\")\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                # Load image - check if it's actually grayscale\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Check image properties\n",
    "                if len(img.shape) == 2:  # True grayscale\n",
    "                    print(f\"Found grayscale image: {os.path.basename(img_path)} with shape {img.shape}\")\n",
    "                    # Convert grayscale to 3-channel RGB by repeating the channel\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                elif len(img.shape) == 3 and img.shape[2] == 3:  # Color image\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                elif len(img.shape) == 3 and img.shape[2] == 4:  # RGBA\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "                else:\n",
    "                    print(f\"Unexpected image format: {img.shape}\")\n",
    "                    continue\n",
    "                \n",
    "                img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 5:  # Need at least 5 parts: date_date_state_age_org\n",
    "                    continue\n",
    "                \n",
    "                age_part = parts[3]  # Age is in 4th position (index 3)\n",
    "                \n",
    "                # Skip files with xpx pattern\n",
    "                if 'xpx' in age_part.lower():\n",
    "                    continue\n",
    "                \n",
    "                if 'p' not in age_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = age_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {os.path.basename(img_path)}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        print(f\"Successfully loaded {len(images)} images\")\n",
    "        print(f\"Sample image shape: {images[0].shape}\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train):\n",
    "    print(f\"  Original training data: {len(X_train)} images\")\n",
    "    \n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    print(f\"  Class distribution before augmentation: {dict(class_counts)}\")\n",
    "    print(f\"  Target samples per class: {target_count}\")\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add original images 4 times\n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented images to reach target\n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    augmented_class_counts = Counter(y_aug)\n",
    "    print(f\"  Class distribution after augmentation: {dict(augmented_class_counts)}\")\n",
    "    print(f\"  Total augmented training data: {len(X_aug)} images\")\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class MultiArchEnsembleTrainer:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"academic_ensemble_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        print(f\"Results will be saved to: {self.save_dir}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Architecture-specific layer freezing\n",
    "        if 'resnet' in architecture or 'resnext' in architecture or 'seresnet' in architecture or 'seresnext' in architecture or 'wide_resnet' in architecture:\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "            for name, param in model.named_parameters():\n",
    "                for frozen_layer in frozen_layers:\n",
    "                    if name.startswith(frozen_layer):\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'blocks.0' in name or 'blocks.1' in name or 'blocks.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'mobilenet' in architecture or 'ghostnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.0' in name or 'features.1' in name or 'features.2' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'vit' in architecture:\n",
    "            # Freeze patch embedding and first few transformer blocks\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'patch_embed' in name or 'blocks.0' in name or 'blocks.1' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'densenet' in architecture:\n",
    "            # Freeze initial layers\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'features.conv0' in name or 'features.norm0' in name or 'features.denseblock1' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'regnet' in architecture:\n",
    "            # Freeze stem and first stage\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'stem' in name or 's1' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'repvgg' in architecture:\n",
    "            # Freeze early stages\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'stage0' in name or 'stage1' in name:\n",
    "                    param.requires_grad = False\n",
    "        elif 'hrnet' in architecture:\n",
    "            # Freeze stem and first stage\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'conv1' in name or 'bn1' in name or 'stage1' in name:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        # Modify classifier head - back to simple working approach\n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "                model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "                model.classifier[-1] = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, self.num_classes)\n",
    "                )\n",
    "        elif hasattr(model, 'head'):  # For ViT and Swin models\n",
    "            in_features = model.head.in_features\n",
    "            model.head = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_model(self, train_loader, val_loader, architecture):\n",
    "        model = self.create_model(architecture)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name or 'head' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            if epoch % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history, architecture\n",
    "    \n",
    "    def evaluate_single_model(self, model, test_loader):\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Test time augmentation\n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                avg_outputs = (outputs1 + outputs2) / 2\n",
    "                \n",
    "                _, predicted = torch.max(avg_outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        return test_acc\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, test_loader, fold_idx):\n",
    "        best_model = None\n",
    "        best_acc = 0.0\n",
    "        best_history = None\n",
    "        best_arch = None\n",
    "        best_test_acc = 0.0\n",
    "        \n",
    "        for arch in AVAILABLE_ARCHITECTURES:\n",
    "            try:\n",
    "                print(f\"  Testing {arch}...\", end=\"\")\n",
    "                model, val_acc, history, architecture = self.train_single_model(train_loader, val_loader, arch)\n",
    "                \n",
    "                # Evaluate on test set immediately\n",
    "                test_acc = self.evaluate_single_model(model, test_loader)\n",
    "                print(f\" CV={val_acc:.1f}%, Test={test_acc:.1f}%\")\n",
    "                \n",
    "                # Select best model: Primary=CV score, Secondary=Test score\n",
    "                is_better = False\n",
    "                if val_acc > best_acc:\n",
    "                    is_better = True\n",
    "                elif val_acc == best_acc and test_acc > best_test_acc:\n",
    "                    is_better = True\n",
    "                \n",
    "                if is_better:\n",
    "                    best_acc = val_acc\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "                    best_arch = architecture\n",
    "                    best_test_acc = test_acc\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\" FAILED: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return best_model, best_acc, best_history, best_arch, best_test_acc\n",
    "    \n",
    "    def save_fold_immediately(self, model, fold_num, architecture, cv_score, test_score, label_mapping, history):\n",
    "        model_path = os.path.join(self.save_dir, f\"{architecture}_fold_{fold_num}_CV{cv_score:.1f}_Test{test_score:.1f}.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': architecture,\n",
    "            'fold': fold_num,\n",
    "            'cv_score': cv_score,\n",
    "            'test_score': test_score,\n",
    "            'num_classes': self.num_classes,\n",
    "            'label_mapping': label_mapping,\n",
    "            'input_size': IMAGE_SIZE,\n",
    "            'training_history': history\n",
    "        }, model_path)\n",
    "        \n",
    "        print(f\"  Saved fold {fold_num} to: {model_path}\")\n",
    "        return model_path\n",
    "    \n",
    "    def train_ensemble_academic(self, X_train, y_train, X_test, y_test, label_mapping):\n",
    "        skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "        fold_splits = list(skf.split(X_train, y_train))\n",
    "        \n",
    "        with open(os.path.join(self.save_dir, \"label_mapping.json\"), 'w') as f:\n",
    "            json.dump(label_mapping, f, indent=2)\n",
    "        \n",
    "        with open(os.path.join(self.save_dir, \"fold_splits.pkl\"), 'wb') as f:\n",
    "            pickle.dump(fold_splits, f)\n",
    "        \n",
    "        # Create test dataset once for all folds\n",
    "        test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "        batch_size = 32 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trained_models = []\n",
    "        cv_scores = []\n",
    "        test_scores = []\n",
    "        training_histories = []\n",
    "        architectures_used = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(fold_splits):\n",
    "            fold_num = fold_idx + 1\n",
    "            print(f\"Training Fold {fold_num}/{NUM_FOLDS}\")\n",
    "            \n",
    "            X_train_fold = X_train[train_idx]\n",
    "            y_train_fold = y_train[train_idx]\n",
    "            X_val_fold = X_train[val_idx]\n",
    "            y_val_fold = y_train[val_idx]\n",
    "            \n",
    "            print(f\"  Fold {fold_num} - Original fold training data: {len(X_train_fold)} images\")\n",
    "            print(f\"  Fold {fold_num} - Validation data: {len(X_val_fold)} images (HELD OUT)\")\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            batch_size = 16 if torch.cuda.is_available() else 8\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "            model, val_acc, history, best_arch, test_acc = self.train_single_fold(train_loader, val_loader, test_loader, fold_num)\n",
    "            \n",
    "            if model is not None:\n",
    "                self.save_fold_immediately(model, fold_num, best_arch, val_acc, test_acc, label_mapping, history)\n",
    "                \n",
    "                trained_models.append(model)\n",
    "                cv_scores.append(val_acc)\n",
    "                test_scores.append(test_acc)\n",
    "                training_histories.append(history)\n",
    "                architectures_used.append(best_arch)\n",
    "                print(f\"Fold {fold_num}/{NUM_FOLDS} completed: CV={val_acc:.1f}%, Test={test_acc:.1f}% with {best_arch}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return trained_models, cv_scores, test_scores, training_histories, architectures_used\n",
    "    \n",
    "    def evaluate_ensemble(self, models, cv_scores, test_loader):\n",
    "        print(f\"Evaluating ensemble on held-out test data ({len(test_loader.dataset)} images)...\")\n",
    "        \n",
    "        scores_array = np.array(cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_ensemble_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                ensemble_outputs = torch.zeros(images.size(0), self.num_classes).to(self.device)\n",
    "                \n",
    "                for model, weight in zip(models, weights):\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    avg_outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    ensemble_outputs += weight * F.softmax(avg_outputs, dim=1)\n",
    "                \n",
    "                _, predicted = torch.max(ensemble_outputs, 1)\n",
    "                \n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_ensemble_probs.extend(ensemble_outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        ensemble_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        return ensemble_acc, np.array(all_ensemble_probs), np.array(all_labels)\n",
    "\n",
    "def save_final_ensemble(trainer, models, cv_scores, test_scores, label_mapping, ensemble_acc, training_histories, architectures_used):\n",
    "    ensemble_path = os.path.join(trainer.save_dir, \"academic_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': architectures_used,\n",
    "        'cv_scores': cv_scores,\n",
    "        'test_scores': test_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    with open(os.path.join(trainer.save_dir, \"training_histories.pkl\"), 'wb') as f:\n",
    "        pickle.dump(training_histories, f)\n",
    "    \n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        'architectures_used': architectures_used,\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'test_scores': test_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'test_mean': float(np.mean(test_scores)),\n",
    "        'test_std': float(np.std(test_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': f'{IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}',\n",
    "        'augmentation_target': AUGMENTATION_TARGET,\n",
    "        'completed': True,\n",
    "        'academic_split': True\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(trainer.save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Final ensemble saved to: {ensemble_path}\")\n",
    "    return trainer.save_dir\n",
    "\n",
    "def plot_training_curves(training_histories, architectures_used, save_dir):\n",
    "    Path(os.path.join(save_dir, \"training_plots\")).mkdir(exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, NUM_FOLDS, figsize=(4*NUM_FOLDS, 4))\n",
    "    if NUM_FOLDS == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for fold, (history, arch) in enumerate(zip(training_histories, architectures_used)):\n",
    "        ax = axes[fold]\n",
    "        epochs = range(1, len(history['train_accs']) + 1)\n",
    "        \n",
    "        ax.plot(epochs, history['train_accs'], 'b-', label='Training', linewidth=2, alpha=0.8)\n",
    "        ax.plot(epochs, history['val_accs'], 'r-', label='Validation', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title(f'Fold {fold + 1} ({arch})')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"training_plots\", \"training_curves.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, NUM_FOLDS, figsize=(4*NUM_FOLDS, 4))\n",
    "    if NUM_FOLDS == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for fold, (history, arch) in enumerate(zip(training_histories, architectures_used)):\n",
    "        ax = axes[fold]\n",
    "        epochs = range(1, len(history['train_losses']) + 1)\n",
    "        \n",
    "        ax.plot(epochs, history['train_losses'], 'b-', label='Training Loss', linewidth=2, alpha=0.8)\n",
    "        ax.plot(epochs, history['val_losses'], 'r-', label='Validation Loss', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_title(f'Fold {fold + 1} Loss ({arch})')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"training_plots\", \"loss_curves.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    print(\"Academically Rigorous Multi-Architecture Ensemble Training\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Available architectures ({len(AVAILABLE_ARCHITECTURES)} total):\")\n",
    "    for i, arch in enumerate(AVAILABLE_ARCHITECTURES, 1):\n",
    "        print(f\"  {i:2d}. {arch}\")\n",
    "    print(f\"Number of folds: {NUM_FOLDS}\")\n",
    "    print(f\"Image size: {IMAGE_SIZE[1]}x{IMAGE_SIZE[0]}\")\n",
    "    print(f\"Augmentation target: {AUGMENTATION_TARGET} samples per class\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        print(f\"Total images: {len(images)}\")\n",
    "        print(f\"Age distribution: {dict(Counter(ages))}\")\n",
    "        \n",
    "        print(\"\\n--- ACADEMIC TRAIN/TEST SPLIT ---\")\n",
    "        X_train_all, X_test_final, y_train_all, y_test_final = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        print(f\"Training data: {len(X_train_all)} images\")\n",
    "        print(f\"Test data: {len(X_test_final)} images\")\n",
    "        print(\"Test set will be evaluated after each fold and for final ensemble\")\n",
    "        \n",
    "        trainer = MultiArchEnsembleTrainer(num_classes=len(unique_ages))\n",
    "        \n",
    "        print(\"\\n--- CROSS-VALIDATION WITH TEST EVALUATION ---\")\n",
    "        models, cv_scores, test_scores, training_histories, architectures_used = trainer.train_ensemble_academic(\n",
    "            X_train_all, y_train_all, X_test_final, y_test_final, label_mapping\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- FINAL ENSEMBLE EVALUATION ---\")\n",
    "        test_dataset = OptimizedDataset(X_test_final, y_test_final, test_time_aug=True)\n",
    "        batch_size = 32 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "        \n",
    "        print(\"Saving final ensemble...\")\n",
    "        save_dir = save_final_ensemble(trainer, models, cv_scores, test_scores, label_mapping, ensemble_acc, training_histories, architectures_used)\n",
    "        \n",
    "        print(\"Generating training curves...\")\n",
    "        plot_training_curves(training_histories, architectures_used, save_dir)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\n=== ACADEMIC RESULTS ===\")\n",
    "        print(\"Cross-Validation and Test Results:\")\n",
    "        for i, (cv_score, test_score, arch) in enumerate(zip(cv_scores, test_scores, architectures_used)):\n",
    "            print(f\"Fold {i+1}: CV={cv_score:.1f}%, Test={test_score:.1f}% ({arch})\")\n",
    "        print(f\"CV Mean: {np.mean(cv_scores):.1f}% ± {np.std(cv_scores):.1f}%\")\n",
    "        print(f\"Test Mean: {np.mean(test_scores):.1f}% ± {np.std(test_scores):.1f}%\")\n",
    "        print(f\"\\nFinal Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "        print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"All results saved to: {save_dir}\")\n",
    "        \n",
    "        print(\"\\n=== OVERFITTING ANALYSIS ===\")\n",
    "        print(\"Check training_plots/ for loss curves to verify no overfitting\")\n",
    "        \n",
    "        return {\n",
    "            'models': models,\n",
    "            'cv_scores': cv_scores,\n",
    "            'test_scores': test_scores,\n",
    "            'test_accuracy': ensemble_acc,\n",
    "            'architectures_used': architectures_used,\n",
    "            'save_directory': save_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3401d-e17c-47d7-9cc1-6690b9bef01c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, f1_score, \n",
    "    precision_score, recall_score, accuracy_score,\n",
    "    precision_recall_curve, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class ComprehensiveEvaluator:\n",
    "    def __init__(self, ensemble_path, test_data_path=None, device=None):\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.ensemble_path = ensemble_path\n",
    "        self.test_data_path = test_data_path\n",
    "        \n",
    "        # Load ensemble\n",
    "        self.ensemble_data = torch.load(ensemble_path, map_location=self.device)\n",
    "        self.models = self._load_ensemble_models()\n",
    "        self.label_mapping = self.ensemble_data['label_mapping']\n",
    "        self.cv_scores = self.ensemble_data['cv_scores']\n",
    "        self.architectures = self.ensemble_data['architectures_used']\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir = Path(\"evaluation_results\")\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"Loaded ensemble with {len(self.models)} models\")\n",
    "        print(f\"Architectures: {self.architectures}\")\n",
    "        print(f\"CV Scores: {[f'{score:.1f}%' for score in self.cv_scores]}\")\n",
    "    \n",
    "    def _load_ensemble_models(self):\n",
    "        models = []\n",
    "        state_dicts = self.ensemble_data['model_state_dicts']\n",
    "        architectures = self.ensemble_data['architectures_used']\n",
    "        num_classes = self.ensemble_data['num_classes']\n",
    "        \n",
    "        for state_dict, arch in zip(state_dicts, architectures):\n",
    "            model = timm.create_model(arch, pretrained=False, num_classes=num_classes)\n",
    "            \n",
    "            # Recreate the same classifier structure used during training\n",
    "            if hasattr(model, 'fc'):\n",
    "                in_features = model.fc.in_features\n",
    "                model.fc = nn.Sequential(\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(in_features, num_classes)\n",
    "                )\n",
    "            elif hasattr(model, 'classifier'):\n",
    "                if hasattr(model.classifier, 'in_features'):\n",
    "                    in_features = model.classifier.in_features\n",
    "                    model.classifier = nn.Sequential(\n",
    "                        nn.Dropout(0.3),\n",
    "                        nn.Linear(in_features, num_classes)\n",
    "                    )\n",
    "                else:\n",
    "                    in_features = model.classifier[-1].in_features\n",
    "                    model.classifier[-1] = nn.Sequential(\n",
    "                        nn.Dropout(0.3),\n",
    "                        nn.Linear(in_features, num_classes)\n",
    "                    )\n",
    "            \n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            models.append(model)\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def load_test_data(self, data_path=None):\n",
    "        \"\"\"Load test data - modify this based on your data format\"\"\"\n",
    "        if data_path:\n",
    "            # Load from specific path\n",
    "            pass\n",
    "        else:\n",
    "            # Load the original data and get test split\n",
    "            fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "            image_paths = glob.glob(fpath)\n",
    "            \n",
    "            images = []\n",
    "            ages = []\n",
    "            image_names = []\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        continue\n",
    "                    \n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img_resized = cv2.resize(img, (448, 224))  # W, H format for cv2\n",
    "                    \n",
    "                    filename = os.path.basename(img_path)\n",
    "                    filename_no_ext = os.path.splitext(filename)[0]\n",
    "                    parts = filename_no_ext.split('_')\n",
    "                    \n",
    "                    if len(parts) < 3:\n",
    "                        continue\n",
    "                    \n",
    "                    bbb_part = parts[1]\n",
    "                    if 'p' not in bbb_part:\n",
    "                        continue\n",
    "                    \n",
    "                    value_str = bbb_part.replace('p', '.')\n",
    "                    age_value = float(value_str)\n",
    "                    age_value = 5.5 if age_value >= 5.5 else age_value\n",
    "                    \n",
    "                    images.append(img_resized)\n",
    "                    ages.append(age_value)\n",
    "                    image_names.append(filename)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            # Convert to test set (same split as training)\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            unique_ages = sorted(list(set(ages)))\n",
    "            age_to_idx = {age: i for i, age in enumerate(unique_ages)}\n",
    "            y_indices = [age_to_idx[age] for age in ages]\n",
    "            \n",
    "            _, X_test, _, y_test, _, names_test = train_test_split(\n",
    "                images, y_indices, image_names, test_size=0.2, random_state=42, stratify=y_indices\n",
    "            )\n",
    "            \n",
    "            self.X_test = np.array(X_test)\n",
    "            self.y_test = np.array(y_test)\n",
    "            self.test_names = names_test\n",
    "            self.class_names = [str(age) for age in unique_ages]\n",
    "            \n",
    "            print(f\"Loaded {len(self.X_test)} test images\")\n",
    "            print(f\"Classes: {self.class_names}\")\n",
    "    \n",
    "    def preprocess_image_for_model(self, image):\n",
    "        \"\"\"Preprocess single image for model input\"\"\"\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        if len(image.shape) == 3:\n",
    "            image = torch.FloatTensor(image).permute(2, 0, 1)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image = (image - mean) / std\n",
    "        \n",
    "        return image.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def get_ensemble_predictions(self, return_probs=True):\n",
    "        \"\"\"Get ensemble predictions for all test data\"\"\"\n",
    "        all_probs = []\n",
    "        all_preds = []\n",
    "        \n",
    "        # Calculate weights based on CV scores\n",
    "        scores_array = np.array(self.cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        print(\"Computing ensemble predictions...\")\n",
    "        \n",
    "        for i, image in enumerate(self.X_test):\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Processing image {i+1}/{len(self.X_test)}\")\n",
    "            \n",
    "            # Preprocess image\n",
    "            img_tensor = self.preprocess_image_for_model(image)\n",
    "            \n",
    "            # Get predictions from each model\n",
    "            ensemble_output = torch.zeros(1, len(self.class_names)).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for model, weight in zip(self.models, weights):\n",
    "                    # Original prediction\n",
    "                    output1 = model(img_tensor)\n",
    "                    # Flipped prediction (TTA)\n",
    "                    flipped = torch.flip(img_tensor, [3])\n",
    "                    output2 = model(flipped)\n",
    "                    # Average and weight\n",
    "                    avg_output = (output1 + output2) / 2\n",
    "                    ensemble_output += weight * F.softmax(avg_output, dim=1)\n",
    "            \n",
    "            probs = ensemble_output.cpu().numpy()[0]\n",
    "            pred = np.argmax(probs)\n",
    "            \n",
    "            all_probs.append(probs)\n",
    "            all_preds.append(pred)\n",
    "        \n",
    "        self.y_pred = np.array(all_preds)\n",
    "        self.y_probs = np.array(all_probs)\n",
    "        \n",
    "        print(\"Ensemble predictions complete!\")\n",
    "        return self.y_pred, self.y_probs if return_probs else self.y_pred\n",
    "    \n",
    "    def generate_confusion_matrix(self):\n",
    "        \"\"\"Generate and save confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "        \n",
    "        # Calculate percentages\n",
    "        cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Raw counts\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=self.class_names, yticklabels=self.class_names, ax=ax1)\n",
    "        ax1.set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Predicted Age', fontsize=12)\n",
    "        ax1.set_ylabel('True Age', fontsize=12)\n",
    "        \n",
    "        # Percentages\n",
    "        sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Oranges',\n",
    "                   xticklabels=self.class_names, yticklabels=self.class_names, ax=ax2)\n",
    "        ax2.set_title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Predicted Age', fontsize=12)\n",
    "        ax2.set_ylabel('True Age', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Confusion matrices saved!\")\n",
    "    \n",
    "    def generate_classification_metrics(self):\n",
    "        \"\"\"Generate comprehensive classification metrics\"\"\"\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        \n",
    "        # Per-class metrics\n",
    "        f1_macro = f1_score(self.y_test, self.y_pred, average='macro')\n",
    "        f1_weighted = f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        f1_per_class = f1_score(self.y_test, self.y_pred, average=None)\n",
    "        \n",
    "        precision_macro = precision_score(self.y_test, self.y_pred, average='macro')\n",
    "        precision_per_class = precision_score(self.y_test, self.y_pred, average=None)\n",
    "        \n",
    "        recall_macro = recall_score(self.y_test, self.y_pred, average='macro')\n",
    "        recall_per_class = recall_score(self.y_test, self.y_pred, average=None)\n",
    "        \n",
    "        # Create metrics DataFrame\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Class': self.class_names,\n",
    "            'F1-Score': f1_per_class,\n",
    "            'Precision': precision_per_class,\n",
    "            'Recall': recall_per_class\n",
    "        })\n",
    "        \n",
    "        # Create bar plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # F1 Scores\n",
    "        bars1 = axes[0,0].bar(self.class_names, f1_per_class, color='skyblue', alpha=0.8)\n",
    "        axes[0,0].axhline(y=f1_macro, color='red', linestyle='--', label=f'Macro Avg: {f1_macro:.3f}')\n",
    "        axes[0,0].set_title('F1-Score per Class', fontsize=14, fontweight='bold')\n",
    "        axes[0,0].set_ylabel('F1-Score', fontsize=12)\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "        axes[0,0].legend()\n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars1, f1_per_class):\n",
    "            axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Precision\n",
    "        bars2 = axes[0,1].bar(self.class_names, precision_per_class, color='lightgreen', alpha=0.8)\n",
    "        axes[0,1].axhline(y=precision_macro, color='red', linestyle='--', label=f'Macro Avg: {precision_macro:.3f}')\n",
    "        axes[0,1].set_title('Precision per Class', fontsize=14, fontweight='bold')\n",
    "        axes[0,1].set_ylabel('Precision', fontsize=12)\n",
    "        axes[0,1].set_ylim(0, 1)\n",
    "        axes[0,1].legend()\n",
    "        for bar, val in zip(bars2, precision_per_class):\n",
    "            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Recall\n",
    "        bars3 = axes[1,0].bar(self.class_names, recall_per_class, color='lightcoral', alpha=0.8)\n",
    "        axes[1,0].axhline(y=recall_macro, color='red', linestyle='--', label=f'Macro Avg: {recall_macro:.3f}')\n",
    "        axes[1,0].set_title('Recall per Class', fontsize=14, fontweight='bold')\n",
    "        axes[1,0].set_ylabel('Recall', fontsize=12)\n",
    "        axes[1,0].set_xlabel('Age Class', fontsize=12)\n",
    "        axes[1,0].set_ylim(0, 1)\n",
    "        axes[1,0].legend()\n",
    "        for bar, val in zip(bars3, recall_per_class):\n",
    "            axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Overall metrics summary\n",
    "        axes[1,1].axis('off')\n",
    "        summary_text = f\"\"\"\n",
    "        Overall Performance Summary:\n",
    "        \n",
    "        Accuracy: {accuracy:.3f}\n",
    "        \n",
    "        F1-Score (Macro): {f1_macro:.3f}\n",
    "        F1-Score (Weighted): {f1_weighted:.3f}\n",
    "        \n",
    "        Precision (Macro): {precision_macro:.3f}\n",
    "        Recall (Macro): {recall_macro:.3f}\n",
    "        \n",
    "        Best F1 Class: {self.class_names[np.argmax(f1_per_class)]} ({f1_per_class.max():.3f})\n",
    "        Worst F1 Class: {self.class_names[np.argmin(f1_per_class)]} ({f1_per_class.min():.3f})\n",
    "        \"\"\"\n",
    "        axes[1,1].text(0.1, 0.9, summary_text, transform=axes[1,1].transAxes, \n",
    "                      fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "                      bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'classification_metrics.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Save metrics to CSV\n",
    "        metrics_df.to_csv(self.output_dir / 'per_class_metrics.csv', index=False)\n",
    "        \n",
    "        print(\"Classification metrics saved!\")\n",
    "        return metrics_df\n",
    "    \n",
    "    def generate_class_distribution_plots(self):\n",
    "        \"\"\"Generate age class distribution plots\"\"\"\n",
    "        # Count distributions\n",
    "        true_counts = Counter(self.y_test)\n",
    "        pred_counts = Counter(self.y_pred)\n",
    "        \n",
    "        # Convert to lists for plotting\n",
    "        true_dist = [true_counts.get(i, 0) for i in range(len(self.class_names))]\n",
    "        pred_dist = [pred_counts.get(i, 0) for i in range(len(self.class_names))]\n",
    "        \n",
    "        # Create comparison plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        x = np.arange(len(self.class_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Side by side bars\n",
    "        bars1 = ax1.bar(x - width/2, true_dist, width, label='True Distribution', \n",
    "                       color='steelblue', alpha=0.8)\n",
    "        bars2 = ax1.bar(x + width/2, pred_dist, width, label='Predicted Distribution', \n",
    "                       color='lightcoral', alpha=0.8)\n",
    "        \n",
    "        ax1.set_xlabel('Age Class', fontsize=12)\n",
    "        ax1.set_ylabel('Number of Samples', fontsize=12)\n",
    "        ax1.set_title('True vs Predicted Class Distributions', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(self.class_names)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Add value labels\n",
    "        for bars in [bars1, bars2]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                        f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Pie chart for true distribution\n",
    "        ax2.pie(true_dist, labels=self.class_names, autopct='%1.1f%%', startangle=90)\n",
    "        ax2.set_title('True Age Distribution', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'class_distributions.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Class distribution plots saved!\")\n",
    "    \n",
    "    def generate_grad_cam_heatmaps(self, num_samples=9):\n",
    "        \"\"\"Generate Grad-CAM attention heatmaps for sample images (original + heatmap overlay)\"\"\"\n",
    "        \n",
    "        class GradCAM:\n",
    "            def __init__(self, model):\n",
    "                self.model = model\n",
    "                self.target_layer = None\n",
    "                self.gradients = None\n",
    "                self.activations = None\n",
    "                \n",
    "                # Find the last convolutional layer\n",
    "                for name, module in self.model.named_modules():\n",
    "                    if isinstance(module, nn.Conv2d):\n",
    "                        self.target_layer = module\n",
    "                \n",
    "                self.target_layer.register_forward_hook(self.save_activation)\n",
    "                self.target_layer.register_backward_hook(self.save_gradient)\n",
    "            \n",
    "            def save_activation(self, module, input, output):\n",
    "                self.activations = output\n",
    "            \n",
    "            def save_gradient(self, module, grad_input, grad_output):\n",
    "                self.gradients = grad_output[0]\n",
    "            \n",
    "            def generate_cam(self, input_tensor, class_idx):\n",
    "                # Forward pass\n",
    "                output = self.model(input_tensor)\n",
    "                \n",
    "                # Backward pass\n",
    "                self.model.zero_grad()\n",
    "                output[0, class_idx].backward(retain_graph=True)\n",
    "                \n",
    "                # Generate CAM\n",
    "                gradients = self.gradients.cpu().data.numpy()[0]\n",
    "                activations = self.activations.cpu().data.numpy()[0]\n",
    "                \n",
    "                weights = np.mean(gradients, axis=(1, 2))\n",
    "                cam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
    "                \n",
    "                for i, w in enumerate(weights):\n",
    "                    cam += w * activations[i]\n",
    "                \n",
    "                cam = np.maximum(cam, 0)\n",
    "                cam = cam / cam.max() if cam.max() > 0 else cam\n",
    "                cam = cv2.resize(cam, (448, 224))\n",
    "                \n",
    "                return cam\n",
    "        \n",
    "        # Select diverse samples (one from each class if possible)\n",
    "        selected_indices = []\n",
    "        for class_idx in range(len(self.class_names)):\n",
    "            class_indices = np.where(self.y_test == class_idx)[0]\n",
    "            if len(class_indices) > 0:\n",
    "                # Select the sample with highest confidence for this class\n",
    "                class_probs = self.y_probs[class_indices, class_idx]\n",
    "                best_idx = class_indices[np.argmax(class_probs)]\n",
    "                selected_indices.append(best_idx)\n",
    "        \n",
    "        # Fill up to num_samples with random samples if needed\n",
    "        while len(selected_indices) < num_samples and len(selected_indices) < len(self.X_test):\n",
    "            remaining_indices = set(range(len(self.X_test))) - set(selected_indices)\n",
    "            if remaining_indices:\n",
    "                selected_indices.append(np.random.choice(list(remaining_indices)))\n",
    "        \n",
    "        selected_indices = selected_indices[:num_samples]\n",
    "        \n",
    "        # Create the visualization\n",
    "        fig = plt.figure(figsize=(12, 4 * len(selected_indices)))\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            image = self.X_test[idx]\n",
    "            true_class = self.y_test[idx]\n",
    "            pred_class = self.y_pred[idx]\n",
    "            probs = self.y_probs[idx]\n",
    "            \n",
    "            # Get Grad-CAM from the best model (highest CV score)\n",
    "            best_model_idx = np.argmax(self.cv_scores)\n",
    "            best_model = self.models[best_model_idx]\n",
    "            \n",
    "            grad_cam = GradCAM(best_model)\n",
    "            img_tensor = self.preprocess_image_for_model(image)\n",
    "            \n",
    "            # Generate heatmap for predicted class\n",
    "            heatmap = grad_cam.generate_cam(img_tensor, pred_class)\n",
    "            \n",
    "            # Create subplot layout: original | heatmap (tight spacing)\n",
    "            gs = plt.GridSpec(1, 2, figure=fig, width_ratios=[1, 1],\n",
    "                            top=1-i/len(selected_indices), bottom=1-(i+1)/len(selected_indices),\n",
    "                            left=0.02, right=0.98, wspace=0.02, hspace=0.02)\n",
    "            \n",
    "            # Original image\n",
    "            ax1 = fig.add_subplot(gs[0])\n",
    "            ax1.imshow(image)\n",
    "            ax1.set_title(f'Original Image\\nTrue: {self.class_names[true_class]} | Pred: {self.class_names[pred_class]}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # Heatmap overlay\n",
    "            ax2 = fig.add_subplot(gs[1])\n",
    "            ax2.imshow(image)\n",
    "            heatmap_colored = plt.cm.jet(heatmap)[:, :, :3]\n",
    "            ax2.imshow(heatmap_colored, alpha=0.6)\n",
    "            ax2.set_title(f'Attention Heatmap\\n(Focus: {self.class_names[pred_class]})', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "            ax2.axis('off')\n",
    "        \n",
    "        plt.savefig(self.output_dir / 'attention_heatmaps.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Attention heatmaps saved!\")\n",
    "    \n",
    "    def generate_ensemble_analysis(self):\n",
    "        \"\"\"Analyze ensemble component performance\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # CV Scores comparison\n",
    "        bars1 = axes[0,0].bar(range(len(self.architectures)), self.cv_scores, \n",
    "                             color=['skyblue', 'lightgreen', 'lightcoral', 'orange', 'purple'][:len(self.architectures)])\n",
    "        axes[0,0].set_title('Cross-Validation Scores by Architecture', fontsize=14, fontweight='bold')\n",
    "        axes[0,0].set_ylabel('CV Score (%)', fontsize=12)\n",
    "        axes[0,0].set_xticks(range(len(self.architectures)))\n",
    "        axes[0,0].set_xticklabels(self.architectures, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, score in zip(bars1, self.cv_scores):\n",
    "            axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                          f'{score:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Ensemble weights\n",
    "        scores_array = np.array(self.cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        bars2 = axes[0,1].bar(range(len(self.architectures)), weights, \n",
    "                             color=['skyblue', 'lightgreen', 'lightcoral', 'orange', 'purple'][:len(self.architectures)])\n",
    "        axes[0,1].set_title('Ensemble Weights', fontsize=14, fontweight='bold')\n",
    "        axes[0,1].set_ylabel('Weight', fontsize=12)\n",
    "        axes[0,1].set_xticks(range(len(self.architectures)))\n",
    "        axes[0,1].set_xticklabels(self.architectures, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, weight in zip(bars2, weights):\n",
    "            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{weight:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Model architecture distribution\n",
    "        arch_counts = Counter(self.architectures)\n",
    "        axes[1,0].pie(arch_counts.values(), labels=arch_counts.keys(), autopct='%1.0f%%', startangle=90)\n",
    "        axes[1,0].set_title('Architecture Distribution in Ensemble', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Performance summary\n",
    "        axes[1,1].axis('off')\n",
    "        ensemble_accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        summary_text = f\"\"\"\n",
    "        Ensemble Performance Summary:\n",
    "        \n",
    "        Number of Models: {len(self.models)}\n",
    "        Architectures Used: {len(set(self.architectures))}\n",
    "        \n",
    "        Best Individual CV: {max(self.cv_scores):.1f}%\n",
    "        Worst Individual CV: {min(self.cv_scores):.1f}%\n",
    "        Mean CV Score: {np.mean(self.cv_scores):.1f}%\n",
    "        \n",
    "        Final Test Accuracy: {ensemble_accuracy:.1f}%\n",
    "        \n",
    "        Ensemble Improvement: {ensemble_accuracy*100 - np.mean(self.cv_scores):.1f} percentage points\n",
    "        \"\"\"\n",
    "        axes[1,1].text(0.1, 0.9, summary_text, transform=axes[1,1].transAxes, \n",
    "                      fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "                      bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'ensemble_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Ensemble analysis saved!\")\n",
    "    \n",
    "    def generate_error_analysis(self):\n",
    "        \"\"\"Analyze prediction errors\"\"\"\n",
    "        # Find misclassified samples\n",
    "        errors = self.y_test != self.y_pred\n",
    "        error_indices = np.where(errors)[0]\n",
    "        \n",
    "        if len(error_indices) == 0:\n",
    "            print(\"No errors found!\")\n",
    "            return\n",
    "        \n",
    "        # Error types\n",
    "        error_types = []\n",
    "        for idx in error_indices:\n",
    "            true_age = float(self.class_names[self.y_test[idx]])\n",
    "            pred_age = float(self.class_names[self.y_pred[idx]])\n",
    "            error_types.append(abs(true_age - pred_age))\n",
    "        \n",
    "        # Create error analysis plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Error magnitude distribution\n",
    "        axes[0,0].hist(error_types, bins=10, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "        axes[0,0].set_title('Error Magnitude Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[0,0].set_xlabel('Age Difference (|True - Predicted|)', fontsize=12)\n",
    "        axes[0,0].set_ylabel('Frequency', fontsize=12)\n",
    "        \n",
    "        # Error by true class\n",
    "        error_by_class = {class_name: [] for class_name in self.class_names}\n",
    "        for idx in error_indices:\n",
    "            true_class_name = self.class_names[self.y_test[idx]]\n",
    "            pred_class_name = self.class_names[self.y_pred[idx]]\n",
    "            error_by_class[true_class_name].append(pred_class_name)\n",
    "        \n",
    "        error_rates = [len(errors) / list(self.y_test).count(i) * 100 \n",
    "                      for i, errors in enumerate([error_by_class[name] for name in self.class_names])]\n",
    "        \n",
    "        bars = axes[0,1].bar(self.class_names, error_rates, color='orange', alpha=0.7)\n",
    "        axes[0,1].set_title('Error Rate by True Class', fontsize=14, fontweight='bold')\n",
    "        axes[0,1].set_ylabel('Error Rate (%)', fontsize=12)\n",
    "        axes[0,1].set_xlabel('True Age Class', fontsize=12)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, rate in zip(bars, error_rates):\n",
    "            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                          f'{rate:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Confidence vs Accuracy\n",
    "        confidences = np.max(self.y_probs, axis=1)\n",
    "        correct = self.y_test == self.y_pred\n",
    "        \n",
    "        axes[1,0].scatter(confidences[correct], [1]*sum(correct), alpha=0.5, color='green', label='Correct')\n",
    "        axes[1,0].scatter(confidences[~correct], [0]*sum(~correct), alpha=0.5, color='red', label='Incorrect')\n",
    "        axes[1,0].set_title('Prediction Confidence vs Accuracy', fontsize=14, fontweight='bold')\n",
    "        axes[1,0].set_xlabel('Max Probability', fontsize=12)\n",
    "        axes[1,0].set_ylabel('Correct (1) / Incorrect (0)', fontsize=12)\n",
    "        axes[1,0].legend()\n",
    "        \n",
    "        # Summary statistics\n",
    "        axes[1,1].axis('off')\n",
    "        total_errors = len(error_indices)\n",
    "        avg_error = np.mean(error_types) if error_types else 0\n",
    "        max_error = max(error_types) if error_types else 0\n",
    "        avg_confidence_correct = np.mean(confidences[correct]) if sum(correct) > 0 else 0\n",
    "        avg_confidence_wrong = np.mean(confidences[~correct]) if sum(~correct) > 0 else 0\n",
    "        \n",
    "        summary_text = f\"\"\"\n",
    "        Error Analysis Summary:\n",
    "        \n",
    "        Total Errors: {total_errors} / {len(self.y_test)} ({total_errors/len(self.y_test)*100:.1f}%)\n",
    "        \n",
    "        Average Error Magnitude: {avg_error:.2f} years\n",
    "        Maximum Error: {max_error:.1f} years\n",
    "        \n",
    "        Avg Confidence (Correct): {avg_confidence_correct:.3f}\n",
    "        Avg Confidence (Wrong): {avg_confidence_wrong:.3f}\n",
    "        \n",
    "        Most Confused Classes:\n",
    "        {self.class_names[np.argmax(error_rates)]} ({max(error_rates):.1f}% error rate)\n",
    "        \"\"\"\n",
    "        axes[1,1].text(0.1, 0.9, summary_text, transform=axes[1,1].transAxes, \n",
    "                      fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "                      bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"mistyrose\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Error analysis saved!\")\n",
    "    \n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"Generate a comprehensive evaluation report\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"COMPREHENSIVE ENSEMBLE MODEL EVALUATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load test data\n",
    "        print(\"\\n1. Loading test data...\")\n",
    "        self.load_test_data()\n",
    "        \n",
    "        # Get predictions\n",
    "        print(\"\\n2. Computing ensemble predictions...\")\n",
    "        self.get_ensemble_predictions()\n",
    "        \n",
    "        # Generate all visualizations\n",
    "        print(\"\\n3. Generating confusion matrices...\")\n",
    "        self.generate_confusion_matrix()\n",
    "        \n",
    "        print(\"\\n4. Computing classification metrics...\")\n",
    "        metrics_df = self.generate_classification_metrics()\n",
    "        \n",
    "        print(\"\\n5. Creating class distribution plots...\")\n",
    "        self.generate_class_distribution_plots()\n",
    "        \n",
    "        print(\"\\n6. Generating attention heatmaps...\")\n",
    "        self.generate_grad_cam_heatmaps()\n",
    "        \n",
    "        print(\"\\n7. Analyzing ensemble performance...\")\n",
    "        self.generate_ensemble_analysis()\n",
    "        \n",
    "        print(\"\\n8. Performing error analysis...\")\n",
    "        self.generate_error_analysis()\n",
    "        \n",
    "        # Save final summary\n",
    "        accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        f1_macro = f1_score(self.y_test, self.y_pred, average='macro')\n",
    "        \n",
    "        summary = {\n",
    "            'test_accuracy': float(accuracy),\n",
    "            'f1_macro': float(f1_macro),\n",
    "            'cv_scores': self.cv_scores,\n",
    "            'architectures': self.architectures,\n",
    "            'num_test_samples': len(self.y_test),\n",
    "            'num_classes': len(self.class_names),\n",
    "            'class_names': self.class_names\n",
    "        }\n",
    "        \n",
    "        with open(self.output_dir / 'evaluation_summary.json', 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"EVALUATION COMPLETE!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Test Accuracy: {accuracy:.1%}\")\n",
    "        print(f\"F1-Score (Macro): {f1_macro:.3f}\")\n",
    "        print(f\"Results saved to: {self.output_dir}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize evaluator\n",
    "    ensemble_path = \"./academic_ensemble_20250721_081845 (90.7 +- 2.6%)/academic_ensemble.pth\"  # Update this path\n",
    "    evaluator = ComprehensiveEvaluator(ensemble_path)\n",
    "    \n",
    "    # Generate comprehensive report\n",
    "    evaluator.generate_comprehensive_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca41c99-14d3-4a7a-b9e6-c8a193257a5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class OverfittingDiagnostic:\n",
    "    def __init__(self, ensemble_path):\n",
    "        self.ensemble_path = ensemble_path\n",
    "        self.ensemble_data = torch.load(ensemble_path, map_location='cpu')\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load original data\n",
    "        self.load_all_data()\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir = Path(\"diagnostic_results\")\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def load_all_data(self):\n",
    "        \"\"\"Load all original data to check for issues\"\"\"\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        image_paths = glob.glob(fpath)\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        filenames = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, (448, 224))\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                age_value = float(value_str)\n",
    "                age_value = 5.5 if age_value >= 5.5 else age_value\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                filenames.append(filename)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Convert ages to indices\n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        self.age_to_idx = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = [self.age_to_idx[age] for age in ages]\n",
    "        \n",
    "        # Same split as used in training\n",
    "        X_train, X_test, y_train, y_test, names_train, names_test = train_test_split(\n",
    "            images, y_indices, filenames, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        self.X_train = np.array(X_train)\n",
    "        self.X_test = np.array(X_test)\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.y_test = np.array(y_test)\n",
    "        self.names_train = names_train\n",
    "        self.names_test = names_test\n",
    "        self.class_names = [str(age) for age in unique_ages]\n",
    "        \n",
    "        print(f\"Loaded {len(self.X_train)} training images, {len(self.X_test)} test images\")\n",
    "        print(f\"Classes: {self.class_names}\")\n",
    "    \n",
    "    def check_data_leakage(self):\n",
    "        \"\"\"Check for potential data leakage between train and test sets\"\"\"\n",
    "        print(\"\\n=== DATA LEAKAGE ANALYSIS ===\")\n",
    "        \n",
    "        # Check for duplicate filenames (should be impossible but let's verify)\n",
    "        train_set = set(self.names_train)\n",
    "        test_set = set(self.names_test)\n",
    "        overlap = train_set.intersection(test_set)\n",
    "        \n",
    "        print(f\"Filename overlap between train/test: {len(overlap)}\")\n",
    "        if overlap:\n",
    "            print(f\"Overlapping files: {list(overlap)[:5]}...\")\n",
    "        \n",
    "        # Check for very similar filenames (potential same patient)\n",
    "        potential_leaks = []\n",
    "        for test_name in self.names_test:\n",
    "            test_base = test_name.split('_')[0] if '_' in test_name else test_name[:5]\n",
    "            for train_name in self.names_train:\n",
    "                train_base = train_name.split('_')[0] if '_' in train_name else train_name[:5]\n",
    "                if test_base == train_base and test_name != train_name:\n",
    "                    potential_leaks.append((test_name, train_name))\n",
    "        \n",
    "        print(f\"Potential patient leaks (same base filename): {len(potential_leaks)}\")\n",
    "        if potential_leaks:\n",
    "            print(\"Examples:\")\n",
    "            for i, (test, train) in enumerate(potential_leaks[:5]):\n",
    "                print(f\"  Test: {test} <-> Train: {train}\")\n",
    "        \n",
    "        # Analyze filename patterns\n",
    "        print(f\"\\nFilename pattern analysis:\")\n",
    "        print(f\"Train filename examples: {self.names_train[:5]}\")\n",
    "        print(f\"Test filename examples: {self.names_test[:5]}\")\n",
    "        \n",
    "        return len(overlap), len(potential_leaks)\n",
    "    \n",
    "    def analyze_class_distributions(self):\n",
    "        \"\"\"Compare train vs test class distributions\"\"\"\n",
    "        print(\"\\n=== CLASS DISTRIBUTION ANALYSIS ===\")\n",
    "        \n",
    "        train_dist = Counter(self.y_train)\n",
    "        test_dist = Counter(self.y_test)\n",
    "        \n",
    "        # Create comparison\n",
    "        comparison_data = []\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            train_count = train_dist.get(i, 0)\n",
    "            test_count = test_dist.get(i, 0)\n",
    "            train_pct = train_count / len(self.y_train) * 100\n",
    "            test_pct = test_count / len(self.y_test) * 100\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Class': class_name,\n",
    "                'Train_Count': train_count,\n",
    "                'Test_Count': test_count,\n",
    "                'Train_Pct': train_pct,\n",
    "                'Test_Pct': test_pct,\n",
    "                'Pct_Diff': abs(train_pct - test_pct)\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        print(df)\n",
    "        \n",
    "        # Plot distributions\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        x = np.arange(len(self.class_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, [train_dist.get(i, 0) for i in range(len(self.class_names))], \n",
    "                width, label='Train', alpha=0.8)\n",
    "        ax1.bar(x + width/2, [test_dist.get(i, 0) for i in range(len(self.class_names))], \n",
    "                width, label='Test', alpha=0.8)\n",
    "        ax1.set_xlabel('Age Class')\n",
    "        ax1.set_ylabel('Count')\n",
    "        ax1.set_title('Train vs Test Distribution (Counts)')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(self.class_names)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Percentage differences\n",
    "        pct_diffs = df['Pct_Diff'].values\n",
    "        bars = ax2.bar(self.class_names, pct_diffs, color='red', alpha=0.7)\n",
    "        ax2.set_xlabel('Age Class')\n",
    "        ax2.set_ylabel('Percentage Point Difference')\n",
    "        ax2.set_title('Train vs Test Distribution Differences')\n",
    "        ax2.axhline(y=5, color='orange', linestyle='--', label='5% threshold')\n",
    "        ax2.legend()\n",
    "        \n",
    "        for bar, diff in zip(bars, pct_diffs):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                    f'{diff:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.output_dir / 'distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        max_diff = df['Pct_Diff'].max()\n",
    "        print(f\"Maximum distribution difference: {max_diff:.1f} percentage points\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def test_individual_fold_performance(self):\n",
    "        \"\"\"Test each fold's performance on the test set individually\"\"\"\n",
    "        print(\"\\n=== INDIVIDUAL FOLD ANALYSIS ===\")\n",
    "        \n",
    "        # We'll need to load the individual fold models\n",
    "        ensemble_dir = Path(self.ensemble_path).parent\n",
    "        fold_files = list(ensemble_dir.glob(\"*_fold_*.pth\"))\n",
    "        \n",
    "        if not fold_files:\n",
    "            print(\"No individual fold files found. Cannot analyze individual performance.\")\n",
    "            return\n",
    "        \n",
    "        individual_results = []\n",
    "        \n",
    "        print(f\"Found {len(fold_files)} fold models\")\n",
    "        \n",
    "        for fold_file in fold_files:\n",
    "            try:\n",
    "                fold_data = torch.load(fold_file, map_location='cpu')\n",
    "                cv_score = fold_data['cv_score']\n",
    "                architecture = fold_data['model_architecture']\n",
    "                fold_num = fold_data['fold']\n",
    "                \n",
    "                # Load and test this individual model\n",
    "                import timm\n",
    "                import torch.nn as nn\n",
    "                \n",
    "                model = timm.create_model(architecture, pretrained=False, \n",
    "                                        num_classes=len(self.class_names))\n",
    "                \n",
    "                # Recreate classifier structure\n",
    "                if hasattr(model, 'fc'):\n",
    "                    in_features = model.fc.in_features\n",
    "                    model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_features, len(self.class_names)))\n",
    "                elif hasattr(model, 'classifier'):\n",
    "                    if hasattr(model.classifier, 'in_features'):\n",
    "                        in_features = model.classifier.in_features\n",
    "                        model.classifier = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_features, len(self.class_names)))\n",
    "                \n",
    "                model.load_state_dict(fold_data['model_state_dict'])\n",
    "                model.eval()\n",
    "                \n",
    "                # Test on test set\n",
    "                test_accuracy = self.evaluate_single_model(model)\n",
    "                \n",
    "                individual_results.append({\n",
    "                    'Fold': fold_num,\n",
    "                    'Architecture': architecture,\n",
    "                    'CV_Score': cv_score,\n",
    "                    'Test_Accuracy': test_accuracy,\n",
    "                    'Gap': cv_score - test_accuracy\n",
    "                })\n",
    "                \n",
    "                print(f\"Fold {fold_num} ({architecture}): CV={cv_score:.1f}%, Test={test_accuracy:.1f}%, Gap={cv_score-test_accuracy:.1f}%\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {fold_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if individual_results:\n",
    "            df = pd.DataFrame(individual_results)\n",
    "            \n",
    "            # Plot individual gaps\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # CV vs Test scores\n",
    "            folds = [f\"Fold {r['Fold']}\" for r in individual_results]\n",
    "            cv_scores = [r['CV_Score'] for r in individual_results]\n",
    "            test_scores = [r['Test_Accuracy'] for r in individual_results]\n",
    "            \n",
    "            x = np.arange(len(folds))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax1.bar(x - width/2, cv_scores, width, label='CV Score', alpha=0.8)\n",
    "            ax1.bar(x + width/2, test_scores, width, label='Test Score', alpha=0.8)\n",
    "            ax1.set_xlabel('Model Fold')\n",
    "            ax1.set_ylabel('Accuracy (%)')\n",
    "            ax1.set_title('CV vs Test Performance by Fold')\n",
    "            ax1.set_xticks(x)\n",
    "            ax1.set_xticklabels(folds, rotation=45)\n",
    "            ax1.legend()\n",
    "            \n",
    "            # Performance gaps\n",
    "            gaps = [r['Gap'] for r in individual_results]\n",
    "            bars = ax2.bar(folds, gaps, color='red', alpha=0.7)\n",
    "            ax2.set_xlabel('Model Fold')\n",
    "            ax2.set_ylabel('Performance Gap (%)')\n",
    "            ax2.set_title('CV - Test Performance Gap by Fold')\n",
    "            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "            ax2.set_xticklabels(folds, rotation=45)\n",
    "            \n",
    "            for bar, gap in zip(bars, gaps):\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                        f'{gap:.1f}%', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(self.output_dir / 'individual_fold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            avg_gap = np.mean(gaps)\n",
    "            print(f\"Average CV-Test gap across folds: {avg_gap:.1f}%\")\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def evaluate_single_model(self, model):\n",
    "        \"\"\"Evaluate a single model on test set\"\"\"\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for image in self.X_test:\n",
    "                # Preprocess\n",
    "                if image.max() > 1.0:\n",
    "                    image = image / 255.0\n",
    "                \n",
    "                image_tensor = torch.FloatTensor(image).permute(2, 0, 1)\n",
    "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "                image_tensor = (image_tensor - mean) / std\n",
    "                image_tensor = image_tensor.unsqueeze(0)\n",
    "                \n",
    "                outputs = model(image_tensor)\n",
    "                predicted = torch.argmax(outputs, dim=1).item()\n",
    "                \n",
    "                correct += 1 if predicted == self.y_test[total] else 0\n",
    "                total += 1\n",
    "        \n",
    "        return (correct / total) * 100\n",
    "    \n",
    "    def analyze_dataset_size_impact(self):\n",
    "        \"\"\"Analyze if small dataset size is causing the issue\"\"\"\n",
    "        print(\"\\n=== DATASET SIZE ANALYSIS ===\")\n",
    "        \n",
    "        total_samples = len(self.X_train) + len(self.X_test)\n",
    "        samples_per_class = total_samples / len(self.class_names)\n",
    "        test_samples_per_class = len(self.X_test) / len(self.class_names)\n",
    "        \n",
    "        print(f\"Total dataset size: {total_samples}\")\n",
    "        print(f\"Average samples per class: {samples_per_class:.1f}\")\n",
    "        print(f\"Test samples per class: {test_samples_per_class:.1f}\")\n",
    "        print(f\"Test set size: {len(self.X_test)} ({len(self.X_test)/total_samples*100:.1f}% of total)\")\n",
    "        \n",
    "        # Check class representation in test set\n",
    "        min_test_class = min(Counter(self.y_test).values())\n",
    "        max_test_class = max(Counter(self.y_test).values())\n",
    "        \n",
    "        print(f\"Test set class range: {min_test_class} to {max_test_class} samples\")\n",
    "        \n",
    "        if min_test_class < 10:\n",
    "            print(\"⚠️  WARNING: Some classes have very few test samples (<10)\")\n",
    "        if test_samples_per_class < 20:\n",
    "            print(\"⚠️  WARNING: Very small test set - high variance expected\")\n",
    "        \n",
    "        return {\n",
    "            'total_samples': total_samples,\n",
    "            'test_size': len(self.X_test),\n",
    "            'min_test_class': min_test_class,\n",
    "            'max_test_class': max_test_class,\n",
    "            'avg_test_per_class': test_samples_per_class\n",
    "        }\n",
    "    \n",
    "    def generate_recommendations(self, leakage_info, distribution_df, size_info, individual_df=None):\n",
    "        \"\"\"Generate recommendations based on analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DIAGNOSTIC SUMMARY & RECOMMENDATIONS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        issues_found = []\n",
    "        recommendations = []\n",
    "        \n",
    "        # Check for data leakage\n",
    "        if leakage_info[0] > 0:\n",
    "            issues_found.append(\"Direct filename overlap between train/test\")\n",
    "            recommendations.append(\"🔥 CRITICAL: Remove overlapping files from train or test set\")\n",
    "        \n",
    "        if leakage_info[1] > 0:\n",
    "            issues_found.append(f\"Potential patient leaks: {leakage_info[1]} cases\")\n",
    "            recommendations.append(\"⚠️  Check if same patients appear in both train/test\")\n",
    "        \n",
    "        # Check distribution differences\n",
    "        max_dist_diff = distribution_df['Pct_Diff'].max()\n",
    "        if max_dist_diff > 10:\n",
    "            issues_found.append(f\"Large distribution differences: {max_dist_diff:.1f}%\")\n",
    "            recommendations.append(\"📊 Consider stratified sampling with more constraints\")\n",
    "        \n",
    "        # Check dataset size\n",
    "        if size_info['test_size'] < 100:\n",
    "            issues_found.append(\"Very small test set\")\n",
    "            recommendations.append(\"📈 Consider larger dataset or repeated train/test splits\")\n",
    "        \n",
    "        if size_info['min_test_class'] < 5:\n",
    "            issues_found.append(\"Some classes have very few test samples\")\n",
    "            recommendations.append(\"⚖️  Use stratified sampling to ensure minimum samples per class\")\n",
    "        \n",
    "        # Check individual model performance\n",
    "        if individual_df is not None:\n",
    "            avg_gap = individual_df['Gap'].mean()\n",
    "            if avg_gap > 10:\n",
    "                issues_found.append(f\"Consistent overfitting across folds: {avg_gap:.1f}% avg gap\")\n",
    "                recommendations.append(\"🔧 Reduce model complexity or increase regularization\")\n",
    "                recommendations.append(\"🔧 Reduce aggressive data augmentation\")\n",
    "                recommendations.append(\"🔧 Add more diverse real data\")\n",
    "        \n",
    "        # Print findings\n",
    "        if issues_found:\n",
    "            print(\"ISSUES FOUND:\")\n",
    "            for i, issue in enumerate(issues_found, 1):\n",
    "                print(f\"{i}. {issue}\")\n",
    "        else:\n",
    "            print(\"No obvious issues detected in basic checks.\")\n",
    "        \n",
    "        print(f\"\\nRECOMMENDATIONS:\")\n",
    "        if recommendations:\n",
    "            for i, rec in enumerate(recommendations, 1):\n",
    "                print(f\"{i}. {rec}\")\n",
    "        else:\n",
    "            print(\"1. 🔍 The 13% CV-Test gap suggests overfitting despite no obvious data issues\")\n",
    "            print(\"2. 🔧 Try reducing augmentation intensity\")\n",
    "            print(\"3. 🔧 Add more regularization (dropout, weight decay)\")\n",
    "            print(\"4. 📊 Consider k-fold evaluation on multiple random splits\")\n",
    "            print(\"5. 📈 Collect more diverse real data if possible\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def run_comprehensive_diagnostic(self):\n",
    "        \"\"\"Run all diagnostic tests\"\"\"\n",
    "        print(\"OVERFITTING DIAGNOSTIC ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Run all analyses\n",
    "        leakage_info = self.check_data_leakage()\n",
    "        distribution_df = self.analyze_class_distributions()\n",
    "        size_info = self.analyze_dataset_size_impact()\n",
    "        individual_df = self.test_individual_fold_performance()\n",
    "        \n",
    "        # Generate recommendations\n",
    "        self.generate_recommendations(leakage_info, distribution_df, size_info, individual_df)\n",
    "        \n",
    "        # Save summary\n",
    "        summary = {\n",
    "            'filename_overlap': leakage_info[0],\n",
    "            'potential_patient_leaks': leakage_info[1],\n",
    "            'max_distribution_difference': float(distribution_df['Pct_Diff'].max()),\n",
    "            'test_set_size': size_info['test_size'],\n",
    "            'min_test_class_size': size_info['min_test_class'],\n",
    "            'individual_fold_gaps': individual_df['Gap'].tolist() if individual_df is not None else []\n",
    "        }\n",
    "        \n",
    "        with open(self.output_dir / 'diagnostic_summary.json', 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nDiagnostic results saved to: {self.output_dir}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    ensemble_path = \"./(teeth) academic_ensemble_20250721_081845 (90.7 +- 2.6%)/academic_ensemble.pth\"\n",
    "    diagnostic = OverfittingDiagnostic(ensemble_path)\n",
    "    diagnostic.run_comprehensive_diagnostic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fe1fc-5563-4d11-8641-7c3159ef59ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Figuring out coloration for heatmap overlay\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import timm\n",
    "from pathlib import Path\n",
    "\n",
    "class JawboneModelRunner:\n",
    "    def __init__(self, ensemble_path):\n",
    "        self.ensemble_path = ensemble_path\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.models = []\n",
    "        self.class_names = []\n",
    "        self.load_ensemble()\n",
    "        \n",
    "    def load_ensemble(self):\n",
    "        \"\"\"Load the ensemble model\"\"\"\n",
    "        ensemble_data = torch.load(self.ensemble_path, map_location=self.device)\n",
    "        \n",
    "        # Handle the specific ensemble format from your script\n",
    "        if 'model_state_dicts' in ensemble_data:\n",
    "            model_state_dicts = ensemble_data['model_state_dicts']\n",
    "            architectures = ensemble_data['architectures_used']\n",
    "            num_classes = ensemble_data['num_classes']\n",
    "            label_mapping = ensemble_data.get('label_mapping', {})\n",
    "            \n",
    "            # Create class names from label mapping or use indices\n",
    "            if label_mapping:\n",
    "                sorted_labels = sorted(label_mapping.items(), key=lambda x: x[1])\n",
    "                self.class_names = [label for label, idx in sorted_labels]\n",
    "            else:\n",
    "                self.class_names = [str(i) for i in range(num_classes)]\n",
    "            \n",
    "            # Load each model\n",
    "            for i, (state_dict, architecture) in enumerate(zip(model_state_dicts, architectures)):\n",
    "                try:\n",
    "                    model = timm.create_model(architecture, pretrained=False, num_classes=num_classes)\n",
    "                    \n",
    "                    # Recreate classifier structure\n",
    "                    if hasattr(model, 'fc'):\n",
    "                        in_features = model.fc.in_features\n",
    "                        model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_features, num_classes))\n",
    "                    elif hasattr(model, 'classifier'):\n",
    "                        if hasattr(model.classifier, 'in_features'):\n",
    "                            in_features = model.classifier.in_features\n",
    "                            model.classifier = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_features, num_classes))\n",
    "                    \n",
    "                    model.load_state_dict(state_dict)\n",
    "                    model.to(self.device)\n",
    "                    model.eval()\n",
    "                    self.models.append(model)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        if not self.models:\n",
    "            raise ValueError(\"Failed to load any models from ensemble!\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resized = cv2.resize(img_rgb, (448, 224))\n",
    "        img_normalized = img_resized.astype(np.float32) / 255.0\n",
    "        \n",
    "        img_tensor = torch.FloatTensor(img_normalized).permute(2, 0, 1)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img_tensor = (img_tensor - mean) / std\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(self.device)\n",
    "        \n",
    "        return img_resized, img_tensor\n",
    "    \n",
    "    def find_target_layer(self, model):\n",
    "        \"\"\"Find the best layer for GradCAM - target the last conv layer before classifier\"\"\"\n",
    "        target_layer = None\n",
    "        \n",
    "        # Look for the last convolutional layer before global pooling/classifier\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                # Skip very small conv layers (like 1x1 convs in classifier)\n",
    "                if module.kernel_size[0] > 1 or module.out_channels > 512:\n",
    "                    target_layer = module\n",
    "        \n",
    "        # Fallback: look for specific layer names in common architectures\n",
    "        if target_layer is None:\n",
    "            layer_candidates = [\n",
    "                'features', 'layer4', 'stages', 'blocks', 'conv_head', \n",
    "                'conv5', 'conv4', 'mixed_7', 'Mixed_7'\n",
    "            ]\n",
    "            \n",
    "            for candidate in layer_candidates:\n",
    "                for name, module in model.named_modules():\n",
    "                    if candidate in name and isinstance(module, (nn.Conv2d, nn.Sequential)):\n",
    "                        target_layer = module\n",
    "                        break\n",
    "                if target_layer:\n",
    "                    break\n",
    "        \n",
    "        return target_layer\n",
    "    \n",
    "    def generate_gradcam_heatmap(self, model, input_tensor, target_class=None):\n",
    "        \"\"\"Generate focused GradCAM heatmap\"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Find the right layer\n",
    "        target_layer = self.find_target_layer(model)\n",
    "        if target_layer is None:\n",
    "            return self.generate_integrated_gradients_heatmap(model, input_tensor)\n",
    "        \n",
    "        # Storage for gradients and activations\n",
    "        gradients = []\n",
    "        activations = []\n",
    "        \n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            if grad_output[0] is not None:\n",
    "                gradients.append(grad_output[0].detach())\n",
    "        \n",
    "        def forward_hook(module, input, output):\n",
    "            activations.append(output.detach())\n",
    "        \n",
    "        # Register hooks\n",
    "        hook1 = target_layer.register_backward_hook(backward_hook)\n",
    "        hook2 = target_layer.register_forward_hook(forward_hook)\n",
    "        \n",
    "        try:\n",
    "            # Forward pass\n",
    "            input_tensor.requires_grad_(True)\n",
    "            output = model(input_tensor)\n",
    "            \n",
    "            if target_class is None:\n",
    "                target_class = torch.argmax(output, dim=1)\n",
    "            \n",
    "            # Backward pass\n",
    "            model.zero_grad()\n",
    "            output[0, target_class].backward(retain_graph=True)\n",
    "            \n",
    "            if gradients and activations:\n",
    "                grads = gradients[0]  # Shape: [1, channels, h, w]\n",
    "                acts = activations[0]  # Shape: [1, channels, h, w]\n",
    "                \n",
    "                # Compute importance weights (global average pooling of gradients)\n",
    "                weights = torch.mean(grads, dim=(2, 3), keepdim=True)  # [1, channels, 1, 1]\n",
    "                \n",
    "                # Weighted combination of feature maps\n",
    "                weighted_acts = weights * acts  # [1, channels, h, w]\n",
    "                heatmap = torch.sum(weighted_acts, dim=1, keepdim=True)  # [1, 1, h, w]\n",
    "                \n",
    "                # Apply ReLU to remove negative influences\n",
    "                heatmap = F.relu(heatmap)\n",
    "                \n",
    "                # Normalize\n",
    "                heatmap_flat = heatmap.view(-1)\n",
    "                if heatmap_flat.max() > 0:\n",
    "                    heatmap = heatmap / heatmap_flat.max()\n",
    "                \n",
    "                # Resize to input image size and convert to numpy\n",
    "                heatmap = F.interpolate(heatmap, size=(224, 448), mode='bilinear', align_corners=False)\n",
    "                heatmap = heatmap.squeeze().cpu().numpy()\n",
    "                \n",
    "                # Apply sharpening to make attention more focused\n",
    "                heatmap = self.sharpen_heatmap(heatmap)\n",
    "                \n",
    "            else:\n",
    "                heatmap = np.zeros((224, 448))\n",
    "        \n",
    "        except Exception as e:\n",
    "            heatmap = np.zeros((224, 448))\n",
    "        \n",
    "        finally:\n",
    "            hook1.remove()\n",
    "            hook2.remove()\n",
    "        \n",
    "        return heatmap\n",
    "    \n",
    "    def generate_integrated_gradients_heatmap(self, model, input_tensor, steps=50):\n",
    "        \"\"\"Generate heatmap using Integrated Gradients as fallback\"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        # Get baseline (black image)\n",
    "        baseline = torch.zeros_like(input_tensor)\n",
    "        \n",
    "        # Generate path from baseline to input\n",
    "        alphas = torch.linspace(0, 1, steps).to(self.device)\n",
    "        \n",
    "        # Get prediction for target\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            target_class = torch.argmax(output, dim=1)\n",
    "        \n",
    "        gradients = []\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            # Create interpolated input\n",
    "            interpolated = baseline + alpha * (input_tensor - baseline)\n",
    "            interpolated.requires_grad_(True)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(interpolated)\n",
    "            \n",
    "            # Backward pass\n",
    "            model.zero_grad()\n",
    "            output[0, target_class].backward(retain_graph=True)\n",
    "            \n",
    "            # Store gradients\n",
    "            if interpolated.grad is not None:\n",
    "                gradients.append(interpolated.grad.detach())\n",
    "        \n",
    "        if gradients:\n",
    "            # Average gradients and multiply by input difference\n",
    "            avg_gradients = torch.mean(torch.stack(gradients), dim=0)\n",
    "            integrated_gradients = (input_tensor - baseline) * avg_gradients\n",
    "            \n",
    "            # Sum across color channels and take absolute value\n",
    "            heatmap = torch.sum(torch.abs(integrated_gradients), dim=1).squeeze()\n",
    "            \n",
    "            # Normalize\n",
    "            if heatmap.max() > 0:\n",
    "                heatmap = heatmap / heatmap.max()\n",
    "            \n",
    "            heatmap = heatmap.cpu().numpy()\n",
    "            heatmap = self.sharpen_heatmap(heatmap)\n",
    "        else:\n",
    "            heatmap = np.zeros((224, 448))\n",
    "        \n",
    "        return heatmap\n",
    "    \n",
    "    def sharpen_heatmap(self, heatmap, percentile=80, gamma=2.0):\n",
    "        \"\"\"Apply sharpening to make attention more focused\"\"\"\n",
    "        # Apply threshold at percentile to focus on highest activations\n",
    "        threshold = np.percentile(heatmap, percentile)\n",
    "        heatmap_sharp = np.copy(heatmap)\n",
    "        heatmap_sharp[heatmap_sharp < threshold] = 0\n",
    "        \n",
    "        # Apply gamma correction to enhance contrast\n",
    "        if heatmap_sharp.max() > 0:\n",
    "            heatmap_sharp = heatmap_sharp / heatmap_sharp.max()\n",
    "            heatmap_sharp = np.power(heatmap_sharp, gamma)\n",
    "        \n",
    "        return heatmap_sharp\n",
    "    \n",
    "    def run_ensemble_prediction(self, image_path):\n",
    "        \"\"\"Run prediction using ensemble and generate averaged heatmap\"\"\"\n",
    "        original_image, input_tensor = self.preprocess_image(image_path)\n",
    "        \n",
    "        if not self.models:\n",
    "            raise ValueError(\"No models loaded in ensemble!\")\n",
    "        \n",
    "        predictions = []\n",
    "        heatmaps = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            try:\n",
    "                # Get prediction\n",
    "                with torch.no_grad():\n",
    "                    output = model(input_tensor)\n",
    "                    pred_probs = F.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                    predictions.append(pred_probs)\n",
    "                \n",
    "                # Generate heatmap\n",
    "                heatmap = self.generate_gradcam_heatmap(model, input_tensor)\n",
    "                heatmaps.append(heatmap)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not predictions:\n",
    "            raise ValueError(\"No successful predictions from any model!\")\n",
    "        \n",
    "        # Average predictions and heatmaps\n",
    "        predictions_array = np.array(predictions)\n",
    "        heatmaps_array = np.array(heatmaps)\n",
    "        \n",
    "        avg_prediction = np.mean(predictions_array, axis=0)\n",
    "        avg_heatmap = np.mean(heatmaps_array, axis=0)\n",
    "        \n",
    "        # Get predicted class and confidence\n",
    "        if avg_prediction.ndim == 0:\n",
    "            predicted_class_idx = 0\n",
    "            confidence = float(avg_prediction)\n",
    "        else:\n",
    "            predicted_class_idx = np.argmax(avg_prediction)\n",
    "            confidence = avg_prediction[predicted_class_idx]\n",
    "        \n",
    "        predicted_age = self.class_names[predicted_class_idx] if self.class_names else str(predicted_class_idx)\n",
    "        \n",
    "        return original_image, avg_heatmap, predicted_age, confidence\n",
    "    \n",
    "    def apply_brightness_contrast(self, image, brightness=0, contrast=0):\n",
    "        \"\"\"Apply brightness and contrast adjustments\"\"\"\n",
    "        if brightness != 0:\n",
    "            if brightness > 0:\n",
    "                shadow = brightness\n",
    "                highlight = 255\n",
    "            else:\n",
    "                shadow = 0\n",
    "                highlight = 255 + brightness\n",
    "            alpha_b = (highlight - shadow) / 255\n",
    "            gamma_b = shadow\n",
    "            image = cv2.addWeighted(image, alpha_b, image, 0, gamma_b)\n",
    "        \n",
    "        if contrast != 0:\n",
    "            f = 131 * (contrast + 127) / (127 * (131 - contrast))\n",
    "            alpha_c = f\n",
    "            gamma_c = 127 * (1 - f)\n",
    "            image = cv2.addWeighted(image, alpha_c, image, 0, gamma_c)\n",
    "        \n",
    "        return np.clip(image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def create_simple_transparent_overlay(self, original_image, heatmap, \n",
    "                                        colormap='hot', heatmap_threshold=0.1, \n",
    "                                        heatmap_alpha=0.7):\n",
    "        \"\"\"Create a simple transparent overlay - easiest method\"\"\"\n",
    "        \n",
    "        # Apply threshold and normalize\n",
    "        heatmap_thresh = np.copy(heatmap)\n",
    "        heatmap_thresh[heatmap_thresh < heatmap_threshold] = 0\n",
    "        if heatmap_thresh.max() > 0:\n",
    "            heatmap_thresh = heatmap_thresh / heatmap_thresh.max()\n",
    "        \n",
    "        # Create figure with transparent overlay\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "        \n",
    "        # Show original image\n",
    "        ax.imshow(original_image)\n",
    "        \n",
    "        # Overlay heatmap with transparency - zeros will be fully transparent\n",
    "        masked_heatmap = np.ma.masked_where(heatmap_thresh == 0, heatmap_thresh)\n",
    "        ax.imshow(masked_heatmap, cmap=colormap, alpha=heatmap_alpha, interpolation='bilinear')\n",
    "        \n",
    "        ax.axis('off')\n",
    "        ax.set_title('Transparent Heatmap Overlay')\n",
    "        \n",
    "        # Convert plot to image array\n",
    "        fig.canvas.draw()\n",
    "        buf = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        buf = buf.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "        \n",
    "        return buf\n",
    "    \n",
    "    def create_heatmap_overlay(self, original_image, heatmap, \n",
    "                             blend_mode='multiply', \n",
    "                             heatmap_alpha=0.6, \n",
    "                             brightness=0, \n",
    "                             contrast=0,\n",
    "                             colormap='hot',\n",
    "                             heatmap_threshold=0.1):\n",
    "        \"\"\"Create heatmap overlay with transparent zero values\"\"\"\n",
    "        \n",
    "        # Apply threshold to heatmap\n",
    "        heatmap_thresh = np.copy(heatmap)\n",
    "        heatmap_thresh[heatmap_thresh < heatmap_threshold] = 0\n",
    "        \n",
    "        # Normalize heatmap\n",
    "        if heatmap_thresh.max() > 0:\n",
    "            heatmap_thresh = heatmap_thresh / heatmap_thresh.max()\n",
    "        \n",
    "        # Apply colormap to heatmap\n",
    "        cmap = plt.cm.get_cmap(colormap)\n",
    "        heatmap_colored = cmap(heatmap_thresh)\n",
    "        heatmap_colored_rgb = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "        \n",
    "        # Create alpha channel from heatmap values - zero values become transparent\n",
    "        alpha_channel = heatmap_thresh.copy()\n",
    "        alpha_channel = (alpha_channel * heatmap_alpha * 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply brightness/contrast adjustments to original image\n",
    "        adjusted_original = self.apply_brightness_contrast(original_image, brightness, contrast)\n",
    "        \n",
    "        # Create 4-channel heatmap (RGBA)\n",
    "        heatmap_rgba = np.zeros((*heatmap_colored_rgb.shape[:2], 4), dtype=np.uint8)\n",
    "        heatmap_rgba[:, :, :3] = heatmap_colored_rgb\n",
    "        heatmap_rgba[:, :, 3] = alpha_channel\n",
    "        \n",
    "        # Create overlay based on blend mode with transparency\n",
    "        if blend_mode == 'multiply':\n",
    "            # Multiply blend with transparency\n",
    "            overlay = adjusted_original.copy().astype(np.float32)\n",
    "            mask = alpha_channel > 0\n",
    "            if np.any(mask):\n",
    "                alpha_norm = alpha_channel[mask].astype(np.float32) / 255.0\n",
    "                blend_factor = heatmap_colored_rgb[mask].astype(np.float32) / 255.0\n",
    "                overlay[mask] = overlay[mask] * (1 - alpha_norm[:, np.newaxis]) + \\\n",
    "                               overlay[mask] * blend_factor * alpha_norm[:, np.newaxis]\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        elif blend_mode == 'overlay':\n",
    "            # Photoshop-style overlay blend with transparency\n",
    "            overlay = adjusted_original.copy().astype(np.float32)\n",
    "            mask = alpha_channel > 0\n",
    "            if np.any(mask):\n",
    "                alpha_norm = alpha_channel[mask].astype(np.float32) / 255.0\n",
    "                base = overlay[mask] / 255.0\n",
    "                blend = heatmap_colored_rgb[mask].astype(np.float32) / 255.0\n",
    "                \n",
    "                overlay_blend = np.zeros_like(base)\n",
    "                dark_mask = base <= 0.5\n",
    "                overlay_blend[dark_mask] = 2 * base[dark_mask] * blend[dark_mask]\n",
    "                overlay_blend[~dark_mask] = 1 - 2 * (1 - base[~dark_mask]) * (1 - blend[~dark_mask])\n",
    "                \n",
    "                overlay[mask] = (base * (1 - alpha_norm[:, np.newaxis]) + \n",
    "                               overlay_blend * alpha_norm[:, np.newaxis]) * 255\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        elif blend_mode == 'additive':\n",
    "            # Additive blend with transparency\n",
    "            overlay = adjusted_original.copy().astype(np.float32)\n",
    "            mask = alpha_channel > 0\n",
    "            if np.any(mask):\n",
    "                alpha_norm = alpha_channel[mask].astype(np.float32) / 255.0\n",
    "                blend_color = heatmap_colored_rgb[mask].astype(np.float32)\n",
    "                overlay[mask] = overlay[mask] + blend_color * alpha_norm[:, np.newaxis]\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        elif blend_mode == 'screen':\n",
    "            # Screen blend with transparency\n",
    "            overlay = adjusted_original.copy().astype(np.float32)\n",
    "            mask = alpha_channel > 0\n",
    "            if np.any(mask):\n",
    "                alpha_norm = alpha_channel[mask].astype(np.float32) / 255.0\n",
    "                base = overlay[mask] / 255.0\n",
    "                blend = heatmap_colored_rgb[mask].astype(np.float32) / 255.0\n",
    "                screen_blend = 1 - (1 - base) * (1 - blend)\n",
    "                overlay[mask] = (base * (1 - alpha_norm[:, np.newaxis]) + \n",
    "                               screen_blend * alpha_norm[:, np.newaxis]) * 255\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        elif blend_mode == 'soft_light':\n",
    "            # Soft light blend with transparency\n",
    "            overlay = adjusted_original.copy().astype(np.float32)\n",
    "            mask = alpha_channel > 0\n",
    "            if np.any(mask):\n",
    "                alpha_norm = alpha_channel[mask].astype(np.float32) / 255.0\n",
    "                base = overlay[mask] / 255.0\n",
    "                blend = heatmap_colored_rgb[mask].astype(np.float32) / 255.0\n",
    "                \n",
    "                soft_light = np.zeros_like(base)\n",
    "                soft_mask = blend <= 0.5\n",
    "                soft_light[soft_mask] = base[soft_mask] - (1 - 2 * blend[soft_mask]) * base[soft_mask] * (1 - base[soft_mask])\n",
    "                soft_light[~soft_mask] = base[~soft_mask] + (2 * blend[~soft_mask] - 1) * (np.sqrt(base[~soft_mask]) - base[~soft_mask])\n",
    "                \n",
    "                overlay[mask] = (base * (1 - alpha_norm[:, np.newaxis]) + \n",
    "                               soft_light * alpha_norm[:, np.newaxis]) * 255\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        else:  # default to alpha blend with transparency\n",
    "            overlay = adjusted_original.copy().astype(np.float32)\n",
    "            mask = alpha_channel > 0\n",
    "            if np.any(mask):\n",
    "                alpha_norm = alpha_channel[mask].astype(np.float32) / 255.0\n",
    "                blend_color = heatmap_colored_rgb[mask].astype(np.float32)\n",
    "                overlay[mask] = overlay[mask] * (1 - alpha_norm[:, np.newaxis]) + \\\n",
    "                               blend_color * alpha_norm[:, np.newaxis]\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        return overlay, heatmap_colored_rgb\n",
    "    \n",
    "    def visualize_results(self, original_image, heatmap, predicted_age, confidence,\n",
    "                         blend_mode='multiply', heatmap_alpha=0.6, \n",
    "                         brightness=0, contrast=0, colormap='hot', heatmap_threshold=0.1):\n",
    "        \"\"\"Visualize all results in a comprehensive plot\"\"\"\n",
    "        \n",
    "        # Create overlay with transparency\n",
    "        overlay, heatmap_colored = self.create_heatmap_overlay(\n",
    "            original_image, heatmap, blend_mode, heatmap_alpha, \n",
    "            brightness, contrast, colormap, heatmap_threshold\n",
    "        )\n",
    "        \n",
    "        # Create alpha mask for transparent visualization\n",
    "        heatmap_thresh = np.copy(heatmap)\n",
    "        heatmap_thresh[heatmap_thresh < heatmap_threshold] = 0\n",
    "        if heatmap_thresh.max() > 0:\n",
    "            heatmap_thresh = heatmap_thresh / heatmap_thresh.max()\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(original_image)\n",
    "        axes[0].set_title('Original Jawbone Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Final overlay\n",
    "        axes[1].imshow(overlay)\n",
    "        axes[1].set_title(f'Overlay ({blend_mode})\\nPredicted Age: {predicted_age} ({confidence:.2f})')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return overlay, heatmap_colored\n",
    "\n",
    "def run_jawbone_analysis(image_path, \n",
    "                        ensemble_path=\"./(teeth) academic_ensemble_20250721_081845 (90.7 +- 2.6%)/academic_ensemble.pth\",\n",
    "                        blend_mode='alpha',\n",
    "                        heatmap_alpha=1,\n",
    "                        brightness=0,\n",
    "                        contrast=0,\n",
    "                        colormap='jet',\n",
    "                        heatmap_threshold=0.05,\n",
    "                        show_plot=True):\n",
    "    \n",
    "    # Initialize model runner\n",
    "    runner = JawboneModelRunner(ensemble_path)\n",
    "    \n",
    "    # Run prediction and get heatmap\n",
    "    original_image, heatmap, predicted_age, confidence = runner.run_ensemble_prediction(image_path)\n",
    "    \n",
    "    # Create visualization\n",
    "    if show_plot:\n",
    "        overlay, heatmap_colored = runner.visualize_results(\n",
    "            original_image, heatmap, predicted_age, confidence,\n",
    "            blend_mode, heatmap_alpha, brightness, contrast, colormap, heatmap_threshold\n",
    "        )\n",
    "    else:\n",
    "        overlay, heatmap_colored = runner.create_heatmap_overlay(\n",
    "            original_image, heatmap, blend_mode, heatmap_alpha,\n",
    "            brightness, contrast, colormap, heatmap_threshold\n",
    "        )\n",
    "    \n",
    "    return original_image, heatmap, overlay\n",
    "\n",
    "def create_transparent_heatmap_only(image_path, ensemble_path, colormap='hot', \n",
    "                                   heatmap_threshold=0.1, heatmap_alpha=0.5):\n",
    "    \"\"\"\n",
    "    Simple function to create just a transparent heatmap overlay\n",
    "    \n",
    "    Returns:\n",
    "    - original_image: Original image array\n",
    "    - transparent_overlay: Image with transparent heatmap overlay\n",
    "    \"\"\"\n",
    "    \n",
    "    runner = JawboneModelRunner(ensemble_path)\n",
    "    original_image, heatmap, predicted_age, confidence = runner.run_ensemble_prediction(image_path)\n",
    "    \n",
    "    # Create simple transparent overlay\n",
    "    transparent_overlay = runner.create_simple_transparent_overlay(\n",
    "        original_image, heatmap, colormap, heatmap_threshold, heatmap_alpha\n",
    "    )\n",
    "    \n",
    "    return original_image, transparent_overlay\n",
    "\n",
    "# Example usage and parameter experimentation\n",
    "if __name__ == \"__main__\":\n",
    "    # Your specific image\n",
    "    image_path = \"G:/Dropbox/AI Projects/buck/tooth_analysis/images/nda_13p5_000.png\"\n",
    "    \n",
    "    # Run with default parameters\n",
    "    original, heatmap, overlay = run_jawbone_analysis(image_path, \n",
    "                                                      blend_mode='overlay',\n",
    "                                                      heatmap_alpha=1.0,\n",
    "                                                      brightness=0,\n",
    "                                                      contrast=-50,\n",
    "                                                      colormap='jet',\n",
    "                                                      heatmap_threshold=0.001)\n",
    "\n",
    "    \"\"\"\n",
    "    - blend_mode: 'multiply', 'overlay', 'additive', 'screen', 'soft_light', 'alpha'\n",
    "    - heatmap_alpha: Transparency of heatmap (0.0 to 1.0)\n",
    "    - brightness: Brightness adjustment (-100 to 100)\n",
    "    - contrast: Contrast adjustment (-100 to 100)\n",
    "    - colormap: 'hot', 'jet', 'viridis', 'plasma', 'inferno'\n",
    "    - heatmap_threshold: Minimum heatmap value to show (0.0 to 1.0)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ee4f8-d4f1-4ec9-857b-d3fa459f6ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
