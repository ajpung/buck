{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bd270a-95d8-4330-92ef-478f908a8604",
   "metadata": {},
   "source": [
    "## Ingest images\n",
    "Images of each deer are roughly square, and stored in a local folder. The images are ingested via `glob` and files that do not contain year information is removed. Once ingested, resized, and stacked, the labels are extracted from each images based on their filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a96314-0633-40b4-b727-9ceef74d57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 images found\n",
      "Sample size: (40, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from generic.analysis.basics import extract_labels\n",
    "from generic.analysis.basics import ingest_resize_stack\n",
    "\n",
    "# Find/ingest files in folder; force square & b/w\n",
    "files = glob(\"..\\\\images\\\\squared\\\\*.png\")\n",
    "files = [s for s in files if \"xpx\" not in s]\n",
    "print(len(files), \"images found\")\n",
    "\n",
    "# Ingest images\n",
    "images = ingest_resize_stack(files)\n",
    "_,_,_,ages,_ = extract_labels(files)\n",
    "print('Sample size:', images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdea1f-2cb5-4ede-bce3-b6a2b349a836",
   "metadata": {},
   "source": [
    "## Split datasets\n",
    "The image stack is then split into training and test data, with a split of 80/20 -- 80% of the data resides in the training set, while the remaining 20% defines the test data. The training and test data are then normalized, and the labels for each dataset are cast to categorical values instead of their age values.\n",
    "\n",
    "The validation data is then extracted from the training dataset, again in an 80/20 split -- 80% of the previous training data remains within the training dataset, and 20% is redefined as the validation set. Each dataset (training, validation, and test) are reshaped based on their format of grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb9da76-9dd0-4571-bda9-5161e636d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged these ages into the 'mature' (5.5+) class: [np.float64(5.5), np.float64(12.5), np.float64(6.5)]\n",
      "New label mapping: {np.float64(1.5): 0, np.float64(2.5): 1, np.float64(3.5): 2, np.float64(4.5): 3, np.float64(5.5): 4}\n",
      "\n",
      "Class distribution after first split:\n",
      "Label 0 (1.5): 3 samples\n",
      "Label 1 (2.5): 9 samples\n",
      "Label 2 (3.5): 8 samples\n",
      "Label 3 (4.5): 3 samples\n",
      "Label 4 (5.5): 9 samples\n",
      "\n",
      "Training set class distribution (after both splits):\n",
      "Label 0 (1.5): 2 samples\n",
      "Label 1 (2.5): 8 samples\n",
      "Label 2 (3.5): 5 samples\n",
      "Label 3 (4.5): 2 samples\n",
      "Label 4 (5.5): 8 samples\n",
      "\n",
      "Validation set class distribution:\n",
      "Label 0 (1.5): 1 samples\n",
      "Label 1 (2.5): 1 samples\n",
      "Label 2 (3.5): 3 samples\n",
      "Label 3 (4.5): 1 samples\n",
      "Label 4 (5.5): 1 samples\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a mapping that combines 5.5+ years into a single \"mature\" class\n",
    "ages_array = np.array(ages)\n",
    "mature_ages = []\n",
    "\n",
    "for i, age in enumerate(ages_array):\n",
    "    if age >= 5.5:\n",
    "        ages_array[i] = 5.5  # Set all ages 5.5+ to 5.5\n",
    "        if age not in mature_ages:\n",
    "            mature_ages.append(age)\n",
    "\n",
    "print(f\"Merged these ages into the 'mature' (5.5+) class: {mature_ages}\")\n",
    "\n",
    "# Now create your label mapping with the modified ages\n",
    "label_mapping = {label: i for i, label in enumerate(np.unique(ages_array))}\n",
    "print(\"New label mapping:\", label_mapping)\n",
    "\n",
    "# Apply the mapping to convert labels to integers\n",
    "integer_labels = np.array([label_mapping[l] for l in ages_array])\n",
    "\n",
    "# First, do a regular split for the test set (remove stratification)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images, integer_labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    "    # Removed stratify parameter\n",
    ")\n",
    "\n",
    "# Check the class distribution in training+validation set\n",
    "print(\"\\nClass distribution after first split:\")\n",
    "for label in np.unique(y_train_val):\n",
    "    count = np.sum(y_train_val == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")\n",
    "\n",
    "# One-hot encode labels AFTER splitting but BEFORE the next split\n",
    "num_classes = len(label_mapping)\n",
    "y_train_val_onehot = keras.utils.to_categorical(y_train_val, num_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Normalize and reshape images\n",
    "X_train_val = X_train_val.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train_val = X_train_val.reshape(X_train_val.shape[0], 288, 288, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 288, 288, 1)\n",
    "\n",
    "# Second split without stratification for validation\n",
    "X_train_orig, X_valid, y_train_orig, y_valid = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val_onehot, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    "    # Removed stratify parameter\n",
    ")\n",
    "\n",
    "# Print the class distribution to check\n",
    "print(\"\\nTraining set class distribution (after both splits):\")\n",
    "train_class_dist = np.argmax(y_train_orig, axis=1)\n",
    "for label in np.unique(train_class_dist):\n",
    "    count = np.sum(train_class_dist == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")\n",
    "\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "valid_class_dist = np.argmax(y_valid, axis=1)\n",
    "for label in np.unique(valid_class_dist):\n",
    "    count = np.sum(valid_class_dist == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb804f4-1bc3-41cc-9932-f760cfa10658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After your initial train/test split, you should have X_train_val, X_test, y_train_val, y_test\n",
    "# X_train_val and y_train_val are what you want to use instead of X_train and y_train\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "# One-hot encode labels BEFORE splitting into train/validation\n",
    "y_train_val_onehot = keras.utils.to_categorical(y_train_val, num_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Reshape data to add channel dimension\n",
    "X_train_val = X_train_val.reshape(X_train_val.shape[0], 288, 288, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 288, 288, 1)\n",
    "\n",
    "# Create a validation set (without stratification)\n",
    "X_train_orig, X_valid, y_train_orig, y_valid = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val_onehot, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc04a4f1-e9c0-41db-8d82-b115a53f4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before augmentation:\n",
      "25 train samples\n",
      "8 test samples\n",
      "7 validation samples\n",
      "\n",
      "After augmentation:\n",
      "Original training samples: 25\n",
      "Augmented training samples: 250\n",
      "Combined training samples: 275\n",
      "Augmentation multiplier: 11.0\n",
      "X_train_combined shape: (275, 288, 288, 1)\n",
      "y_train_combined shape: (275, 5)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Print original sizes\n",
    "print(\"\\nBefore augmentation:\")\n",
    "print(X_train_orig.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "print(X_valid.shape[0], \"validation samples\")\n",
    "\n",
    "# Setup more diverse but moderate data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,              # Slightly more rotation\n",
    "    width_shift_range=0.2,          # More shifting\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,                 # More zooming\n",
    "    horizontal_flip=True,           # Horizontal flip is good\n",
    "    brightness_range=[0.7, 1.3],    # More brightness variation\n",
    "    shear_range=15,                 # More shearing\n",
    "    fill_mode='nearest',\n",
    "    # Add these new augmentations:\n",
    "    channel_shift_range=0.1,        # Slight color changes\n",
    "    vertical_flip=False,            # Deer won't be upside down in real images\n",
    ")\n",
    "\n",
    "# Method 2: Generate augmented data in advance\n",
    "# Define how many augmented samples per original sample - reduced from 50 to 10\n",
    "augmentation_factor = 10  # More reasonable multiplication factor\n",
    "num_to_generate = X_train_orig.shape[0] * augmentation_factor\n",
    "\n",
    "# Initialize empty arrays for augmented data\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# Create augmented images batch by batch\n",
    "batch_size = 32\n",
    "generated_count = 0\n",
    "\n",
    "# Create a flow from the original data (without shuffling)\n",
    "aug_gen = datagen.flow(\n",
    "    X_train_orig, \n",
    "    y_train_orig,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # Important: keep the same order as labels\n",
    ")\n",
    "\n",
    "while generated_count < num_to_generate:\n",
    "    # Get the next batch\n",
    "    x_batch, y_batch = next(aug_gen)\n",
    "    \n",
    "    # Add to our collections\n",
    "    augmented_images.append(x_batch)\n",
    "    augmented_labels.append(y_batch)\n",
    "    \n",
    "    # Update the count\n",
    "    generated_count += len(x_batch)\n",
    "    \n",
    "    # Break if we've generated enough\n",
    "    if generated_count >= num_to_generate:\n",
    "        break\n",
    "\n",
    "# Concatenate all batches\n",
    "augmented_images = np.concatenate(augmented_images)\n",
    "augmented_labels = np.concatenate(augmented_labels)\n",
    "\n",
    "# Trim excess (due to batch size)\n",
    "augmented_images = augmented_images[:num_to_generate]\n",
    "augmented_labels = augmented_labels[:num_to_generate]\n",
    "\n",
    "# Combine with original data\n",
    "X_train_combined = np.concatenate([X_train_orig, augmented_images])\n",
    "y_train_combined = np.concatenate([y_train_orig, augmented_labels])\n",
    "\n",
    "# Print new sizes after augmentation\n",
    "print(\"\\nAfter augmentation:\")\n",
    "print(\"Original training samples:\", X_train_orig.shape[0])\n",
    "print(\"Augmented training samples:\", augmented_images.shape[0])\n",
    "print(\"Combined training samples:\", X_train_combined.shape[0])\n",
    "print(\"Augmentation multiplier:\", X_train_combined.shape[0] / X_train_orig.shape[0])\n",
    "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
    "print(\"y_train_combined shape:\", y_train_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd20bb-a4f0-4593-98f0-c191d3f28d1e",
   "metadata": {},
   "source": [
    "## Build network\n",
    "With the data formatted and separated, we can now build the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250b9a6d-8c7c-4d47-b8e1-625e828ae551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,709</span> (252.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,709\u001b[0m (252.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,709</span> (252.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,709\u001b[0m (252.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Redefine the model with L2 regularization\n",
    "model = Sequential()\n",
    "# Start with fewer filters\n",
    "model.add(Conv2D(8, kernel_size=3, padding='same', activation='relu', input_shape=(288, 288, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "# Global pooling instead of more conv layers\n",
    "model.add(GlobalAveragePooling2D())\n",
    "# Single dense layer with higher dropout\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.6))  # Higher dropout to prevent overfitting\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "from keras.optimizers import RMSprop\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=RMSprop(learning_rate=0.0001), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab9a6daa-ee89-4170-83f4-d4379ef0978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(2.5), 1: np.float64(0.625), 2: np.float64(1.0), 3: np.float64(2.5), 4: np.float64(0.625)}\n",
      "\n",
      "Training with class weights:\n",
      "Epoch 1/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2577 - loss: 1.7458\n",
      "Epoch 1: val_loss improved from inf to 1.79642, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.2627 - loss: 1.7514 - val_accuracy: 0.1429 - val_loss: 1.7964\n",
      "Epoch 2/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2109 - loss: 1.7016\n",
      "Epoch 2: val_loss improved from 1.79642 to 1.79257, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.2128 - loss: 1.7114 - val_accuracy: 0.1429 - val_loss: 1.7926\n",
      "Epoch 3/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2347 - loss: 1.8400\n",
      "Epoch 3: val_loss improved from 1.79257 to 1.78912, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.2349 - loss: 1.8349 - val_accuracy: 0.1429 - val_loss: 1.7891\n",
      "Epoch 4/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.3059 - loss: 1.8710\n",
      "Epoch 4: val_loss improved from 1.78912 to 1.78548, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.3024 - loss: 1.8622 - val_accuracy: 0.1429 - val_loss: 1.7855\n",
      "Epoch 5/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.3012 - loss: 1.7587\n",
      "Epoch 5: val_loss improved from 1.78548 to 1.78180, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.2970 - loss: 1.7614 - val_accuracy: 0.4286 - val_loss: 1.7818\n",
      "Epoch 6/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2450 - loss: 1.7300\n",
      "Epoch 6: val_loss improved from 1.78180 to 1.77822, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.2460 - loss: 1.7353 - val_accuracy: 0.4286 - val_loss: 1.7782\n",
      "Epoch 7/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2247 - loss: 1.7091\n",
      "Epoch 7: val_loss improved from 1.77822 to 1.77489, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.2286 - loss: 1.7163 - val_accuracy: 0.4286 - val_loss: 1.7749\n",
      "Epoch 8/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2043 - loss: 1.7649\n",
      "Epoch 8: val_loss improved from 1.77489 to 1.77136, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2065 - loss: 1.7659 - val_accuracy: 0.4286 - val_loss: 1.7714\n",
      "Epoch 9/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2039 - loss: 1.8229\n",
      "Epoch 9: val_loss improved from 1.77136 to 1.76841, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.2054 - loss: 1.8175 - val_accuracy: 0.4286 - val_loss: 1.7684\n",
      "Epoch 10/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2199 - loss: 1.7256\n",
      "Epoch 10: val_loss improved from 1.76841 to 1.76529, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.2236 - loss: 1.7301 - val_accuracy: 0.4286 - val_loss: 1.7653\n",
      "Epoch 11/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2077 - loss: 1.8062\n",
      "Epoch 11: val_loss improved from 1.76529 to 1.76248, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.2076 - loss: 1.8019 - val_accuracy: 0.4286 - val_loss: 1.7625\n",
      "Epoch 12/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2398 - loss: 1.8041\n",
      "Epoch 12: val_loss improved from 1.76248 to 1.75956, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.2375 - loss: 1.7997 - val_accuracy: 0.1429 - val_loss: 1.7596\n",
      "Epoch 13/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2187 - loss: 1.7016\n",
      "Epoch 13: val_loss improved from 1.75956 to 1.75651, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2179 - loss: 1.7076 - val_accuracy: 0.4286 - val_loss: 1.7565\n",
      "Epoch 14/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2152 - loss: 1.7672\n",
      "Epoch 14: val_loss improved from 1.75651 to 1.75338, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.2163 - loss: 1.7660 - val_accuracy: 0.4286 - val_loss: 1.7534\n",
      "Epoch 15/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.1990 - loss: 1.7834\n",
      "Epoch 15: val_loss improved from 1.75338 to 1.75053, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.2003 - loss: 1.7802 - val_accuracy: 0.4286 - val_loss: 1.7505\n",
      "Epoch 16/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2837 - loss: 1.7919\n",
      "Epoch 16: val_loss improved from 1.75053 to 1.74810, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.2830 - loss: 1.7875 - val_accuracy: 0.1429 - val_loss: 1.7481\n",
      "Epoch 17/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.3479 - loss: 1.6867\n",
      "Epoch 17: val_loss improved from 1.74810 to 1.74526, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.3427 - loss: 1.6931 - val_accuracy: 0.1429 - val_loss: 1.7453\n",
      "Epoch 18/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2306 - loss: 1.6929\n",
      "Epoch 18: val_loss improved from 1.74526 to 1.74242, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.2331 - loss: 1.6984 - val_accuracy: 0.1429 - val_loss: 1.7424\n",
      "Epoch 19/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2963 - loss: 1.7946\n",
      "Epoch 19: val_loss improved from 1.74242 to 1.74015, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.2973 - loss: 1.7891 - val_accuracy: 0.1429 - val_loss: 1.7401\n",
      "Epoch 20/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.3417 - loss: 1.7536\n",
      "Epoch 20: val_loss improved from 1.74015 to 1.73776, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.3340 - loss: 1.7522 - val_accuracy: 0.1429 - val_loss: 1.7378\n",
      "Epoch 21/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2919 - loss: 1.8319\n",
      "Epoch 21: val_loss improved from 1.73776 to 1.73528, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.2895 - loss: 1.8219 - val_accuracy: 0.1429 - val_loss: 1.7353\n",
      "Epoch 22/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2814 - loss: 1.6789\n",
      "Epoch 22: val_loss improved from 1.73528 to 1.73281, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2836 - loss: 1.6847 - val_accuracy: 0.1429 - val_loss: 1.7328\n",
      "Epoch 23/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.2612 - loss: 1.7037\n",
      "Epoch 23: val_loss improved from 1.73281 to 1.73059, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.2636 - loss: 1.7066 - val_accuracy: 0.1429 - val_loss: 1.7306\n",
      "Epoch 24/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.3299 - loss: 1.7262\n",
      "Epoch 24: val_loss improved from 1.73059 to 1.72817, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.3319 - loss: 1.7265 - val_accuracy: 0.1429 - val_loss: 1.7282\n",
      "Epoch 25/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2913 - loss: 1.6546\n",
      "Epoch 25: val_loss improved from 1.72817 to 1.72579, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.2905 - loss: 1.6623 - val_accuracy: 0.1429 - val_loss: 1.7258\n",
      "Epoch 26/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.3145 - loss: 1.7669\n",
      "Epoch 26: val_loss improved from 1.72579 to 1.72358, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.3139 - loss: 1.7625 - val_accuracy: 0.1429 - val_loss: 1.7236\n",
      "Epoch 27/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.3439 - loss: 1.7429\n",
      "Epoch 27: val_loss improved from 1.72358 to 1.72121, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.3452 - loss: 1.7408 - val_accuracy: 0.1429 - val_loss: 1.7212\n",
      "Epoch 28/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2872 - loss: 1.8300\n",
      "Epoch 28: val_loss improved from 1.72121 to 1.71898, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2868 - loss: 1.8185 - val_accuracy: 0.1429 - val_loss: 1.7190\n",
      "Epoch 29/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2840 - loss: 1.7088\n",
      "Epoch 29: val_loss improved from 1.71898 to 1.71679, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.2847 - loss: 1.7098 - val_accuracy: 0.1429 - val_loss: 1.7168\n",
      "Epoch 30/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.3421 - loss: 1.8127\n",
      "Epoch 30: val_loss improved from 1.71679 to 1.71469, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.3401 - loss: 1.8025 - val_accuracy: 0.1429 - val_loss: 1.7147\n",
      "Epoch 31/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2997 - loss: 1.6097\n",
      "Epoch 31: val_loss improved from 1.71469 to 1.71223, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.2992 - loss: 1.6207 - val_accuracy: 0.1429 - val_loss: 1.7122\n",
      "Epoch 32/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.2685 - loss: 1.7302\n",
      "Epoch 32: val_loss improved from 1.71223 to 1.71030, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.2686 - loss: 1.7283 - val_accuracy: 0.1429 - val_loss: 1.7103\n",
      "Epoch 33/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.3390 - loss: 1.7663\n",
      "Epoch 33: val_loss improved from 1.71030 to 1.70822, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.3423 - loss: 1.7603 - val_accuracy: 0.1429 - val_loss: 1.7082\n",
      "Epoch 34/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.3024 - loss: 1.7227\n",
      "Epoch 34: val_loss improved from 1.70822 to 1.70626, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.2997 - loss: 1.7211 - val_accuracy: 0.1429 - val_loss: 1.7063\n",
      "Epoch 35/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.2675 - loss: 1.8354\n",
      "Epoch 35: val_loss improved from 1.70626 to 1.70454, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.2696 - loss: 1.8218 - val_accuracy: 0.1429 - val_loss: 1.7045\n",
      "Epoch 36/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2885 - loss: 1.6987\n",
      "Epoch 36: val_loss improved from 1.70454 to 1.70241, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.2838 - loss: 1.6992 - val_accuracy: 0.1429 - val_loss: 1.7024\n",
      "Epoch 37/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2842 - loss: 1.7757\n",
      "Epoch 37: val_loss improved from 1.70241 to 1.70036, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.2834 - loss: 1.7680 - val_accuracy: 0.1429 - val_loss: 1.7004\n",
      "Epoch 38/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2842 - loss: 1.8363\n",
      "Epoch 38: val_loss improved from 1.70036 to 1.69856, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2846 - loss: 1.8220 - val_accuracy: 0.1429 - val_loss: 1.6986\n",
      "Epoch 39/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2667 - loss: 1.6685\n",
      "Epoch 39: val_loss improved from 1.69856 to 1.69671, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.2704 - loss: 1.6716 - val_accuracy: 0.1429 - val_loss: 1.6967\n",
      "Epoch 40/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2810 - loss: 1.7339\n",
      "Epoch 40: val_loss improved from 1.69671 to 1.69491, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.2824 - loss: 1.7300 - val_accuracy: 0.1429 - val_loss: 1.6949\n",
      "Epoch 41/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2457 - loss: 1.6561\n",
      "Epoch 41: val_loss improved from 1.69491 to 1.69301, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2478 - loss: 1.6602 - val_accuracy: 0.1429 - val_loss: 1.6930\n",
      "Epoch 42/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2315 - loss: 1.7034\n",
      "Epoch 42: val_loss improved from 1.69301 to 1.69114, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2362 - loss: 1.7023 - val_accuracy: 0.1429 - val_loss: 1.6911\n",
      "Epoch 43/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2518 - loss: 1.7174\n",
      "Epoch 43: val_loss improved from 1.69114 to 1.68975, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.2551 - loss: 1.7147 - val_accuracy: 0.1429 - val_loss: 1.6898\n",
      "Epoch 44/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2275 - loss: 1.7266\n",
      "Epoch 44: val_loss improved from 1.68975 to 1.68807, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.2307 - loss: 1.7227 - val_accuracy: 0.1429 - val_loss: 1.6881\n",
      "Epoch 45/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.3032 - loss: 1.7499\n",
      "Epoch 45: val_loss improved from 1.68807 to 1.68641, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.3027 - loss: 1.7433 - val_accuracy: 0.1429 - val_loss: 1.6864\n",
      "Epoch 46/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.3057 - loss: 1.6944\n",
      "Epoch 46: val_loss improved from 1.68641 to 1.68482, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.3061 - loss: 1.6937 - val_accuracy: 0.1429 - val_loss: 1.6848\n",
      "Epoch 47/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2822 - loss: 1.8940\n",
      "Epoch 47: val_loss improved from 1.68482 to 1.68327, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2824 - loss: 1.8720 - val_accuracy: 0.1429 - val_loss: 1.6833\n",
      "Epoch 48/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2723 - loss: 1.6700\n",
      "Epoch 48: val_loss improved from 1.68327 to 1.68178, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.2742 - loss: 1.6714 - val_accuracy: 0.1429 - val_loss: 1.6818\n",
      "Epoch 49/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.3602 - loss: 1.6719\n",
      "Epoch 49: val_loss improved from 1.68178 to 1.68024, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.3533 - loss: 1.6729 - val_accuracy: 0.1429 - val_loss: 1.6802\n",
      "Epoch 50/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.2381 - loss: 1.6822\n",
      "Epoch 50: val_loss improved from 1.68024 to 1.67885, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.2414 - loss: 1.6820 - val_accuracy: 0.1429 - val_loss: 1.6788\n",
      "Epoch 51/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.1979 - loss: 1.6530\n",
      "Epoch 51: val_loss improved from 1.67885 to 1.67755, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.1993 - loss: 1.6558 - val_accuracy: 0.1429 - val_loss: 1.6776\n",
      "Epoch 52/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.3019 - loss: 1.6222\n",
      "Epoch 52: val_loss improved from 1.67755 to 1.67623, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.3000 - loss: 1.6281 - val_accuracy: 0.1429 - val_loss: 1.6762\n",
      "Epoch 53/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2908 - loss: 1.5587\n",
      "Epoch 53: val_loss improved from 1.67623 to 1.67504, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2893 - loss: 1.5711 - val_accuracy: 0.1429 - val_loss: 1.6750\n",
      "Epoch 54/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2921 - loss: 1.7046\n",
      "Epoch 54: val_loss improved from 1.67504 to 1.67335, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.2950 - loss: 1.7014 - val_accuracy: 0.1429 - val_loss: 1.6734\n",
      "Epoch 55/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.3316 - loss: 1.6239\n",
      "Epoch 55: val_loss improved from 1.67335 to 1.67182, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.3323 - loss: 1.6290 - val_accuracy: 0.1429 - val_loss: 1.6718\n",
      "Epoch 56/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2574 - loss: 1.6887\n",
      "Epoch 56: val_loss improved from 1.67182 to 1.67059, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.2598 - loss: 1.6869 - val_accuracy: 0.1429 - val_loss: 1.6706\n",
      "Epoch 57/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.3409 - loss: 1.7087\n",
      "Epoch 57: val_loss improved from 1.67059 to 1.66921, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.3395 - loss: 1.7046 - val_accuracy: 0.1429 - val_loss: 1.6692\n",
      "Epoch 58/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.3142 - loss: 1.6123\n",
      "Epoch 58: val_loss improved from 1.66921 to 1.66782, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.3114 - loss: 1.6183 - val_accuracy: 0.1429 - val_loss: 1.6678\n",
      "Epoch 59/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.3155 - loss: 1.5899\n",
      "Epoch 59: val_loss improved from 1.66782 to 1.66644, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.3129 - loss: 1.5981 - val_accuracy: 0.1429 - val_loss: 1.6664\n",
      "Epoch 60/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2567 - loss: 1.6591\n",
      "Epoch 60: val_loss improved from 1.66644 to 1.66540, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2565 - loss: 1.6600 - val_accuracy: 0.1429 - val_loss: 1.6654\n",
      "Epoch 61/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2986 - loss: 1.6258\n",
      "Epoch 61: val_loss improved from 1.66540 to 1.66447, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.2970 - loss: 1.6300 - val_accuracy: 0.1429 - val_loss: 1.6645\n",
      "Epoch 62/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2509 - loss: 1.6790\n",
      "Epoch 62: val_loss improved from 1.66447 to 1.66339, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.2532 - loss: 1.6775 - val_accuracy: 0.1429 - val_loss: 1.6634\n",
      "Epoch 63/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.3580 - loss: 1.7059\n",
      "Epoch 63: val_loss improved from 1.66339 to 1.66224, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.3540 - loss: 1.7015 - val_accuracy: 0.1429 - val_loss: 1.6622\n",
      "Epoch 64/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2347 - loss: 1.7708\n",
      "Epoch 64: val_loss improved from 1.66224 to 1.66112, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2387 - loss: 1.7594 - val_accuracy: 0.1429 - val_loss: 1.6611\n",
      "Epoch 65/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.3389 - loss: 1.6484\n",
      "Epoch 65: val_loss improved from 1.66112 to 1.66011, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.3384 - loss: 1.6497 - val_accuracy: 0.1429 - val_loss: 1.6601\n",
      "Epoch 66/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2562 - loss: 1.5958\n",
      "Epoch 66: val_loss improved from 1.66011 to 1.65913, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.2591 - loss: 1.6026 - val_accuracy: 0.1429 - val_loss: 1.6591\n",
      "Epoch 67/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.3669 - loss: 1.7136\n",
      "Epoch 67: val_loss improved from 1.65913 to 1.65804, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.3642 - loss: 1.7078 - val_accuracy: 0.1429 - val_loss: 1.6580\n",
      "Epoch 68/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2674 - loss: 1.5710\n",
      "Epoch 68: val_loss improved from 1.65804 to 1.65700, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.2695 - loss: 1.5802 - val_accuracy: 0.1429 - val_loss: 1.6570\n",
      "Epoch 69/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.3717 - loss: 1.5206\n",
      "Epoch 69: val_loss improved from 1.65700 to 1.65586, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.3666 - loss: 1.5349 - val_accuracy: 0.1429 - val_loss: 1.6559\n",
      "Epoch 70/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.3022 - loss: 1.7105\n",
      "Epoch 70: val_loss improved from 1.65586 to 1.65496, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.3018 - loss: 1.7047 - val_accuracy: 0.1429 - val_loss: 1.6550\n",
      "Epoch 71/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.3515 - loss: 1.5785\n",
      "Epoch 71: val_loss improved from 1.65496 to 1.65414, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.3474 - loss: 1.5865 - val_accuracy: 0.1429 - val_loss: 1.6541\n",
      "Epoch 72/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.3171 - loss: 1.6713\n",
      "Epoch 72: val_loss improved from 1.65414 to 1.65334, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.3178 - loss: 1.6695 - val_accuracy: 0.1429 - val_loss: 1.6533\n",
      "Epoch 73/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.2928 - loss: 1.6433\n",
      "Epoch 73: val_loss improved from 1.65334 to 1.65248, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.2918 - loss: 1.6443 - val_accuracy: 0.1429 - val_loss: 1.6525\n",
      "Epoch 74/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.3224 - loss: 1.6267\n",
      "Epoch 74: val_loss improved from 1.65248 to 1.65164, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.3218 - loss: 1.6295 - val_accuracy: 0.1429 - val_loss: 1.6516\n",
      "Epoch 75/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.3316 - loss: 1.6498\n",
      "Epoch 75: val_loss improved from 1.65164 to 1.65091, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.3316 - loss: 1.6500 - val_accuracy: 0.1429 - val_loss: 1.6509\n",
      "Epoch 76/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.3430 - loss: 1.6846\n",
      "Epoch 76: val_loss improved from 1.65091 to 1.65013, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.3414 - loss: 1.6810 - val_accuracy: 0.1429 - val_loss: 1.6501\n",
      "Epoch 77/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2772 - loss: 1.7084\n",
      "Epoch 77: val_loss improved from 1.65013 to 1.64943, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.2790 - loss: 1.7023 - val_accuracy: 0.1429 - val_loss: 1.6494\n",
      "Epoch 78/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2977 - loss: 1.6480\n",
      "Epoch 78: val_loss improved from 1.64943 to 1.64847, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.2989 - loss: 1.6481 - val_accuracy: 0.1429 - val_loss: 1.6485\n",
      "Epoch 79/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.3605 - loss: 1.7270\n",
      "Epoch 79: val_loss improved from 1.64847 to 1.64732, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.3570 - loss: 1.7187 - val_accuracy: 0.1429 - val_loss: 1.6473\n",
      "Epoch 80/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.3213 - loss: 1.6141\n",
      "Epoch 80: val_loss improved from 1.64732 to 1.64633, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.3200 - loss: 1.6176 - val_accuracy: 0.1429 - val_loss: 1.6463\n",
      "Epoch 81/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.3229 - loss: 1.7323\n",
      "Epoch 81: val_loss improved from 1.64633 to 1.64535, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.3191 - loss: 1.7233 - val_accuracy: 0.1429 - val_loss: 1.6453\n",
      "Epoch 82/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.2735 - loss: 1.6542\n",
      "Epoch 82: val_loss improved from 1.64535 to 1.64456, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.2769 - loss: 1.6533 - val_accuracy: 0.1429 - val_loss: 1.6446\n",
      "Epoch 83/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.3269 - loss: 1.6711\n",
      "Epoch 83: val_loss improved from 1.64456 to 1.64367, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.3312 - loss: 1.6683 - val_accuracy: 0.1429 - val_loss: 1.6437\n",
      "Epoch 84/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.3380 - loss: 1.6223\n",
      "Epoch 84: val_loss improved from 1.64367 to 1.64301, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.3346 - loss: 1.6246 - val_accuracy: 0.1429 - val_loss: 1.6430\n",
      "Epoch 85/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.3537 - loss: 1.6464\n",
      "Epoch 85: val_loss improved from 1.64301 to 1.64238, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.3532 - loss: 1.6461 - val_accuracy: 0.1429 - val_loss: 1.6424\n",
      "Epoch 86/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2729 - loss: 1.7555\n",
      "Epoch 86: val_loss improved from 1.64238 to 1.64170, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.2756 - loss: 1.7436 - val_accuracy: 0.1429 - val_loss: 1.6417\n",
      "Epoch 87/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.3154 - loss: 1.6050\n",
      "Epoch 87: val_loss improved from 1.64170 to 1.64075, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.3151 - loss: 1.6088 - val_accuracy: 0.1429 - val_loss: 1.6407\n",
      "Epoch 88/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2327 - loss: 1.6213\n",
      "Epoch 88: val_loss improved from 1.64075 to 1.64017, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.2373 - loss: 1.6234 - val_accuracy: 0.1429 - val_loss: 1.6402\n",
      "Epoch 89/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.3396 - loss: 1.5310\n",
      "Epoch 89: val_loss improved from 1.64017 to 1.63939, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.3337 - loss: 1.5426 - val_accuracy: 0.1429 - val_loss: 1.6394\n",
      "Epoch 90/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.3051 - loss: 1.6338\n",
      "Epoch 90: val_loss improved from 1.63939 to 1.63875, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.3052 - loss: 1.6344 - val_accuracy: 0.1429 - val_loss: 1.6388\n",
      "Epoch 91/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.3360 - loss: 1.5820\n",
      "Epoch 91: val_loss improved from 1.63875 to 1.63816, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.3347 - loss: 1.5880 - val_accuracy: 0.1429 - val_loss: 1.6382\n",
      "Epoch 92/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2724 - loss: 1.6540\n",
      "Epoch 92: val_loss improved from 1.63816 to 1.63753, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.2751 - loss: 1.6524 - val_accuracy: 0.1429 - val_loss: 1.6375\n",
      "Epoch 93/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.3302 - loss: 1.6152\n",
      "Epoch 93: val_loss improved from 1.63753 to 1.63699, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.3279 - loss: 1.6176 - val_accuracy: 0.1429 - val_loss: 1.6370\n",
      "Epoch 94/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2555 - loss: 1.6660\n",
      "Epoch 94: val_loss improved from 1.63699 to 1.63662, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2562 - loss: 1.6630 - val_accuracy: 0.1429 - val_loss: 1.6366\n",
      "Epoch 95/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2968 - loss: 1.6672\n",
      "Epoch 95: val_loss improved from 1.63662 to 1.63603, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2977 - loss: 1.6640 - val_accuracy: 0.1429 - val_loss: 1.6360\n",
      "Epoch 96/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.2991 - loss: 1.6421\n",
      "Epoch 96: val_loss improved from 1.63603 to 1.63541, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.2990 - loss: 1.6415 - val_accuracy: 0.1429 - val_loss: 1.6354\n",
      "Epoch 97/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2864 - loss: 1.6484\n",
      "Epoch 97: val_loss improved from 1.63541 to 1.63476, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.2850 - loss: 1.6470 - val_accuracy: 0.1429 - val_loss: 1.6348\n",
      "Epoch 98/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2926 - loss: 1.6861\n",
      "Epoch 98: val_loss improved from 1.63476 to 1.63410, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.2955 - loss: 1.6807 - val_accuracy: 0.1429 - val_loss: 1.6341\n",
      "Epoch 99/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2691 - loss: 1.6232\n",
      "Epoch 99: val_loss improved from 1.63410 to 1.63358, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.2714 - loss: 1.6244 - val_accuracy: 0.1429 - val_loss: 1.6336\n",
      "Epoch 100/100\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2704 - loss: 1.7489\n",
      "Epoch 100: val_loss improved from 1.63358 to 1.63314, saving model to model_augmented.weights.best.hdf5.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.2722 - loss: 1.7368 - val_accuracy: 0.1429 - val_loss: 1.6331\n",
      "Restoring model weights from the end of the best epoch: 100.\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights properly based on the class distribution\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Extract the class labels from one-hot encoded y_train_orig\n",
    "y_integers = np.argmax(y_train_orig, axis=1)\n",
    "\n",
    "# Compute balanced class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_integers),\n",
    "    y=y_integers\n",
    ")\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# Now train the model with properly calculated class weights\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='model_augmented.weights.best.hdf5.keras',\n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,  # Give it more time to learn with class weights\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining with class weights:\")\n",
    "hist_augmented = model.fit(\n",
    "    X_train_combined, \n",
    "    y_train_combined,\n",
    "    batch_size=16,\n",
    "    epochs=100,  # Increase epochs to give more training time\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpointer, early_stopping],\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight_dict  # Use the properly calculated weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ac9b50-bb7a-4aee-a69f-16a16fd54457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Class Evaluation:\n",
      " Class Index  Original Label  In Test Set  In Predictions  Precision  Recall  F1 Score\n",
      "           0             1.5         True           False        NaN     NaN       NaN\n",
      "           1             2.5         True            True      0.375     1.0  0.545455\n",
      "           2             3.5         True           False        NaN     NaN       NaN\n",
      "           3             4.5         True           False        NaN     NaN       NaN\n",
      "           4             5.5         True           False        NaN     NaN       NaN\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Evaluate with the best weights\n",
    "model.load_weights('model_augmented.weights.best.hdf5.keras')\n",
    "\n",
    "# Create a reverse mapping to get original labels\n",
    "reverse_mapping = {i: label for label, i in label_mapping.items()}\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# Create a comprehensive evaluation table that includes all classes\n",
    "all_classes = list(range(num_classes))\n",
    "all_class_names = [reverse_mapping[i] for i in all_classes]\n",
    "\n",
    "# Create a comprehensive DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Class Index': all_classes,\n",
    "    'Original Label': all_class_names,\n",
    "    'In Test Set': [i in y_true for i in all_classes],\n",
    "    'In Predictions': [i in y_pred for i in all_classes]\n",
    "})\n",
    "\n",
    "# Add metrics where applicable\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "f1_values = []\n",
    "for cls in all_classes:\n",
    "    if cls in y_true and cls in y_pred:\n",
    "        # We can calculate metrics for this class\n",
    "        true_binary = (y_true == cls).astype(int)\n",
    "        pred_binary = (y_pred == cls).astype(int)\n",
    "        precision_values.append(precision_score(true_binary, pred_binary, zero_division=0))\n",
    "        recall_values.append(recall_score(true_binary, pred_binary, zero_division=0))\n",
    "        f1_values.append(f1_score(true_binary, pred_binary, zero_division=0))\n",
    "    else:\n",
    "        # Class not present in test set or predictions\n",
    "        precision_values.append(float('nan'))\n",
    "        recall_values.append(float('nan'))\n",
    "        f1_values.append(float('nan'))\n",
    "\n",
    "results_df['Precision'] = precision_values\n",
    "results_df['Recall'] = recall_values\n",
    "results_df['F1 Score'] = f1_values\n",
    "\n",
    "print(\"Comprehensive Class Evaluation:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Create a confusion matrix (will only show classes present in test set)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "present_classes = sorted(set(np.concatenate([y_true, y_pred])))\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=[f\"{reverse_mapping[i]}\" for i in present_classes],\n",
    "           yticklabels=[f\"{reverse_mapping[i]}\" for i in present_classes])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Only Classes Present in Test Set)')\n",
    "plt.show()\n",
    "\n",
    "# Show overall accuracy\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"\\nOverall Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d1a4d-6096-4720-a0c6-7ccfaf03d613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
