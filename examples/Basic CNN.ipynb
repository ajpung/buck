{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bd270a-95d8-4330-92ef-478f908a8604",
   "metadata": {},
   "source": [
    "## Ingest images\n",
    "Images of each deer are roughly square, and stored in a local folder. The images are ingested via `glob` and files that do not contain year information is removed. Once ingested, resized, and stacked, the labels are extracted from each images based on their filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a96314-0633-40b4-b727-9ceef74d57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 images found\n",
      "Sample size: (77, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from generic.analysis.basics import extract_labels\n",
    "from generic.analysis.basics import ingest_resize_stack\n",
    "\n",
    "# Find/ingest files in folder; force square & b/w\n",
    "files = glob(\"..\\\\images\\\\squared\\\\*.png\")\n",
    "files = [s for s in files if \"xpx\" not in s]\n",
    "print(len(files), \"images found\")\n",
    "\n",
    "# Ingest images\n",
    "images = ingest_resize_stack(files)\n",
    "_,_,_,ages,_ = extract_labels(files)\n",
    "print('Sample size:', images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdea1f-2cb5-4ede-bce3-b6a2b349a836",
   "metadata": {},
   "source": [
    "## Split datasets\n",
    "The image stack is then split into training and test data, with a split of 80/20 -- 80% of the data resides in the training set, while the remaining 20% defines the test data. The training and test data are then normalized, and the labels for each dataset are cast to categorical values instead of their age values.\n",
    "\n",
    "The validation data is then extracted from the training dataset, again in an 80/20 split -- 80% of the previous training data remains within the training dataset, and 20% is redefined as the validation set. Each dataset (training, validation, and test) are reshaped based on their format of grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb9da76-9dd0-4571-bda9-5161e636d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged these ages into the 'mature' (5.5+) class: [np.float64(5.5), np.float64(12.5), np.float64(6.5), np.float64(7.5)]\n",
      "New label mapping: {np.float64(1.5): 0, np.float64(2.5): 1, np.float64(3.5): 2, np.float64(4.5): 3, np.float64(5.5): 4}\n",
      "\n",
      "Class distribution after first split:\n",
      "Label 0 (1.5): 11 samples\n",
      "Label 1 (2.5): 15 samples\n",
      "Label 2 (3.5): 14 samples\n",
      "Label 3 (4.5): 7 samples\n",
      "Label 4 (5.5): 14 samples\n",
      "\n",
      "Training set class distribution (after both splits):\n",
      "Label 0 (1.5): 9 samples\n",
      "Label 1 (2.5): 12 samples\n",
      "Label 2 (3.5): 11 samples\n",
      "Label 3 (4.5): 5 samples\n",
      "Label 4 (5.5): 11 samples\n",
      "\n",
      "Validation set class distribution:\n",
      "Label 0 (1.5): 2 samples\n",
      "Label 1 (2.5): 3 samples\n",
      "Label 2 (3.5): 3 samples\n",
      "Label 3 (4.5): 2 samples\n",
      "Label 4 (5.5): 3 samples\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a mapping that combines 5.5+ years into a single \"mature\" class\n",
    "ages_array = np.array(ages)\n",
    "mature_ages = []\n",
    "\n",
    "for i, age in enumerate(ages_array):\n",
    "    if age >= 5.5:\n",
    "        ages_array[i] = 5.5  # Set all ages 5.5+ to 5.5\n",
    "        if age not in mature_ages:\n",
    "            mature_ages.append(age)\n",
    "\n",
    "print(f\"Merged these ages into the 'mature' (5.5+) class: {mature_ages}\")\n",
    "\n",
    "# Now create your label mapping with the modified ages\n",
    "label_mapping = {label: i for i, label in enumerate(np.unique(ages_array))}\n",
    "print(\"New label mapping:\", label_mapping)\n",
    "\n",
    "# Apply the mapping to convert labels to integers\n",
    "integer_labels = np.array([label_mapping[l] for l in ages_array])\n",
    "\n",
    "# Implement a stratified split to ensure all classes appear in train and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    images, integer_labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=integer_labels  # This ensures proportional representation of classes\n",
    ")\n",
    "\n",
    "# Check the class distribution in training+validation set\n",
    "print(\"\\nClass distribution after first split:\")\n",
    "for label in np.unique(y_train_val):\n",
    "    count = np.sum(y_train_val == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")\n",
    "\n",
    "# One-hot encode labels AFTER splitting but BEFORE the next split\n",
    "num_classes = len(label_mapping)\n",
    "y_train_val_onehot = keras.utils.to_categorical(y_train_val, num_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Normalize and reshape images\n",
    "X_train_val = X_train_val.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train_val = X_train_val.reshape(X_train_val.shape[0], 288, 288, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 288, 288, 1)\n",
    "\n",
    "# Implement stratified split for validation too\n",
    "X_train_orig, X_valid, y_train_orig, y_valid = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val_onehot, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=np.argmax(y_train_val_onehot, axis=1)  # Stratify by class\n",
    ")\n",
    "\n",
    "# Print the class distribution to check\n",
    "print(\"\\nTraining set class distribution (after both splits):\")\n",
    "train_class_dist = np.argmax(y_train_orig, axis=1)\n",
    "for label in np.unique(train_class_dist):\n",
    "    count = np.sum(train_class_dist == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")\n",
    "\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "valid_class_dist = np.argmax(y_valid, axis=1)\n",
    "for label in np.unique(valid_class_dist):\n",
    "    count = np.sum(valid_class_dist == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb804f4-1bc3-41cc-9932-f760cfa10658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After your initial train/test split, you should have X_train_val, X_test, y_train_val, y_test\n",
    "# X_train_val and y_train_val are what you want to use instead of X_train and y_train\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "# One-hot encode labels BEFORE splitting into train/validation\n",
    "y_train_val_onehot = keras.utils.to_categorical(y_train_val, num_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Reshape data to add channel dimension\n",
    "X_train_val = X_train_val.reshape(X_train_val.shape[0], 288, 288, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 288, 288, 1)\n",
    "\n",
    "# Create a validation set (without stratification)\n",
    "X_train_orig, X_valid, y_train_orig, y_valid = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val_onehot, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc04a4f1-e9c0-41db-8d82-b115a53f4f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before augmentation:\n",
      "48 train samples\n",
      "16 test samples\n",
      "13 validation samples\n",
      "\n",
      "After class-balanced augmentation:\n",
      "Original training samples: 48\n",
      "Augmented training samples: 72\n",
      "Combined training samples: 120\n",
      "Augmentation multiplier: 2.5\n",
      "X_train_combined shape: (120, 288, 288, 1)\n",
      "y_train_combined shape: (120, 5)\n",
      "\n",
      "Class distribution after augmentation:\n",
      "Label 0 (1.5): 24 samples\n",
      "Label 1 (2.5): 24 samples\n",
      "Label 2 (3.5): 24 samples\n",
      "Label 3 (4.5): 24 samples\n",
      "Label 4 (5.5): 24 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Print original sizes\n",
    "print(\"\\nBefore augmentation:\")\n",
    "print(X_train_orig.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "print(X_valid.shape[0], \"validation samples\")\n",
    "\n",
    "# Setup moderate data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,              \n",
    "    width_shift_range=0.2,          \n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,                 \n",
    "    horizontal_flip=True,           \n",
    "    brightness_range=[0.7, 1.3],    \n",
    "    shear_range=10,                \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create augmented images per class to balance the dataset\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# Find the count of the majority class\n",
    "unique_classes = np.unique(np.argmax(y_train_orig, axis=1))\n",
    "class_counts = [np.sum(np.argmax(y_train_orig, axis=1) == c) for c in unique_classes]\n",
    "max_count = max(class_counts)\n",
    "target_per_class = max_count * 2  # Increase all classes to 2x the size of the largest class\n",
    "\n",
    "# Augment each class separately\n",
    "for class_idx in unique_classes:\n",
    "    # Get indices of samples from this class\n",
    "    class_indices = np.where(np.argmax(y_train_orig, axis=1) == class_idx)[0]\n",
    "    class_count = len(class_indices)\n",
    "    \n",
    "    # Calculate how many augmented samples to generate\n",
    "    samples_to_generate = target_per_class - class_count\n",
    "    \n",
    "    if samples_to_generate <= 0:\n",
    "        continue  # Skip if we already have enough\n",
    "    \n",
    "    # Get the class samples\n",
    "    class_images = X_train_orig[class_indices]\n",
    "    class_labels = y_train_orig[class_indices]\n",
    "    \n",
    "    # Generate augmented samples\n",
    "    aug_gen = datagen.flow(\n",
    "        class_images,\n",
    "        class_labels,\n",
    "        batch_size=class_count,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Generate the required number of samples\n",
    "    batch_count = int(np.ceil(samples_to_generate / class_count))\n",
    "    aug_img_list = []\n",
    "    aug_label_list = []\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        imgs, lbls = next(aug_gen)\n",
    "        aug_img_list.append(imgs)\n",
    "        aug_label_list.append(lbls)\n",
    "    \n",
    "    # Concatenate all batches and trim excess\n",
    "    aug_images = np.concatenate(aug_img_list)[:samples_to_generate]\n",
    "    aug_labels = np.concatenate(aug_label_list)[:samples_to_generate]\n",
    "    \n",
    "    # Add to our collections\n",
    "    augmented_images.append(aug_images)\n",
    "    augmented_labels.append(aug_labels)\n",
    "\n",
    "# Combine all augmented data\n",
    "if augmented_images:  # Check if we actually generated any augmentations\n",
    "    X_aug = np.concatenate(augmented_images)\n",
    "    y_aug = np.concatenate(augmented_labels)\n",
    "    \n",
    "    # Combine with original data\n",
    "    X_train_combined = np.concatenate([X_train_orig, X_aug])\n",
    "    y_train_combined = np.concatenate([y_train_orig, y_aug])\n",
    "else:\n",
    "    X_train_combined = X_train_orig\n",
    "    y_train_combined = y_train_orig\n",
    "\n",
    "# Print new sizes after augmentation\n",
    "print(\"\\nAfter class-balanced augmentation:\")\n",
    "print(\"Original training samples:\", X_train_orig.shape[0])\n",
    "print(\"Augmented training samples:\", X_train_combined.shape[0] - X_train_orig.shape[0])\n",
    "print(\"Combined training samples:\", X_train_combined.shape[0])\n",
    "print(\"Augmentation multiplier:\", X_train_combined.shape[0] / X_train_orig.shape[0])\n",
    "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
    "print(\"y_train_combined shape:\", y_train_combined.shape)\n",
    "\n",
    "# Check class distribution after augmentation\n",
    "print(\"\\nClass distribution after augmentation:\")\n",
    "aug_class_dist = np.argmax(y_train_combined, axis=1)\n",
    "for label in unique_classes:\n",
    "    count = np.sum(aug_class_dist == label)\n",
    "    print(f\"Label {label} ({list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd20bb-a4f0-4593-98f0-c191d3f28d1e",
   "metadata": {},
   "source": [
    "## Build network\n",
    "With the data formatted and separated, we can now build the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250b9a6d-8c7c-4d47-b8e1-625e828ae551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │              \u001b[38;5;34m80\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m1,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m4,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m165\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,109</span> (27.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,109\u001b[0m (27.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,109</span> (27.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,109\u001b[0m (27.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create a simpler model that's less likely to overfit\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional block - keep it simple\n",
    "model.add(Conv2D(8, kernel_size=3, padding='same', activation='relu', input_shape=(288, 288, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Third convolutional block\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Global pooling to reduce parameters\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Classification head - minimal dense layers\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Moderate dropout\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Use a much lower learning rate - crucial for small datasets\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=Adam(learning_rate=0.00005),  # Very low learning rate\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab9a6daa-ee89-4170-83f4-d4379ef0978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(1.0), 1: np.float64(1.0), 2: np.float64(1.0), 3: np.float64(1.0), 4: np.float64(1.0)}\n",
      "\n",
      "Training with improved configuration:\n",
      "Epoch 1/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1762 - loss: 1.6094\n",
      "Epoch 1: val_accuracy improved from -inf to 0.23077, saving model to model_improved.weights.best.hdf5.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1720 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 5.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2681 - loss: 1.6094\n",
      "Epoch 2: val_accuracy improved from 0.23077 to 0.30769, saving model to model_improved.weights.best.hdf5.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2610 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 5.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1821 - loss: 1.6094\n",
      "Epoch 3: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1756 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 5.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1955 - loss: 1.6095\n",
      "Epoch 4: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1988 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 5.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3054 - loss: 1.6094\n",
      "Epoch 5: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2892 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 5.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2246 - loss: 1.6093\n",
      "Epoch 6: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2273 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6091 - learning_rate: 5.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1897 - loss: 1.6094 \n",
      "Epoch 7: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1990 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 5.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1453 - loss: 1.6095\n",
      "Epoch 8: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1521 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6091 - learning_rate: 5.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2395 - loss: 1.6095\n",
      "Epoch 9: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2346 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6091 - learning_rate: 5.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2803 - loss: 1.6093\n",
      "Epoch 10: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2672 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6090 - learning_rate: 5.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2162 - loss: 1.6092\n",
      "Epoch 11: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2119 - loss: 1.6093 - val_accuracy: 0.3077 - val_loss: 1.6091 - learning_rate: 5.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1820 - loss: 1.6095\n",
      "Epoch 12: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1811 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 5.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1558 - loss: 1.6094 \n",
      "Epoch 13: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1591 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 5.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1384 - loss: 1.6095 \n",
      "Epoch 14: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1434 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 5.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2439 - loss: 1.6095\n",
      "Epoch 15: val_accuracy did not improve from 0.30769\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2381 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 5.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1940 - loss: 1.6094\n",
      "Epoch 16: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1943 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 2.5000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1994 - loss: 1.6094\n",
      "Epoch 17: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2062 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 2.5000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2709 - loss: 1.6095\n",
      "Epoch 18: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2617 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 2.5000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2065 - loss: 1.6094\n",
      "Epoch 19: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2055 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 2.5000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2418 - loss: 1.6094\n",
      "Epoch 20: val_accuracy did not improve from 0.30769\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2332 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 2.5000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1969 - loss: 1.6094\n",
      "Epoch 21: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1898 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 1.2500e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2248 - loss: 1.6094\n",
      "Epoch 22: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2248 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 1.2500e-05\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights properly based on the raw class distribution\n",
    "# Extract the class labels from one-hot encoded y_train_orig\n",
    "y_integers = np.argmax(y_train_combined, axis=1)\n",
    "\n",
    "# Compute balanced class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_integers),\n",
    "    y=y_integers\n",
    ")\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# Set up improved callbacks\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='model_improved.weights.best.hdf5.keras',\n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy'  # Changed to monitor accuracy instead of loss\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=20,  # Give it more time to learn\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining with improved configuration:\")\n",
    "hist_improved = model.fit(\n",
    "    X_train_combined, \n",
    "    y_train_combined,\n",
    "    batch_size=8,  # Smaller batch size for better learning with small dataset\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpointer, early_stopping, reduce_lr],\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ac9b50-bb7a-4aee-a69f-16a16fd54457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom class weights: {np.int64(0): np.float64(1.0), np.int64(1): np.float64(1.0), np.int64(2): np.float64(1.0), np.int64(3): np.float64(1.0), np.int64(4): np.float64(1.0)}\n",
      "\n",
      "Training with custom class weights:\n",
      "Epoch 1/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2055 - loss: 1.6094\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15385, saving model to model_improved.weights.best.hdf5.keras\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2046 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 2/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2497 - loss: 1.6094\n",
      "Epoch 2: val_accuracy improved from 0.15385 to 0.30769, saving model to model_improved.weights.best.hdf5.keras\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2453 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 3/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2789 - loss: 1.6094\n",
      "Epoch 3: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2613 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 4/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2112 - loss: 1.6094\n",
      "Epoch 4: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2138 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 5/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1472 - loss: 1.6094\n",
      "Epoch 5: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1565 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 6/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1762 - loss: 1.6095\n",
      "Epoch 6: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1822 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 7/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2551 - loss: 1.6095\n",
      "Epoch 7: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2512 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 8/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2437 - loss: 1.6094\n",
      "Epoch 8: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2427 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 9/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1363 - loss: 1.6095\n",
      "Epoch 9: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1388 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 10/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2170 - loss: 1.6094\n",
      "Epoch 10: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2170 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 11/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1721 - loss: 1.6094\n",
      "Epoch 11: val_accuracy did not improve from 0.30769\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.749999905267032e-06.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.1724 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 1.2500e-05\n",
      "Epoch 12/150\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1474 - loss: 1.6094\n",
      "Epoch 12: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1562 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 13/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1839 - loss: 1.6094\n",
      "Epoch 13: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1839 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 14/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2308 - loss: 1.6093\n",
      "Epoch 14: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2325 - loss: 1.6093 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 15/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2033 - loss: 1.6094\n",
      "Epoch 15: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2033 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 16/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2214 - loss: 1.6094\n",
      "Epoch 16: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2223 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 17/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2265 - loss: 1.6095\n",
      "Epoch 17: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2236 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 18/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2241 - loss: 1.6094\n",
      "Epoch 18: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2252 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 19/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2510 - loss: 1.6095\n",
      "Epoch 19: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2514 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 20/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1624 - loss: 1.6095\n",
      "Epoch 20: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1670 - loss: 1.6095 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 21/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2416 - loss: 1.6094\n",
      "Epoch 21: val_accuracy did not improve from 0.30769\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.1249999715801096e-06.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2348 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 3.7500e-06\n",
      "Epoch 22/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1401 - loss: 1.6094\n",
      "Epoch 22: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1412 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 23/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2425 - loss: 1.6094\n",
      "Epoch 23: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2432 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 24/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2197 - loss: 1.6095\n",
      "Epoch 24: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2165 - loss: 1.6095 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 25/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0945 - loss: 1.6095\n",
      "Epoch 25: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1022 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 26/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2032 - loss: 1.6094\n",
      "Epoch 26: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2068 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 27/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3472 - loss: 1.6093\n",
      "Epoch 27: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3327 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 28/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3569 - loss: 1.6093\n",
      "Epoch 28: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3441 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 29/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1918 - loss: 1.6095\n",
      "Epoch 29: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1959 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 30/150\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2791 - loss: 1.6093\n",
      "Epoch 30: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2750 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 31/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2756 - loss: 1.6095\n",
      "Epoch 31: val_accuracy did not improve from 0.30769\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2742 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.1250e-06\n",
      "Epoch 32/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1991 - loss: 1.6094\n",
      "Epoch 32: val_accuracy did not improve from 0.30769\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1986 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.0000e-06\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights using a more aggressive approach for small datasets\n",
    "y_integers = np.argmax(y_train_combined, axis=1)\n",
    "\n",
    "# Count samples per class\n",
    "unique_classes, class_counts = np.unique(y_integers, return_counts=True)\n",
    "count_dict = dict(zip(unique_classes, class_counts))\n",
    "\n",
    "# Custom class weight calculation - more aggressive than sklearn's balanced approach\n",
    "max_count = max(class_counts)\n",
    "class_weight_dict = {cls: max_count / count for cls, count in count_dict.items()}\n",
    "\n",
    "# Optional: Make weights even more extreme to force the model to learn minority classes\n",
    "for cls in class_weight_dict:\n",
    "    if class_weight_dict[cls] > 1:\n",
    "        class_weight_dict[cls] *= 1.5  # Boost minority classes even more\n",
    "\n",
    "print(\"Custom class weights:\", class_weight_dict)\n",
    "\n",
    "# Set up improved callbacks\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='model_improved.weights.best.hdf5.keras',\n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=30,  # More patience for a small dataset\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.3,  # Larger reduction\n",
    "    patience=10,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining with custom class weights:\")\n",
    "hist_improved = model.fit(\n",
    "    X_train_combined, \n",
    "    y_train_combined,\n",
    "    batch_size=4,  # Very small batch size to help with class imbalance\n",
    "    epochs=150,    # More epochs since we have early stopping\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpointer, early_stopping, reduce_lr],\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae60e167-c088-43c8-94e1-6cd4701c29b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training an ensemble of models for better performance\n",
      "\n",
      "Training model 1/3\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1705 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2637 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1925 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2604 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6095 - learning_rate: 5.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.1977 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6095 - learning_rate: 5.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1980 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6095 - learning_rate: 5.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2298 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6095 - learning_rate: 5.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2051 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1128 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1821 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1805 - loss: 1.6094\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.1814 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 5.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1716 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2267 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1839 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2377 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1088 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0601 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2612 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2036 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2830 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2870 - loss: 1.6093\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-06.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2830 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 1.5000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2139 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2380 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2070 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2163 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1380 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2258 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2599 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1660 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3442 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2468 - loss: 1.6094\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.3499999113264492e-06.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2456 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 4.5000e-06\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Training model 2/3\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.2215 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 7.5000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2894 - loss: 1.6093 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 7.5000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2676 - loss: 1.6092 - val_accuracy: 0.3077 - val_loss: 1.6091 - learning_rate: 7.5000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1362 - loss: 1.6096 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 7.5000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1897 - loss: 1.6094 - val_accuracy: 0.0769 - val_loss: 1.6093 - learning_rate: 7.5000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1530 - loss: 1.6094 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 7.5000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1341 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 7.5000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1868 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 7.5000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1976 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 7.5000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2166 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 7.5000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1652 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 7.5000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2248 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6093 - learning_rate: 7.5000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1811 - loss: 1.6095\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.2500001068692655e-05.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1813 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6094 - learning_rate: 7.5000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2938 - loss: 1.6094 - val_accuracy: 0.3846 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2093 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2334 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1872 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2066 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2338 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1920 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1913 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1529 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2065 - loss: 1.6094\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.7500001023290675e-06.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2080 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.2500e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1405 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1952 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1922 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1777 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1800 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2858 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1743 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1506 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2455 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2072 - loss: 1.6094\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 2.025000003413879e-06.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2057 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 6.7500e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2515 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1738 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1858 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1920 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1307 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1836 - loss: 1.6095 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2071 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2322 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1622 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2579 - loss: 1.6094\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2571 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 2.0250e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2067 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6094 - learning_rate: 1.0000e-06\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "Training model 3/3\n",
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.1629 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1497 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0893 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6093 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1994 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2635 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1222 - loss: 1.6095 - val_accuracy: 0.1538 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1784 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1767 - loss: 1.6095 - val_accuracy: 0.1538 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2358 - loss: 1.6094 - val_accuracy: 0.3077 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1569 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6091 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2114 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6091 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1717 - loss: 1.6095 - val_accuracy: 0.1538 - val_loss: 1.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2970 - loss: 1.6093 - val_accuracy: 0.3077 - val_loss: 1.6091 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1850 - loss: 1.6095 \n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1881 - loss: 1.6095 - val_accuracy: 0.1538 - val_loss: 1.6093 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1664 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0947 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2611 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6091 - learning_rate: 3.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1531 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1842 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1973 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6091 - learning_rate: 3.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1370 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1885 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1925 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2374 - loss: 1.6093\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2260 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 3.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2435 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2265 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2100 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2615 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2382 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2171 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1539 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1949 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2027 - loss: 1.6095 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2053 - loss: 1.6093\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2056 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 9.0000e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1905 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 2.7000e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1499 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 2.7000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1551 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 2.7000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2259 - loss: 1.6094 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 2.7000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2340 - loss: 1.6093 - val_accuracy: 0.2308 - val_loss: 1.6092 - learning_rate: 2.7000e-06\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A7A08C93A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A7A08C9BC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Ensemble Test Accuracy: 0.2500\n",
      "Ensemble predicts 1 different classes: {np.int64(1)}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEnsemble predicts \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(unique_predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m different classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_predictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Show confusion matrix for ensemble\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m cm_ensemble = \u001b[43mconfusion_matrix\u001b[49m(y_true, ensemble_pred)\n\u001b[32m     69\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m     70\u001b[39m sns.heatmap(cm_ensemble, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     71\u001b[39m            xticklabels=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreverse_mapping[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m yrs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes)],\n\u001b[32m     72\u001b[39m            yticklabels=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreverse_mapping[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m yrs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes)])\n",
      "\u001b[31mNameError\u001b[39m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an ensemble of models to improve performance\n",
    "print(\"\\nTraining an ensemble of models for better performance\")\n",
    "\n",
    "# First, define y_true from the test set for evaluation\n",
    "y_true = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Number of models in our ensemble\n",
    "num_models = 3\n",
    "ensemble_models = []\n",
    "\n",
    "for i in range(num_models):\n",
    "    print(f\"\\nTraining model {i+1}/{num_models}\")\n",
    "    \n",
    "    # Create a model with slightly different architecture\n",
    "    model_i = Sequential()\n",
    "    model_i.add(Conv2D(8, kernel_size=3+i, padding='same', activation='relu', input_shape=(288, 288, 1)))\n",
    "    model_i.add(MaxPooling2D(pool_size=2))\n",
    "    model_i.add(Conv2D(16, kernel_size=3, padding='same', activation='relu'))\n",
    "    model_i.add(MaxPooling2D(pool_size=2))\n",
    "    model_i.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model_i.add(MaxPooling2D(pool_size=2))\n",
    "    model_i.add(GlobalAveragePooling2D())\n",
    "    model_i.add(Dense(32, activation='relu'))\n",
    "    model_i.add(Dropout(0.3))\n",
    "    model_i.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile with slightly different learning rate\n",
    "    model_i.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=Adam(learning_rate=0.00005 * (1 + i*0.5)),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train with slightly different hyperparameters\n",
    "    model_i.fit(\n",
    "        X_train_combined, \n",
    "        y_train_combined,\n",
    "        batch_size=4+i*2,\n",
    "        epochs=100,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "    \n",
    "    ensemble_models.append(model_i)\n",
    "\n",
    "# Make ensemble predictions on test set\n",
    "ensemble_preds = []\n",
    "for model_i in ensemble_models:\n",
    "    pred_i = model_i.predict(X_test, verbose=0)\n",
    "    ensemble_preds.append(pred_i)\n",
    "\n",
    "# Average predictions from all models\n",
    "ensemble_pred_prob = sum(ensemble_preds) / len(ensemble_preds)\n",
    "ensemble_pred = np.argmax(ensemble_pred_prob, axis=1)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "ensemble_accuracy = np.mean(ensemble_pred == y_true)\n",
    "print(f\"\\nEnsemble Test Accuracy: {ensemble_accuracy:.4f}\")\n",
    "\n",
    "# Check if ensemble makes diverse predictions\n",
    "unique_predictions = set(ensemble_pred)\n",
    "print(f\"Ensemble predicts {len(unique_predictions)} different classes: {unique_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65464c15-8dce-45b5-b488-7faf239f16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying traditional machine learning approaches better suited for very small datasets\n",
      "Reduced dimensions from 82944 to 20\n",
      "\n",
      "Decision Tree Accuracy: 0.1875\n",
      "Decision Tree predicts 3 different classes: {np.int64(2), np.int64(3), np.int64(4)}\n",
      "\n",
      "Random Forest Accuracy: 0.2500\n",
      "Random Forest predicts 4 different classes: {np.int64(1), np.int64(2), np.int64(3), np.int64(4)}\n",
      "\n",
      "Gradient Boosting Accuracy: 0.1250\n",
      "Gradient Boosting predicts 5 different classes: {np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)}\n",
      "\n",
      "Logistic Regression Accuracy: 0.1250\n",
      "Logistic Regression predicts 5 different classes: {np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)}\n",
      "\n",
      "Best model is Random Forest with accuracy 0.2500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Age 1.5       0.00      0.00      0.00         2\n",
      "     Age 2.5       0.17      0.25      0.20         4\n",
      "     Age 3.5       0.14      0.25      0.18         4\n",
      "     Age 4.5       0.50      0.50      0.50         2\n",
      "     Age 5.5       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.36      0.25      0.26        16\n",
      "weighted avg       0.39      0.25      0.26        16\n",
      "\n",
      "\n",
      "Trying a voting classifier to combine all models\n",
      "Voting Classifier Accuracy: 0.1875\n",
      "Voting Classifier predicts 5 different classes: {np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)}\n",
      "\n",
      "Predictions for each test sample:\n",
      "\n",
      "Sample 1 - True age: 4.5 years\n",
      "  Decision Tree: 4.5 years ✓\n",
      "  Random Forest: 4.5 years ✓\n",
      "  Gradient Boosting: 2.5 years ✗\n",
      "  Logistic Regression: 4.5 years ✓\n",
      "\n",
      "Sample 2 - True age: 1.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 4.5 years ✗\n",
      "  Gradient Boosting: 2.5 years ✗\n",
      "  Logistic Regression: 4.5 years ✗\n",
      "\n",
      "Sample 3 - True age: 2.5 years\n",
      "  Decision Tree: 3.5 years ✗\n",
      "  Random Forest: 3.5 years ✗\n",
      "  Gradient Boosting: 3.5 years ✗\n",
      "  Logistic Regression: 5.5 years ✗\n",
      "\n",
      "Sample 4 - True age: 3.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 2.5 years ✗\n",
      "  Gradient Boosting: 5.5 years ✗\n",
      "  Logistic Regression: 2.5 years ✗\n",
      "\n",
      "Sample 5 - True age: 4.5 years\n",
      "  Decision Tree: 5.5 years ✗\n",
      "  Random Forest: 3.5 years ✗\n",
      "  Gradient Boosting: 5.5 years ✗\n",
      "  Logistic Regression: 3.5 years ✗\n",
      "\n",
      "Sample 6 - True age: 5.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 2.5 years ✗\n",
      "  Gradient Boosting: 4.5 years ✗\n",
      "  Logistic Regression: 1.5 years ✗\n",
      "\n",
      "Sample 7 - True age: 2.5 years\n",
      "  Decision Tree: 3.5 years ✗\n",
      "  Random Forest: 3.5 years ✗\n",
      "  Gradient Boosting: 3.5 years ✗\n",
      "  Logistic Regression: 5.5 years ✗\n",
      "\n",
      "Sample 8 - True age: 3.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 2.5 years ✗\n",
      "  Gradient Boosting: 2.5 years ✗\n",
      "  Logistic Regression: 2.5 years ✗\n",
      "\n",
      "Sample 9 - True age: 3.5 years\n",
      "  Decision Tree: 5.5 years ✗\n",
      "  Random Forest: 3.5 years ✓\n",
      "  Gradient Boosting: 5.5 years ✗\n",
      "  Logistic Regression: 5.5 years ✗\n",
      "\n",
      "Sample 10 - True age: 3.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 2.5 years ✗\n",
      "  Gradient Boosting: 2.5 years ✗\n",
      "  Logistic Regression: 5.5 years ✗\n",
      "\n",
      "Sample 11 - True age: 5.5 years\n",
      "  Decision Tree: 5.5 years ✓\n",
      "  Random Forest: 5.5 years ✓\n",
      "  Gradient Boosting: 5.5 years ✓\n",
      "  Logistic Regression: 5.5 years ✓\n",
      "\n",
      "Sample 12 - True age: 1.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 3.5 years ✗\n",
      "  Gradient Boosting: 3.5 years ✗\n",
      "  Logistic Regression: 3.5 years ✗\n",
      "\n",
      "Sample 13 - True age: 2.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 3.5 years ✗\n",
      "  Gradient Boosting: 4.5 years ✗\n",
      "  Logistic Regression: 3.5 years ✗\n",
      "\n",
      "Sample 14 - True age: 5.5 years\n",
      "  Decision Tree: 4.5 years ✗\n",
      "  Random Forest: 3.5 years ✗\n",
      "  Gradient Boosting: 1.5 years ✗\n",
      "  Logistic Regression: 3.5 years ✗\n",
      "\n",
      "Sample 15 - True age: 5.5 years\n",
      "  Decision Tree: 5.5 years ✓\n",
      "  Random Forest: 2.5 years ✗\n",
      "  Gradient Boosting: 3.5 years ✗\n",
      "  Logistic Regression: 3.5 years ✗\n",
      "\n",
      "Sample 16 - True age: 2.5 years\n",
      "  Decision Tree: 5.5 years ✗\n",
      "  Random Forest: 2.5 years ✓\n",
      "  Gradient Boosting: 2.5 years ✓\n",
      "  Logistic Regression: 1.5 years ✗\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nTrying traditional machine learning approaches better suited for very small datasets\")\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Create reverse mapping to get original labels\n",
    "reverse_mapping = {i: label for label, i in label_mapping.items()}\n",
    "\n",
    "# Flatten the images for use with simpler models\n",
    "X_train_flat = X_train_combined.reshape(X_train_combined.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "y_train_flat = np.argmax(y_train_combined, axis=1)\n",
    "y_true = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# Apply dimensionality reduction - critical for such high-dimensional data with few samples\n",
    "pca = PCA(n_components=min(20, X_train_flat.shape[0] - 5))  # Fewer components than samples\n",
    "X_train_pca = pca.fit_transform(StandardScaler().fit_transform(X_train_flat))\n",
    "X_test_pca = pca.transform(StandardScaler().fit_transform(X_test_flat))\n",
    "\n",
    "print(f\"Reduced dimensions from {X_train_flat.shape[1]} to {X_train_pca.shape[1]}\")\n",
    "\n",
    "# 1. Decision Tree with limited depth to avoid overfitting\n",
    "tree_model = DecisionTreeClassifier(max_depth=3, class_weight='balanced', random_state=42)\n",
    "tree_model.fit(X_train_pca, y_train_flat)\n",
    "tree_pred = tree_model.predict(X_test_pca)\n",
    "tree_accuracy = accuracy_score(y_true, tree_pred)\n",
    "print(f\"\\nDecision Tree Accuracy: {tree_accuracy:.4f}\")\n",
    "print(f\"Decision Tree predicts {len(set(tree_pred))} different classes: {set(tree_pred)}\")\n",
    "\n",
    "# 2. Random Forest - an ensemble of decision trees\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, \n",
    "                                  class_weight='balanced', random_state=42)\n",
    "rf_model.fit(X_train_pca, y_train_flat)\n",
    "rf_pred = rf_model.predict(X_test_pca)\n",
    "rf_accuracy = accuracy_score(y_true, rf_pred)\n",
    "print(f\"\\nRandom Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Random Forest predicts {len(set(rf_pred))} different classes: {set(rf_pred)}\")\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=50, max_depth=2, \n",
    "                                      learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train_pca, y_train_flat)\n",
    "gb_pred = gb_model.predict(X_test_pca)\n",
    "gb_accuracy = accuracy_score(y_true, gb_pred)\n",
    "print(f\"\\nGradient Boosting Accuracy: {gb_accuracy:.4f}\")\n",
    "print(f\"Gradient Boosting predicts {len(set(gb_pred))} different classes: {set(gb_pred)}\")\n",
    "\n",
    "# 4. Logistic Regression with strong regularization\n",
    "logreg_model = LogisticRegression(C=0.1, class_weight='balanced', \n",
    "                                 max_iter=10000, random_state=42)\n",
    "logreg_model.fit(X_train_pca, y_train_flat)\n",
    "logreg_pred = logreg_model.predict(X_test_pca)\n",
    "logreg_accuracy = accuracy_score(y_true, logreg_pred)\n",
    "print(f\"\\nLogistic Regression Accuracy: {logreg_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression predicts {len(set(logreg_pred))} different classes: {set(logreg_pred)}\")\n",
    "\n",
    "# Find which model is making the most diverse predictions\n",
    "all_preds = np.vstack([tree_pred, rf_pred, gb_pred, logreg_pred]).T\n",
    "all_models = [\"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"Logistic Regression\"]\n",
    "\n",
    "# Show confusion matrix for the best performing model in terms of accuracy\n",
    "best_model_idx = np.argmax([tree_accuracy, rf_accuracy, gb_accuracy, logreg_accuracy])\n",
    "best_model_name = all_models[best_model_idx]\n",
    "best_pred = all_preds[:, best_model_idx]\n",
    "\n",
    "print(f\"\\nBest model is {best_model_name} with accuracy {np.mean(best_pred == y_true):.4f}\")\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_true, best_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=[f\"{reverse_mapping[i]} yrs\" for i in range(num_classes)],\n",
    "           yticklabels=[f\"{reverse_mapping[i]} yrs\" for i in range(num_classes)])\n",
    "plt.xlabel('Predicted Age')\n",
    "plt.ylabel('True Age')\n",
    "plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report for Best Model:\")\n",
    "print(classification_report(y_true, best_pred, \n",
    "                          target_names=[f\"Age {reverse_mapping[i]}\" for i in range(num_classes)],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Create a voting classifier to combine all models\n",
    "print(\"\\nTrying a voting classifier to combine all models\")\n",
    "predictions = np.zeros((len(y_true), num_classes))\n",
    "\n",
    "# Get probabilities from each model if available\n",
    "if hasattr(tree_model, 'predict_proba'):\n",
    "    predictions += tree_model.predict_proba(X_test_pca)\n",
    "if hasattr(rf_model, 'predict_proba'):\n",
    "    predictions += rf_model.predict_proba(X_test_pca)\n",
    "if hasattr(gb_model, 'predict_proba'):\n",
    "    predictions += gb_model.predict_proba(X_test_pca)\n",
    "if hasattr(logreg_model, 'predict_proba'):\n",
    "    predictions += logreg_model.predict_proba(X_test_pca)\n",
    "\n",
    "# Get final predictions\n",
    "voting_pred = np.argmax(predictions, axis=1)\n",
    "voting_accuracy = accuracy_score(y_true, voting_pred)\n",
    "\n",
    "print(f\"Voting Classifier Accuracy: {voting_accuracy:.4f}\")\n",
    "print(f\"Voting Classifier predicts {len(set(voting_pred))} different classes: {set(voting_pred)}\")\n",
    "\n",
    "# Report the results for each sample\n",
    "print(\"\\nPredictions for each test sample:\")\n",
    "for i in range(len(y_true)):\n",
    "    true_class = y_true[i]\n",
    "    true_age = reverse_mapping[true_class]\n",
    "    \n",
    "    # Print predictions from all models\n",
    "    print(f\"\\nSample {i+1} - True age: {true_age} years\")\n",
    "    for j, model_name in enumerate(all_models):\n",
    "        pred_class = all_preds[i, j]\n",
    "        pred_age = reverse_mapping[pred_class]\n",
    "        correct = \"✓\" if pred_class == true_class else \"✗\"\n",
    "        print(f\"  {model_name}: {pred_age} years {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb71e9f-18e9-497d-a48a-f245228ed2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAttempting a different approach: One-vs-Rest classifiers\")\n",
    "\n",
    "# Import necessary libraries for the alternative approach\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Prepare the data for sklearn models\n",
    "X_train_flat = X_train_combined.reshape(X_train_combined.shape[0], -1)  # Flatten images\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)  # Flatten images\n",
    "y_train_sklearn = np.argmax(y_train_combined, axis=1)  # Convert one-hot back to integers\n",
    "\n",
    "# Create and train a One-vs-Rest classifier with SVM\n",
    "ovr_classifier = OneVsRestClassifier(\n",
    "    make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel='rbf', probability=True, class_weight='balanced', C=10.0, gamma='scale')\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Training One-vs-Rest SVM classifier...\")\n",
    "ovr_classifier.fit(X_train_flat, y_train_sklearn)\n",
    "\n",
    "# Make predictions\n",
    "ovr_predictions = ovr_classifier.predict(X_test_flat)\n",
    "ovr_accuracy = np.mean(ovr_predictions == y_true)\n",
    "print(f\"One-vs-Rest SVM Accuracy: {ovr_accuracy:.4f}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "cm_ovr = confusion_matrix(y_true, ovr_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_ovr, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=[f\"{reverse_mapping[i]} yrs\" for i in range(num_classes)],\n",
    "           yticklabels=[f\"{reverse_mapping[i]} yrs\" for i in range(num_classes)])\n",
    "plt.xlabel('Predicted Age')\n",
    "plt.ylabel('True Age')\n",
    "plt.title('One-vs-Rest SVM Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check which classes are being predicted\n",
    "unique_ovr_predictions = set(ovr_predictions)\n",
    "print(f\"OVR predicts {len(unique_ovr_predictions)} different classes: {unique_ovr_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d1a4d-6096-4720-a0c6-7ccfaf03d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the most confident and least confident predictions\n",
    "correct_indices = np.where(y_pred == y_true)[0]\n",
    "incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "\n",
    "# Function to display confidence scores for a sample\n",
    "def display_prediction_details(idx, title):\n",
    "    true_class = y_true[idx]\n",
    "    pred_class = y_pred[idx]\n",
    "    confidence = y_pred_prob[idx][pred_class]\n",
    "    \n",
    "    print(f\"\\n{title}\")\n",
    "    print(f\"True age: {reverse_mapping[true_class]} years\")\n",
    "    print(f\"Predicted age: {reverse_mapping[pred_class]} years\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    \n",
    "    # Show all class probabilities\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(num_classes), y_pred_prob[idx])\n",
    "    plt.xticks(range(num_classes), [f\"{reverse_mapping[i]} yrs\" for i in range(num_classes)])\n",
    "    plt.xlabel('Age Class')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'Prediction Probabilities for Sample {idx}')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display most confident correct prediction\n",
    "if len(correct_indices) > 0:\n",
    "    confidences = [y_pred_prob[i][y_pred[i]] for i in correct_indices]\n",
    "    most_confident_correct_idx = correct_indices[np.argmax(confidences)]\n",
    "    display_prediction_details(most_confident_correct_idx, \"Most Confident Correct Prediction\")\n",
    "\n",
    "# Display most confident incorrect prediction\n",
    "if len(incorrect_indices) > 0:\n",
    "    confidences = [y_pred_prob[i][y_pred[i]] for i in incorrect_indices]\n",
    "    most_confident_incorrect_idx = incorrect_indices[np.argmax(confidences)]\n",
    "    display_prediction_details(most_confident_incorrect_idx, \"Most Confident Incorrect Prediction\")\n",
    "\n",
    "# Display prediction entropy (measure of uncertainty)\n",
    "from scipy.stats import entropy\n",
    "prediction_entropy = np.array([entropy(y_pred_prob[i]) for i in range(len(y_test))])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), prediction_entropy, c=y_pred==y_true, cmap='coolwarm', alpha=0.8)\n",
    "plt.colorbar(label='Correct Prediction')\n",
    "plt.xlabel('Test Sample Index')\n",
    "plt.ylabel('Prediction Entropy (Uncertainty)')\n",
    "plt.title('Model Uncertainty for Each Test Sample')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAverage entropy for correct predictions:\", \n",
    "      np.mean(prediction_entropy[correct_indices]) if len(correct_indices) > 0 else \"N/A\")\n",
    "print(\"Average entropy for incorrect predictions:\", \n",
    "      np.mean(prediction_entropy[incorrect_indices]) if len(incorrect_indices) > 0 else \"N/A\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
