{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a5b6e2-ade6-40ef-9121-92a94d2a855e",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "\n",
    "This notebook takes the output result of `250813_nda_all` and attempts to optimize a single model instead of an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62247f7c-827d-4f33-99dd-bc10db9c0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"❌ CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa4928b-d228-4d97-b29e-b0b0abf0737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GhostNet-100 Advanced Optimization\n",
      "==================================================\n",
      "Loading 237 images...\n",
      "Loaded 236 images (237 color, 0 grayscale)\n",
      "Dataset: 236 images, 5 age classes\n",
      "Age distribution: {2.5: 40, 3.5: 50, 4.5: 56, 5.5: 58, 1.5: 32}\n",
      "Training: 188, Test: 48\n",
      "Using device: cuda\n",
      "Using mixed precision training\n",
      "Starting optimization with 8 configurations\n",
      "Using 5-fold cross-validation with 60 max epochs per fold\n",
      "\n",
      "[1/8] Testing: baseline_deep\n",
      "  Fold 1/5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 18728, 11216, 6760, 31408) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1243\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py:114\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 801\u001b[39m\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResults saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer.save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 780\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    779\u001b[39m optimizer = GhostNetOptimizer(num_classes=\u001b[38;5;28mlen\u001b[39m(unique_ages))\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m results, best_config, _ = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize_ghostnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mapping\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    784\u001b[39m elapsed = (time.time() - start_time) / \u001b[32m60\u001b[39m\n\u001b[32m    785\u001b[39m best_score = \u001b[38;5;28mmax\u001b[39m(result[\u001b[33m'\u001b[39m\u001b[33mtest_mean\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 467\u001b[39m, in \u001b[36mGhostNetOptimizer.optimize_ghostnet\u001b[39m\u001b[34m(self, X_train, y_train, X_test, y_test, label_mapping)\u001b[39m\n\u001b[32m    464\u001b[39m train_loader = DataLoader(train_dataset, batch_size=config[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m], shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers=\u001b[32m4\u001b[39m)\n\u001b[32m    465\u001b[39m val_loader = DataLoader(val_dataset, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m4\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m model, val_acc, history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m test_acc, test_f1 = \u001b[38;5;28mself\u001b[39m.evaluate_test_performance(model, test_loader)\n\u001b[32m    470\u001b[39m fold_cv_scores.append(val_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 552\u001b[39m, in \u001b[36mGhostNetOptimizer.train_with_config\u001b[39m\u001b[34m(self, train_loader, val_loader, config)\u001b[39m\n\u001b[32m    549\u001b[39m train_loss_total = \u001b[32m0.0\u001b[39m\n\u001b[32m    550\u001b[39m train_batches = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1448\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1412\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1409\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1414\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1256\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1255\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1257\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1258\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 18728, 11216, 6760, 31408) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "OPTIMIZATION_CONFIGS = [\n",
    "    {\n",
    "        'name': 'baseline_deep',\n",
    "        'lr_backbone': 0.0003,\n",
    "        'lr_head': 0.001,\n",
    "        'weight_decay': 0.03,\n",
    "        'dropout': 0.3,\n",
    "        'label_smoothing': 0.1,\n",
    "        'augmentation_strength': 'medium',\n",
    "        'scheduler': 'cosine',\n",
    "        'warmup_epochs': 8,\n",
    "        'freeze_layers': 3,\n",
    "        'head_architecture': 'simple',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'name': 'aggressive_lr',\n",
    "        'lr_backbone': 0.0008,\n",
    "        'lr_head': 0.003,\n",
    "        'weight_decay': 0.05,\n",
    "        'dropout': 0.4,\n",
    "        'label_smoothing': 0.15,\n",
    "        'augmentation_strength': 'strong',\n",
    "        'scheduler': 'cosine',\n",
    "        'warmup_epochs': 12,\n",
    "        'freeze_layers': 5,\n",
    "        'head_architecture': 'complex',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    {\n",
    "        'name': 'conservative_deep',\n",
    "        'lr_backbone': 0.0001,\n",
    "        'lr_head': 0.0005,\n",
    "        'weight_decay': 0.01,\n",
    "        'dropout': 0.2,\n",
    "        'label_smoothing': 0.05,\n",
    "        'augmentation_strength': 'light',\n",
    "        'scheduler': 'cosine',\n",
    "        'warmup_epochs': 5,\n",
    "        'freeze_layers': 1,\n",
    "        'head_architecture': 'simple',\n",
    "        'batch_size': 20\n",
    "    },\n",
    "    {\n",
    "        'name': 'step_balanced',\n",
    "        'lr_backbone': 0.0004,\n",
    "        'lr_head': 0.0012,\n",
    "        'weight_decay': 0.04,\n",
    "        'dropout': 0.35,\n",
    "        'label_smoothing': 0.12,\n",
    "        'augmentation_strength': 'medium',\n",
    "        'scheduler': 'step',\n",
    "        'warmup_epochs': 6,\n",
    "        'freeze_layers': 3,\n",
    "        'head_architecture': 'adaptive',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'name': 'heavy_reg',\n",
    "        'lr_backbone': 0.0002,\n",
    "        'lr_head': 0.0008,\n",
    "        'weight_decay': 0.08,\n",
    "        'dropout': 0.5,\n",
    "        'label_smoothing': 0.2,\n",
    "        'augmentation_strength': 'strong',\n",
    "        'scheduler': 'cosine',\n",
    "        'warmup_epochs': 10,\n",
    "        'freeze_layers': 0,\n",
    "        'head_architecture': 'complex',\n",
    "        'batch_size': 14\n",
    "    },\n",
    "    {\n",
    "        'name': 'minimal_freeze_high_lr',\n",
    "        'lr_backbone': 0.0006,\n",
    "        'lr_head': 0.002,\n",
    "        'weight_decay': 0.02,\n",
    "        'dropout': 0.25,\n",
    "        'label_smoothing': 0.08,\n",
    "        'augmentation_strength': 'medium',\n",
    "        'scheduler': 'cosine',\n",
    "        'warmup_epochs': 8,\n",
    "        'freeze_layers': 1,\n",
    "        'head_architecture': 'adaptive',\n",
    "        'batch_size': 18\n",
    "    },\n",
    "    {\n",
    "        'name': 'cyclical_advanced',\n",
    "        'lr_backbone': 0.0005,\n",
    "        'lr_head': 0.0015,\n",
    "        'weight_decay': 0.06,\n",
    "        'dropout': 0.45,\n",
    "        'label_smoothing': 0.18,\n",
    "        'augmentation_strength': 'strong',\n",
    "        'scheduler': 'cyclical',\n",
    "        'warmup_epochs': 7,\n",
    "        'freeze_layers': 4,\n",
    "        'head_architecture': 'complex',\n",
    "        'batch_size': 14\n",
    "    },\n",
    "    {\n",
    "        'name': 'extreme_reg',\n",
    "        'lr_backbone': 0.00015,\n",
    "        'lr_head': 0.0006,\n",
    "        'weight_decay': 0.12,\n",
    "        'dropout': 0.6,\n",
    "        'label_smoothing': 0.25,\n",
    "        'augmentation_strength': 'strong',\n",
    "        'scheduler': 'cosine',\n",
    "        'warmup_epochs': 15,\n",
    "        'freeze_layers': 0,\n",
    "        'head_architecture': 'complex',\n",
    "        'batch_size': 12\n",
    "    }\n",
    "]\n",
    "\n",
    "AUGMENTATION_TARGET = 400\n",
    "NUM_FOLDS = 5\n",
    "IMAGE_SIZE = (224, 224)\n",
    "MAX_EPOCHS = 60\n",
    "PATIENCE = 12\n",
    "\n",
    "class AdvancedAugmentationDataset(Dataset):\n",
    "    def __init__(self, X, y, augmentation_strength='medium', test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.augmentation_strength = augmentation_strength\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def advanced_augment(self, image):\n",
    "        is_grayscale = torch.allclose(image[0], image[1]) and torch.allclose(image[1], image[2])\n",
    "        \n",
    "        if self.augmentation_strength == 'light':\n",
    "            if random.random() < 0.5:\n",
    "                image = torch.flip(image, [2])\n",
    "            if random.random() < 0.3:\n",
    "                shift = random.randint(-5, 5)\n",
    "                if shift != 0:\n",
    "                    image = torch.roll(image, shift, dims=2)\n",
    "            if is_grayscale and random.random() < 0.3:\n",
    "                image = self.apply_false_color(image[0])\n",
    "            elif not is_grayscale and random.random() < 0.1:\n",
    "                gray = 0.299 * image[0] + 0.587 * image[1] + 0.114 * image[2]\n",
    "                image = gray.unsqueeze(0).repeat(3, 1, 1)\n",
    "        \n",
    "        elif self.augmentation_strength == 'medium':\n",
    "            if random.random() < 0.5:\n",
    "                image = torch.flip(image, [2])\n",
    "            if random.random() < 0.4:\n",
    "                factor = random.uniform(0.85, 1.15) if is_grayscale else random.uniform(0.8, 1.2)\n",
    "                image = torch.clamp(image * factor, 0, 1)\n",
    "            if random.random() < 0.2:\n",
    "                angle = random.uniform(-10, 10)\n",
    "                image = self.rotate_tensor(image, angle)\n",
    "            if is_grayscale and random.random() < 0.4:\n",
    "                image = self.apply_false_color(image[0])\n",
    "            elif not is_grayscale and random.random() < 0.15:\n",
    "                gray = 0.299 * image[0] + 0.587 * image[1] + 0.114 * image[2]\n",
    "                image = gray.unsqueeze(0).repeat(3, 1, 1)\n",
    "        \n",
    "        elif self.augmentation_strength == 'strong':\n",
    "            if random.random() < 0.6:\n",
    "                image = torch.flip(image, [2])\n",
    "            if random.random() < 0.5:\n",
    "                factor = random.uniform(0.8, 1.2) if is_grayscale else random.uniform(0.7, 1.3)\n",
    "                image = torch.clamp(image * factor, 0, 1)\n",
    "            if random.random() < 0.3:\n",
    "                angle = random.uniform(-15, 15)\n",
    "                image = self.rotate_tensor(image, angle)\n",
    "            if random.random() < 0.2:\n",
    "                noise = torch.randn_like(image) * 0.02\n",
    "                image = torch.clamp(image + noise, 0, 1)\n",
    "            if random.random() < 0.15:\n",
    "                image = self.apply_blur(image)\n",
    "            if is_grayscale and random.random() < 0.5:\n",
    "                image = self.apply_false_color(image[0])\n",
    "            elif not is_grayscale and random.random() < 0.2:\n",
    "                gray = 0.299 * image[0] + 0.587 * image[1] + 0.114 * image[2]\n",
    "                image = gray.unsqueeze(0).repeat(3, 1, 1)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def rotate_tensor(self, image, angle):\n",
    "        angle_rad = torch.tensor(angle * 3.14159 / 180.0)\n",
    "        cos_a = torch.cos(angle_rad)\n",
    "        sin_a = torch.sin(angle_rad)\n",
    "        \n",
    "        rotation_matrix = torch.tensor([\n",
    "            [cos_a, -sin_a, 0],\n",
    "            [sin_a, cos_a, 0]\n",
    "        ], dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        grid = F.affine_grid(rotation_matrix, image.unsqueeze(0).size(), align_corners=False)\n",
    "        rotated = F.grid_sample(image.unsqueeze(0), grid, align_corners=False, mode='bilinear', padding_mode='reflection')\n",
    "        return rotated.squeeze(0)\n",
    "    \n",
    "    def apply_blur(self, image):\n",
    "        kernel_size = random.choice([3, 5])\n",
    "        sigma = random.uniform(0.5, 1.5)\n",
    "        \n",
    "        channels = image.shape[0]\n",
    "        kernel_1d = torch.exp(-0.5 * (torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2) ** 2 / sigma ** 2)\n",
    "        kernel_1d = kernel_1d / kernel_1d.sum()\n",
    "        kernel_2d = kernel_1d[:, None] * kernel_1d[None, :]\n",
    "        kernel = kernel_2d.expand(channels, 1, kernel_size, kernel_size)\n",
    "        \n",
    "        padding = kernel_size // 2\n",
    "        blurred = F.conv2d(image.unsqueeze(0), kernel, groups=channels, padding=padding)\n",
    "        return blurred.squeeze(0)\n",
    "    \n",
    "    def apply_false_color(self, grayscale_channel):\n",
    "        strategy = random.choice(['brown_deer', 'autumn_forest', 'summer_green', 'winter_muted'])\n",
    "        \n",
    "        if strategy == 'brown_deer':\n",
    "            r = torch.clamp(grayscale_channel * 1.1 + 0.1, 0, 1)\n",
    "            g = torch.clamp(grayscale_channel * 0.9 + 0.05, 0, 1)\n",
    "            b = torch.clamp(grayscale_channel * 0.7, 0, 1)\n",
    "        elif strategy == 'autumn_forest':\n",
    "            r = torch.clamp(grayscale_channel * 1.2 + 0.15, 0, 1)\n",
    "            g = torch.clamp(grayscale_channel * 1.0 + 0.08, 0, 1)\n",
    "            b = torch.clamp(grayscale_channel * 0.6, 0, 1)\n",
    "        elif strategy == 'summer_green':\n",
    "            r = torch.clamp(grayscale_channel * 0.8 + 0.1, 0, 1)\n",
    "            g = torch.clamp(grayscale_channel * 1.1 + 0.1, 0, 1)\n",
    "            b = torch.clamp(grayscale_channel * 0.8, 0, 1)\n",
    "        else:\n",
    "            r = torch.clamp(grayscale_channel * 0.95 + 0.05, 0, 1)\n",
    "            g = torch.clamp(grayscale_channel * 0.98 + 0.02, 0, 1)\n",
    "            b = torch.clamp(grayscale_channel * 1.05, 0, 1)\n",
    "        \n",
    "        return torch.stack([r, g, b], dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != IMAGE_SIZE:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=IMAGE_SIZE, mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if not self.test_time_aug and self.augmentation_strength != 'none':\n",
    "            image = self.advanced_augment(image)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class WarmupScheduler:\n",
    "    def __init__(self, optimizer, warmup_epochs, target_lr, total_epochs):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.target_lr = target_lr\n",
    "        self.total_epochs = total_epochs\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def step(self):\n",
    "        if self.current_epoch < self.warmup_epochs:\n",
    "            lr_scale = (self.current_epoch + 1) / self.warmup_epochs\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = self.target_lr * lr_scale\n",
    "        self.current_epoch += 1\n",
    "\n",
    "class GhostNetOptimizer:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"ghostnet_optimization_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            try:\n",
    "                from torch.cuda.amp import autocast, GradScaler\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "                print(\"Using mixed precision training\")\n",
    "            except ImportError:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "    \n",
    "    def create_optimized_model(self, config):\n",
    "        model = timm.create_model('ghostnet_100', pretrained=True, num_classes=1000)\n",
    "        \n",
    "        in_features = model.classifier.in_features\n",
    "        head_arch = config.get('head_architecture', 'simple')\n",
    "        \n",
    "        if head_arch == 'simple':\n",
    "            model.classifier = nn.Linear(in_features, self.num_classes)\n",
    "        elif head_arch == 'complex':\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(config['dropout']),\n",
    "                nn.Linear(in_features, in_features // 2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(config['dropout'] / 2),\n",
    "                nn.Linear(in_features // 2, self.num_classes)\n",
    "            )\n",
    "        else:\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(),\n",
    "                nn.Dropout(config['dropout']),\n",
    "                nn.Linear(in_features, in_features // 2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(config['dropout'] / 2),\n",
    "                nn.Linear(in_features // 2, in_features // 4),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(config['dropout'] / 4),\n",
    "                nn.Linear(in_features // 4, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        freeze_layers = config.get('freeze_layers', 3)\n",
    "        frozen_count = 0\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if 'features.' in name and frozen_count < freeze_layers:\n",
    "                if any(layer in name for layer in ['features.0.', 'features.1.', 'features.2.', 'features.3.', 'features.4.']):\n",
    "                    param.requires_grad = False\n",
    "                    frozen_count += 1\n",
    "        \n",
    "        model.to(self.device)\n",
    "        return model\n",
    "    \n",
    "    def create_enhanced_augmented_data(self, X_train, y_train):\n",
    "        class_counts = Counter(y_train)\n",
    "        target_count = AUGMENTATION_TARGET\n",
    "        \n",
    "        X_aug = []\n",
    "        y_aug = []\n",
    "        \n",
    "        for class_idx in range(len(set(y_train))):\n",
    "            class_mask = y_train == class_idx\n",
    "            class_images = X_train[class_mask]\n",
    "            current_count = len(class_images)\n",
    "            \n",
    "            if current_count == 0:\n",
    "                continue\n",
    "            \n",
    "            for _ in range(3):\n",
    "                X_aug.extend(class_images)\n",
    "                y_aug.extend([class_idx] * current_count)\n",
    "            \n",
    "            needed = target_count - (current_count * 3)\n",
    "            if needed > 0:\n",
    "                for i in range(needed):\n",
    "                    orig_idx = random.randint(0, current_count - 1)\n",
    "                    aug_img = self.enhanced_augment_image(class_images[orig_idx].copy())\n",
    "                    X_aug.append(aug_img)\n",
    "                    y_aug.append(class_idx)\n",
    "        \n",
    "        return np.array(X_aug), np.array(y_aug)\n",
    "    \n",
    "    def enhanced_augment_image(self, image):\n",
    "        if image.dtype != np.uint8:\n",
    "            image = image.astype(np.uint8)\n",
    "        \n",
    "        is_grayscale = np.allclose(image[:,:,0], image[:,:,1]) and np.allclose(image[:,:,1], image[:,:,2])\n",
    "        \n",
    "        if random.random() < 0.8:\n",
    "            angle = random.uniform(-25, 25)\n",
    "            h, w = image.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "            image = cv2.warpAffine(image, M, (w, h))\n",
    "        \n",
    "        if random.random() < 0.6:\n",
    "            image = cv2.flip(image, 1)\n",
    "        \n",
    "        if random.random() < 0.9:\n",
    "            alpha = random.uniform(0.7, 1.3) if is_grayscale else random.uniform(0.6, 1.4)\n",
    "            beta = random.randint(-20, 20) if is_grayscale else random.randint(-30, 30)\n",
    "            image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            gamma = random.uniform(0.6, 1.4)\n",
    "            inv_gamma = 1.0 / gamma\n",
    "            table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "            image = cv2.LUT(image, table)\n",
    "        \n",
    "        if random.random() < 0.4:\n",
    "            noise_strength = 10 if is_grayscale else 12\n",
    "            noise = np.random.normal(0, noise_strength, image.shape).astype(np.int16)\n",
    "            image_int16 = image.astype(np.int16)\n",
    "            noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "            image = noisy_image.astype(np.uint8)\n",
    "        \n",
    "        if random.random() < 0.3:\n",
    "            ksize = random.choice([3, 5])\n",
    "            image = cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def optimize_ghostnet(self, X_train, y_train, X_test, y_test, label_mapping):\n",
    "        results = []\n",
    "        best_config = None\n",
    "        best_score = 0.0\n",
    "        \n",
    "        print(f\"Starting optimization with {len(OPTIMIZATION_CONFIGS)} configurations\")\n",
    "        print(f\"Using {NUM_FOLDS}-fold cross-validation with {MAX_EPOCHS} max epochs per fold\")\n",
    "        \n",
    "        test_dataset = AdvancedAugmentationDataset(X_test, y_test, 'none', test_time_aug=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "        \n",
    "        for config_idx, config in enumerate(OPTIMIZATION_CONFIGS):\n",
    "            print(f\"\\n[{config_idx+1}/{len(OPTIMIZATION_CONFIGS)}] Testing: {config['name']}\")\n",
    "            \n",
    "            skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "            fold_cv_scores = []\n",
    "            fold_test_scores = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "                print(f\"  Fold {fold+1}/{NUM_FOLDS}\")\n",
    "                \n",
    "                X_train_fold = X_train[train_idx]\n",
    "                X_val_fold = X_train[val_idx]\n",
    "                y_train_fold = y_train[train_idx]\n",
    "                y_val_fold = y_train[val_idx]\n",
    "                \n",
    "                X_train_aug, y_train_aug = self.create_enhanced_augmented_data(X_train_fold, y_train_fold)\n",
    "                \n",
    "                train_dataset = AdvancedAugmentationDataset(X_train_aug, y_train_aug, config['augmentation_strength'])\n",
    "                val_dataset = AdvancedAugmentationDataset(X_val_fold, y_val_fold, 'none', test_time_aug=True)\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "                \n",
    "                model, val_acc, history = self.train_with_config(train_loader, val_loader, config)\n",
    "                test_acc, test_f1 = self.evaluate_test_performance(model, test_loader)\n",
    "                \n",
    "                fold_cv_scores.append(val_acc)\n",
    "                fold_test_scores.append(test_acc)\n",
    "                \n",
    "                print(f\"    CV: {val_acc:.2f}%, Test: {test_acc:.2f}%\")\n",
    "                \n",
    "                del model, train_loader, val_loader, train_dataset, val_dataset, X_train_aug, y_train_aug\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            cv_mean = np.mean(fold_cv_scores)\n",
    "            cv_std = np.std(fold_cv_scores)\n",
    "            test_mean = np.mean(fold_test_scores)\n",
    "            test_std = np.std(fold_test_scores)\n",
    "            \n",
    "            results.append({\n",
    "                'config_name': config['name'],\n",
    "                'config': config,\n",
    "                'cv_mean': cv_mean,\n",
    "                'cv_std': cv_std,\n",
    "                'test_mean': test_mean,\n",
    "                'test_std': test_std,\n",
    "                'fold_cv_scores': fold_cv_scores,\n",
    "                'fold_test_scores': fold_test_scores\n",
    "            })\n",
    "            \n",
    "            if test_mean > best_score:\n",
    "                best_score = test_mean\n",
    "                best_config = config\n",
    "                print(f\"  NEW BEST: {test_mean:.2f}% test accuracy\")\n",
    "            \n",
    "            print(f\"  Final: CV={cv_mean:.2f}±{cv_std:.2f}%, Test={test_mean:.2f}±{test_std:.2f}%\")\n",
    "        \n",
    "        self.save_results(results, label_mapping)\n",
    "        return results, best_config, None\n",
    "    \n",
    "    def train_with_config(self, train_loader, val_loader, config):\n",
    "        model = self.create_optimized_model(config)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': config['lr_backbone']},\n",
    "            {'params': classifier_params, 'lr': config['lr_head']}\n",
    "        ], weight_decay=config['weight_decay'])\n",
    "        \n",
    "        if config['scheduler'] == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n",
    "        elif config['scheduler'] == 'step':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "        else:\n",
    "            scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=config['lr_backbone']/10, max_lr=config['lr_backbone'], step_size_up=10)\n",
    "        \n",
    "        warmup_scheduler = WarmupScheduler(optimizer, config['warmup_epochs'], config['lr_backbone'], MAX_EPOCHS)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        training_history = {\n",
    "            'train_accs': [], 'val_accs': [], 'train_losses': [], 'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(MAX_EPOCHS):\n",
    "            if epoch < config['warmup_epochs']:\n",
    "                warmup_scheduler.step()\n",
    "            \n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "            \n",
    "            if epoch >= config['warmup_epochs']:\n",
    "                scheduler.step()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            \n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history\n",
    "    \n",
    "    def evaluate_test_performance(self, model, test_loader):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs1 = model(images)\n",
    "                        flipped = torch.flip(images, [3])\n",
    "                        outputs2 = model(flipped)\n",
    "                else:\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                \n",
    "                outputs = (outputs1 + outputs2) / 2\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        return accuracy, f1_macro\n",
    "    \n",
    "    def save_results(self, results, label_mapping):\n",
    "        results_file = os.path.join(self.save_dir, 'optimization_results.json')\n",
    "        \n",
    "        results_data = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'label_mapping': {str(k): v for k, v in label_mapping.items()},\n",
    "            'configs_tested': len(results),\n",
    "            'results': []\n",
    "        }\n",
    "        \n",
    "        for result in results:\n",
    "            results_data['results'].append({\n",
    "                'config_name': result['config_name'],\n",
    "                'config': result['config'],\n",
    "                'cv_mean': float(result['cv_mean']),\n",
    "                'cv_std': float(result['cv_std']),\n",
    "                'test_mean': float(result['test_mean']),\n",
    "                'test_std': float(result['test_std']),\n",
    "                'fold_cv_scores': [float(x) for x in result['fold_cv_scores']],\n",
    "                'fold_test_scores': [float(x) for x in result['fold_test_scores']]\n",
    "            })\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2)\n",
    "\n",
    "def load_color_and_grayscale_data():\n",
    "    fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\**\\\\*_NDA.png\"\n",
    "    image_paths = glob.glob(fpath, recursive=True)\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    color_count = 0\n",
    "    grayscale_count = 0\n",
    "    \n",
    "    print(f\"Loading {len(image_paths)} images...\")\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            original_is_grayscale = len(img.shape) == 2\n",
    "            \n",
    "            if len(img.shape) == 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                grayscale_count += 1\n",
    "            elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                color_count += 1\n",
    "            elif len(img.shape) == 3 and img.shape[2] == 4:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "                color_count += 1\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            img_resized = cv2.resize(img, (224, 224))\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            value_str = age_part.replace('p', '.')\n",
    "            age_value = float(value_str)\n",
    "            age_value = 5.5 if age_value >= 5.5 else age_value\n",
    "            \n",
    "            images.append(img_resized)\n",
    "            ages.append(age_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images ({color_count} color, {grayscale_count} grayscale)\")\n",
    "    \n",
    "    age_counts = Counter(ages)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    \n",
    "    for img, age in zip(images, ages):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages\n",
    "\n",
    "def main():\n",
    "    print(\"GhostNet-100 Advanced Optimization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    images, ages = load_color_and_grayscale_data()\n",
    "    \n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"Dataset: {len(images)} images, {len(unique_ages)} age classes\")\n",
    "    print(f\"Age distribution: {dict(Counter(ages))}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    print(f\"Training: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    \n",
    "    optimizer = GhostNetOptimizer(num_classes=len(unique_ages))\n",
    "    results, best_config, _ = optimizer.optimize_ghostnet(\n",
    "        X_train, y_train, X_test, y_test, label_mapping\n",
    "    )\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    best_score = max(result['test_mean'] for result in results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"{result['config_name']:>20}: \"\n",
    "              f\"CV={result['cv_mean']:.2f}±{result['cv_std']:.2f}%, \"\n",
    "              f\"Test={result['test_mean']:.2f}±{result['test_std']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nBest: {best_config['name']} - {best_score:.2f}%\")\n",
    "    print(f\"Training time: {elapsed:.1f} minutes\")\n",
    "    print(f\"Results saved to: {optimizer.save_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b5770-1cde-45f0-923b-35dadaf83033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
