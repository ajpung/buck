{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a5b6e2-ade6-40ef-9121-92a94d2a855e",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "\n",
    "This notebook takes the output result of `250813_nda_all` and attempts to optimize a single model instead of an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62247f7c-827d-4f33-99dd-bc10db9c0700",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccd28f-ace7-4023-989c-f597892f9d2b",
   "metadata": {},
   "source": [
    "### Initial color/grayscale exploration\n",
    "\n",
    "(ghostnet_100 wins, Val 84.2%, Test 72.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4928b-d228-4d97-b29e-b0b0abf0737e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Optimized Deer Age Prediction Model\n",
      "==================================================\n",
      "Loading color images...\n",
      "Loaded 199 color images\n",
      "Loading grayscale images...\n",
      "Loaded 37 grayscale images\n",
      "Total images: 236\n",
      "Final dataset: 236 images\n",
      "Age distribution: {2.5: 40, 3.5: 50, 4.5: 56, 5.5: 58, 1.5: 32}\n",
      "Source distribution: {'color': 199, 'grayscale': 37}\n",
      "\n",
      "Classes: 5\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "\n",
      "Data split:\n",
      "Train: 150 images\n",
      "Val: 38 images\n",
      "Test: 48 images\n",
      "\n",
      "Creating balanced training set...\n",
      "\n",
      "Original class distribution:\n",
      "  Class 0: 20 images\n",
      "  Class 1: 25 images\n",
      "  Class 2: 32 images\n",
      "  Class 3: 36 images\n",
      "  Class 4: 37 images\n",
      "\n",
      "Target samples per class: 1000\n",
      "  Class 0: 20 original + 980 augmented = 1000 total\n",
      "  Class 1: 25 original + 975 augmented = 1000 total\n",
      "  Class 2: 32 original + 968 augmented = 1000 total\n",
      "  Class 3: 36 original + 964 augmented = 1000 total\n",
      "  Class 4: 37 original + 963 augmented = 1000 total\n",
      "\n",
      "Final balanced class distribution:\n",
      "  Class 0: 1000 images\n",
      "  Class 1: 1000 images\n",
      "  Class 2: 1000 images\n",
      "  Class 3: 1000 images\n",
      "  Class 4: 1000 images\n",
      "Total training images after balancing: 5000\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Testing 15 diverse architectural families...\n",
      "[ 1/15] Testing efficientnet_b1...\n",
      "Training efficientnet_b1...\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 31 (patience reached)\n",
      "  efficientnet_b1 best validation: 73.7%\n",
      "  ‚úì efficientnet_b1: Val 73.7%, Test 70.8%\n",
      "\n",
      "[ 2/15] Testing resnet34...\n",
      "Training resnet34...\n",
      "    Epoch 20: Train 100.0%, Val 76.3%\n",
      "    Early stopping at epoch 32 (patience reached)\n",
      "  resnet34 best validation: 78.9%\n",
      "  ‚úì resnet34: Val 78.9%, Test 64.6%\n",
      "\n",
      "[ 3/15] Testing densenet169...\n",
      "Training densenet169...\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Epoch 40: Train 100.0%, Val 73.7%\n",
      "    Epoch 60: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 61 (patience reached)\n",
      "  densenet169 best validation: 81.6%\n",
      "  ‚úì densenet169: Val 81.6%, Test 66.7%\n",
      "\n",
      "[ 4/15] Testing hrnet_w32...\n",
      "Training hrnet_w32...\n",
      "    Epoch 20: Train 100.0%, Val 65.8%\n",
      "    Early stopping at epoch 26 (patience reached)\n",
      "  hrnet_w32 best validation: 81.6%\n",
      "  ‚úì hrnet_w32: Val 81.6%, Test 62.5%\n",
      "\n",
      "[ 5/15] Testing mobilenetv3_large_100...\n",
      "Training mobilenetv3_large_100...\n",
      "    Epoch 20: Train 100.0%, Val 78.9%\n",
      "    Early stopping at epoch 25 (patience reached)\n",
      "  mobilenetv3_large_100 best validation: 84.2%\n",
      "  ‚úì mobilenetv3_large_100: Val 84.2%, Test 68.8%\n",
      "\n",
      "[ 6/15] Testing vit_small_patch16_224...\n",
      "Training vit_small_patch16_224...\n",
      "    Epoch 20: Train 97.4%, Val 73.7%\n",
      "    Early stopping at epoch 27 (patience reached)\n",
      "  vit_small_patch16_224 best validation: 78.9%\n",
      "  ‚úì vit_small_patch16_224: Val 78.9%, Test 66.7%\n",
      "\n",
      "[ 7/15] Testing regnetx_004...\n",
      "Training regnetx_004...\n",
      "  ‚úó regnetx_004 failed: mat1 and mat2 shapes cannot be multiplied (32256x7...\n",
      "\n",
      "[ 8/15] Testing convnext_tiny...\n",
      "Training convnext_tiny...\n",
      "  ‚úó convnext_tiny failed: mat1 and mat2 shapes cannot be multiplied (64512x7...\n",
      "\n",
      "[ 9/15] Testing swin_tiny_patch4_window7_224...\n",
      "Training swin_tiny_patch4_window7_224...\n",
      "  ‚úó swin_tiny_patch4_window7_224 failed: only batches of spatial targets supported (3D tens...\n",
      "\n",
      "[10/15] Testing maxvit_tiny_tf_224...\n",
      "Training maxvit_tiny_tf_224...\n",
      "  ‚úó maxvit_tiny_tf_224 failed: mat1 and mat2 shapes cannot be multiplied (43008x7...\n",
      "\n",
      "[11/15] Testing repvgg_b1...\n",
      "Training repvgg_b1...\n",
      "  ‚úó repvgg_b1 failed: mat1 and mat2 shapes cannot be multiplied (172032x...\n",
      "\n",
      "[12/15] Testing ghostnet_100...\n",
      "Training ghostnet_100...\n",
      "    Epoch 20: Train 100.0%, Val 73.7%\n",
      "    Early stopping at epoch 29 (patience reached)\n",
      "  ghostnet_100 best validation: 84.2%\n",
      "  ‚úì ghostnet_100: Val 84.2%, Test 72.9%\n",
      "\n",
      "[13/15] Testing mobilevit_s...\n",
      "Training mobilevit_s...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9423ec14b924accbbfce9bacfa0a0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/22.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úó mobilevit_s failed: mat1 and mat2 shapes cannot be multiplied (53760x7...\n",
      "\n",
      "[14/15] Testing resnext50_32x4d...\n",
      "Training resnext50_32x4d...\n",
      "    Epoch 20: Train 100.0%, Val 63.2%\n",
      "    Early stopping at epoch 25 (patience reached)\n",
      "  resnext50_32x4d best validation: 73.7%\n",
      "  ‚úì resnext50_32x4d: Val 73.7%, Test 60.4%\n",
      "\n",
      "[15/15] Testing seresnet50...\n",
      "Training seresnet50...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 15 different architectural families for comprehensive testing\n",
    "TOP_ARCHITECTURES = [\n",
    "    'efficientnet_b1',           # 1. EfficientNet (Google)\n",
    "    'resnet34',                  # 2. ResNet (Microsoft Research)\n",
    "    'densenet169',               # 3. DenseNet (Cornell/Tsinghua)\n",
    "    'hrnet_w32',                 # 4. HRNet (Microsoft Research)\n",
    "    'mobilenetv3_large_100',     # 5. MobileNet (Google)\n",
    "    'vit_small_patch16_224',     # 6. Vision Transformer (Google)\n",
    "    'regnetx_004',               # 7. RegNet (Facebook)\n",
    "    'convnext_tiny',             # 8. ConvNeXt (Facebook)\n",
    "    'swin_tiny_patch4_window7_224', # 9. Swin Transformer (Microsoft)\n",
    "    'maxvit_tiny_tf_224',        # 10. MaxViT (Google)\n",
    "    'repvgg_b1',                 # 11. RepVGG (Tsinghua)\n",
    "    'ghostnet_100',              # 12. GhostNet (Huawei)\n",
    "    'mobilevit_s',               # 13. MobileViT (Apple)\n",
    "    'resnext50_32x4d',           # 14. ResNeXt (Facebook)\n",
    "    'seresnet50'                 # 15. SENet (WMW)\n",
    "]\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "BATCH_SIZE = 12  # RTX 2060 friendly\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    \"\"\"Detect if image is grayscale and convert to 3-channel RGB\"\"\"\n",
    "    if len(image.shape) == 2:  # Grayscale\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:  # Single channel\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:  # Already RGB\n",
    "            return image\n",
    "        elif image.shape[2] == 4:  # RGBA\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"Load data from both color and grayscale folders\"\"\"\n",
    "    color_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []  # Track if image came from color or grayscale\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter classes with enough samples\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    print(f\"Source distribution: {dict(Counter(filtered_sources))}\")\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    \"\"\"Enhanced augmentation for deer images with strategic color conversion\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Rotation\n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Strategic color conversion (RGB -> Grayscale -> RGB)\n",
    "    # Based on ensemble results showing grayscale superiority\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Brightness/contrast\n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gamma correction\n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    # Noise\n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_balanced_dataset(X, y):\n",
    "    \"\"\"Create balanced dataset through augmentation\"\"\"\n",
    "    print(f\"\\nOriginal class distribution:\")\n",
    "    class_counts = Counter(y)\n",
    "    for class_idx, count in sorted(class_counts.items()):\n",
    "        print(f\"  Class {class_idx}: {count} images\")\n",
    "    \n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    print(f\"\\nTarget samples per class: {target_count}\")\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for class_idx in range(len(set(y))):\n",
    "        class_mask = np.array(y) == class_idx\n",
    "        class_images = X[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add originals\n",
    "        X_balanced.extend(class_images)\n",
    "        y_balanced.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented to reach target\n",
    "        needed = target_count - current_count\n",
    "        augmented_for_class = 0\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_balanced.append(aug_img)\n",
    "            y_balanced.append(class_idx)\n",
    "            augmented_for_class += 1\n",
    "        \n",
    "        print(f\"  Class {class_idx}: {current_count} original + {augmented_for_class} augmented = {current_count + augmented_for_class} total\")\n",
    "    \n",
    "    # Verify final balance\n",
    "    final_counts = Counter(y_balanced)\n",
    "    print(f\"\\nFinal balanced class distribution:\")\n",
    "    for class_idx, count in sorted(final_counts.items()):\n",
    "        print(f\"  Class {class_idx}: {count} images\")\n",
    "    \n",
    "    print(f\"Total training images after balancing: {len(X_balanced)}\")\n",
    "    \n",
    "    return np.array(X_balanced), np.array(y_balanced)\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.training = training\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        # Ensure CHW format\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        # Test time augmentation for validation\n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        # ImageNet normalization\n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class SingleModelTrainer:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"single_model_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        \"\"\"Create model with optimized head for diverse architectures\"\"\"\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Architecture-specific layer freezing\n",
    "        if any(arch in architecture for arch in ['resnet', 'resnext', 'seresnet']):\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2']\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in frozen_layers):\n",
    "                    param.requires_grad = False\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(block in name for block in ['blocks.0', 'blocks.1', 'blocks.2']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'densenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['features.conv0', 'features.norm0', 'features.denseblock1']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'hrnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['conv1', 'bn1', 'stage1']):\n",
    "                    param.requires_grad = False\n",
    "        elif any(arch in architecture for arch in ['mobilenet', 'ghostnet']):\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['features.0', 'features.1', 'features.2']):\n",
    "                    param.requires_grad = False\n",
    "        elif any(arch in architecture for arch in ['vit', 'swin', 'mobilevit']):\n",
    "            # Freeze patch embedding and early transformer blocks\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['patch_embed', 'blocks.0', 'blocks.1', 'layers.0']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'regnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stem', 's1']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'convnext' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stem', 'stages.0']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'maxvit' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stem', 'stages.0']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'repvgg' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stage0', 'stage1']):\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier head based on architecture\n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'head'):\n",
    "            if hasattr(model.head, 'in_features'):\n",
    "                in_features = model.head.in_features\n",
    "            else:\n",
    "                in_features = model.head[-1].in_features if hasattr(model.head, '__getitem__') else 512\n",
    "            model.head = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_architecture(self, train_loader, val_loader, architecture):\n",
    "        \"\"\"Train a single architecture\"\"\"\n",
    "        print(f\"Training {architecture}...\")\n",
    "        \n",
    "        model = self.create_model(architecture)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        # Separate learning rates\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if any(head in name for head in ['fc', 'classifier', 'head']):\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0002},\n",
    "            {'params': classifier_params, 'lr': 0.0008}\n",
    "        ], weight_decay=0.02)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 25  # Increased patience\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(80):  # Increased max epochs\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch} (patience reached)\")\n",
    "                break\n",
    "            \n",
    "            # Memory management for RTX 2060\n",
    "            if epoch % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load best weights\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        print(f\"  {architecture} best validation: {best_val_acc:.1f}%\")\n",
    "        return model, best_val_acc\n",
    "    \n",
    "    def find_best_architecture(self, train_loader, val_loader, test_loader):\n",
    "        \"\"\"Test all architectures and return the best\"\"\"\n",
    "        results = {}\n",
    "        failed_archs = []\n",
    "        \n",
    "        print(f\"Testing {len(TOP_ARCHITECTURES)} diverse architectural families...\")\n",
    "        for i, arch in enumerate(TOP_ARCHITECTURES, 1):\n",
    "            try:\n",
    "                print(f\"[{i:2d}/{len(TOP_ARCHITECTURES)}] Testing {arch}...\")\n",
    "                model, val_acc = self.train_single_architecture(train_loader, val_loader, arch)\n",
    "                \n",
    "                # Evaluate on test set for comparison (not selection)\n",
    "                test_acc = evaluate_model(model, test_loader, self.device)\n",
    "                \n",
    "                results[arch] = (model, val_acc, test_acc)\n",
    "                print(f\"  ‚úì {arch}: Val {val_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "                print()  # Add blank line between architectures\n",
    "                torch.cuda.empty_cache()\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚úó {arch} failed: {str(e)[:50]}...\")\n",
    "                print()  # Add blank line for failed architectures too\n",
    "                failed_archs.append(arch)\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "        \n",
    "        if not results:\n",
    "            raise ValueError(\"All architectures failed to train!\")\n",
    "        \n",
    "        # Find best based on VALIDATION (not test) to avoid contamination\n",
    "        best_arch = max(results.keys(), key=lambda x: results[x][1])\n",
    "        best_model, best_val_acc, best_test_acc = results[best_arch]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ARCHITECTURE COMPARISON RESULTS\")\n",
    "        print('='*60)\n",
    "        print(f\"{'Rank':<4} {'Architecture':<30} {'Validation':<12} {'Test':<8}\")\n",
    "        print('-'*60)\n",
    "        \n",
    "        # Sort by validation performance for ranking\n",
    "        sorted_results = sorted(results.items(), key=lambda x: x[1][1], reverse=True)\n",
    "        for i, (arch, (_, val_acc, test_acc)) in enumerate(sorted_results, 1):\n",
    "            marker = \"üèÜ\" if arch == best_arch else \"  \"\n",
    "            print(f\"{i:2d}. {marker} {arch:<28} {val_acc:5.1f}%      {test_acc:5.1f}%\")\n",
    "        \n",
    "        if failed_archs:\n",
    "            print(f\"\\nFailed architectures ({len(failed_archs)}): {', '.join(failed_archs)}\")\n",
    "        \n",
    "        print(f\"\\nüèÜ WINNER: {best_arch} (Val: {best_val_acc:.1f}%, Test: {best_test_acc:.1f}%)\")\n",
    "        print(\"Note: Selection based on validation performance to avoid test contamination\")\n",
    "        \n",
    "        return best_model, best_arch, best_val_acc\n",
    "    \n",
    "    def final_optimization(self, model, train_loader, val_loader, architecture):\n",
    "        \"\"\"Final optimization of the best model\"\"\"\n",
    "        print(f\"\\nFinal optimization of {architecture}...\")\n",
    "        \n",
    "        # Unfreeze more layers for fine-tuning\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Lower learning rate for fine-tuning\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.01)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-7)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 15\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(50):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Test time augmentation\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"  Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        print(f\"  Final optimization complete: {best_val_acc:.1f}%\")\n",
    "        return model, best_val_acc\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Test time augmentation\n",
    "            outputs1 = model(images)\n",
    "            flipped = torch.flip(images, [3])\n",
    "            outputs2 = model(flipped)\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return test_acc\n",
    "\n",
    "def main():\n",
    "    print(\"Single Optimized Deer Age Prediction Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load combined data\n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    # Create label mapping\n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"\\nClasses: {len(unique_ages)}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Further split training into train/val\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Train: {len(X_train_final)} images\")\n",
    "    print(f\"Val: {len(X_val)} images\") \n",
    "    print(f\"Test: {len(X_test)} images\")\n",
    "    \n",
    "    # Create balanced training set\n",
    "    print(\"\\nCreating balanced training set...\")\n",
    "    X_train_balanced, y_train_balanced = create_balanced_dataset(X_train_final, y_train_final)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DeerDataset(X_train_balanced, y_train_balanced, training=True)\n",
    "    val_dataset = DeerDataset(X_val, y_val, training=False)\n",
    "    test_dataset = DeerDataset(X_test, y_test, training=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = SingleModelTrainer(num_classes=len(unique_ages))\n",
    "    \n",
    "    # Find best architecture\n",
    "    best_model, best_arch, val_acc = trainer.find_best_architecture(train_loader, val_loader, test_loader)\n",
    "    \n",
    "    # Final optimization\n",
    "    optimized_model, final_val_acc = trainer.final_optimization(best_model, train_loader, val_loader, best_arch)\n",
    "    \n",
    "    # Test evaluation\n",
    "    test_acc = evaluate_model(optimized_model, test_loader, trainer.device)\n",
    "    \n",
    "    # Save final model\n",
    "    save_path = os.path.join(trainer.save_dir, f\"deer_age_model_{best_arch}_{test_acc:.1f}pct.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dict': optimized_model.state_dict(),\n",
    "        'architecture': best_arch,\n",
    "        'num_classes': len(unique_ages),\n",
    "        'label_mapping': label_mapping,\n",
    "        'test_accuracy': test_acc,\n",
    "        'val_accuracy': final_val_acc,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, save_path)\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Best architecture: {best_arch}\")\n",
    "    print(f\"Validation accuracy: {final_val_acc:.1f}%\")\n",
    "    print(f\"Test accuracy: {test_acc:.1f}%\")\n",
    "    print(f\"Training time: {elapsed:.1f} minutes\")\n",
    "    print(f\"Model saved: {save_path}\")\n",
    "    \n",
    "    return optimized_model, best_arch, test_acc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, architecture, accuracy = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1083fe-4efc-4cf3-874a-b0056cb1eafa",
   "metadata": {},
   "source": [
    "### Fine-tuning hyperparameters of ghostnet_100\n",
    "\n",
    "- original: Val 84.2%, Test 72.9%\n",
    "- tuned: Val 84.2%, Test 81.2%\n",
    "  ```\n",
    "  [23/30] Testing combination 23\n",
    "  Optimizer: adamw, LR: 0.0001/0.0005\n",
    "  Batch: 12, Dropout: 0.3, Freeze: 4\n",
    "    Epoch 20: Train 100.0%, Val 78.9%\n",
    "    Early stopping at epoch 25\n",
    "  ‚úì Val: 84.2%, Test: 81.2%\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb90355-602e-495d-a537-d567709b2de2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GhostNet Hyperparameter Search Space\n",
    "HYPERPARAMETER_GRID = {\n",
    "    'backbone_lr': [0.0001, 0.0003, 0.0005],\n",
    "    'classifier_lr': [0.0005, 0.001, 0.002],\n",
    "    'weight_decay': [0.01, 0.03, 0.05],\n",
    "    'batch_size': [8, 12, 16],\n",
    "    'optimizer': ['adamw', 'sgd'],\n",
    "    'scheduler': ['cosine', 'plateau'],\n",
    "    'dropout': [0.2, 0.3, 0.4, 0.5],\n",
    "    'label_smoothing': [0.05, 0.1, 0.15],\n",
    "    'augmentation_strength': ['light', 'medium', 'heavy'],\n",
    "    'freeze_layers': [2, 3, 4]  # How many early block groups to freeze\n",
    "}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "MAX_COMBINATIONS = 30  # Test 30 combinations\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    \"\"\"Detect if image is grayscale and convert to 3-channel RGB\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"Load data from both color and grayscale folders\"\"\"\n",
    "    color_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter classes with enough samples\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image, strength='medium'):\n",
    "    \"\"\"Enhanced augmentation with variable strength\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Set probabilities based on strength\n",
    "    if strength == 'light':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.5, 0.3, 0.6, 0.2, 0.1\n",
    "        rot_range, bright_range = 10, (0.8, 1.2)\n",
    "    elif strength == 'medium':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.7, 0.5, 0.8, 0.4, 0.3\n",
    "        rot_range, bright_range = 15, (0.7, 1.3)\n",
    "    else:  # heavy\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.8, 0.6, 0.9, 0.5, 0.4\n",
    "        rot_range, bright_range = 20, (0.6, 1.4)\n",
    "    \n",
    "    # Rotation\n",
    "    if random.random() < rot_prob:\n",
    "        angle = random.uniform(-rot_range, rot_range)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if random.random() < flip_prob:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Strategic color conversion (RGB -> Grayscale -> RGB)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Brightness/contrast\n",
    "    if random.random() < bright_prob:\n",
    "        alpha = random.uniform(*bright_range)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gamma correction\n",
    "    if random.random() < gamma_prob:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    # Noise\n",
    "    if random.random() < noise_prob:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_balanced_dataset(X, y, aug_strength='medium'):\n",
    "    \"\"\"Create balanced dataset through augmentation\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for class_idx in range(len(set(y))):\n",
    "        class_mask = np.array(y) == class_idx\n",
    "        class_images = X[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add originals\n",
    "        X_balanced.extend(class_images)\n",
    "        y_balanced.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented to reach target\n",
    "        needed = target_count - current_count\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy(), aug_strength)\n",
    "            X_balanced.append(aug_img)\n",
    "            y_balanced.append(class_idx)\n",
    "    \n",
    "    return np.array(X_balanced), np.array(y_balanced)\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.training = training\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class GhostNetHyperparameterTuner:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"ghostnet_tuning_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    def create_ghostnet_model(self, dropout=0.3, freeze_layers=3):\n",
    "        \"\"\"Create GhostNet model with specified dropout and freezing\"\"\"\n",
    "        model = timm.create_model('ghostnet_100', pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Freeze early layers based on freeze_layers parameter\n",
    "        freeze_patterns = [\n",
    "            ['conv_stem'],\n",
    "            ['conv_stem', 'blocks.0'],\n",
    "            ['conv_stem', 'blocks.0', 'blocks.1'],\n",
    "            ['conv_stem', 'blocks.0', 'blocks.1', 'blocks.2']\n",
    "        ]\n",
    "        \n",
    "        if freeze_layers <= len(freeze_patterns):\n",
    "            for name, param in model.named_parameters():\n",
    "                for pattern in freeze_patterns[freeze_layers - 1]:\n",
    "                    if pattern in name:\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        \n",
    "        # Replace classifier with custom dropout\n",
    "        if hasattr(model, 'classifier'):\n",
    "            in_features = model.classifier.in_features\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_optimizer(self, model, opt_type, backbone_lr, classifier_lr, weight_decay):\n",
    "        \"\"\"Create optimizer based on hyperparameters\"\"\"\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': backbone_lr},\n",
    "            {'params': classifier_params, 'lr': classifier_lr}\n",
    "        ]\n",
    "        \n",
    "        if opt_type == 'adamw':\n",
    "            return optim.AdamW(param_groups, weight_decay=weight_decay)\n",
    "        elif opt_type == 'sgd':\n",
    "            return optim.SGD(param_groups, weight_decay=weight_decay, momentum=0.9)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {opt_type}\")\n",
    "    \n",
    "    def get_scheduler(self, optimizer, scheduler_type, max_epochs):\n",
    "        \"\"\"Create learning rate scheduler\"\"\"\n",
    "        if scheduler_type == 'cosine':\n",
    "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=1e-6)\n",
    "        elif scheduler_type == 'plateau':\n",
    "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5, verbose=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler: {scheduler_type}\")\n",
    "    \n",
    "    def train_with_hyperparams(self, train_loader, val_loader, test_loader, hyperparams, combo_num):\n",
    "        \"\"\"Train model with specific hyperparameters\"\"\"\n",
    "        model = self.create_ghostnet_model(\n",
    "            dropout=hyperparams['dropout'], \n",
    "            freeze_layers=hyperparams['freeze_layers']\n",
    "        )\n",
    "        \n",
    "        optimizer = self.get_optimizer(\n",
    "            model, hyperparams['optimizer'], \n",
    "            hyperparams['backbone_lr'], hyperparams['classifier_lr'], \n",
    "            hyperparams['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = self.get_scheduler(optimizer, hyperparams['scheduler'], 80)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=hyperparams['label_smoothing'])\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 20\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(80):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Update scheduler\n",
    "            if hyperparams['scheduler'] == 'plateau':\n",
    "                scheduler.step(val_acc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Print progress every 20 epochs\n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load best weights and evaluate on test\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        # Test evaluation with TTA\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Test time augmentation\n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                outputs = (outputs1 + outputs2) / 2\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        return model, best_val_acc, test_acc\n",
    "    \n",
    "    def generate_hyperparameter_combinations(self):\n",
    "        \"\"\"Generate smart hyperparameter combinations\"\"\"\n",
    "        # Create all possible combinations\n",
    "        keys = list(HYPERPARAMETER_GRID.keys())\n",
    "        values = list(HYPERPARAMETER_GRID.values())\n",
    "        all_combinations = list(itertools.product(*values))\n",
    "        \n",
    "        # Shuffle and limit\n",
    "        random.shuffle(all_combinations)\n",
    "        selected_combinations = all_combinations[:MAX_COMBINATIONS]\n",
    "        \n",
    "        # Convert to list of dictionaries\n",
    "        combinations = []\n",
    "        for combo in selected_combinations:\n",
    "            hyperparams = dict(zip(keys, combo))\n",
    "            combinations.append(hyperparams)\n",
    "        \n",
    "        return combinations\n",
    "    \n",
    "    def tune_hyperparameters(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "        \"\"\"Main hyperparameter tuning loop\"\"\"\n",
    "        print(f\"Starting GhostNet hyperparameter tuning...\")\n",
    "        print(f\"Testing {MAX_COMBINATIONS} hyperparameter combinations\")\n",
    "        \n",
    "        combinations = self.generate_hyperparameter_combinations()\n",
    "        results = []\n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        for i, hyperparams in enumerate(combinations, 1):\n",
    "            print(f\"\\n[{i:2d}/{MAX_COMBINATIONS}] Testing combination {i}\")\n",
    "            print(f\"  Optimizer: {hyperparams['optimizer']}, LR: {hyperparams['backbone_lr']}/{hyperparams['classifier_lr']}\")\n",
    "            print(f\"  Batch: {hyperparams['batch_size']}, Dropout: {hyperparams['dropout']}, Freeze: {hyperparams['freeze_layers']}\")\n",
    "            \n",
    "            try:\n",
    "                # Create datasets with current augmentation strength\n",
    "                X_train_aug, y_train_aug = create_balanced_dataset(\n",
    "                    X_train, y_train, hyperparams['augmentation_strength']\n",
    "                )\n",
    "                \n",
    "                train_dataset = DeerDataset(X_train_aug, y_train_aug, training=True)\n",
    "                val_dataset = DeerDataset(X_val, y_val, training=False)\n",
    "                test_dataset = DeerDataset(X_test, y_test, training=False)\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True, num_workers=0)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=hyperparams['batch_size'], shuffle=False, num_workers=0)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=hyperparams['batch_size'], shuffle=False, num_workers=0)\n",
    "                \n",
    "                model, val_acc, test_acc = self.train_with_hyperparams(\n",
    "                    train_loader, val_loader, test_loader, hyperparams, i\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    'combination': i,\n",
    "                    'hyperparams': hyperparams,\n",
    "                    'val_accuracy': val_acc,\n",
    "                    'test_accuracy': test_acc\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "                print(f\"  ‚úì Val: {val_acc:.1f}%, Test: {test_acc:.1f}%\")\n",
    "                \n",
    "                # Save best model so far\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_path = os.path.join(self.save_dir, f\"ghostnet_best_val_{val_acc:.1f}.pth\")\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'hyperparams': hyperparams,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'test_accuracy': test_acc,\n",
    "                        'combination': i\n",
    "                    }, best_path)\n",
    "                    print(f\"  üíæ New best model saved: {val_acc:.1f}%\")\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚úó Combination {i} failed: {str(e)[:60]}...\")\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "        \n",
    "        # Save all results\n",
    "        results_path = os.path.join(self.save_dir, \"hyperparameter_results.json\")\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        return results\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set with TTA\"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Test time augmentation\n",
    "            outputs1 = model(images)\n",
    "            flipped = torch.flip(images, [3])\n",
    "            outputs2 = model(flipped)\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return test_acc\n",
    "\n",
    "def main():\n",
    "    print(\"GhostNet Hyperparameter Tuning for Deer Age Prediction\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load combined data\n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    # Create label mapping\n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"\\nClasses: {len(unique_ages)}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Further split training into train/val\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Train: {len(X_train_final)} images\")\n",
    "    print(f\"Val: {len(X_val)} images\") \n",
    "    print(f\"Test: {len(X_test)} images\")\n",
    "    \n",
    "    # Initialize tuner\n",
    "    tuner = GhostNetHyperparameterTuner(num_classes=len(unique_ages))\n",
    "    \n",
    "    # Run hyperparameter tuning\n",
    "    results = tuner.tune_hyperparameters(X_train_final, y_train_final, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    # Analyze results\n",
    "    if results:\n",
    "        # Sort by validation accuracy\n",
    "        sorted_results = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"GHOSTNET HYPERPARAMETER TUNING RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"{'Rank':<4} {'Combination':<6} {'Validation':<12} {'Test':<8} {'Key Hyperparams'}\")\n",
    "        print('-' * 75)\n",
    "        \n",
    "        for i, result in enumerate(sorted_results[:10], 1):  # Top 10\n",
    "            hp = result['hyperparams']\n",
    "            key_params = f\"opt={hp['optimizer']}, lr={hp['backbone_lr']}, bs={hp['batch_size']}, drop={hp['dropout']}\"\n",
    "            print(f\"{i:2d}. {result['combination']:4d}       {result['val_accuracy']:5.1f}%      {result['test_accuracy']:5.1f}%    {key_params}\")\n",
    "        \n",
    "        best_result = sorted_results[0]\n",
    "        print(f\"\\nüèÜ BEST HYPERPARAMETERS:\")\n",
    "        for key, value in best_result['hyperparams'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        print(f\"\\nüìä PERFORMANCE:\")\n",
    "        print(f\"  Best Validation: {best_result['val_accuracy']:.1f}%\")\n",
    "        print(f\"  Best Test: {best_result['test_accuracy']:.1f}%\")\n",
    "        print(f\"  Tuning Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"  Results saved to: {tuner.save_dir}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No successful combinations found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9eeae-fac6-4e5c-8470-2c2ad0050976",
   "metadata": {},
   "source": [
    "### Removing randomness from the dataset applied to each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff8203-8b4e-4c4a-9929-eb4ccd19cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused GhostNet Hyperparameter Tuning for Deer Age Prediction\n",
      "======================================================================\n",
      "Loading color images...\n",
      "Loaded 200 color images\n",
      "Loading grayscale images...\n",
      "Loaded 38 grayscale images\n",
      "Total images: 238\n",
      "Final dataset: 238 images\n",
      "Age distribution: {2.5: 40, 3.5: 50, 4.5: 56, 5.5: 60, 1.5: 32}\n",
      "\n",
      "Classes: 5\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "\n",
      "Data split:\n",
      "Train: 152 images\n",
      "Val: 38 images\n",
      "Test: 48 images\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Starting Focused GhostNet hyperparameter tuning...\n",
      "Testing 324 hyperparameter combinations (best-first strategy)\n",
      "\n",
      "[  1/324] Testing combination 1\n",
      "  Optimizer: adamw, LR: 0.0001/0.0005\n",
      "  Batch: 12, Dropout: 0.3, Freeze: 4\n",
      "  ‚≠ê PRIORITY COMBINATION (known good)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def set_reproducible_seeds(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Ultra-focused GhostNet Hyperparameter Search Space around best results\n",
    "HYPERPARAMETER_GRID = {\n",
    "    'backbone_lr': [0.00009, 0.0001, 0.00011],          # Very tight around 0.0001\n",
    "    'classifier_lr': [0.00045, 0.0005, 0.00055],        # Very tight around 0.0005\n",
    "    'weight_decay': [0.009, 0.01, 0.011],               # Very tight around 0.01\n",
    "    'batch_size': [12, 14],                             # Focus on 12 and 14\n",
    "    'optimizer': ['adamw'],                              # Fixed at adamw\n",
    "    'scheduler': ['cosine', 'plateau'],                  # Keep both\n",
    "    'dropout': [0.25, 0.3, 0.32],                       # Around 0.25-0.3\n",
    "    'label_smoothing': [0.09, 0.1, 0.11],               # Very tight around 0.1\n",
    "    'augmentation_strength': ['medium'],                 # Fixed at medium\n",
    "    'freeze_layers': [3, 4]                             # Keep 3-4\n",
    "}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "MAX_COMBINATIONS = 324  # Test all combinations in focused grid\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    \"\"\"Detect if image is grayscale and convert to 3-channel RGB\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"Load data from both color and grayscale folders\"\"\"\n",
    "    color_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter classes with enough samples\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image, strength='medium'):\n",
    "    \"\"\"Enhanced augmentation with variable strength\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Set probabilities based on strength\n",
    "    if strength == 'light':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.5, 0.3, 0.6, 0.2, 0.1\n",
    "        rot_range, bright_range = 10, (0.8, 1.2)\n",
    "    elif strength == 'medium':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.7, 0.5, 0.8, 0.4, 0.3\n",
    "        rot_range, bright_range = 15, (0.7, 1.3)\n",
    "    else:  # heavy\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.8, 0.6, 0.9, 0.5, 0.4\n",
    "        rot_range, bright_range = 20, (0.6, 1.4)\n",
    "    \n",
    "    # Rotation\n",
    "    if random.random() < rot_prob:\n",
    "        angle = random.uniform(-rot_range, rot_range)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if random.random() < flip_prob:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Strategic color conversion (RGB -> Grayscale -> RGB)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Brightness/contrast\n",
    "    if random.random() < bright_prob:\n",
    "        alpha = random.uniform(*bright_range)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gamma correction\n",
    "    if random.random() < gamma_prob:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    # Noise\n",
    "    if random.random() < noise_prob:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_balanced_dataset(X, y, aug_strength='medium'):\n",
    "    \"\"\"Create balanced dataset through augmentation\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for class_idx in range(len(set(y))):\n",
    "        class_mask = np.array(y) == class_idx\n",
    "        class_images = X[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add originals\n",
    "        X_balanced.extend(class_images)\n",
    "        y_balanced.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented to reach target\n",
    "        needed = target_count - current_count\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy(), aug_strength)\n",
    "            X_balanced.append(aug_img)\n",
    "            y_balanced.append(class_idx)\n",
    "    \n",
    "    return np.array(X_balanced), np.array(y_balanced)\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.training = training\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class GhostNetHyperparameterTuner:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"ghostnet_focused_tuning_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            torch.backends.cudnn.benchmark = False  # Set to False for reproducibility\n",
    "    \n",
    "    def create_ghostnet_model(self, dropout=0.3, freeze_layers=3):\n",
    "        \"\"\"Create GhostNet model with specified dropout and freezing\"\"\"\n",
    "        model = timm.create_model('ghostnet_100', pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Freeze early layers based on freeze_layers parameter\n",
    "        freeze_patterns = [\n",
    "            ['conv_stem'],\n",
    "            ['conv_stem', 'blocks.0'],\n",
    "            ['conv_stem', 'blocks.0', 'blocks.1'],\n",
    "            ['conv_stem', 'blocks.0', 'blocks.1', 'blocks.2']\n",
    "        ]\n",
    "        \n",
    "        if freeze_layers <= len(freeze_patterns):\n",
    "            for name, param in model.named_parameters():\n",
    "                for pattern in freeze_patterns[freeze_layers - 1]:\n",
    "                    if pattern in name:\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        \n",
    "        # Replace classifier with custom dropout\n",
    "        if hasattr(model, 'classifier'):\n",
    "            in_features = model.classifier.in_features\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_optimizer(self, model, opt_type, backbone_lr, classifier_lr, weight_decay):\n",
    "        \"\"\"Create optimizer based on hyperparameters\"\"\"\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': backbone_lr},\n",
    "            {'params': classifier_params, 'lr': classifier_lr}\n",
    "        ]\n",
    "        \n",
    "        if opt_type == 'adamw':\n",
    "            return optim.AdamW(param_groups, weight_decay=weight_decay)\n",
    "        elif opt_type == 'sgd':\n",
    "            return optim.SGD(param_groups, weight_decay=weight_decay, momentum=0.9)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {opt_type}\")\n",
    "    \n",
    "    def get_scheduler(self, optimizer, scheduler_type, max_epochs):\n",
    "        \"\"\"Create learning rate scheduler\"\"\"\n",
    "        if scheduler_type == 'cosine':\n",
    "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=1e-6)\n",
    "        elif scheduler_type == 'plateau':\n",
    "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5, verbose=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler: {scheduler_type}\")\n",
    "    \n",
    "    def train_with_hyperparams(self, train_loader, val_loader, test_loader, hyperparams, combo_num):\n",
    "        \"\"\"Train model with specific hyperparameters\"\"\"\n",
    "        # Set seed for this specific combination\n",
    "        torch.manual_seed(42 + combo_num)\n",
    "        \n",
    "        model = self.create_ghostnet_model(\n",
    "            dropout=hyperparams['dropout'], \n",
    "            freeze_layers=hyperparams['freeze_layers']\n",
    "        )\n",
    "        \n",
    "        optimizer = self.get_optimizer(\n",
    "            model, hyperparams['optimizer'], \n",
    "            hyperparams['backbone_lr'], hyperparams['classifier_lr'], \n",
    "            hyperparams['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = self.get_scheduler(optimizer, hyperparams['scheduler'], 80)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=hyperparams['label_smoothing'])\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 20\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(80):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Update scheduler\n",
    "            if hyperparams['scheduler'] == 'plateau':\n",
    "                scheduler.step(val_acc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Print progress every 20 epochs\n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load best weights and evaluate on test\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        # Test evaluation with TTA\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Test time augmentation\n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                outputs = (outputs1 + outputs2) / 2\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        return model, best_val_acc, test_acc\n",
    "    \n",
    "    def generate_best_first_combinations(self):\n",
    "        \"\"\"Test known good combinations first, then systematic exploration\"\"\"\n",
    "        # Your best known combinations first\n",
    "        priority_combinations = [\n",
    "            {\n",
    "                'backbone_lr': 0.0001, 'classifier_lr': 0.0005, 'weight_decay': 0.01,\n",
    "                'batch_size': 12, 'optimizer': 'adamw', 'scheduler': 'cosine',\n",
    "                'dropout': 0.3, 'label_smoothing': 0.1, 'augmentation_strength': 'medium',\n",
    "                'freeze_layers': 4\n",
    "            },\n",
    "            {\n",
    "                'backbone_lr': 0.0001, 'classifier_lr': 0.00055, 'weight_decay': 0.01,\n",
    "                'batch_size': 14, 'optimizer': 'adamw', 'scheduler': 'cosine',\n",
    "                'dropout': 0.25, 'label_smoothing': 0.1, 'augmentation_strength': 'medium',\n",
    "                'freeze_layers': 3\n",
    "            },\n",
    "            {\n",
    "                'backbone_lr': 0.0001, 'classifier_lr': 0.0005, 'weight_decay': 0.01,\n",
    "                'batch_size': 12, 'optimizer': 'adamw', 'scheduler': 'plateau',\n",
    "                'dropout': 0.3, 'label_smoothing': 0.1, 'augmentation_strength': 'medium',\n",
    "                'freeze_layers': 4\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Generate all systematic combinations\n",
    "        keys = list(HYPERPARAMETER_GRID.keys())\n",
    "        values = list(HYPERPARAMETER_GRID.values())\n",
    "        all_combinations = list(itertools.product(*values))\n",
    "        \n",
    "        # Convert to dictionaries\n",
    "        all_combo_dicts = []\n",
    "        for combo in all_combinations:\n",
    "            combo_dict = dict(zip(keys, combo))\n",
    "            # Skip if already in priority list\n",
    "            if combo_dict not in priority_combinations:\n",
    "                all_combo_dicts.append(combo_dict)\n",
    "        \n",
    "        # Return priority first, then systematic exploration\n",
    "        final_combinations = priority_combinations + all_combo_dicts\n",
    "        return final_combinations[:MAX_COMBINATIONS]\n",
    "    \n",
    "    def tune_hyperparameters(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "        \"\"\"Main hyperparameter tuning loop\"\"\"\n",
    "        print(f\"Starting Focused GhostNet hyperparameter tuning...\")\n",
    "        \n",
    "        combinations = self.generate_best_first_combinations()\n",
    "        actual_combinations = min(len(combinations), MAX_COMBINATIONS)\n",
    "        print(f\"Testing {actual_combinations} hyperparameter combinations (best-first strategy)\")\n",
    "        \n",
    "        results = []\n",
    "        best_val_acc = 0.0\n",
    "        best_test_acc = 0.0\n",
    "        \n",
    "        for i, hyperparams in enumerate(combinations[:MAX_COMBINATIONS], 1):\n",
    "            print(f\"\\n[{i:3d}/{actual_combinations}] Testing combination {i}\")\n",
    "            print(f\"  Optimizer: {hyperparams['optimizer']}, LR: {hyperparams['backbone_lr']}/{hyperparams['classifier_lr']}\")\n",
    "            print(f\"  Batch: {hyperparams['batch_size']}, Dropout: {hyperparams['dropout']}, Freeze: {hyperparams['freeze_layers']}\")\n",
    "            if i <= 3:\n",
    "                print(f\"  ‚≠ê PRIORITY COMBINATION (known good)\")\n",
    "            \n",
    "            try:\n",
    "                # Set seed for reproducible augmentation\n",
    "                set_reproducible_seeds(42 + i)\n",
    "                \n",
    "                # Create datasets with current augmentation strength\n",
    "                X_train_aug, y_train_aug = create_balanced_dataset(\n",
    "                    X_train, y_train, hyperparams['augmentation_strength']\n",
    "                )\n",
    "                \n",
    "                train_dataset = DeerDataset(X_train_aug, y_train_aug, training=True)\n",
    "                val_dataset = DeerDataset(X_val, y_val, training=False)\n",
    "                test_dataset = DeerDataset(X_test, y_test, training=False)\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True, num_workers=0)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=hyperparams['batch_size'], shuffle=False, num_workers=0)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=hyperparams['batch_size'], shuffle=False, num_workers=0)\n",
    "                \n",
    "                model, val_acc, test_acc = self.train_with_hyperparams(\n",
    "                    train_loader, val_loader, test_loader, hyperparams, i\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    'combination': i,\n",
    "                    'hyperparams': hyperparams,\n",
    "                    'val_accuracy': val_acc,\n",
    "                    'test_accuracy': test_acc\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "                print(f\"  ‚úì Val: {val_acc:.1f}%, Test: {test_acc:.1f}%\")\n",
    "                \n",
    "                # Save every model\n",
    "                model_path = os.path.join(self.save_dir, f\"ghostnet_combo_{i:03d}_val_{val_acc:.1f}_test_{test_acc:.1f}.pth\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'hyperparams': hyperparams,\n",
    "                    'val_accuracy': val_acc,\n",
    "                    'test_accuracy': test_acc,\n",
    "                    'combination': i\n",
    "                }, model_path)\n",
    "                print(f\"  üíæ Model saved: combo_{i:03d}_val_{val_acc:.1f}_test_{test_acc:.1f}.pth\")\n",
    "                \n",
    "                # Track best for summary\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    print(f\"  üèÜ New best validation: {val_acc:.1f}%\")\n",
    "                \n",
    "                if test_acc > best_test_acc:\n",
    "                    best_test_acc = test_acc\n",
    "                    print(f\"  üéØ New best test: {test_acc:.1f}%\")\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚úó Combination {i} failed: {str(e)[:60]}...\")\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "        \n",
    "        # Save all results\n",
    "        results_path = os.path.join(self.save_dir, \"focused_hyperparameter_results.json\")\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        return results\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set with TTA\"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Test time augmentation\n",
    "            outputs1 = model(images)\n",
    "            flipped = torch.flip(images, [3])\n",
    "            outputs2 = model(flipped)\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return test_acc\n",
    "\n",
    "def main():\n",
    "    # Set reproducible seeds first\n",
    "    set_reproducible_seeds(42)\n",
    "    \n",
    "    print(\"Focused GhostNet Hyperparameter Tuning for Deer Age Prediction\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load combined data\n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    # Create label mapping\n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"\\nClasses: {len(unique_ages)}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Train/test split with fixed random state\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Further split training into train/val with fixed random state\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Train: {len(X_train_final)} images\")\n",
    "    print(f\"Val: {len(X_val)} images\") \n",
    "    print(f\"Test: {len(X_test)} images\")\n",
    "    \n",
    "    # Initialize tuner\n",
    "    tuner = GhostNetHyperparameterTuner(num_classes=len(unique_ages))\n",
    "    \n",
    "    # Run hyperparameter tuning\n",
    "    results = tuner.tune_hyperparameters(X_train_final, y_train_final, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    # Analyze results\n",
    "    if results:\n",
    "        # Sort by test accuracy (primary) and validation accuracy (secondary)\n",
    "        sorted_by_test = sorted(results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "        sorted_by_val = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FOCUSED GHOSTNET TUNING RESULTS - SORTED BY TEST ACCURACY\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Rank':<4} {'Combo':<5} {'Validation':<12} {'Test':<8} {'Key Hyperparams'}\")\n",
    "        print('-' * 70)\n",
    "        \n",
    "        for i, result in enumerate(sorted_by_test[:15], 1):  # Top 15 by test\n",
    "            hp = result['hyperparams']\n",
    "            key_params = f\"lr={hp['backbone_lr']}/{hp['classifier_lr']}, bs={hp['batch_size']}, drop={hp['dropout']}, freeze={hp['freeze_layers']}\"\n",
    "            print(f\"{i:2d}. {result['combination']:4d}       {result['val_accuracy']:5.1f}%      {result['test_accuracy']:5.1f}%    {key_params}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"TOP RESULTS BY VALIDATION ACCURACY\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, result in enumerate(sorted_by_val[:10], 1):  # Top 10 by val\n",
    "            hp = result['hyperparams']\n",
    "            key_params = f\"lr={hp['backbone_lr']}/{hp['classifier_lr']}, bs={hp['batch_size']}, drop={hp['dropout']}, freeze={hp['freeze_layers']}\"\n",
    "            print(f\"{i:2d}. {result['combination']:4d}       {result['val_accuracy']:5.1f}%      {result['test_accuracy']:5.1f}%    {key_params}\")\n",
    "        \n",
    "        best_test_result = sorted_by_test[0]\n",
    "        best_val_result = sorted_by_val[0]\n",
    "        \n",
    "        print(f\"\\nüéØ BEST TEST ACCURACY: {best_test_result['test_accuracy']:.1f}% (Combo {best_test_result['combination']})\")\n",
    "        print(f\"üèÜ BEST VALIDATION ACCURACY: {best_val_result['val_accuracy']:.1f}% (Combo {best_val_result['combination']})\")\n",
    "        \n",
    "        print(f\"\\nüìä SUMMARY:\")\n",
    "        print(f\"  Best Test: {best_test_result['test_accuracy']:.1f}%\")\n",
    "        print(f\"  Best Validation: {best_val_result['val_accuracy']:.1f}%\")\n",
    "        print(f\"  Tuning Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"  Results saved to: {tuner.save_dir}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No successful combinations found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c13841-464e-4971-9a64-def1e12fe3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
