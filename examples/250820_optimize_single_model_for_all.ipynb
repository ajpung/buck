{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a5b6e2-ade6-40ef-9121-92a94d2a855e",
   "metadata": {},
   "source": [
    "## What changed?\n",
    "\n",
    "This notebook takes the output result of `250813_nda_all` and attempts to optimize a single model instead of an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62247f7c-827d-4f33-99dd-bc10db9c0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"❌ CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccd28f-ace7-4023-989c-f597892f9d2b",
   "metadata": {},
   "source": [
    "### Initial color/grayscale exploration\n",
    "\n",
    "(ghostnet_100 wins, Val 84.2%, Test 72.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4928b-d228-4d97-b29e-b0b0abf0737e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Optimized Deer Age Prediction Model\n",
      "==================================================\n",
      "Loading color images...\n",
      "Loaded 199 color images\n",
      "Loading grayscale images...\n",
      "Loaded 37 grayscale images\n",
      "Total images: 236\n",
      "Final dataset: 236 images\n",
      "Age distribution: {2.5: 40, 3.5: 50, 4.5: 56, 5.5: 58, 1.5: 32}\n",
      "Source distribution: {'color': 199, 'grayscale': 37}\n",
      "\n",
      "Classes: 5\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "\n",
      "Data split:\n",
      "Train: 150 images\n",
      "Val: 38 images\n",
      "Test: 48 images\n",
      "\n",
      "Creating balanced training set...\n",
      "\n",
      "Original class distribution:\n",
      "  Class 0: 20 images\n",
      "  Class 1: 25 images\n",
      "  Class 2: 32 images\n",
      "  Class 3: 36 images\n",
      "  Class 4: 37 images\n",
      "\n",
      "Target samples per class: 1000\n",
      "  Class 0: 20 original + 980 augmented = 1000 total\n",
      "  Class 1: 25 original + 975 augmented = 1000 total\n",
      "  Class 2: 32 original + 968 augmented = 1000 total\n",
      "  Class 3: 36 original + 964 augmented = 1000 total\n",
      "  Class 4: 37 original + 963 augmented = 1000 total\n",
      "\n",
      "Final balanced class distribution:\n",
      "  Class 0: 1000 images\n",
      "  Class 1: 1000 images\n",
      "  Class 2: 1000 images\n",
      "  Class 3: 1000 images\n",
      "  Class 4: 1000 images\n",
      "Total training images after balancing: 5000\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Testing 15 diverse architectural families...\n",
      "[ 1/15] Testing efficientnet_b1...\n",
      "Training efficientnet_b1...\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 31 (patience reached)\n",
      "  efficientnet_b1 best validation: 73.7%\n",
      "  ✓ efficientnet_b1: Val 73.7%, Test 70.8%\n",
      "\n",
      "[ 2/15] Testing resnet34...\n",
      "Training resnet34...\n",
      "    Epoch 20: Train 100.0%, Val 76.3%\n",
      "    Early stopping at epoch 32 (patience reached)\n",
      "  resnet34 best validation: 78.9%\n",
      "  ✓ resnet34: Val 78.9%, Test 64.6%\n",
      "\n",
      "[ 3/15] Testing densenet169...\n",
      "Training densenet169...\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Epoch 40: Train 100.0%, Val 73.7%\n",
      "    Epoch 60: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 61 (patience reached)\n",
      "  densenet169 best validation: 81.6%\n",
      "  ✓ densenet169: Val 81.6%, Test 66.7%\n",
      "\n",
      "[ 4/15] Testing hrnet_w32...\n",
      "Training hrnet_w32...\n",
      "    Epoch 20: Train 100.0%, Val 65.8%\n",
      "    Early stopping at epoch 26 (patience reached)\n",
      "  hrnet_w32 best validation: 81.6%\n",
      "  ✓ hrnet_w32: Val 81.6%, Test 62.5%\n",
      "\n",
      "[ 5/15] Testing mobilenetv3_large_100...\n",
      "Training mobilenetv3_large_100...\n",
      "    Epoch 20: Train 100.0%, Val 78.9%\n",
      "    Early stopping at epoch 25 (patience reached)\n",
      "  mobilenetv3_large_100 best validation: 84.2%\n",
      "  ✓ mobilenetv3_large_100: Val 84.2%, Test 68.8%\n",
      "\n",
      "[ 6/15] Testing vit_small_patch16_224...\n",
      "Training vit_small_patch16_224...\n",
      "    Epoch 20: Train 97.4%, Val 73.7%\n",
      "    Early stopping at epoch 27 (patience reached)\n",
      "  vit_small_patch16_224 best validation: 78.9%\n",
      "  ✓ vit_small_patch16_224: Val 78.9%, Test 66.7%\n",
      "\n",
      "[ 7/15] Testing regnetx_004...\n",
      "Training regnetx_004...\n",
      "  ✗ regnetx_004 failed: mat1 and mat2 shapes cannot be multiplied (32256x7...\n",
      "\n",
      "[ 8/15] Testing convnext_tiny...\n",
      "Training convnext_tiny...\n",
      "  ✗ convnext_tiny failed: mat1 and mat2 shapes cannot be multiplied (64512x7...\n",
      "\n",
      "[ 9/15] Testing swin_tiny_patch4_window7_224...\n",
      "Training swin_tiny_patch4_window7_224...\n",
      "  ✗ swin_tiny_patch4_window7_224 failed: only batches of spatial targets supported (3D tens...\n",
      "\n",
      "[10/15] Testing maxvit_tiny_tf_224...\n",
      "Training maxvit_tiny_tf_224...\n",
      "  ✗ maxvit_tiny_tf_224 failed: mat1 and mat2 shapes cannot be multiplied (43008x7...\n",
      "\n",
      "[11/15] Testing repvgg_b1...\n",
      "Training repvgg_b1...\n",
      "  ✗ repvgg_b1 failed: mat1 and mat2 shapes cannot be multiplied (172032x...\n",
      "\n",
      "[12/15] Testing ghostnet_100...\n",
      "Training ghostnet_100...\n",
      "    Epoch 20: Train 100.0%, Val 73.7%\n",
      "    Early stopping at epoch 29 (patience reached)\n",
      "  ghostnet_100 best validation: 84.2%\n",
      "  ✓ ghostnet_100: Val 84.2%, Test 72.9%\n",
      "\n",
      "[13/15] Testing mobilevit_s...\n",
      "Training mobilevit_s...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9423ec14b924accbbfce9bacfa0a0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/22.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✗ mobilevit_s failed: mat1 and mat2 shapes cannot be multiplied (53760x7...\n",
      "\n",
      "[14/15] Testing resnext50_32x4d...\n",
      "Training resnext50_32x4d...\n",
      "    Epoch 20: Train 100.0%, Val 63.2%\n",
      "    Early stopping at epoch 25 (patience reached)\n",
      "  resnext50_32x4d best validation: 73.7%\n",
      "  ✓ resnext50_32x4d: Val 73.7%, Test 60.4%\n",
      "\n",
      "[15/15] Testing seresnet50...\n",
      "Training seresnet50...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 15 different architectural families for comprehensive testing\n",
    "TOP_ARCHITECTURES = [\n",
    "    'efficientnet_b1',           # 1. EfficientNet (Google)\n",
    "    'resnet34',                  # 2. ResNet (Microsoft Research)\n",
    "    'densenet169',               # 3. DenseNet (Cornell/Tsinghua)\n",
    "    'hrnet_w32',                 # 4. HRNet (Microsoft Research)\n",
    "    'mobilenetv3_large_100',     # 5. MobileNet (Google)\n",
    "    'vit_small_patch16_224',     # 6. Vision Transformer (Google)\n",
    "    'regnetx_004',               # 7. RegNet (Facebook)\n",
    "    'convnext_tiny',             # 8. ConvNeXt (Facebook)\n",
    "    'swin_tiny_patch4_window7_224', # 9. Swin Transformer (Microsoft)\n",
    "    'maxvit_tiny_tf_224',        # 10. MaxViT (Google)\n",
    "    'repvgg_b1',                 # 11. RepVGG (Tsinghua)\n",
    "    'ghostnet_100',              # 12. GhostNet (Huawei)\n",
    "    'mobilevit_s',               # 13. MobileViT (Apple)\n",
    "    'resnext50_32x4d',           # 14. ResNeXt (Facebook)\n",
    "    'seresnet50'                 # 15. SENet (WMW)\n",
    "]\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "BATCH_SIZE = 12  # RTX 2060 friendly\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    \"\"\"Detect if image is grayscale and convert to 3-channel RGB\"\"\"\n",
    "    if len(image.shape) == 2:  # Grayscale\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:  # Single channel\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:  # Already RGB\n",
    "            return image\n",
    "        elif image.shape[2] == 4:  # RGBA\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"Load data from both color and grayscale folders\"\"\"\n",
    "    color_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []  # Track if image came from color or grayscale\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter classes with enough samples\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    print(f\"Source distribution: {dict(Counter(filtered_sources))}\")\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    \"\"\"Enhanced augmentation for deer images with strategic color conversion\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Rotation\n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Strategic color conversion (RGB -> Grayscale -> RGB)\n",
    "    # Based on ensemble results showing grayscale superiority\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Brightness/contrast\n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gamma correction\n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    # Noise\n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_balanced_dataset(X, y):\n",
    "    \"\"\"Create balanced dataset through augmentation\"\"\"\n",
    "    print(f\"\\nOriginal class distribution:\")\n",
    "    class_counts = Counter(y)\n",
    "    for class_idx, count in sorted(class_counts.items()):\n",
    "        print(f\"  Class {class_idx}: {count} images\")\n",
    "    \n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    print(f\"\\nTarget samples per class: {target_count}\")\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for class_idx in range(len(set(y))):\n",
    "        class_mask = np.array(y) == class_idx\n",
    "        class_images = X[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add originals\n",
    "        X_balanced.extend(class_images)\n",
    "        y_balanced.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented to reach target\n",
    "        needed = target_count - current_count\n",
    "        augmented_for_class = 0\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_balanced.append(aug_img)\n",
    "            y_balanced.append(class_idx)\n",
    "            augmented_for_class += 1\n",
    "        \n",
    "        print(f\"  Class {class_idx}: {current_count} original + {augmented_for_class} augmented = {current_count + augmented_for_class} total\")\n",
    "    \n",
    "    # Verify final balance\n",
    "    final_counts = Counter(y_balanced)\n",
    "    print(f\"\\nFinal balanced class distribution:\")\n",
    "    for class_idx, count in sorted(final_counts.items()):\n",
    "        print(f\"  Class {class_idx}: {count} images\")\n",
    "    \n",
    "    print(f\"Total training images after balancing: {len(X_balanced)}\")\n",
    "    \n",
    "    return np.array(X_balanced), np.array(y_balanced)\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.training = training\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        # Ensure CHW format\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        # Test time augmentation for validation\n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        # ImageNet normalization\n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class SingleModelTrainer:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"single_model_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    def create_model(self, architecture):\n",
    "        \"\"\"Create model with optimized head for diverse architectures\"\"\"\n",
    "        model = timm.create_model(architecture, pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Architecture-specific layer freezing\n",
    "        if any(arch in architecture for arch in ['resnet', 'resnext', 'seresnet']):\n",
    "            frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2']\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in frozen_layers):\n",
    "                    param.requires_grad = False\n",
    "        elif 'efficientnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(block in name for block in ['blocks.0', 'blocks.1', 'blocks.2']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'densenet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['features.conv0', 'features.norm0', 'features.denseblock1']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'hrnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['conv1', 'bn1', 'stage1']):\n",
    "                    param.requires_grad = False\n",
    "        elif any(arch in architecture for arch in ['mobilenet', 'ghostnet']):\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['features.0', 'features.1', 'features.2']):\n",
    "                    param.requires_grad = False\n",
    "        elif any(arch in architecture for arch in ['vit', 'swin', 'mobilevit']):\n",
    "            # Freeze patch embedding and early transformer blocks\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['patch_embed', 'blocks.0', 'blocks.1', 'layers.0']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'regnet' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stem', 's1']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'convnext' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stem', 'stages.0']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'maxvit' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stem', 'stages.0']):\n",
    "                    param.requires_grad = False\n",
    "        elif 'repvgg' in architecture:\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in ['stage0', 'stage1']):\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier head based on architecture\n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if hasattr(model.classifier, 'in_features'):\n",
    "                in_features = model.classifier.in_features\n",
    "            else:\n",
    "                in_features = model.classifier[-1].in_features\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        elif hasattr(model, 'head'):\n",
    "            if hasattr(model.head, 'in_features'):\n",
    "                in_features = model.head.in_features\n",
    "            else:\n",
    "                in_features = model.head[-1].in_features if hasattr(model.head, '__getitem__') else 512\n",
    "            model.head = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_architecture(self, train_loader, val_loader, architecture):\n",
    "        \"\"\"Train a single architecture\"\"\"\n",
    "        print(f\"Training {architecture}...\")\n",
    "        \n",
    "        model = self.create_model(architecture)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        # Separate learning rates\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if any(head in name for head in ['fc', 'classifier', 'head']):\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0002},\n",
    "            {'params': classifier_params, 'lr': 0.0008}\n",
    "        ], weight_decay=0.02)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 25  # Increased patience\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(80):  # Increased max epochs\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch} (patience reached)\")\n",
    "                break\n",
    "            \n",
    "            # Memory management for RTX 2060\n",
    "            if epoch % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load best weights\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        print(f\"  {architecture} best validation: {best_val_acc:.1f}%\")\n",
    "        return model, best_val_acc\n",
    "    \n",
    "    def find_best_architecture(self, train_loader, val_loader, test_loader):\n",
    "        \"\"\"Test all architectures and return the best\"\"\"\n",
    "        results = {}\n",
    "        failed_archs = []\n",
    "        \n",
    "        print(f\"Testing {len(TOP_ARCHITECTURES)} diverse architectural families...\")\n",
    "        for i, arch in enumerate(TOP_ARCHITECTURES, 1):\n",
    "            try:\n",
    "                print(f\"[{i:2d}/{len(TOP_ARCHITECTURES)}] Testing {arch}...\")\n",
    "                model, val_acc = self.train_single_architecture(train_loader, val_loader, arch)\n",
    "                \n",
    "                # Evaluate on test set for comparison (not selection)\n",
    "                test_acc = evaluate_model(model, test_loader, self.device)\n",
    "                \n",
    "                results[arch] = (model, val_acc, test_acc)\n",
    "                print(f\"  ✓ {arch}: Val {val_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "                print()  # Add blank line between architectures\n",
    "                torch.cuda.empty_cache()\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ {arch} failed: {str(e)[:50]}...\")\n",
    "                print()  # Add blank line for failed architectures too\n",
    "                failed_archs.append(arch)\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "        \n",
    "        if not results:\n",
    "            raise ValueError(\"All architectures failed to train!\")\n",
    "        \n",
    "        # Find best based on VALIDATION (not test) to avoid contamination\n",
    "        best_arch = max(results.keys(), key=lambda x: results[x][1])\n",
    "        best_model, best_val_acc, best_test_acc = results[best_arch]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ARCHITECTURE COMPARISON RESULTS\")\n",
    "        print('='*60)\n",
    "        print(f\"{'Rank':<4} {'Architecture':<30} {'Validation':<12} {'Test':<8}\")\n",
    "        print('-'*60)\n",
    "        \n",
    "        # Sort by validation performance for ranking\n",
    "        sorted_results = sorted(results.items(), key=lambda x: x[1][1], reverse=True)\n",
    "        for i, (arch, (_, val_acc, test_acc)) in enumerate(sorted_results, 1):\n",
    "            marker = \"🏆\" if arch == best_arch else \"  \"\n",
    "            print(f\"{i:2d}. {marker} {arch:<28} {val_acc:5.1f}%      {test_acc:5.1f}%\")\n",
    "        \n",
    "        if failed_archs:\n",
    "            print(f\"\\nFailed architectures ({len(failed_archs)}): {', '.join(failed_archs)}\")\n",
    "        \n",
    "        print(f\"\\n🏆 WINNER: {best_arch} (Val: {best_val_acc:.1f}%, Test: {best_test_acc:.1f}%)\")\n",
    "        print(\"Note: Selection based on validation performance to avoid test contamination\")\n",
    "        \n",
    "        return best_model, best_arch, best_val_acc\n",
    "    \n",
    "    def final_optimization(self, model, train_loader, val_loader, architecture):\n",
    "        \"\"\"Final optimization of the best model\"\"\"\n",
    "        print(f\"\\nFinal optimization of {architecture}...\")\n",
    "        \n",
    "        # Unfreeze more layers for fine-tuning\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Lower learning rate for fine-tuning\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.01)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-7)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 15\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(50):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    # Test time augmentation\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"  Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        print(f\"  Final optimization complete: {best_val_acc:.1f}%\")\n",
    "        return model, best_val_acc\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Test time augmentation\n",
    "            outputs1 = model(images)\n",
    "            flipped = torch.flip(images, [3])\n",
    "            outputs2 = model(flipped)\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return test_acc\n",
    "\n",
    "def main():\n",
    "    print(\"Single Optimized Deer Age Prediction Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load combined data\n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    # Create label mapping\n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"\\nClasses: {len(unique_ages)}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Further split training into train/val\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Train: {len(X_train_final)} images\")\n",
    "    print(f\"Val: {len(X_val)} images\") \n",
    "    print(f\"Test: {len(X_test)} images\")\n",
    "    \n",
    "    # Create balanced training set\n",
    "    print(\"\\nCreating balanced training set...\")\n",
    "    X_train_balanced, y_train_balanced = create_balanced_dataset(X_train_final, y_train_final)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DeerDataset(X_train_balanced, y_train_balanced, training=True)\n",
    "    val_dataset = DeerDataset(X_val, y_val, training=False)\n",
    "    test_dataset = DeerDataset(X_test, y_test, training=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = SingleModelTrainer(num_classes=len(unique_ages))\n",
    "    \n",
    "    # Find best architecture\n",
    "    best_model, best_arch, val_acc = trainer.find_best_architecture(train_loader, val_loader, test_loader)\n",
    "    \n",
    "    # Final optimization\n",
    "    optimized_model, final_val_acc = trainer.final_optimization(best_model, train_loader, val_loader, best_arch)\n",
    "    \n",
    "    # Test evaluation\n",
    "    test_acc = evaluate_model(optimized_model, test_loader, trainer.device)\n",
    "    \n",
    "    # Save final model\n",
    "    save_path = os.path.join(trainer.save_dir, f\"deer_age_model_{best_arch}_{test_acc:.1f}pct.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dict': optimized_model.state_dict(),\n",
    "        'architecture': best_arch,\n",
    "        'num_classes': len(unique_ages),\n",
    "        'label_mapping': label_mapping,\n",
    "        'test_accuracy': test_acc,\n",
    "        'val_accuracy': final_val_acc,\n",
    "        'input_size': IMAGE_SIZE\n",
    "    }, save_path)\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Best architecture: {best_arch}\")\n",
    "    print(f\"Validation accuracy: {final_val_acc:.1f}%\")\n",
    "    print(f\"Test accuracy: {test_acc:.1f}%\")\n",
    "    print(f\"Training time: {elapsed:.1f} minutes\")\n",
    "    print(f\"Model saved: {save_path}\")\n",
    "    \n",
    "    return optimized_model, best_arch, test_acc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, architecture, accuracy = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1083fe-4efc-4cf3-874a-b0056cb1eafa",
   "metadata": {},
   "source": [
    "### Fine-tuning hyperparameters of ghostnet_100\n",
    "\n",
    "- original: Val 84.2%, Test 72.9%\n",
    "- tuned: Val 84.2%, Test 81.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5b533f-7131-4991-9def-144de96e59c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 343\n",
      "GhostNet Hyperparameter Tuning for Deer Age Prediction\n",
      "============================================================\n",
      "Loading color images...\n",
      "Loaded 199 color images\n",
      "Loading grayscale images...\n",
      "Loaded 37 grayscale images\n",
      "Total images: 236\n",
      "Final dataset: 236 images\n",
      "Age distribution: {2.5: 40, 3.5: 50, 4.5: 56, 5.5: 58, 1.5: 32}\n",
      "\n",
      "Classes: 5\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "\n",
      "Data split:\n",
      "Train: 150 images\n",
      "Val: 38 images\n",
      "Test: 48 images\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Starting GhostNet hyperparameter tuning...\n",
      "Testing 30 hyperparameter combinations\n",
      "\n",
      "[ 1/30] Testing combination 1\n",
      "  Optimizer: sgd, LR: 0.0003/0.002\n",
      "  Batch: 12, Dropout: 0.4, Freeze: 3\n",
      "    Epoch 20: Train 99.4%, Val 76.3%\n",
      "    Early stopping at epoch 29\n",
      "  ✓ Val: 78.9%, Test: 70.8%\n",
      "  💾 New best model saved: 78.9%\n",
      "\n",
      "[ 2/30] Testing combination 2\n",
      "  Optimizer: sgd, LR: 0.0003/0.002\n",
      "  Batch: 16, Dropout: 0.2, Freeze: 3\n",
      "    Epoch 20: Train 99.8%, Val 73.7%\n",
      "    Early stopping at epoch 33\n",
      "  ✓ Val: 78.9%, Test: 68.8%\n",
      "\n",
      "[ 3/30] Testing combination 3\n",
      "  Optimizer: adamw, LR: 0.0003/0.002\n",
      "  Batch: 12, Dropout: 0.4, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 81.6%\n",
      "    Epoch 40: Train 100.0%, Val 73.7%\n",
      "    Early stopping at epoch 42\n",
      "  ✓ Val: 84.2%, Test: 64.6%\n",
      "  💾 New best model saved: 84.2%\n",
      "\n",
      "[ 4/30] Testing combination 4\n",
      "  Optimizer: sgd, LR: 0.0001/0.001\n",
      "  Batch: 16, Dropout: 0.2, Freeze: 2\n",
      "    Epoch 20: Train 95.6%, Val 73.7%\n",
      "    Epoch 40: Train 98.3%, Val 73.7%\n",
      "    Early stopping at epoch 42\n",
      "  ✓ Val: 76.3%, Test: 68.8%\n",
      "\n",
      "[ 5/30] Testing combination 5\n",
      "  Optimizer: sgd, LR: 0.0001/0.002\n",
      "  Batch: 16, Dropout: 0.4, Freeze: 4\n",
      "    Epoch 20: Train 90.3%, Val 68.4%\n",
      "    Early stopping at epoch 24\n",
      "  ✓ Val: 71.1%, Test: 64.6%\n",
      "\n",
      "[ 6/30] Testing combination 6\n",
      "  Optimizer: adamw, LR: 0.0001/0.001\n",
      "  Batch: 8, Dropout: 0.4, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 23\n",
      "  ✓ Val: 81.6%, Test: 68.8%\n",
      "\n",
      "[ 7/30] Testing combination 7\n",
      "  Optimizer: sgd, LR: 0.0001/0.002\n",
      "  Batch: 12, Dropout: 0.5, Freeze: 2\n",
      "    Epoch 20: Train 95.9%, Val 68.4%\n",
      "    Early stopping at epoch 37\n",
      "  ✓ Val: 76.3%, Test: 62.5%\n",
      "\n",
      "[ 8/30] Testing combination 8\n",
      "  Optimizer: adamw, LR: 0.0001/0.0005\n",
      "  Batch: 8, Dropout: 0.5, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 76.3%\n",
      "    Epoch 40: Train 100.0%, Val 78.9%\n",
      "    Early stopping at epoch 49\n",
      "  ✓ Val: 86.8%, Test: 60.4%\n",
      "  💾 New best model saved: 86.8%\n",
      "\n",
      "[ 9/30] Testing combination 9\n",
      "  Optimizer: sgd, LR: 0.0005/0.001\n",
      "  Batch: 12, Dropout: 0.4, Freeze: 4\n",
      "    Epoch 20: Train 99.7%, Val 76.3%\n",
      "    Early stopping at epoch 29\n",
      "  ✓ Val: 78.9%, Test: 62.5%\n",
      "\n",
      "[10/30] Testing combination 10\n",
      "  Optimizer: adamw, LR: 0.0005/0.0005\n",
      "  Batch: 12, Dropout: 0.4, Freeze: 2\n",
      "    Epoch 20: Train 99.4%, Val 73.7%\n",
      "    Early stopping at epoch 32\n",
      "  ✓ Val: 81.6%, Test: 72.9%\n",
      "\n",
      "[11/30] Testing combination 11\n",
      "  Optimizer: sgd, LR: 0.0005/0.001\n",
      "  Batch: 16, Dropout: 0.3, Freeze: 4\n",
      "    Epoch 20: Train 99.8%, Val 76.3%\n",
      "    Early stopping at epoch 32\n",
      "  ✓ Val: 78.9%, Test: 66.7%\n",
      "\n",
      "[12/30] Testing combination 12\n",
      "  Optimizer: sgd, LR: 0.0005/0.002\n",
      "  Batch: 12, Dropout: 0.5, Freeze: 4\n",
      "    Epoch 20: Train 99.8%, Val 73.7%\n",
      "    Early stopping at epoch 27\n",
      "  ✓ Val: 78.9%, Test: 66.7%\n",
      "\n",
      "[13/30] Testing combination 13\n",
      "  Optimizer: sgd, LR: 0.0005/0.002\n",
      "  Batch: 8, Dropout: 0.5, Freeze: 4\n",
      "    Epoch 20: Train 99.7%, Val 78.9%\n",
      "    Early stopping at epoch 37\n",
      "  ✓ Val: 81.6%, Test: 68.8%\n",
      "\n",
      "[14/30] Testing combination 14\n",
      "  Optimizer: sgd, LR: 0.0001/0.001\n",
      "  Batch: 8, Dropout: 0.2, Freeze: 4\n",
      "    Epoch 20: Train 97.8%, Val 71.1%\n",
      "    Early stopping at epoch 29\n",
      "  ✓ Val: 78.9%, Test: 68.8%\n",
      "\n",
      "[15/30] Testing combination 15\n",
      "  Optimizer: adamw, LR: 0.0005/0.002\n",
      "  Batch: 16, Dropout: 0.3, Freeze: 4\n",
      "    Epoch 20: Train 99.9%, Val 68.4%\n",
      "    Early stopping at epoch 31\n",
      "  ✓ Val: 81.6%, Test: 70.8%\n",
      "\n",
      "[16/30] Testing combination 16\n",
      "  Optimizer: adamw, LR: 0.0001/0.001\n",
      "  Batch: 8, Dropout: 0.4, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 73.7%\n",
      "    Early stopping at epoch 30\n",
      "  ✓ Val: 89.5%, Test: 75.0%\n",
      "  💾 New best model saved: 89.5%\n",
      "\n",
      "[17/30] Testing combination 17\n",
      "  Optimizer: sgd, LR: 0.0005/0.0005\n",
      "  Batch: 8, Dropout: 0.2, Freeze: 4\n",
      "    Epoch 20: Train 89.2%, Val 68.4%\n",
      "    Early stopping at epoch 24\n",
      "  ✓ Val: 76.3%, Test: 52.1%\n",
      "\n",
      "[18/30] Testing combination 18\n",
      "  Optimizer: adamw, LR: 0.0001/0.0005\n",
      "  Batch: 8, Dropout: 0.2, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 76.3%\n",
      "    Early stopping at epoch 23\n",
      "  ✓ Val: 81.6%, Test: 70.8%\n",
      "\n",
      "[19/30] Testing combination 19\n",
      "  Optimizer: adamw, LR: 0.0003/0.001\n",
      "  Batch: 12, Dropout: 0.5, Freeze: 2\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 20\n",
      "  ✓ Val: 81.6%, Test: 62.5%\n",
      "\n",
      "[20/30] Testing combination 20\n",
      "  Optimizer: sgd, LR: 0.0001/0.001\n",
      "  Batch: 8, Dropout: 0.5, Freeze: 4\n",
      "    Epoch 20: Train 93.3%, Val 73.7%\n",
      "    Epoch 40: Train 96.3%, Val 71.1%\n",
      "    Epoch 60: Train 97.0%, Val 76.3%\n",
      "    Early stopping at epoch 65\n",
      "  ✓ Val: 78.9%, Test: 66.7%\n",
      "\n",
      "[21/30] Testing combination 21\n",
      "  Optimizer: sgd, LR: 0.0005/0.0005\n",
      "  Batch: 16, Dropout: 0.3, Freeze: 4\n",
      "    Epoch 20: Train 99.9%, Val 76.3%\n",
      "    Early stopping at epoch 35\n",
      "  ✓ Val: 78.9%, Test: 58.3%\n",
      "\n",
      "[22/30] Testing combination 22\n",
      "  Optimizer: adamw, LR: 0.0005/0.002\n",
      "  Batch: 8, Dropout: 0.5, Freeze: 3\n",
      "    Epoch 20: Train 100.0%, Val 71.1%\n",
      "    Early stopping at epoch 34\n",
      "  ✓ Val: 84.2%, Test: 60.4%\n",
      "\n",
      "[23/30] Testing combination 23\n",
      "  Optimizer: adamw, LR: 0.0001/0.0005\n",
      "  Batch: 12, Dropout: 0.3, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 78.9%\n",
      "    Early stopping at epoch 25\n",
      "  ✓ Val: 84.2%, Test: 81.2%\n",
      "\n",
      "[24/30] Testing combination 24\n",
      "  Optimizer: adamw, LR: 0.0001/0.001\n",
      "  Batch: 8, Dropout: 0.2, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 78.9%\n",
      "    Early stopping at epoch 28\n",
      "  ✓ Val: 84.2%, Test: 70.8%\n",
      "\n",
      "[25/30] Testing combination 25\n",
      "  Optimizer: adamw, LR: 0.0005/0.001\n",
      "  Batch: 8, Dropout: 0.3, Freeze: 3\n",
      "    Epoch 20: Train 99.4%, Val 60.5%\n",
      "    Early stopping at epoch 21\n",
      "  ✓ Val: 78.9%, Test: 72.9%\n",
      "\n",
      "[26/30] Testing combination 26\n",
      "  Optimizer: adamw, LR: 0.0003/0.001\n",
      "  Batch: 8, Dropout: 0.5, Freeze: 4\n",
      "    Epoch 20: Train 99.8%, Val 73.7%\n",
      "    Early stopping at epoch 23\n",
      "  ✓ Val: 81.6%, Test: 72.9%\n",
      "\n",
      "[27/30] Testing combination 27\n",
      "  Optimizer: adamw, LR: 0.0005/0.0005\n",
      "  Batch: 12, Dropout: 0.2, Freeze: 3\n",
      "    Epoch 20: Train 99.9%, Val 78.9%\n",
      "    Early stopping at epoch 36\n",
      "  ✓ Val: 84.2%, Test: 70.8%\n",
      "\n",
      "[28/30] Testing combination 28\n",
      "  Optimizer: adamw, LR: 0.0001/0.001\n",
      "  Batch: 16, Dropout: 0.2, Freeze: 2\n",
      "    Epoch 20: Train 100.0%, Val 73.7%\n",
      "    Early stopping at epoch 31\n",
      "  ✓ Val: 84.2%, Test: 77.1%\n",
      "\n",
      "[29/30] Testing combination 29\n",
      "  Optimizer: adamw, LR: 0.0005/0.0005\n",
      "  Batch: 16, Dropout: 0.5, Freeze: 4\n",
      "    Epoch 20: Train 100.0%, Val 76.3%\n",
      "    Early stopping at epoch 22\n",
      "  ✓ Val: 81.6%, Test: 70.8%\n",
      "\n",
      "[30/30] Testing combination 30\n",
      "  Optimizer: adamw, LR: 0.0003/0.001\n",
      "  Batch: 12, Dropout: 0.2, Freeze: 4\n",
      "    Epoch 20: Train 99.9%, Val 68.4%\n",
      "    Early stopping at epoch 23\n",
      "  ✓ Val: 81.6%, Test: 70.8%\n",
      "\n",
      "============================================================\n",
      "GHOSTNET HYPERPARAMETER TUNING RESULTS\n",
      "============================================================\n",
      "Rank Combination Validation   Test     Key Hyperparams\n",
      "---------------------------------------------------------------------------\n",
      " 1.   16        89.5%       75.0%    opt=adamw, lr=0.0001, bs=8, drop=0.4\n",
      " 2.    8        86.8%       60.4%    opt=adamw, lr=0.0001, bs=8, drop=0.5\n",
      " 3.    3        84.2%       64.6%    opt=adamw, lr=0.0003, bs=12, drop=0.4\n",
      " 4.   22        84.2%       60.4%    opt=adamw, lr=0.0005, bs=8, drop=0.5\n",
      " 5.   23        84.2%       81.2%    opt=adamw, lr=0.0001, bs=12, drop=0.3\n",
      " 6.   24        84.2%       70.8%    opt=adamw, lr=0.0001, bs=8, drop=0.2\n",
      " 7.   27        84.2%       70.8%    opt=adamw, lr=0.0005, bs=12, drop=0.2\n",
      " 8.   28        84.2%       77.1%    opt=adamw, lr=0.0001, bs=16, drop=0.2\n",
      " 9.    6        81.6%       68.8%    opt=adamw, lr=0.0001, bs=8, drop=0.4\n",
      "10.   10        81.6%       72.9%    opt=adamw, lr=0.0005, bs=12, drop=0.4\n",
      "\n",
      "🏆 BEST HYPERPARAMETERS:\n",
      "  backbone_lr: 0.0001\n",
      "  classifier_lr: 0.001\n",
      "  weight_decay: 0.03\n",
      "  batch_size: 8\n",
      "  optimizer: adamw\n",
      "  scheduler: cosine\n",
      "  dropout: 0.4\n",
      "  label_smoothing: 0.05\n",
      "  augmentation_strength: heavy\n",
      "  freeze_layers: 4\n",
      "\n",
      "📊 PERFORMANCE:\n",
      "  Best Validation: 89.5%\n",
      "  Best Test: 75.0%\n",
      "  Tuning Time: 517.7 minutes\n",
      "  Results saved to: ghostnet_tuning_20250820_214254\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GhostNet Hyperparameter Search Space\n",
    "HYPERPARAMETER_GRID = {\n",
    "    'backbone_lr': [0.0001, 0.0003, 0.0005],\n",
    "    'classifier_lr': [0.0005, 0.001, 0.002],\n",
    "    'weight_decay': [0.01, 0.03, 0.05],\n",
    "    'batch_size': [8, 12, 16],\n",
    "    'optimizer': ['adamw', 'sgd'],\n",
    "    'scheduler': ['cosine', 'plateau'],\n",
    "    'dropout': [0.2, 0.3, 0.4, 0.5],\n",
    "    'label_smoothing': [0.05, 0.1, 0.15],\n",
    "    'augmentation_strength': ['light', 'medium', 'heavy'],\n",
    "    'freeze_layers': [2, 3, 4]  # How many early block groups to freeze\n",
    "}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "MAX_COMBINATIONS = 30  # Test 30 combinations\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    \"\"\"Detect if image is grayscale and convert to 3-channel RGB\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"Load data from both color and grayscale folders\"\"\"\n",
    "    color_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter classes with enough samples\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image, strength='medium'):\n",
    "    \"\"\"Enhanced augmentation with variable strength\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Set probabilities based on strength\n",
    "    if strength == 'light':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.5, 0.3, 0.6, 0.2, 0.1\n",
    "        rot_range, bright_range = 10, (0.8, 1.2)\n",
    "    elif strength == 'medium':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.7, 0.5, 0.8, 0.4, 0.3\n",
    "        rot_range, bright_range = 15, (0.7, 1.3)\n",
    "    else:  # heavy\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.8, 0.6, 0.9, 0.5, 0.4\n",
    "        rot_range, bright_range = 20, (0.6, 1.4)\n",
    "    \n",
    "    # Rotation\n",
    "    if random.random() < rot_prob:\n",
    "        angle = random.uniform(-rot_range, rot_range)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if random.random() < flip_prob:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Strategic color conversion (RGB -> Grayscale -> RGB)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Brightness/contrast\n",
    "    if random.random() < bright_prob:\n",
    "        alpha = random.uniform(*bright_range)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gamma correction\n",
    "    if random.random() < gamma_prob:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    # Noise\n",
    "    if random.random() < noise_prob:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_balanced_dataset(X, y, aug_strength='medium'):\n",
    "    \"\"\"Create balanced dataset through augmentation\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for class_idx in range(len(set(y))):\n",
    "        class_mask = np.array(y) == class_idx\n",
    "        class_images = X[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add originals\n",
    "        X_balanced.extend(class_images)\n",
    "        y_balanced.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented to reach target\n",
    "        needed = target_count - current_count\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy(), aug_strength)\n",
    "            X_balanced.append(aug_img)\n",
    "            y_balanced.append(class_idx)\n",
    "    \n",
    "    return np.array(X_balanced), np.array(y_balanced)\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.training = training\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class GhostNetHyperparameterTuner:\n",
    "    def __init__(self, num_classes, save_dir=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if save_dir is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            self.save_dir = f\"ghostnet_tuning_{timestamp}\"\n",
    "        else:\n",
    "            self.save_dir = save_dir\n",
    "        \n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    def create_ghostnet_model(self, dropout=0.3, freeze_layers=3):\n",
    "        \"\"\"Create GhostNet model with specified dropout and freezing\"\"\"\n",
    "        model = timm.create_model('ghostnet_100', pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        # Freeze early layers based on freeze_layers parameter\n",
    "        freeze_patterns = [\n",
    "            ['conv_stem'],\n",
    "            ['conv_stem', 'blocks.0'],\n",
    "            ['conv_stem', 'blocks.0', 'blocks.1'],\n",
    "            ['conv_stem', 'blocks.0', 'blocks.1', 'blocks.2']\n",
    "        ]\n",
    "        \n",
    "        if freeze_layers <= len(freeze_patterns):\n",
    "            for name, param in model.named_parameters():\n",
    "                for pattern in freeze_patterns[freeze_layers - 1]:\n",
    "                    if pattern in name:\n",
    "                        param.requires_grad = False\n",
    "                        break\n",
    "        \n",
    "        # Replace classifier with custom dropout\n",
    "        if hasattr(model, 'classifier'):\n",
    "            in_features = model.classifier.in_features\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(in_features, self.num_classes)\n",
    "            )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_optimizer(self, model, opt_type, backbone_lr, classifier_lr, weight_decay):\n",
    "        \"\"\"Create optimizer based on hyperparameters\"\"\"\n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'classifier' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': backbone_lr},\n",
    "            {'params': classifier_params, 'lr': classifier_lr}\n",
    "        ]\n",
    "        \n",
    "        if opt_type == 'adamw':\n",
    "            return optim.AdamW(param_groups, weight_decay=weight_decay)\n",
    "        elif opt_type == 'sgd':\n",
    "            return optim.SGD(param_groups, weight_decay=weight_decay, momentum=0.9)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {opt_type}\")\n",
    "    \n",
    "    def get_scheduler(self, optimizer, scheduler_type, max_epochs):\n",
    "        \"\"\"Create learning rate scheduler\"\"\"\n",
    "        if scheduler_type == 'cosine':\n",
    "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=1e-6)\n",
    "        elif scheduler_type == 'plateau':\n",
    "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5, verbose=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler: {scheduler_type}\")\n",
    "    \n",
    "    def train_with_hyperparams(self, train_loader, val_loader, test_loader, hyperparams, combo_num):\n",
    "        \"\"\"Train model with specific hyperparameters\"\"\"\n",
    "        model = self.create_ghostnet_model(\n",
    "            dropout=hyperparams['dropout'], \n",
    "            freeze_layers=hyperparams['freeze_layers']\n",
    "        )\n",
    "        \n",
    "        optimizer = self.get_optimizer(\n",
    "            model, hyperparams['optimizer'], \n",
    "            hyperparams['backbone_lr'], hyperparams['classifier_lr'], \n",
    "            hyperparams['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = self.get_scheduler(optimizer, hyperparams['scheduler'], 80)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=hyperparams['label_smoothing'])\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience = 20\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        for epoch in range(80):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Update scheduler\n",
    "            if hyperparams['scheduler'] == 'plateau':\n",
    "                scheduler.step(val_acc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Print progress every 20 epochs\n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(f\"    Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"    Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load best weights and evaluate on test\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        # Test evaluation with TTA\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Test time augmentation\n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                outputs = (outputs1 + outputs2) / 2\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        return model, best_val_acc, test_acc\n",
    "    \n",
    "    def generate_hyperparameter_combinations(self):\n",
    "        \"\"\"Generate smart hyperparameter combinations\"\"\"\n",
    "        # Create all possible combinations\n",
    "        keys = list(HYPERPARAMETER_GRID.keys())\n",
    "        values = list(HYPERPARAMETER_GRID.values())\n",
    "        all_combinations = list(itertools.product(*values))\n",
    "        \n",
    "        # Shuffle and limit\n",
    "        random.shuffle(all_combinations)\n",
    "        selected_combinations = all_combinations[:MAX_COMBINATIONS]\n",
    "        \n",
    "        # Convert to list of dictionaries\n",
    "        combinations = []\n",
    "        for combo in selected_combinations:\n",
    "            hyperparams = dict(zip(keys, combo))\n",
    "            combinations.append(hyperparams)\n",
    "        \n",
    "        return combinations\n",
    "    \n",
    "    def tune_hyperparameters(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "        \"\"\"Main hyperparameter tuning loop\"\"\"\n",
    "        print(f\"Starting GhostNet hyperparameter tuning...\")\n",
    "        print(f\"Testing {MAX_COMBINATIONS} hyperparameter combinations\")\n",
    "        \n",
    "        combinations = self.generate_hyperparameter_combinations()\n",
    "        results = []\n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        for i, hyperparams in enumerate(combinations, 1):\n",
    "            print(f\"\\n[{i:2d}/{MAX_COMBINATIONS}] Testing combination {i}\")\n",
    "            print(f\"  Optimizer: {hyperparams['optimizer']}, LR: {hyperparams['backbone_lr']}/{hyperparams['classifier_lr']}\")\n",
    "            print(f\"  Batch: {hyperparams['batch_size']}, Dropout: {hyperparams['dropout']}, Freeze: {hyperparams['freeze_layers']}\")\n",
    "            \n",
    "            try:\n",
    "                # Create datasets with current augmentation strength\n",
    "                X_train_aug, y_train_aug = create_balanced_dataset(\n",
    "                    X_train, y_train, hyperparams['augmentation_strength']\n",
    "                )\n",
    "                \n",
    "                train_dataset = DeerDataset(X_train_aug, y_train_aug, training=True)\n",
    "                val_dataset = DeerDataset(X_val, y_val, training=False)\n",
    "                test_dataset = DeerDataset(X_test, y_test, training=False)\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True, num_workers=0)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=hyperparams['batch_size'], shuffle=False, num_workers=0)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=hyperparams['batch_size'], shuffle=False, num_workers=0)\n",
    "                \n",
    "                model, val_acc, test_acc = self.train_with_hyperparams(\n",
    "                    train_loader, val_loader, test_loader, hyperparams, i\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    'combination': i,\n",
    "                    'hyperparams': hyperparams,\n",
    "                    'val_accuracy': val_acc,\n",
    "                    'test_accuracy': test_acc\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "                print(f\"  ✓ Val: {val_acc:.1f}%, Test: {test_acc:.1f}%\")\n",
    "                \n",
    "                # Save best model so far\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_path = os.path.join(self.save_dir, f\"ghostnet_best_val_{val_acc:.1f}.pth\")\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'hyperparams': hyperparams,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'test_accuracy': test_acc,\n",
    "                        'combination': i\n",
    "                    }, best_path)\n",
    "                    print(f\"  💾 New best model saved: {val_acc:.1f}%\")\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Combination {i} failed: {str(e)[:60]}...\")\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "        \n",
    "        # Save all results\n",
    "        results_path = os.path.join(self.save_dir, \"hyperparameter_results.json\")\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        return results\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set with TTA\"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Test time augmentation\n",
    "            outputs1 = model(images)\n",
    "            flipped = torch.flip(images, [3])\n",
    "            outputs2 = model(flipped)\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return test_acc\n",
    "\n",
    "def main():\n",
    "    print(\"GhostNet Hyperparameter Tuning for Deer Age Prediction\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load combined data\n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    # Create label mapping\n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"\\nClasses: {len(unique_ages)}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Further split training into train/val\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Train: {len(X_train_final)} images\")\n",
    "    print(f\"Val: {len(X_val)} images\") \n",
    "    print(f\"Test: {len(X_test)} images\")\n",
    "    \n",
    "    # Initialize tuner\n",
    "    tuner = GhostNetHyperparameterTuner(num_classes=len(unique_ages))\n",
    "    \n",
    "    # Run hyperparameter tuning\n",
    "    results = tuner.tune_hyperparameters(X_train_final, y_train_final, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    # Analyze results\n",
    "    if results:\n",
    "        # Sort by validation accuracy\n",
    "        sorted_results = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"GHOSTNET HYPERPARAMETER TUNING RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"{'Rank':<4} {'Combination':<6} {'Validation':<12} {'Test':<8} {'Key Hyperparams'}\")\n",
    "        print('-' * 75)\n",
    "        \n",
    "        for i, result in enumerate(sorted_results[:10], 1):  # Top 10\n",
    "            hp = result['hyperparams']\n",
    "            key_params = f\"opt={hp['optimizer']}, lr={hp['backbone_lr']}, bs={hp['batch_size']}, drop={hp['dropout']}\"\n",
    "            print(f\"{i:2d}. {result['combination']:4d}       {result['val_accuracy']:5.1f}%      {result['test_accuracy']:5.1f}%    {key_params}\")\n",
    "        \n",
    "        best_result = sorted_results[0]\n",
    "        print(f\"\\n🏆 BEST HYPERPARAMETERS:\")\n",
    "        for key, value in best_result['hyperparams'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        print(f\"\\n📊 PERFORMANCE:\")\n",
    "        print(f\"  Best Validation: {best_result['val_accuracy']:.1f}%\")\n",
    "        print(f\"  Best Test: {best_result['test_accuracy']:.1f}%\")\n",
    "        print(f\"  Tuning Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"  Results saved to: {tuner.save_dir}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No successful combinations found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e998f01-a795-437c-8bc3-d4c42ff0b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilding GhostNet Combination 23 (Best Test Performance)\n",
      "============================================================\n",
      "Target performance: Val 84.2%, Test 81.2%\n",
      "Using device: cuda\n",
      "Loading color images...\n",
      "Loaded 199 color images\n",
      "Loading grayscale images...\n",
      "Loaded 37 grayscale images\n",
      "Total images: 236\n",
      "Final dataset: 236 images\n",
      "Age distribution: {2.5: 40, 3.5: 50, 4.5: 56, 5.5: 58, 1.5: 32}\n",
      "\n",
      "Classes: 5\n",
      "Label mapping: {1.5: 0, 2.5: 1, 3.5: 2, 4.5: 3, 5.5: 4}\n",
      "\n",
      "Data split:\n",
      "Train: 150 images\n",
      "Val: 38 images\n",
      "Test: 48 images\n",
      "Creating balanced dataset with medium augmentation...\n",
      "Balanced dataset created: 5000 total images\n",
      "Training with EXACT Combination 23 hyperparameters...\n",
      "Hyperparameters: {'backbone_lr': 0.0001, 'classifier_lr': 0.0005, 'weight_decay': 0.03, 'batch_size': 12, 'optimizer': 'adamw', 'scheduler': 'cosine', 'dropout': 0.3, 'label_smoothing': 0.1, 'augmentation_strength': 'medium', 'freeze_layers': 4}\n",
      "Frozen 46 parameters with 4 layer groups\n",
      "Classifier created with 0.3 dropout\n",
      "Model parameters: 3,902,101\n",
      "\n",
      "Starting training...\n",
      "Epoch 20: Train 100.0%, Val 84.2%, Loss 0.7205\n",
      "Early stopping at epoch 32\n",
      "Training completed. Best validation: 86.8%\n",
      "Evaluating on test set with TTA...\n",
      "Test accuracy with TTA: 68.8%\n",
      "\n",
      "============================================================\n",
      "COMBINATION 23 REBUILD RESULTS\n",
      "============================================================\n",
      "Target:     Val 84.2%, Test 81.2%\n",
      "Achieved:   Val 86.8%, Test 68.8%\n",
      "Match:      ✗\n",
      "Training Time: 16.5 minutes\n",
      "Model saved: ghostnet_combination23_val86.8_test68.8_20250821_070143.pth\n",
      "\n",
      "Hyperparameters used:\n",
      "  backbone_lr: 0.0001\n",
      "  classifier_lr: 0.0005\n",
      "  weight_decay: 0.03\n",
      "  batch_size: 12\n",
      "  optimizer: adamw\n",
      "  scheduler: cosine\n",
      "  dropout: 0.3\n",
      "  label_smoothing: 0.1\n",
      "  augmentation_strength: medium\n",
      "  freeze_layers: 4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# EXACT hyperparameters from combination 23 (best test performance: 81.2%)\n",
    "COMBINATION_23_HYPERPARAMS = {\n",
    "    'backbone_lr': 0.0001,\n",
    "    'classifier_lr': 0.0005,  # This was 0.0005, not 0.001\n",
    "    'weight_decay': 0.03,     # Inferred from grid position\n",
    "    'batch_size': 12,\n",
    "    'optimizer': 'adamw',\n",
    "    'scheduler': 'cosine',    # Inferred from grid position\n",
    "    'dropout': 0.3,\n",
    "    'label_smoothing': 0.1,   # Inferred from grid position  \n",
    "    'augmentation_strength': 'medium',  # Inferred from grid position\n",
    "    'freeze_layers': 4\n",
    "}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUGMENTATION_TARGET = 1000\n",
    "\n",
    "def detect_and_convert_image(image):\n",
    "    \"\"\"Detect if image is grayscale and convert to 3-channel RGB\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(image.shape) == 3:\n",
    "        if image.shape[2] == 1:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 3:\n",
    "            return image\n",
    "        elif image.shape[2] == 4:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    return image\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"Load data from both color and grayscale folders\"\"\"\n",
    "    color_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\color\\\\*_NDA.png\"\n",
    "    gray_path = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\images\\\\squared\\\\grayscale\\\\*_NDA.png\"\n",
    "    \n",
    "    images = []\n",
    "    ages = []\n",
    "    sources = []\n",
    "    \n",
    "    print(\"Loading color images...\")\n",
    "    color_files = glob.glob(color_path)\n",
    "    for img_path in color_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('color')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'color'])} color images\")\n",
    "    \n",
    "    print(\"Loading grayscale images...\")\n",
    "    gray_files = glob.glob(gray_path)\n",
    "    for img_path in gray_files:\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            img = detect_and_convert_image(img)\n",
    "            img_resized = cv2.resize(img, IMAGE_SIZE[::-1])\n",
    "            \n",
    "            filename = os.path.basename(img_path)\n",
    "            filename_no_ext = os.path.splitext(filename)[0]\n",
    "            parts = filename_no_ext.split('_')\n",
    "            \n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            age_part = parts[3]\n",
    "            if 'xpx' in age_part.lower() or 'p' not in age_part:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                age_value = float(age_part.replace('p', '.'))\n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                sources.append('grayscale')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Loaded {len([s for s in sources if s == 'grayscale'])} grayscale images\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    \n",
    "    # Group ages\n",
    "    ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "    \n",
    "    # Filter classes with enough samples\n",
    "    age_counts = Counter(ages_grouped)\n",
    "    valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "    \n",
    "    filtered_images = []\n",
    "    filtered_ages = []\n",
    "    filtered_sources = []\n",
    "    \n",
    "    for img, age, source in zip(images, ages_grouped, sources):\n",
    "        if age in valid_ages:\n",
    "            filtered_images.append(img)\n",
    "            filtered_ages.append(age)\n",
    "            filtered_sources.append(source)\n",
    "    \n",
    "    print(f\"Final dataset: {len(filtered_images)} images\")\n",
    "    print(f\"Age distribution: {dict(Counter(filtered_ages))}\")\n",
    "    \n",
    "    return np.array(filtered_images), filtered_ages, filtered_sources\n",
    "\n",
    "def enhanced_augment_image(image, strength='medium'):\n",
    "    \"\"\"Enhanced augmentation with variable strength\"\"\"\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Set probabilities based on strength\n",
    "    if strength == 'light':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.5, 0.3, 0.6, 0.2, 0.1\n",
    "        rot_range, bright_range = 10, (0.8, 1.2)\n",
    "    elif strength == 'medium':\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.7, 0.5, 0.8, 0.4, 0.3\n",
    "        rot_range, bright_range = 15, (0.7, 1.3)\n",
    "    else:  # heavy\n",
    "        rot_prob, flip_prob, bright_prob, gamma_prob, noise_prob = 0.8, 0.6, 0.9, 0.5, 0.4\n",
    "        rot_range, bright_range = 20, (0.6, 1.4)\n",
    "    \n",
    "    # Rotation\n",
    "    if random.random() < rot_prob:\n",
    "        angle = random.uniform(-rot_range, rot_range)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if random.random() < flip_prob:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    # Strategic color conversion (RGB -> Grayscale -> RGB)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3 and random.random() < 0.4:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Brightness/contrast\n",
    "    if random.random() < bright_prob:\n",
    "        alpha = random.uniform(*bright_range)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Gamma correction\n",
    "    if random.random() < gamma_prob:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    # Noise\n",
    "    if random.random() < noise_prob:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_balanced_dataset(X, y, aug_strength='medium'):\n",
    "    \"\"\"Create balanced dataset through augmentation\"\"\"\n",
    "    print(f\"Creating balanced dataset with {aug_strength} augmentation...\")\n",
    "    \n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max(AUGMENTATION_TARGET, max_count)\n",
    "    \n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "    \n",
    "    for class_idx in range(len(set(y))):\n",
    "        class_mask = np.array(y) == class_idx\n",
    "        class_images = X[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # Add originals\n",
    "        X_balanced.extend(class_images)\n",
    "        y_balanced.extend([class_idx] * current_count)\n",
    "        \n",
    "        # Add augmented to reach target\n",
    "        needed = target_count - current_count\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy(), aug_strength)\n",
    "            X_balanced.append(aug_img)\n",
    "            y_balanced.append(class_idx)\n",
    "    \n",
    "    print(f\"Balanced dataset created: {len(X_balanced)} total images\")\n",
    "    return np.array(X_balanced), np.array(y_balanced)\n",
    "\n",
    "class DeerDataset(Dataset):\n",
    "    def __init__(self, X, y, training=True):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.training = training\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if not self.training and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "def create_ghostnet_model(num_classes, dropout=0.3, freeze_layers=4):\n",
    "    \"\"\"Create GhostNet model with exact combination 23 specifications\"\"\"\n",
    "    model = timm.create_model('ghostnet_100', pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    # Freeze early layers based on freeze_layers parameter (4 means aggressive freezing)\n",
    "    freeze_patterns = [\n",
    "        ['conv_stem'],\n",
    "        ['conv_stem', 'blocks.0'],\n",
    "        ['conv_stem', 'blocks.0', 'blocks.1'],\n",
    "        ['conv_stem', 'blocks.0', 'blocks.1', 'blocks.2']\n",
    "    ]\n",
    "    \n",
    "    if freeze_layers <= len(freeze_patterns):\n",
    "        frozen_count = 0\n",
    "        for name, param in model.named_parameters():\n",
    "            for pattern in freeze_patterns[freeze_layers - 1]:\n",
    "                if pattern in name:\n",
    "                    param.requires_grad = False\n",
    "                    frozen_count += 1\n",
    "                    break\n",
    "        print(f\"Frozen {frozen_count} parameters with {freeze_layers} layer groups\")\n",
    "    \n",
    "    # Replace classifier with exact dropout from combination 23\n",
    "    if hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "        print(f\"Classifier created with {dropout} dropout\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_combination_23(train_loader, val_loader, test_loader, num_classes, device):\n",
    "    \"\"\"Train model with exact combination 23 hyperparameters\"\"\"\n",
    "    print(\"Training with EXACT Combination 23 hyperparameters...\")\n",
    "    print(f\"Hyperparameters: {COMBINATION_23_HYPERPARAMS}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_ghostnet_model(\n",
    "        num_classes=num_classes,\n",
    "        dropout=COMBINATION_23_HYPERPARAMS['dropout'], \n",
    "        freeze_layers=COMBINATION_23_HYPERPARAMS['freeze_layers']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create optimizer with exact learning rates\n",
    "    backbone_params = []\n",
    "    classifier_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            if 'classifier' in name:\n",
    "                classifier_params.append(param)\n",
    "            else:\n",
    "                backbone_params.append(param)\n",
    "    \n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': backbone_params, 'lr': COMBINATION_23_HYPERPARAMS['backbone_lr']},\n",
    "        {'params': classifier_params, 'lr': COMBINATION_23_HYPERPARAMS['classifier_lr']}\n",
    "    ], weight_decay=COMBINATION_23_HYPERPARAMS['weight_decay'])\n",
    "    \n",
    "    # Create scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "    \n",
    "    # Create loss function\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=COMBINATION_23_HYPERPARAMS['label_smoothing'])\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    training_history = []\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(80):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_loss_total = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_loss_total += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_loss_total = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_loss_total += loss.item()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        train_loss = train_loss_total / len(train_loader)\n",
    "        val_loss = val_loss_total / len(val_loader)\n",
    "        \n",
    "        training_history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss\n",
    "        })\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print progress every 20 epochs\n",
    "        if epoch % 20 == 0 and epoch > 0:\n",
    "            print(f\"Epoch {epoch}: Train {train_acc:.1f}%, Val {val_acc:.1f}%, Loss {val_loss:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Load best weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    print(f\"Training completed. Best validation: {best_val_acc:.1f}%\")\n",
    "    \n",
    "    # Test evaluation with TTA\n",
    "    print(\"Evaluating on test set with TTA...\")\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Test time augmentation\n",
    "            outputs1 = model(images)\n",
    "            flipped = torch.flip(images, [3])\n",
    "            outputs2 = model(flipped)\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    print(f\"Test accuracy with TTA: {test_acc:.1f}%\")\n",
    "    \n",
    "    return model, best_val_acc, test_acc, training_history\n",
    "\n",
    "def main():\n",
    "    print(\"Rebuilding GhostNet Combination 23 (Best Test Performance)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Target performance: Val 84.2%, Test 81.2%\")\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load combined data\n",
    "    images, ages, sources = load_combined_data()\n",
    "    \n",
    "    # Create label mapping\n",
    "    unique_ages = sorted(list(set(ages)))\n",
    "    label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "    y_indices = np.array([label_mapping[age] for age in ages])\n",
    "    \n",
    "    print(f\"\\nClasses: {len(unique_ages)}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    \n",
    "    # EXACT same train/test split as original (same random_state)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # Further split training into train/val\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Train: {len(X_train_final)} images\")\n",
    "    print(f\"Val: {len(X_val)} images\") \n",
    "    print(f\"Test: {len(X_test)} images\")\n",
    "    \n",
    "    # Create balanced training set with EXACT augmentation strength from combination 23\n",
    "    X_train_balanced, y_train_balanced = create_balanced_dataset(\n",
    "        X_train_final, y_train_final, COMBINATION_23_HYPERPARAMS['augmentation_strength']\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DeerDataset(X_train_balanced, y_train_balanced, training=True)\n",
    "    val_dataset = DeerDataset(X_val, y_val, training=False)\n",
    "    test_dataset = DeerDataset(X_test, y_test, training=False)\n",
    "    \n",
    "    # Create data loaders with EXACT batch size from combination 23\n",
    "    batch_size = COMBINATION_23_HYPERPARAMS['batch_size']\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Train model with exact combination 23 hyperparameters\n",
    "    model, val_acc, test_acc, history = train_combination_23(\n",
    "        train_loader, val_loader, test_loader, len(unique_ages), device\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = f\"ghostnet_combination23_val{val_acc:.1f}_test{test_acc:.1f}_{timestamp}.pth\"\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'architecture': 'ghostnet_100',\n",
    "        'hyperparams': COMBINATION_23_HYPERPARAMS,\n",
    "        'val_accuracy': val_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'num_classes': len(unique_ages),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': IMAGE_SIZE,\n",
    "        'training_history': history,\n",
    "        'combination_number': 23,\n",
    "        'model_type': 'combination_23_rebuild'\n",
    "    }, save_path)\n",
    "    \n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMBINATION 23 REBUILD RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Target:     Val 84.2%, Test 81.2%\")\n",
    "    print(f\"Achieved:   Val {val_acc:.1f}%, Test {test_acc:.1f}%\")\n",
    "    print(f\"Match:      {'✓' if abs(val_acc - 84.2) < 2 and abs(test_acc - 81.2) < 2 else '✗'}\")\n",
    "    print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "    print(f\"Model saved: {save_path}\")\n",
    "    print(\"\\nHyperparameters used:\")\n",
    "    for key, value in COMBINATION_23_HYPERPARAMS.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c13841-464e-4971-9a64-def1e12fe3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
