{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bd270a-95d8-4330-92ef-478f908a8604",
   "metadata": {},
   "source": [
    "## Ingest images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a96314-0633-40b4-b727-9ceef74d57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from buck.analysis.basics import ingest_images\n",
    "\n",
    "fpath = \"..\\\\images\\\\squared\\\\*.png\"\n",
    "images,ages = ingest_images(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdea1f-2cb5-4ede-bce3-b6a2b349a836",
   "metadata": {},
   "source": [
    "## Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572f3c3c-89db-4ef1-90f8-8a56e6890e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buck.analysis.basics import split_data\n",
    "\n",
    "Xtr_og, ytr_og, Xval, yval, Xte, yte_onehot, ages, l_map = split_data(images, ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415e8a2-4981-46df-9980-e2f0c35bd3a3",
   "metadata": {},
   "source": [
    "## Homogenize data across classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57820b7d-7f52-4ca1-9b6c-43b1db82d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 0 (Age 1.5): 38 → 1725 samples\n",
      "  Class 1 (Age 2.5): 47 → 1725 samples\n",
      "  Class 2 (Age 3.5): 68 → 1725 samples\n",
      "  Class 3 (Age 4.5): 50 → 1725 samples\n",
      "  Class 4 (Age 5.5): 69 → 1725 samples\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.33 GiB for an array with shape (8625, 82944) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbuck\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalysis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m homogenize_data\n\u001b[32m      3\u001b[39m augment_multiplier = \u001b[32m25\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train_pca, y_train_flat, X_test_pca, y_true, label_mapping, num_classes = \u001b[43mhomogenize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr_og\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr_og\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXte\u001b[49m\u001b[43m,\u001b[49m\u001b[43myte_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment_multiplier\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\src\\buck\\analysis\\basics.py:270\u001b[39m, in \u001b[36mhomogenize_data\u001b[39m\u001b[34m(X_train_orig, y_train_orig, X_test, y_test_onehot, label_mapping, aug_mult)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;66;03m# Apply standardization\u001b[39;00m\n\u001b[32m    269\u001b[39m scaler = StandardScaler()\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m X_train_scaled = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m X_test_scaled = scaler.transform(X_test_flat)\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m# Free up memory\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1016\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1013\u001b[39m         \u001b[38;5;28mself\u001b[39m.n_samples_seen_ += X.shape[\u001b[32m0\u001b[39m] - np.isnan(X).sum(axis=\u001b[32m0\u001b[39m)\n\u001b[32m   1015\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m         \u001b[38;5;28mself\u001b[39m.mean_, \u001b[38;5;28mself\u001b[39m.var_, \u001b[38;5;28mself\u001b[39m.n_samples_seen_ = \u001b[43m_incremental_mean_and_var\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvar_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_samples_seen_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;66;03m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;66;03m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# missing values)\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.ptp(\u001b[38;5;28mself\u001b[39m.n_samples_seen_) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\Dropbox\\AI Projects\\buck\\buck-env\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1107\u001b[39m, in \u001b[36m_incremental_mean_and_var\u001b[39m\u001b[34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[39m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m     T = new_sum / new_sample_count\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     temp = \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1109\u001b[39m         \u001b[38;5;66;03m# equivalent to np.nansum((X-T)**2 * sample_weight, axis=0)\u001b[39;00m\n\u001b[32m   1110\u001b[39m         \u001b[38;5;66;03m# safer because np.float64(X*W) != np.float64(X)*np.float64(W)\u001b[39;00m\n\u001b[32m   1111\u001b[39m         correction = _safe_accumulator_op(\n\u001b[32m   1112\u001b[39m             np.matmul, sample_weight, np.where(X_nan_mask, \u001b[32m0\u001b[39m, temp)\n\u001b[32m   1113\u001b[39m         )\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 5.33 GiB for an array with shape (8625, 82944) and data type float64"
     ]
    }
   ],
   "source": [
    "from buck.analysis.basics import homogenize_data\n",
    "\n",
    "augment_multiplier = 25\n",
    "X_train_pca, y_train_flat, X_test_pca, y_true, label_mapping, num_classes = homogenize_data(Xtr_og, ytr_og, Xte,yte_onehot, l_map, augment_multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c2ba6-9153-4ea4-a8f6-55201f91bb7b",
   "metadata": {},
   "source": [
    "## Comparison classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54486b36-c48f-4b93-9069-1faf2c1f0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from buck.analysis.optimize_model import compare_models\n",
    "#\n",
    "#best_model = compare_models(X_train_pca, y_train_flat, X_test_pca, y_true, num_classes, label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e2411-0697-4db3-80fd-9ed0135120b0",
   "metadata": {},
   "source": [
    "## General cleanup before optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7397f6-e47c-4b23-8a86-86f5fab48d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# You can also check how many objects were collected\n",
    "collected = gc.collect()\n",
    "print(f\"Garbage collector: collected {collected} objects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5627d8c-3c08-43dd-ad01-450afbb5e6b8",
   "metadata": {},
   "source": [
    "## Optimize top-performing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff54c98-31ae-415a-8151-673b18ad15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buck.classifiers.gradient_boost import _optimize_gradient_boost\n",
    "\n",
    "optimals, accuracy = _optimize_gradient_boost(X_train_pca, y_train_flat, X_test_pca, y_true, cycles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d214f6-9cc9-4ab7-b4cd-c9e32ed0331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracy)\n",
    "title = f\"Max. accuracy: {np.max(accuracy)*100:.2f}%\"\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffe19d-b85a-4224-b85d-285edf0de636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
