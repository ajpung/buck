%This is a template file for use of iopjournal.cls

\documentclass{iopjournal}

% Options
%  [anonymous]  Provides output without author names, affiliations or acknowledgments to facilitate double-anonymous peer-review
%
% The following packages are required by iopjournal.cls and do not need to be declared again:
%  graphicx
%  fancyhdr
%  xcolora
%  hyperref
%
\begin{document}

\articletype{Journal Article} %	 e.g. Paper, Letter, Topical Review...

\title{Computer Vision for White-Tailed Deer Age Estimation: A Dual-Modality Approach Using Trail Camera Images and Jawbone Morphology}

\author{Aaron J. Pung, Ph.D.}

\email{aaron.pung@gmail.com}

\keywords{machine learning, computer vision, neural network, deer, age, classification, prediction, dental analysis, tooth wear, wildlife management, automation, deep learning, transfer learning}

\begin{abstract}
Accurate age estimation of white-tailed deer remains a critical challenge for wildlife management, with existing methods limited by low accuracy, high cost, or extensive processing delays. This study presents the first comprehensive computer vision approach addressing both field scenarios (live deer from trail cameras) and post-harvest scenarios (jawbone dental analysis). Using transfer learning with Convolutional Neural Networks, two complementary systems were developed: a ResNet-18 ensemble for trail camera images achieving $76.7\% \pm 5.9\%$ cross-validation accuracy, and an EfficientNet ensemble for jawbone images achieving $90.7\% \pm 2.6\%$ cross-validation accuracy. Both models substantially outperform traditional methods including human visual assessment ($60.6\%$), morphometric models ($63\%$), and manual tooth wear analysis, while exceeding the $70\%$ accuracy threshold required for wildlife management decisions. Attention map analysis confirms both models autonomously discover and utilize biologically relevant features---body morphology (neck, chest, stomach) for trail camera images and dental characteristics (tooth eruption sequences, wear patterns) for jawbone images---that precisely match the anatomical features wildlife biologists rely upon, despite never being explicitly programmed with these domain rules. This biological plausibility, combined with dramatic improvements in speed and consistency over traditional methods, positions these complementary systems as practical tools for transforming deer population monitoring and management across North America. The success of transfer learning with limited wildlife datasets (197 and 243 images) demonstrates broader implications for developing specialized computer vision tools in data-scarce biological domains.
\end{abstract}

\section{Introduction}

\subsection{Wildlife Management Context}

Accurate age estimation of white-tailed deer (\textit{Odocoileus virginianus}) is fundamental to effective wildlife management, impacting harvest regulations, population modeling, and conservation strategies across North America. Age-structure data inform critical decisions including harvest quotas, antler point restrictions, and habitat management priorities. However, obtaining reliable age estimates faces a persistent challenge: methods that work for live deer (non-invasive field observations) lack accuracy, while methods that achieve higher accuracy (laboratory dental analysis) require harvested specimens and substantial processing time.

Wildlife management requires age data from \textit{both} live populations and harvested specimens. Pre-season trail camera surveys of live deer enable population monitoring, buck-to-doe ratio estimation, and age-class distribution assessment without requiring harvest. Post-harvest analysis of jawbones from hunter-harvested deer provides validation data and detailed age-structure information for population models. Current methods address these scenarios independently, each with significant limitations. This study presents the first unified computer vision solution addressing both modalities, providing complementary tools that match the diverse data collection contexts wildlife managers actually encounter.

\subsection{Current Methods and Their Limitations}

For live deer, wildlife professionals and outdoor enthusiasts rely on "aging on the hoof" (AOTH), a set of visual assessment guidelines applied to trail camera images or field observations. First documented in 1978 \cite{1978knowlton}, AOTH attempts to predict deer age based on morphological features including chest depth, stomach sag, neck thickness, and leg proportions \cite{1996kroll, 1999demarais, 2003richards, 2008hellickson}. The biological rationale follows predictable ontogenetic changes: yearling bucks (1.5 years) exhibit proportionally longer legs, narrow chests, and minimal neck development due to incomplete skeletal maturity. As bucks mature (2.5-4.5 years), chest depth increases relative to body length, neck circumference expands due to muscle hypertrophy during breeding season, and stomach contour changes from flat to increasingly sagging as body mass increases. Aged bucks ($\geq 5.5$ years) typically show pronounced stomach sag, thick necks, shorter-appearing legs relative to body depth, and graying facial fur.

Despite these predictable biological patterns, human AOTH accuracy remains problematic. Gee et al. \cite{2013gee} found wildlife enthusiasts and trained professionals achieved only $36\%$ age prediction accuracy in systematic testing, with individual scores ranging between $16-56\%$. Recent data from the National Deer Association's (NDA) "Age This!" survey---used as ground truth in this study given the scarcity of publicly available known-age deer data---confirm these challenges. As shown in Figure \ref{fig:human-prediction}, human AOTH prediction accuracy revealed a correct prediction rate of $58.64\%$ with an inverse relationship between accuracy and buck age, consistent with previous studies \cite{2013gee, 2025pung}. Incorrect predictions for 2.5-year-old deer split nearly evenly between 1.5 and 3.5 years, whereas incorrect predictions for 3.5- and 4.5-year-old deer overwhelmingly skewed younger. For deer $\geq 5.5$ years, incorrect predictions dropped to 4.5 years nearly half the time. No age classes achieved the $70\%$ threshold professionals identify as necessary for management decisions, much less the $80\%$ threshold required for research applications.

%\begin{figure}[htbp!]
%\centering
%\includegraphics[width=12cm]{images/Fig0_HumanConfusionMatrix.jpg}
%\caption{Human prediction accuracy for white-tailed deer aging on the hoof from trail camera images. (Left) Accuracy by age class shows consistent underperformance below management thresholds. (Right) Confusion matrix reveals systematic bias toward predicting younger ages for mature deer (2.5-4.5 years) while yearlings are more reliably identified.}
%\label{fig:human-prediction}
%\end{figure}

The fundamental limitation of AOTH stems from individual morphological variation. Body condition varies dramatically with local nutrition quality, genetics, population density, and environmental stressors. Two bucks of identical age from different management units may exhibit substantially different body conformations, confounding visual assessment \cite{2013gee}. Morphometric approaches attempted to address this through quantitative measurements. Flinn \cite{2010flinn} developed models based on 64 body measurement ratios, achieving $63\%$ accuracy during post-breeding periods. While an improvement over unaided human assessment, this performance still falls short of practical thresholds and requires precise body measurements rarely obtainable from trail camera imagery.

For harvested deer, postmortem dental analysis provides two alternatives: tooth replacement and wear (TRW) and cementum annuli (CA). TRW relies on predictable dental development patterns. White-tailed deer are born with deciduous premolars and develop permanent dentition following a known eruption sequence. By 1.5 years, the third premolar ($P_3$) exhibits a characteristic three-crested structure. As deer age, molar tooth wear progresses in a predictable sequence based on masticatory mechanics and diet abrasiveness. The dentine-to-enamel ratio (DER) of successive molars ($M_1$, $M_2$, $M_3$) increases systematically with age as enamel wears away, exposing underlying dentine. By $\geq 6.5$ years, the first molar ($M_1$) typically shows extreme wear with flattened occlusal surfaces \cite{1949severinghaus, 1980larson}.

CA exploits annual cementum deposition patterns. Cementum layers form seasonally on tooth roots, with light bands depositing during summer (abundant nutrition, rapid growth) and dark bands during winter (nutritional stress, slow growth). Thin-section microscopy of incisors or premolars enables annuli counting similar to tree ring analysis \cite{1949severinghaus, 1963low, 1966ransom}. While conceptually elegant, both TRW and CA face practical limitations. TRW accuracy varies with soil abrasiveness (affecting wear rates), nutritional stress (affecting eruption timing), and analyst experience \cite{1966gilbert, 1967ludwig, 1979cook}. CA faces technical challenges including indistinct or condensed annulus patterns \cite{1966ransom, 1979cook} and requires specialized laboratory processing with multi-week turnaround times \cite{2012nda}.

Critically, studies comparing TRW and CA show inconsistent results. Some report equivalent performance \cite{1989jacobson}, others favor CA \cite{2000hamlin, 2013cooper}, while still others demonstrate TRW superiority even with specialized CA laboratories \cite{1979cook}. This lack of consensus reflects genuine biological variability in dental aging markers, suggesting neither method provides a definitive gold standard. The practical consequence for wildlife management is clear: current methods lack the combination of accuracy, speed, and accessibility required for large-scale population monitoring.

\subsection{Computer Vision and Transfer Learning}

Machine learning (ML) and computer vision (CV) have revolutionized classification tasks across domains by automatically learning hierarchical feature representations from raw data. Convolutional Neural Networks (CNNs) eliminate laborious manual feature engineering, instead discovering optimal features through data-driven optimization. For image classification, CNNs learn progressively complex representations: early layers detect edges and textures, intermediate layers recognize shapes and patterns, and deep layers capture high-level semantic concepts \cite{2015he}.

Transfer learning further enables high accuracy with limited domain-specific data by leveraging CNNs pre-trained on large datasets like ImageNet (14 million images across 1000 categories). Architectures including ResNet \cite{2015he}, EfficientNet \cite{2019tan}, and DenseNet \cite{2018huang} achieve exceptional performance through architectural innovations like residual connections and compound scaling. By freezing early layers (preserving general visual features) while fine-tuning deep layers (adapting to domain-specific patterns), transfer learning achieves strong performance even in data-scarce domains---a critical advantage for wildlife research where obtaining large quantities of professionally verified specimens is prohibitively expensive and time-consuming.

This study presents the first comprehensive application of deep learning to white-tailed deer age estimation, developing complementary models for both trail camera imagery and dental specimens. The dual-modality approach directly addresses the practical reality that wildlife managers collect age data from both live monitoring and post-harvest sampling, requiring tools optimized for each context.

\section{Trail Camera Assessment}

\subsection{Dataset Collection and Preparation}

The trail camera dataset contains 197 color images sourced exclusively from National Deer Association (NDA) materials including the weekly "Age This!" survey, educational videos, and published guides. While many images meet strict NDA quality standards---broadside posture, head-up position, minimal motion blur, good lighting, entire body visible---the dataset also includes video screenshots and media captures with more challenging conditions, expanding morphological variation and imaging quality. Geographic coverage spans 14 U.S. states, capturing regional variation in body morphology, though specific locations were not tracked. Age determinations represent NDA expert consensus, the most readily available source of systematically vetted age labels for supervised learning.

Importantly, image metadata including capture date, time, and location were stored but deliberately excluded as model inputs. This design choice forces the model to rely exclusively on visual morphology rather than potentially spurious correlations with temporal or geographic patterns. While metadata might improve predictions (e.g., correlating body condition with pre-rut timing), the goal was developing a generalizable model based purely on biological features that wildlife professionals could interpret and trust.

Age distribution reflects natural collection patterns: 30 yearlings (1.5 years), 36 images each of 2.5 and 3.5 year-olds, 52 images of 4.5 year-olds, and 43 images of deer $\geq 5.5$ years. Following standard wildlife management practice, all deer $\geq 5.5$ years were grouped into a single class, as age-related morphological changes become less distinct in mature animals while biological variation increases.

Image standardization followed a minimal preprocessing approach. Original photographs were cropped to square format capturing maximum deer body coverage while eliminating extraneous background. Cropped images were resized to $224 \times 224$ pixels to match ResNet-18 input requirements. Crucially, backgrounds remained unmodified---the model must learn to focus on deer morphology while ignoring diverse environmental contexts including forests, fields, feeding stations, and human structures. No artificial borders or digital artifacts were added, ensuring classification accuracy reflects genuine feature recognition rather than dataset-specific markers. Figure \ref{fig:trail-camera-sample} illustrates the standardized dataset's diversity in deer pose, lighting, background, and image quality.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig1_TrailCameraDataset.jpg}
%\caption{Representative sample from the standardized trail camera dataset, demonstrating variation in deer age, pose, lighting conditions, background environments, and image quality. All images were cropped to square format and resized to $224 \times 224$ pixels while preserving original backgrounds to ensure models learn deer-specific morphological features rather than imaging artifacts.}
%\label{fig:trail-camera-sample}
%\end{figure}

\subsection{Data Augmentation Strategy}

Deep learning classification typically requires $\sim$1000 samples per category for optimal performance---approximately 25× the data available in this study. To address this limitation, systematic data augmentation expanded the training set (80\%, 157 images) 40-fold through transformations simulating natural field variation while preserving biological features critical for age assessment.

Augmentation transformations included:
\begin{itemize}
\item \textbf{Rotation} ($\pm 10^{\circ}$): Simulates camera mounting angle variation and deer positioning relative to trail camera
\item \textbf{Horizontal flipping}: Mirrors deer walking direction, effectively doubling data while preserving body morphology
\item \textbf{Brightness adjustment} ($0.8-1.2\times$): Replicates lighting changes across time of day, weather conditions, and seasonal canopy coverage
\item \textbf{Contrast variation} ($0.8-1.2\times$): Accounts for camera sensor differences and exposure settings
\item \textbf{Gaussian noise addition} ($\sigma = 0.01$): Models sensor noise and image compression artifacts
\end{itemize}

Critically, augmentation ranges were constrained to avoid distorting age-diagnostic features. Excessive rotation would alter apparent body proportions (e.g., chest depth relative to body length), extreme brightness changes would obscure facial features and coat color, and aggressive cropping would eliminate key body regions. Each transformation preserves the morphological relationships wildlife biologists rely upon for visual assessment. The test set (20\%, 40 images) remained non-augmented and held out throughout model development, providing unbiased performance evaluation.

\subsection{Model Architecture and Training}

Following preliminary evaluation of traditional machine learning methods (achieving $\sim 57\%$ accuracy, substantially below CNN performance) and over 60 deep learning architectures, ResNet-18 \cite{2015he} was selected based on superior validation accuracy while maintaining computational efficiency suitable for practical deployment.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig2_ResNet18Architecture.jpg}
%\caption{ResNet-18 architecture adapted for deer age classification. The network comprises an initial convolution layer (Conv1) and batch normalization (BN), followed by four residual blocks (Layers 1-4), global average pooling, and a fully connected classifier. Pink layers remain frozen to preserve ImageNet-learned low- and mid-level features (edges, textures, shapes). Green layers are trainable, adapting high-level features to deer-specific morphology. The classifier head was replaced with a 5-class output corresponding to deer age categories (1.5, 2.5, 3.5, 4.5, $\geq 5.5$ years).}
%\label{fig:resnet18-architecture}
%\end{figure}

The ResNet-18 architecture (Figure \ref{fig:resnet18-architecture}) comprises an initial convolution layer followed by four residual blocks and a fully connected classifier. Transfer learning was implemented by freezing the initial convolution, batch normalization, and first three residual blocks, preserving ImageNet-learned features for edges, textures, and shape primitives. These low- to mid-level features transfer effectively across visual domains. The fourth residual block remained trainable, adapting high-level semantic features to deer-specific morphology including body proportion patterns, coat texture changes with age, and muscle conformation. The original 1000-class ImageNet classifier was replaced with a 5-class output layer for deer age categories.

To maximize data utilization given limited sample size, a 5-fold stratified cross-validation ensemble approach was employed. Training data were partitioned into five folds with proportional age class representation. Each fold was subdivided into training (125 images) and validation (32 images) components. Training images underwent 40× augmentation, yielding 5000 balanced samples per fold. Five independent ResNet-18 models were trained, one per fold, with each model training exclusively on its fold's augmented data and validating on the corresponding non-augmented validation set.

Training utilized AdamW optimization with differential learning rates: $0.0003$ for frozen backbone layers (minimal adjustment to preserve ImageNet features) and $0.001$ for trainable layers (enabling deer-specific adaptation). Learning rates followed exponential decay ($\gamma = 0.95$) to gradually reduce step sizes as models converged. Label smoothing ($\alpha = 0.1$) provided regularization by softening one-hot encoded labels, preventing overconfident predictions on the limited dataset. Cross-entropy loss served as the objective function. Early stopping with 20-epoch patience prevented overfitting, terminating training when validation loss ceased improving. Models typically converged after approximately 40 epochs per fold, requiring 45 minutes total training time on NVIDIA RTX 2060 hardware.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig3_ResNet18Inference.jpg}
%\caption{ResNet-18 ensemble inference process employing test-time augmentation (TTA). Each input image and its horizontally flipped version are passed through all five fold-specific models. Within each model, predictions on original and flipped images are averaged (TTA). The five TTA-averaged predictions are then ensemble-averaged using softmax normalization to produce final classification probabilities. This multi-stage averaging improves robustness and reduces prediction variance.}
%\label{fig:resnet18-inference}
%\end{figure}

Inference utilized test-time augmentation (TTA) with ensemble averaging (Figure \ref{fig:resnet18-inference}). For each test image, all five models generated predictions on both the original image and its horizontal flip. Within each model, predictions from original and flipped versions were averaged. The five TTA-averaged predictions were then ensemble-averaged using softmax normalization to produce final classification probabilities. This multi-stage process reduces prediction variance and improves robustness to minor pose variations.

\subsection{Trail Camera Results}

The ResNet-18 ensemble achieved $76.7\% \pm 5.9\%$ mean cross-validation accuracy across five folds and $97.5\%$ test accuracy. The substantial test-test performance likely reflects overfitting to the small dataset, making cross-validation the more reliable metric for expected real-world performance. Nonetheless, the cross-validation accuracy exceeds human expert assessment ($60.6\%$), morphometric models ($63\%$), and the $70\%$ threshold required for management decisions.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=12cm]{images/Fig4_TrailCameraConfusionMatrix.jpg}
%\caption{Trail camera model performance. (Left) Per-class accuracy shows strong performance across all age categories except 4.5 years, where one test specimen was misclassified as 2.5 years---the same age class most challenging for human assessors. (Right) Confusion matrix demonstrates near-perfect classification with minimal off-diagonal errors. The model achieves $100\%$ accuracy for yearlings (1.5 years), 2.5 years, 3.5 years, and mature deer ($\geq 5.5$ years) on the test set.}
%\label{fig:trail-camera-results}
%\end{figure}

Per-class performance (Figure \ref{fig:trail-camera-results}) remained strong across age categories with one notable exception: a single 4.5-year-old buck was misclassified as 2.5 years old on the test set. Interestingly, 4.5 years is also the age class most challenging for human assessors \cite{2013gee}, suggesting this may represent a genuinely difficult specimen exhibiting atypical morphology for its age rather than a systematic model failure. All other age classes achieved $100\%$ test accuracy, though this should be interpreted cautiously given the small test set size (40 images).

\subsection{Biological Interpretation via Attention Maps}

Beyond classification accuracy, understanding \textit{which} image features drive predictions is critical for biological validation and professional acceptance. Attention map analysis visualizes spatial regions the model deems most important for classification decisions. Figure \ref{fig:trail-camera-attention} shows attention maps for representative specimens from each age class.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig5_TrailCameraAttentionMaps.jpg}
%\caption{Attention map analysis for trail camera images. (Top row) Original images labeled with NDA-determined age. (Bottom row) Attention heatmaps overlaid on original images, with red/yellow indicating high attention and blue indicating low attention. The model autonomously focuses on neck, chest, and stomach regions across age classes while largely ignoring antlers---precisely matching the anatomical features wildlife professionals emphasize in AOTH assessment.}
%\label{fig:trail-camera-attention}
%\end{figure}

Despite variation in background, pose, and lighting, attention maps consistently focus on biologically relevant morphological features:

\begin{itemize}
\item \textbf{Yearlings (1.5 years)}: Attention concentrates on neck and chest regions, key indicators of immature body conformation. Young bucks exhibit narrow chests and thin necks relative to body size.

\item \textbf{2.5 years}: Focus distributes across neck, chest, and body, reflecting the transitional growth phase where proportions shift toward mature conformation but remain incomplete.

\item \textbf{Mature deer ($\geq 5.5$ years)}: Attention strongly emphasizes the stomach region, a primary characteristic experts use for identifying aged bucks. Pronounced stomach sag results from accumulated body mass and age-related changes in body composition.
\end{itemize}

Critically, attention maps largely ignore antlers across all age classes, aligning with expert guidance that antler size is an unreliable age indicator due to high variation with genetics, nutrition, and injury history \cite{1999demarais, 2003richards}. The model's spontaneous focus on body morphology rather than antlers---despite never being explicitly instructed to do so---provides compelling evidence that learned features reflect genuine age-related biological patterns rather than spurious correlations.

\section{Dental Assessment}

\subsection{Biological Foundations of Dental Aging}

White-tailed deer dental aging exploits two fundamental biological processes: predictable tooth eruption sequences during development and systematic tooth wear progression throughout life. Fawns are born with four deciduous premolars, with permanent premolars and molars erupting following a genetically determined schedule. By 1.5 years, the full adult dentition has erupted, with the third premolar ($P_3$) exhibiting a diagnostic three-crested structure. Deer $\geq 2.5$ years show two-crested $P_3$, providing clear separation between yearlings and older animals \cite{1949severinghaus, 1980larson}.

For deer $\geq 2.5$ years, aging relies on tooth wear patterns driven by masticatory mechanics. White-tailed deer are browsers and grazers, consuming vegetation with varying abrasiveness. Chewing mechanics produce predictable wear progression: the first molar ($M_1$) erupts earliest and experiences the longest wear period, followed sequentially by $M_2$ and $M_3$. As enamel wears away on occlusal surfaces, the underlying dentine becomes increasingly exposed. The dentine-to-enamel ratio (DER) of each molar increases systematically with age, providing quantitative aging criteria.

Traditional tooth replacement and wear (TRW) protocols follow a sequential decision tree based on tooth count (fawns vs. older deer), $P_3$ crest structure (1.5 years vs. $\geq 2.5$ years), and progressive DER thresholds for $M_1$, $M_2$, and $M_3$ to separate older age classes. However, work by Meares et al. \cite{2006meares} demonstrated that individual variation in tooth wear rates undermines DER reliability for separating 2.5-4.5 year classes, suggesting this age range represents a fundamental biological challenge for dental aging.

\subsection{Dataset Collection and Preparation}

The jawbone dataset comprises 243 color images collected from 17 independent sources including Quality Deer Management Association, National Deer Association, state wildlife agencies, and university wildlife programs via educational videos, training tutorials, and published guides. Unlike trail camera images, no restrictions were placed on geographic region or deer sex, as dental aging principles apply broadly across white-tailed deer populations. Age distribution included 39 fawns (0.5 years), 62 yearlings (1.5 years), 33 images of 2.5 year-olds, 29 images of 3.5 year-olds, 20 images of 4.5 year-olds, 22 images of 5.5 year-olds, and 38 images from deer aged 6.5-16.5 years (grouped as $5.5+$ years). Specimens confirmed as $\geq 9.5$ years were exclusively sourced from NDA documentation of exceptionally aged deer.

Jawbone image standardization followed similar principles to trail camera processing but adapted for dental specimens. Raw images often contained annotations, age labels, or measurement markings added during original educational material creation. These were digitally removed using editing tools on a Samsung Galaxy S25 Ultra to prevent the model from exploiting text information rather than learning dental features. Images were cropped to 2:1 aspect ratio ensuring all visible teeth remained in frame. Original backgrounds and lighting were preserved, and fingertips holding jawbones were retained in some images to simulate realistic field submission conditions where enthusiasts or agency personnel would photograph specimens in-hand. Figure \ref{fig:jawbone-sample} illustrates the standardized dataset's variation in jawbone orientation, lighting, background, and presentation.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig6_JawboneDataset.jpg}
%\caption{Representative sample from the standardized jawbone dataset, demonstrating variation in jawbone orientation, tooth condition, lighting, background, and imaging context (some include fingertips, some do not). Images were cropped to 2:1 aspect ratio and annotations were removed, but original backgrounds were preserved to ensure models learn dental features rather than imaging artifacts.}
%\label{fig:jawbone-sample}
%\end{figure}

Data splitting followed 80/20 train/test stratification with proportional age representation. Training data (80\%, 194 images) underwent balanced augmentation to 1200 samples per class through rotations ($\pm 10^{\circ}$), horizontal flipping (simulating imaging either side of the jaw), brightness adjustments ($0.8-1.2\times$), and contrast variation ($0.8-1.2\times$). Unlike trail camera augmentation, no Gaussian noise was added given that jawbone images are typically captured under more controlled conditions. The test set (20\%, 49 images) remained non-augmented.

\subsection{Model Architecture and Training}

EfficientNet \cite{2019tan} was selected for dental assessment based on its compound scaling approach balancing network depth, width, and resolution for computational efficiency. The architecture employs seven Mobile Inverted Bottleneck Convolution (MBConv) blocks with squeeze-and-excitation optimization, enabling efficient feature extraction with fewer parameters than comparably accurate architectures.

Transfer learning froze the stem convolution and first three MBConv blocks (blocks 0-2), preserving ImageNet-learned low- to mid-level features including edges, textures, and basic shapes. These general visual features transfer effectively to dental imaging. Subsequent blocks (blocks 3-6) remained trainable, adapting to dental-specific features including tooth outline shapes, wear surface textures, and eruption patterns. The classification head was replaced with a 6-class output to include fawns (0.5 years) in addition to the five age classes used for trail camera analysis.

A 5-fold nested cross-validation ensemble was employed with per-fold architecture selection. Training data were stratified into five folds (155 training, 39 validation per fold). For each fold, EfficientNet-B0, B1, and B2 variants were evaluated, selecting the best-performing architecture based on validation accuracy. The final ensemble comprised two EfficientNet-B2 models (folds 1 and 4) and three EfficientNet-B0 models (folds 2, 3, 5), as illustrated in Figure \ref{fig:efficientnet-ensemble}. This mixed-architecture approach captures complementary feature hierarchies: B0 emphasizes computational efficiency while B2 captures finer details through additional parameters.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig7_EfficientNetEnsemble.jpg}
%\caption{EfficientNet ensemble structure for dental age assessment. Each of five folds trains independently with balanced augmentation to 1200 samples per class. Architecture selection occurred per fold, with B2 selected for folds 1 and 4 (higher capacity for fine detail) and B0 selected for folds 2, 3, and 5 (computational efficiency). Inference employs test-time augmentation with validation-accuracy weighting of ensemble predictions.}
%\label{fig:efficientnet-ensemble}
%\end{figure}

Training utilized AdamW optimization with differential learning rates ($0.0003$ for frozen layers, $0.001$ for trainable layers). Learning rates followed cosine annealing scheduling with $T_{max} = 80$ and $\eta_{min} = 1 \times 10^{-6}$, providing smooth decay for stable convergence. Label smoothing ($\alpha = 0.1$) and dropout ($p = 0.3$) provided regularization. Cross-entropy loss with mixed precision training accelerated convergence. Early stopping with 20-epoch patience improved efficiency. Training converged after approximately 40-60 epochs per fold, requiring 536 minutes total on NVIDIA RTX 2060 hardware. Inference utilized TTA with cross-validation score weighting, where predictions from each model were weighted by its validation accuracy before ensemble averaging.

\subsection{Dental Assessment Results}

The EfficientNet ensemble achieved $90.7\% \pm 2.6\%$ mean cross-validation accuracy and $77.6\%$ test accuracy. The 13.1\% discrepancy between cross-validation and test performance likely reflects specimen-level data leakage (multiple images from individual specimens appearing in both training and test sets) combined with limited test set size. The more conservative test accuracy ($77.6\%$) still substantially exceeds traditional TRW performance and surpasses the $70\%$ management threshold. The cross-validation accuracy ($90.7\%$) well exceeds the $80\%$ research threshold.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=12cm]{images/Fig8_JawboneConfusionMatrix.jpg}
%\caption{Jawbone model performance. (Left) Per-class F1 scores show strong performance for fawns (0.5 years), yearlings (1.5 years), mature deer (4.5 and $\geq 5.5$ years), but reduced accuracy for 2.5 and 3.5 year classes. The macro-average F1 score (0.760, dashed line) reflects this uneven performance. (Right) Confusion matrix reveals the model's primary challenge: distinguishing 2.5 from 3.5 year-olds, predicting 2.5 years half the time for true 3.5 year specimens. This aligns with Meares et al.'s finding that individual variation in tooth wear undermines DER-based age separation for this range.}
%\label{fig:jawbone-results}
%\end{figure}

Per-class performance (Figure \ref{fig:jawbone-results}) reveals strong accuracy for fawns (0.5 years, $100\%$), yearlings (1.5 years, $91.7\%$), 4.5 years ($100\%$), and aged deer ($\geq 5.5$ years, $83.3\%$). However, 2.5 and 3.5 year classes showed reduced accuracy. For true age 2.5 years, the model split predictions evenly between 1.5, 2.5, and 3.5 years. For true age 3.5 years, the model predicted 2.5 years half the time, correctly identifying 3.5 years only one-third of the time. This difficulty aligns precisely with Meares et al.'s finding that DER cannot reliably separate 2.5-4.5 year classes due to individual tooth wear variation \cite{2006meares}. The model's confusion in this age range likely reflects genuine biological ambiguity rather than a correctable model limitation---even expert TRW analysts face this challenge.

\subsection{Biological Interpretation via Attention Maps}

Attention map analysis (Figure \ref{fig:jawbone-attention}) provides critical validation that the model learns dental-specific features matching TRW criteria despite never being explicitly programmed with these rules.

%\begin{figure}[htpb!]
%\centering
%\includegraphics[width=\linewidth]{images/Fig9_JawboneAttentionMaps.jpg}
%\caption{Attention map analysis for jawbone images. (Left column) Original standardized images. (Right column) Attention heatmaps overlaid on originals, with red/yellow indicating high attention and blue indicating low attention. Attention patterns precisely follow the TRW decision tree: (0.5 years) focuses on molars for tooth count, (1.5 years) focuses on premolars for crest counting, (2.5-4.5 years) progressively emphasizes sequential molars for DER assessment, ($\geq 5.5$ years) highlights extensive wear across all teeth. The model spontaneously discovers the same dental features wildlife biologists rely upon.}
%\label{fig:jawbone-attention}
%\end{figure}

Attention patterns across age classes demonstrate remarkable alignment with traditional TRW decision trees:

\begin{itemize}
\item \textbf{Fawns (0.5 years)}: Attention concentrates on molars, consistent with tooth count assessment (discriminating 4-tooth newborns from older deer).

\item \textbf{Yearlings (1.5 years)}: Focus shifts to premolars, matching crest-counting criteria. The three-crested $P_3$ structure characteristic of 1.5-year-olds is the primary diagnostic feature.

\item \textbf{2.5 years}: Attention distributes across the molar region, particularly $M_1$, corresponding to DER evaluation for the earliest-erupted molar showing measurable wear.

\item \textbf{3.5 years}: Focus targets posterior molars ($M_2$-$M_3$), consistent with sequential DER assessment as wear progresses to later-erupting teeth.

\item \textbf{4.5 years}: Attention remains focused on the molar region, reflecting continued DER evaluation across all three molars.

\item \textbf{Aged deer ($\geq 5.5$ years)}: Model highlights extensive wear characteristics and flattening across all teeth, the hallmark of extreme age.
\end{itemize}

Critically, attention maps focus exclusively on dental features despite variable backgrounds, finger presence in some images, and different jawbone orientations. The model learned to identify and ignore imaging artifacts while extracting genuine biological aging signatures. This spontaneous discovery of the TRW decision tree---tooth count, premolar structure, sequential molar wear---provides compelling evidence that the model captures authentic biological patterns rather than spurious dataset correlations.

\section{Comparative Analysis and Discussion}

\subsection{Performance Comparison Across Methods}

Table \ref{tab:comparison} summarizes performance across aging methods for both live and harvested deer assessment. The computer vision approaches substantially outperform traditional techniques while offering practical advantages in speed, consistency, and accessibility.

\begin{table}[htpb!]
\centering
\caption{Comparison of white-tailed deer aging methods across accuracy, processing time, and practical constraints. Computer vision approaches exceed traditional methods in accuracy while dramatically reducing analysis time and eliminating inter-observer variation. Management threshold: $70\%$; research threshold: $80\%$.}
\label{tab:comparison}
\begin{tabular}{lcccc}
\hline
\textbf{Method} & \textbf{Accuracy} & \textbf{Processing Time} & \textbf{Specimen Type} & \textbf{Key Limitation} \\
\hline
\multicolumn{5}{c}{\textit{Traditional Methods}} \\
Human AOTH & 36-60.6\% & Immediate & Live & High inter-observer variation \\
Morphometric & 63\% & Minutes-hours & Live & Requires precise measurements \\
Manual TRW & Variable & 5-15 minutes & Harvested & Analyst experience dependent \\
Cementum Annuli & Variable & 2-6 weeks & Harvested & Laboratory processing required \\
\hline
\multicolumn{5}{c}{\textit{Computer Vision (This Study)} } \\
Trail Camera CNN & 76.7\%$^\dagger$ & <1 second & Live & Morphological variation \\
Jawbone CNN & 90.7\%$^\dagger$ (77.6\%$^\ddagger$) & <1 second & Harvested & 2.5-3.5 year confusion \\
\hline
\multicolumn{5}{l}{$^\dagger$Cross-validation accuracy; $^\ddagger$Test accuracy} \\
\end{tabular}
\end{table}

For live deer assessment, the ResNet-18 ensemble ($76.7\%$) exceeds human AOTH ($60.6\%$) and morphometric models ($63\%$) while meeting the $70\%$ management threshold. Inference requires less than one second per image on modest GPU hardware, enabling rapid processing of large trail camera datasets. The primary limitation remains AOTH's fundamental constraint: morphological variation with nutrition, genetics, and environmental conditions prevents perfect classification. However, the model's ability to consistently exceed human performance while learning biologically interpretable features demonstrates practical value for population monitoring applications.

For harvested deer, the EfficientNet ensemble achieves $90.7\%$ cross-validation accuracy, substantially exceeding the $80\%$ research threshold. Even the more conservative test accuracy ($77.6\%$) surpasses traditional TRW performance. Processing time (<1 second) represents a dramatic improvement over manual TRW analysis (5-15 minutes) and laboratory CA processing (2-6 weeks). The automated approach eliminates inter-observer variation, a persistent challenge for traditional methods. The model's difficulty with 2.5-3.5 year separation reflects genuine biological ambiguity rather than a correctable failure---traditional TRW faces the same limitation.

\subsection{Biological Plausibility and Professional Acceptance}

Attention map validation provides critical evidence that both models learn biologically meaningful features that align with expert knowledge. This biological plausibility distinguishes the approach from opaque "black box" machine learning and facilitates professional acceptance by wildlife management agencies.

For trail camera assessment, the model's focus on neck, chest, and stomach regions while ignoring antlers precisely matches the anatomical features wildlife professionals emphasize in AOTH training \cite{1999demarais, 2003richards}. The model spontaneously discovers these features despite never being explicitly programmed with AOTH guidelines. This convergence between learned features and expert knowledge suggests the CNN identifies genuine ontogenetic changes (skeletal maturity, muscle development, body composition shifts) rather than spurious correlations.

For dental assessment, the progression from tooth count (fawns) to premolar structure (yearlings) to sequential molar wear (mature deer) perfectly follows the TRW decision tree \cite{1949severinghaus, 1980larson}. Again, these rules were never programmed---the model autonomously discovered them through data-driven optimization. The alignment demonstrates that CNN feature hierarchies can capture domain-specific biological knowledge that experts have codified through decades of field experience.

This biological interpretability addresses a common concern about deploying machine learning in wildlife management: that "black box" predictions lack scientific justification and cannot be trusted for critical decisions. By demonstrating that learned features match established biological principles, attention map validation builds confidence that predictions reflect genuine aging signals rather than dataset artifacts. This transparency facilitates adoption by wildlife agencies accustomed to traditional methods with clear biological rationales.

\subsection{Complementary Deployment Scenarios}

The dual-modality approach directly addresses practical realities of wildlife management data collection. Trail camera analysis enables non-invasive population monitoring: age-structure assessment, buck-to-doe ratio estimation, and cohort tracking over multiple years without requiring harvest. Wildlife agencies conduct pre-season trail camera surveys to inform harvest regulations, and hunters use trail cameras for selective harvest decisions. The $76.7\%$ accuracy meets management thresholds while processing speed (<1 second per image) enables analyzing thousands of images per season.

Jawbone analysis provides higher accuracy ($90.7\%$ cross-validation) for harvested specimens, meeting research standards for detailed population models and survival analyses. State agencies routinely collect jawbones from check stations during hunting season, often accumulating hundreds to thousands of samples. Traditional processing through manual TRW or laboratory CA creates bottlenecks limiting timely analysis. Automated CV assessment enables rapid screening: process all samples immediately, flag low-confidence cases for expert review, and provide age-structure data to managers within days rather than months.

The complementary nature of both tools addresses the full data collection pipeline wildlife managers actually encounter. Trail cameras monitor live populations throughout the year. Harvest-season jawbone collection validates pre-season estimates and provides high-accuracy age data for population models. Together, the systems transform both field monitoring and post-harvest analysis.

\subsection{Limitations and Future Directions}

Despite strong performance, several limitations warrant consideration. First, both datasets (197 and 243 images) remain modest compared to typical deep learning applications. This data scarcity reflects wildlife research reality: obtaining professionally verified known-age specimens is expensive and time-consuming. Transfer learning and data augmentation mitigate this limitation, but larger datasets from institutional collections would likely improve performance. Collaboration with state agencies and research institutions accessing archive collections could substantially expand training data.

Second, specimen-level data leakage may occur in the jawbone dataset, where multiple images from individual specimens likely appear in both training and test sets. While attention map analysis suggests the model learns biological features rather than specimen-specific artifacts, future work should implement specimen-level splitting to eliminate this confound. The 13.1\% gap between cross-validation and test accuracy suggests some overfitting, though the conservative test accuracy ($77.6\%$) still exceeds traditional methods.

Third, both models show reduced performance for 2.5-3.5 year classes, reflecting genuine biological challenges. For trail cameras, this age range represents a transitional growth phase where morphology shifts from immature to mature conformation but individual variation increases with nutrition and genetics. For jawbone analysis, Meares et al. \cite{2006meares} demonstrated that individual tooth wear variation undermines DER-based age separation for this range. Both human experts and automated systems struggle with these transitional ages, suggesting an inherent ceiling on classification accuracy absent additional information.

Fourth, geographic generalization requires systematic validation. Both datasets span multiple U.S. states, but body morphology and tooth wear patterns may vary with regional differences in nutrition, genetics (subspecies boundaries), habitat quality, and population density. Validation studies across management units would strengthen confidence in broad deployment. Regional model variants trained on local data might improve performance in specific contexts.

Fifth, ground truth uncertainty deserves acknowledgment. NDA expert consensus represents the best available age labels given data scarcity, but even experts disagree on challenging specimens. The true "correct" age remains unknown without independently verified known-age deer (e.g., from captive populations or longitudinal field studies). Model performance metrics inherently reflect agreement with expert consensus rather than absolute accuracy. Obtaining known-age validation sets from research facilities would enable more rigorous evaluation.

Future work should prioritize collaboration with wildlife agencies to access larger specimen collections, implement specimen-level data splitting, conduct geographic validation studies across management units, and develop uncertainty quantification methods to flag ambiguous cases for expert review. Extension to other cervid species (mule deer, elk, moose) where similar aging principles apply would demonstrate generalizability. Integration with existing wildlife management databases and workflows would facilitate practical deployment.

\subsection{Broader Implications for Wildlife Research}

The success of transfer learning with limited datasets (197 and 243 images) demonstrates important implications beyond deer aging. Wildlife research consistently faces data scarcity: obtaining large quantities of verified specimens is prohibitively expensive and field data collection is inherently challenging. Traditional machine learning struggled in these contexts, requiring extensive domain expertise for manual feature engineering and large sample sizes for reliable performance.

Transfer learning circumvents both limitations. Pre-trained CNNs capture generalizable visual features applicable across domains, enabling strong performance with modest domain-specific data. Automatic feature learning eliminates manual engineering, allowing wildlife biologists to leverage computer vision without extensive machine learning expertise. The approach demonstrated here---collecting limited labeled data from existing educational resources, applying transfer learning with CNN ensembles, validating biological plausibility through attention analysis---provides a template for developing specialized tools across wildlife biology.

Potential applications include automated species identification from camera traps, body condition scoring, injury detection, individual identification from coat patterns or other features, habitat quality assessment from vegetation imagery, and behavior classification from video. In each case, transfer learning enables domain experts to build effective tools with achievable data collection efforts. As wildlife agencies increasingly adopt trail cameras and digital documentation, computer vision tools can transform how biological data are extracted from imagery.

The biological interpretability demonstrated through attention analysis addresses a critical barrier to adoption: professional acceptance requires understanding \textit{why} predictions are made, not just achieving high accuracy. By confirming that learned features match established domain knowledge, attention validation builds confidence that models capture genuine biological signals. This transparency facilitates trust in automated systems for informing management decisions.

\section{Conclusions}

This study presents the first comprehensive computer vision approach to white-tailed deer age estimation, demonstrating that transfer learning with CNN ensembles achieves breakthrough performance for both field (trail camera) and post-harvest (dental) scenarios. The complementary systems address the practical reality that wildlife managers collect age data from both live monitoring and harvested specimens, requiring tools optimized for each context.

The ResNet-18 ensemble for trail camera imagery achieves $76.7\% \pm 5.9\%$ cross-validation accuracy, exceeding human AOTH assessment ($60.6\%$), morphometric models ($63\%$), and meeting the $70\%$ threshold for management decisions. The EfficientNet ensemble for jawbone imagery achieves $90.7\% \pm 2.6\%$ cross-validation accuracy ($77.6\%$ test accuracy), substantially outperforming traditional TRW and CA methods while dramatically reducing processing time from weeks to seconds and eliminating inter-observer variation.

Critically, attention map validation confirms that both models autonomously discover and utilize biologically relevant features that precisely match the anatomical characteristics wildlife biologists rely upon---body morphology (neck, chest, stomach) for trail cameras and dental patterns (tooth eruption, sequential wear) for jawbones---despite never being explicitly programmed with domain rules. This biological plausibility distinguishes the approach from opaque machine learning and facilitates professional acceptance by demonstrating that predictions reflect genuine biological aging signals rather than spurious correlations.

Together, these complementary systems offer wildlife managers practical tools for transforming population monitoring and management. Trail camera analysis enables rapid, non-invasive age-structure assessment for pre-season population surveys and real-time harvest decisions. Jawbone analysis provides high-accuracy validation from harvested specimens with immediate turnaround, eliminating processing bottlenecks that delay management actions. Both systems maintain or exceed accuracy standards for their respective applications while offering dramatic improvements in speed, consistency, and accessibility.

The success of transfer learning with limited datasets (197 and 243 images) demonstrates broader implications for wildlife research, where data scarcity persistently constrains method development. By leveraging pre-trained CNNs and validating biological plausibility through attention analysis, domain experts can develop specialized computer vision tools without massive data collection efforts or extensive machine learning expertise. As wildlife agencies increasingly adopt digital documentation, automated image analysis can transform how biological information is extracted from visual data, advancing conservation and management across species and contexts.

\bibliographystyle{unsrt}
\bibliography{iopbib}

\ack{The author acknowledges the wildlife management organizations, state agencies, and educational institutions that provided trail camera and post-mortem dental analysis training materials used in dataset construction. Particular appreciation is extended to the wildlife professionals who developed these educational resources, enabling this interdisciplinary application of computer vision to wildlife biology. Special thanks to the National Deer Association for their "Age This!" survey data and educational content that formed the foundation of both datasets. Appreciation is also extended to the open-source community for the deep learning frameworks and tools that enabled this work.}

\funding{This research received no external funding.}

\end{document}