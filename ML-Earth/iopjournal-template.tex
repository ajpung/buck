%This is a template file for use of iopjournal.cls

\documentclass{iopjournal}

% Options
%  [anonymous]  Provides output without author names, affiliations or acknowledgments to facilitate double-anonymous peer-review
%
% The following packages are required by iopjournal.cls and do not need to be declared again:
%  graphicx
%  fancyhdr
%  xcolor
%  hyperref
%
\begin{document}

\articletype{Journal Article} %	 e.g. Paper, Letter, Topical Review...

\title{Computer Vision for White-Tailed Deer Age Estimation: A Dual-Modality Approach Using Trail Camera Images and Jawbone Morphology}

\author{Aaron J. Pung, Ph.D.$^{1,*}$}

\email{aaron.pung@gmail.com}

\keywords{machine learning, computer vision, neural network, deer, age, classification, prediction, dental analysis, tooth wear, wildlife, management, automation, assessment}

\begin{abstract}
Accurate age estimation of white-tailed deer is critical for wildlife management but relies on specialized expertise that limits accessibility. We developed two complementary deep learning models for deer age classification using different data modalities. The trail camera model achieved $76.7\% \pm  5.9\%$ accuracy on live buck imagery, outperforming human experts ($60.6\%$) and traditional CNN methods ($57-63\%$). The dental model achieved $90.7\%$ accuracy on jawbone images, eliminating manual tooth evaluation. Attention map analysis confirmed both models focus on anatomically relevant features: body morphology (neck, chest, stomach) for trail cameras and dental wear patterns for jawbones. Both approaches exceed the $70\%$ accuracy threshold required for management decisions. The trail camera method enables non-invasive population monitoring while the dental approach provides verification for harvested specimens. This dual-modality framework democratizes wildlife age assessment, supporting sustainable harvest management and conservation decision-making without requiring specialized training.
\end{abstract}

\section{Introduction}
% Accurate age assessment is crucial for characterizing population structure and predicting ecological impacts due to its direct influence on body growth, doe fertility, antler quality, and offspring sex ratios. It fundamentally shapes ecosystem dynamics, disease transmission, and human-wildlife interactions, all demographic parameters that drive herd health and inform critical management decisions including hunting regulations and disease response strategies. Nonetheless, accurately predicting the age of white-tailed deer remains a significant challenge for wildlife management, with implications for both field monitoring and harvest assessment.

Understanding white-tailed deer population demographics remains foundational to ecological management. Amongst other environmental parameters, deer age is a primary driver of reproductive capacity, physical development, antler morphology, and offspring characteristics -- all biological metrics that define herd health and guide regulatory frameworks for harvest quotas and disease intervention protocols.

Wildlife professionals face persistent challenges in age determination across two distinct contexts. For living animals, visual assessment techniques rely on morphological cues observable through camouflaged camera systems deployed in the deer's environment. The non-invasive approaches to age prediction examine body proportions and seasonal characteristics, yet consistently underperform relative to management standards. For instance, predicting the age of white-tailed bucks based on relative body portions ("Aging On The Hoof", or AOTH) demonstrate accuracy rates between $36-63\%$ among both trained biologists and recreational observers, falling substantially below the $70\%$ threshold agencies require for population modeling and the $80\%$ benchmark researchers demand for demographic studies.

Alternatively, post-mortem analysis offers enhanced precision through direct dental examination. When examining whitetail jawbones, practitioners employ two established methodologies: evaluating tooth emergence patterns and enamel degradation ("tooth wear analysis", or TWA), or measuring seasonal growth rings deposited in root cementum ("cementum annuli", or CA). Both approaches exhibit documented limitations. Wear-based assessment proves sensitive to environmental variables including forage composition and soil mineral content, while ring-counting techniques struggle with irregular deposition patterns that compromise interpretation reliability. Investigations comparing the two techniques further reveals inconsistent performance metrics between the two methods, with relative accuracy varying by specimen age class and analyst experience. Laboratory processing capacity further constrains operational utility since specimen backlogs extend weeks to months, creating bottlenecks for agencies processing hundreds of submissions annually.

In an effort to educate hunters and wildlife enthusiasts, outdoor organizations such as the National Deer Association (NDA) create clear instructional videos, pamphlets, posters, and newsletters to teach AOTH and TWA methods. Using photographs, video walkthroughs, and annotated diagrams, viewers are shown numerous examples for different age classes, complete with an age determination and detailed justification. Despite these efforts, though, assessment proficiency remains highly variable and subject to expertise and experience.

As an alternative, automated pattern recognition systems offer a novel solution to these persistent accuracy and scalability challenges. Deep learning and computer vision architectures excel at extracting complex visual features from image data, identifying subtle morphological signatures that correlate with biological age. Such computational approaches operate consistently across specimens, eliminate inter-observer variability, and process submissions at speeds unattainable through manual review.

In this study, we present dual computer vision frameworks addressing both field surveillance and laboratory assessment scenarios. The first model processes trail camera photographs to classify the age of living white-tailed bucks based on somatic characteristics. The second framework analyzes jawbone images to determine age from dental morphology without requiring physical specimen sectioning or microscopic examination. By automating these complementary assessment pathways, we provide wildlife management agencies scalable tools that maintain diagnostic accuracy while dramatically reducing expert workload and analysis turnaround times.






State-of-the-art deer aging practices trail cameras enable hunters and professionals to monitor the movement and health of local deer populations, but estimating the age of white-tailed bucks from camera imagery remains challenging. One technique known as "Aging On The Hoof" (AOTH) attempts to determine age by analyzing the location and date of each image as well as the relative body proportions of the buck in the image \cite{1996Kroll, 1978Knowlton, 1999Demarais, 2003Richards, 2008Hellickson}. When the buck's body measurements are not known, human AOTH estimate averages just 36\% -- less than half the accuracy required for management-related selective harvest decisions ($\geq70\%$) or research purposes ($\geq80\%$) \cite{2014Gee}. 

%However, when the buck's body measurements are known, morphometric models can be used to achieve a prediction accuracy of 63\% during post-breeding periods \cite{2010flinn}. More recent efforts have achieved significantly greater prediction accuracy (76.7\%) by applying computer vision (CV) and deep learning (DL) to trail camera imagery \cite{2025pung}, providing the first automated approach that meets the accuracy thresholds necessary for practical wildlife management applications.

%As machine learning (ML) and computer vision (CV) become more engrained in societyare With the dawn of AI and ML, ... with existing computer vision methods limited to trail camera imagery and manual dental analysis requiring specialized expertise.

%Sample text inserted for demonstration. Organize the main text of your article using section headings, and include any equations, figures, tables, lists etc using your preferred \LaTeX\ packages and commands. Example code for a figure and a table is given below, but you do not have to use this format. For general guidance on using \LaTeX , including information on figures, tables, equations and references, please refer to documents such as the \LaTeX\ WikiBook: \href{https://en.wikibooks.org/wiki/LaTeX}{https://en.wikibooks.org/wiki/LaTeX}.

%Note that clarity of presentation is the most important consideration when preparing your article for submission. It is not necessary to format your article in the style used for published articles in the journal.

\subsection{Subsection title}
Sample text inserted for demonstration, including links to figure \ref{fig1} and table \ref{tab1}.

\subsubsection{Subsubsection heading}
Sample text inserted for demonstration.

\begin{figure}
 \centering
        \includegraphics[width=0.5\textwidth]{figure1}
 \caption{Text describing the figure and the main conclusions drawn from it. To make your figures accessible to as many readers as possible, try to avoid using colour as the only means of conveying information. For example, in charts and graphs use different line styles and symbols. Further information is available in the online guide: \href{https://publishingsupport.iopscience.iop.org/publishing-support/authors/authoring-for-journals/writing-journal-article/\#figures}{https://publishingsupport.iopscience.iop.org/publishing-support/authors/authoring-for-journals/writing-journal-article/\#figures}}
\label{fig1}
\end{figure}


\begin{table}
\caption{Caption text describing the table. Adapt the template table below or replace with a new table. To add more tables, copy and paste the whole {\tt \textbackslash begin\{table\}...\textbackslash end\{table\}} block.}
\centering
\begin{tabular}{l c c c}
\hline
Column heading & Column heading & Column heading & Column heading \\
\hline
Data row 1 & 1.0 & 1.5 & 2.0 \\
Data row 2 & 2.0 & 2.5 & 3.0 \\
Data row 3 & 3.0 & 3.5 & 4.0 \\
\hline
\end{tabular}
\label{tab1}
\end{table}

\bibliographystyle{plain}
\bibliography{iopbib}

%
% Each of the commands below will create an unnumbered section with the appropriate heading.
% Remove any sections that are not relevant for your article.
% All sections except suppdata will be removed if the [anonymous] option is used.
% See iopjournal-guidelines.pdf for more information.
%

\ack{The author acknowledges the wildlife management organizations, state agencies, and educational institutions that provided trail camera and post-mortem dental analysis training materials used in dataset construction. Particular appreciation is extended to the wildlife professionals who developed these educational resources, enabling this interdisciplinary application of computer vision to wildlife biology. Appreciation is also extended to the open-source community for the deep learning frameworks and tools that enabled this work.}

\funding{This research received no external funding.}
% This section is a list of funder names and grant numbers

\data{Sample text inserted for demonstration.}
% For more information on IOP Publishing's research data policy see: https://publishingsupport.iopscience.iop.org/questions/research-data/

\end{document}