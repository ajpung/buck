%This is a template file for use of iopjournal.cls

\documentclass{iopjournal}

% Options
%  [anonymous]  Provides output without author names, affiliations or acknowledgments to facilitate double-anonymous peer-review
%
% The following packages are required by iopjournal.cls and do not need to be declared again:
%  graphicx
%  fancyhdr
%  xcolor
%  hyperref
%
\begin{document}

\articletype{Journal Article} %	 e.g. Paper, Letter, Topical Review...

\title{Computer Vision for White-Tailed Deer Age Estimation: A Dual-Modality Approach Using Trail Camera Images and Jawbone Morphology}

\author{Aaron J. Pung, Ph.D.$^{*}$}

\email{aaron.pung@gmail.com}

\keywords{machine learning, computer vision, neural network, deer, age, classification, prediction, dental analysis, tooth wear, wildlife, management, automation, assessment}

\begin{abstract}
Accurate age estimation of white-tailed deer remains fundamental to wildlife management, yet current methods depend on highly specialized expertise that severely restrict its widespread application. This study presents two complementary deep learning models that enhance accessibility to automated age classification across different field and laboratory contexts. The first model analyzes color and grayscale trail camera images of live bucks, achieving $76.7\% \pm 5.9\%$ cross-validation accuracy, substantially outperforming average human assessment ($58.6\%$) and traditional morphometric approaches ($57-63\%$). The second model analyzes post-harvest jawbone imagery, achieving $90.7\%$ accuracy while eliminating the need for manual tooth replacement and wear evaluation. Attention heatmap visualization reveals that both models successfully identify the same anatomical features wildlife biologists rely upon: neck, chest, and stomach morphology in trail camera assessments, and dental wear patterns with tooth eruption sequences in jawbone analysis. The biological alignment between biologists and ML attention maps validates our models' ability to learn genuine age-related characteristics rather than spurious image correlations. The trail camera method enables scalable, non-invasive population monitoring of free-ranging animals, while the dental approach provides rapid, objective verification for harvested specimens.
\end{abstract}

\section{Introduction}
Understanding population dynamics of white-tailed deer (\textit{Odocoileus virginianus}) remains foundational to ecological management. Amongst other variables, age is a primary driver of biological metrics like reproductive capacity, physical development, antler morphology, and offspring characteristics, each of which help define herd health and guide regulatory frameworks for harvest quotas.

However, wildlife professionals continue to face challenges in age determination across two distinct contexts. For living deer, visual assessment techniques like "aging on the hoof" (AOTH) rely on morphological traits extracted through trail camera images. Based on comparing relative body proportions and seasonal characteristics of whitetail bucks, AOTH is a non-invasive technique that consistently underperforms relative to management standards. For both trained biologists and recreational observers, AOTH accuracy rates range from $36-63\%$, falling substantially below the $70\%$ threshold agencies require for population modeling and the $80\%$ benchmark researchers demand for demographic studies.

Alternatively, post-mortem dental analysis offers two additional methods to predict a deer's age. The first method, "tooth wear analysis" (TWA) evaluates tooth emergence patterns and enamel degradation, while a second method, cementum annuli (CA), measures seasonal growth rings deposited in root cementum. Both approaches show promise, but exhibit documented limitations. For instance, TWA assessment has proven sensitive to environmental variables including forage composition and soil mineral content, while CA techniques struggle with irregular deposition patterns that compromise interpretation reliability. Investigations comparing the two techniques further reveal inconsistent performance metrics with relative accuracy varying by specimen age class and analyst experience. Laboratory processing capacity further constrains operational utility since specimen backlogs can extend months into the future, creating bottlenecks for agencies processing hundreds of submissions annually.

In an effort to teach hunters and wildlife enthusiasts about age prediction methods, outdoor organizations like the National Deer Association (NDA) create instructional videos, newsletters, and other publications. Each walk-through includes photographic samples, annotated diagrams, and verbal explanations of context-specific features unique to each age class. Despite the abundance of documentation, however, age assessment proficiency remains variable and subject to expertise and experience.

As a modern alternative, computer vision (CV) offers a novel approach to persistent accuracy and scalability challenges. Deep learning (DL) architectures excel at extracting complex spatial features from image data, identifying subtle morphological signatures that strongly correlate with biological age. Such computational approaches operate consistently across specimens, eliminate observer variability, and process submissions at speeds unattainable through manual review.

This study details two computer vision frameworks, addressing both field surveillance and laboratory assessment scenarios. The first model processes trail camera photographs to classify the age of living white-tailed bucks based on somatic characteristics. The second framework analyzes jawbone images of white-tailed deer to determine age from dental morphology without requiring physical specimen sectioning or microscopic examination. By automating these complementary assessment pathways, wildlife management agencies gain scalable tools that maintain diagnostic accuracy while dramatically reducing expert workload and analysis turnaround times.

\section{Related work}
\subsection{Wildlife Age Estimation Using Machine Learning}
Computer vision applications in wildlife biology have expanded rapidly over the past decade, driven by advances in deep learning architectures and the proliferation of motion-activated trail cameras worldwide. Age estimation represents a particularly challenging classification problem due to continuous biological variation, environmental factors, and limited availability of ground-truth labeled datasets. Much of the published research focuses on species identification, individual recognition, or behavioral classification rather than age determination reflecting both the difficulty of obtaining verified age labels and the specialized domain knowledge required to establish training datasets. Data availability is further diminished by wildlife management agencies, whose interests commonly focus on differentiating between fawns, 1.5 year old deer, and 2.5 year old deer or older. While useful, the paradigm does not aid in discriminating between 1.5, 2.5, 3.5, 4.5, and 5.5+ year old deer.
 
Built on AOTH principles (\cite{1978Knowlton,1996Kroll,1999Demarais,2003Richards,2008Hellickson,2013Gee}), early computational approaches to cervid aging employed conventional signal processing to develop age prediction models (2010flinn). By examining 64 morphometric ratios of living white-tailed deer across Mississippi, Louisiana, and Texas, the models achieved a maximum of $63\%$ accuracy for post-breeding periods. However, these methods required manual measurement extraction and demonstrated limited generalization across geographic regions or imaging conditions. Recent applications of convolutional neural networks (CNNs) to wildlife imagery have achieved success in species classification and individual identification tasks (\cite{2019favorskaya,2023hindarto,2024sharma,2025Roca}), yet automated age estimation remains comparatively unexplored. Of the few studies that exist (\cite{2022mazurek,2022qi,2023saini}), emphasis is typically placed on facial features or pugmarks, not on body morphometrics.

% v------------------------------------- START HERE -------------------------------------v

\subsection{Aging Techniques for White-tailed Deer}
Traditional white-tailed deer age estimation is divided into field-based visual assessment and laboratory-based dental analysis. Visual aging methodologies emerged in the late 1970s (CITE), documenting relationships between body proportions and age classes in free-ranging populations. These approaches correlate chest depth, neck diameter, leg length ratios, and torso characteristics with known-age specimens from captive populations or harvest records. Morphometric studies have quantified these relationships through discriminant analysis and regression modeling, yet prediction accuracy plateaus substantially below operational requirements.

Dental aging techniques possess longer research histories, with foundational work establishing tooth replacement schedules and wear progression patterns in the 1940s. Practitioners distinguish fawns through incisor counts, separate yearlings via premolar crest enumeration, and classify mature animals through molar wear ratios. This sequential decision framework provides the conceptual foundation for field application, though substantial inter-observer variation limits reliability. Cementum annuli counting offers enhanced precision through microscopic examination of seasonal growth layers in tooth roots, analogous to dendrochronology in tree aging. Laboratory studies demonstrate variable agreement between wear-based and annuli-based age assignments, with concordance declining in older age classes where wear patterns become ambiguous and annuli deposition grows irregular.

Comparative investigations across ungulate species reveal similar accuracy limitations. Studies of mule deer, elk, and pronghorn document parallel challenges with both field assessment and laboratory techniques, suggesting these constraints reflect fundamental biological variability rather than species-specific complications. Geographic variation in soils, forage quality, and climate further compounds assessment difficulty by altering wear rates and body condition independent of age.

\subsection{Deep Learning in Biological Image Analysis}
To overcome limitations in conventional deep learning methods, transfer learning has emerged as the dominant paradigm for applying deep learning to specialized biological domains where labeled training data remains scarce. Pre-trained convolutional neural networks leverage feature representations learned from millions of natural images, then adapt final classification layers to domain-specific tasks through fine-tuning. This approach has proven particularly effective for medical imaging, agricultural applications, and ecological monitoring where acquiring thousands of expert-labeled training examples proves infeasible.

Attention mechanisms and gradient-based visualization techniques enhance human interpretation of the model's decision-making processes. This step is particularly important in biological applications where predictions must align with domain expertise to establish scientific credibility. Visualized as heatmaps overlayed on the raw image, attention mechanisms identify image regions that most strongly influence classification decisions, allowing researchers to verify whether models learn biologically meaningful features or exploit spurious correlations present in training data. Studies applying attention visualization to wildlife imagery have demonstrated that well-trained models can identify anatomical features consistent with expert knowledge, lending confidence to automated classification systems.

Furthermore, ensemble methods combining predictions from multiple independently trained models have consistently demonstrated improved accuracy and robustness compared to single-model approaches. This technique proves particularly valuable in limited-data regimes where individual models exhibit high variance. Cross-validation frameworks using stratified fold partitioning help ensure representative age class distribution across training and validation sets, providing reliable performance estimates despite small sample sizes.

\subsection{Gaps in Current Approaches}
Despite extensive research on white-tailed deer aging methodology, only two prior studies have applied deep learning to trail camera imagery [PUNG] or dental photographs for age classification [PUNG], both showing very strong potential. In both cases, the models exceeded average human performance and traditional morphometric approaches,  as well as accepted thresholds for population modeling and demographic research. Together, these models create an integrated framework leveraging both data modalities to provide wildlife managers with flexible assessment options appropriate to specific monitoring objectives and resource constraints.


\section{Materials and Methods}
\subsection{Data Collection and Sources}
We compiled two independent datasets addressing distinct operational contexts in white-tailed deer age assessment. The trail camera dataset targets field-based monitoring of free-ranging animals, while the dental dataset addresses post-harvest laboratory verification. Both datasets derive from publicly available educational resources produced by wildlife management organizations, reflecting the practical reality that verified age data for wild ungulates exists primarily within institutional training materials rather than research repositories.
\subsubsection{Trail Camera Dataset}
The trail camera image collection contains 197 photographs of male white-tailed deer sourced from the National Deer Association's educational media. Images originated from the organization's weekly "Age This!" feature, where readers estimate buck age from submitted trail camera photographs before receiving expert consensus determinations from a panel of wildlife biologists. This crowdsourced assessment program has operated continuously for multiple years, accumulating photographs spanning at least fourteen U.S. states and representing diverse habitat types, regional ecotypes, and nutritional environments.
To ensure consistency with professional age estimation standards, we included only photographs accompanied by National Deer Association panel consensus ages. Within this verified subset, we retained exclusively color imagery given documented changes in pelage coloration with age progression. This filtering process reduced the dataset to 197 images but ensured all training data met the quality standards wildlife professionals employ for age determination. The modest dataset size reflects the fundamental challenge in wildlife research: obtaining large quantities of professionally verified data remains difficult and expensive, requiring long-term monitoring programs or extensive harvest sampling with laboratory confirmation.
Images exhibit substantial natural variation in deer positioning, lighting conditions, camera angles, and background clutter. Deer orientations range from broadside profiles to quartering angles, with head positions varying from lowered grazing postures to alert upright stances. Lighting spans dawn through dusk conditions with corresponding variations in contrast and shadow patterns. Background environments include agricultural fields, forest edges, feeding stations, and trail corridors—reflecting the diverse contexts where trail cameras operate. This heterogeneity ensures that model training addresses real-world deployment conditions rather than artificially constrained laboratory imaging scenarios.
Critically, no metadata beyond visual content entered the modeling pipeline. We deliberately excluded photograph date, geographic location, and time-of-day information despite their availability. This design choice ensures the model learns age-related morphological characteristics rather than confounding correlations with temporal or spatial patterns. For instance, including photograph dates could enable the model to exploit seasonal rut timing rather than body morphology, while geographic coordinates might correlate with regional nutrition levels that influence body size independent of age.
\subsubsection{Dental Dataset}
The jawbone image collection comprises 243 photographs sourced from seventeen independent wildlife organizations including the National Deer Association, Quality Deer Management Association, state wildlife agencies, university extension programs, and professional training materials. Each source employs wildlife biologists or certified aging technicians who assign ages through established tooth replacement and wear protocols. We applied no filtering for geographic origin, specimen sex, or photographic quality beyond requiring that all teeth remain visible within the image frame.
Source diversity provides critical advantages for model generalization. Images span multiple decades of educational content production, encompassing changes in photographic equipment, lighting approaches, and presentation formats. Some sources photograph specimens on neutral backgrounds while others include measurement scales, color references, or hand positioning for size context. Jawbone orientations vary from perfect lateral profiles to slight angular deviations. This heterogeneity in imaging protocols mirrors the variability wildlife professionals encounter when processing field-collected specimens under non-standardized conditions.
Age assignments derive from expert application of the tooth replacement and wear decision framework. Analysts evaluate tooth counts to identify fawns and yearlings, examine premolar crest patterns to separate young adults, then assess molar dentine-to-enamel ratios to classify mature age classes. For specimens exceeding 5.5 years, experts often assign ages exceeding this threshold based on extreme wear patterns or tooth flattening, though training protocols typically group these animals into a single "mature" category for management purposes. We inherited these expert age determinations without independent verification, recognizing that even laboratory cementum annuli analysis produces inconsistent results when applied to the same specimens.
No jawbone specimens received preprocessing to remove identifying markings, measurement annotations, or handling artifacts. Some images contain partial finger presence from specimen positioning, visible measurement scales with numeric labels, or institutional watermarks. We intentionally preserved these elements to evaluate whether models learn dental morphology rather than spurious correlations with image metadata or handling cues. Subsequent attention map analysis would reveal whether the model focuses on tooth structures or extraneous image content.
Dataset availability reflects a fundamental constraint in wildlife biology: known-age specimens exist primarily within institutional collections or educational materials rather than publicly accessible research databases. Unlike computer vision domains where millions of labeled images enable model development, wildlife age estimation must operate within the boundaries of available verified data. Our dataset compilation represents months of systematic extraction from video tutorials, presentation slides, and published educational materials—a labor-intensive process necessitated by the absence of centralized data repositories for this application domain.







State-of-the-art deer aging practices trail cameras enable hunters and professionals to monitor the movement and health of local deer populations, but estimating the age of white-tailed bucks from camera imagery remains challenging. One technique known as "Aging On The Hoof" (AOTH) attempts to determine age by analyzing the location and date of each image as well as the relative body proportions of the buck in the image \cite{1996Kroll, 1978Knowlton, 1999Demarais, 2003Richards, 2008Hellickson}. When the buck's body measurements are not known, human AOTH estimate averages just 36\% -- less than half the accuracy required for management-related selective harvest decisions ($\geq70\%$) or research purposes ($\geq80\%$) \cite{2014Gee}. 

%However, when the buck's body measurements are known, morphometric models can be used to achieve a prediction accuracy of 63\% during post-breeding periods \cite{2010flinn}. More recent efforts have achieved significantly greater prediction accuracy (76.7\%) by applying computer vision (CV) and deep learning (DL) to trail camera imagery \cite{2025pung}, providing the first automated approach that meets the accuracy thresholds necessary for practical wildlife management applications.

%As machine learning (ML) and computer vision (CV) become more engrained in societyare With the dawn of AI and ML, ... with existing computer vision methods limited to trail camera imagery and manual dental analysis requiring specialized expertise.

%Sample text inserted for demonstration. Organize the main text of your article using section headings, and include any equations, figures, tables, lists etc using your preferred \LaTeX\ packages and commands. Example code for a figure and a table is given below, but you do not have to use this format. For general guidance on using \LaTeX , including information on figures, tables, equations and references, please refer to documents such as the \LaTeX\ WikiBook: \href{https://en.wikibooks.org/wiki/LaTeX}{https://en.wikibooks.org/wiki/LaTeX}.

%Note that clarity of presentation is the most important consideration when preparing your article for submission. It is not necessary to format your article in the style used for published articles in the journal.

\subsection{Subsection title}
Sample text inserted for demonstration, including links to figure \ref{fig1} and table \ref{tab1}.

\subsubsection{Subsubsection heading}
Sample text inserted for demonstration.

\begin{figure}
 \centering
        \includegraphics[width=0.5\textwidth]{figure1}
 \caption{Text describing the figure and the main conclusions drawn from it. To make your figures accessible to as many readers as possible, try to avoid using colour as the only means of conveying information. For example, in charts and graphs use different line styles and symbols. Further information is available in the online guide: \href{https://publishingsupport.iopscience.iop.org/publishing-support/authors/authoring-for-journals/writing-journal-article/\#figures}{https://publishingsupport.iopscience.iop.org/publishing-support/authors/authoring-for-journals/writing-journal-article/\#figures}}
\label{fig1}
\end{figure}


\begin{table}
\caption{Caption text describing the table. Adapt the template table below or replace with a new table. To add more tables, copy and paste the whole {\tt \textbackslash begin\{table\}...\textbackslash end\{table\}} block.}
\centering
\begin{tabular}{l c c c}
\hline
Column heading & Column heading & Column heading & Column heading \\
\hline
Data row 1 & 1.0 & 1.5 & 2.0 \\
Data row 2 & 2.0 & 2.5 & 3.0 \\
Data row 3 & 3.0 & 3.5 & 4.0 \\
\hline
\end{tabular}
\label{tab1}
\end{table}

\bibliographystyle{plain}
\bibliography{iopbib}

%
% Each of the commands below will create an unnumbered section with the appropriate heading.
% Remove any sections that are not relevant for your article.
% All sections except suppdata will be removed if the [anonymous] option is used.
% See iopjournal-guidelines.pdf for more information.
%

\ack{The author acknowledges the wildlife management organizations, state agencies, and educational institutions that provided trail camera and post-mortem dental analysis training materials used in dataset construction. Particular appreciation is extended to the wildlife professionals who developed these educational resources, enabling this interdisciplinary application of computer vision to wildlife biology. Appreciation is also extended to the open-source community for the deep learning frameworks and tools that enabled this work.}

\funding{This research received no external funding.}
% This section is a list of funder names and grant numbers

\data{Sample text inserted for demonstration.}
% For more information on IOP Publishing's research data policy see: https://publishingsupport.iopscience.iop.org/questions/research-data/

\end{document}