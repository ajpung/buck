{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e7a989-f872-4a6b-94d8-d60f6225e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "GPU memory: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected by PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7f717-95ca-4ef8-aa66-78473ba082d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete ResNet-34 Ensemble Training, Analysis, and Visualization Pipeline\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    MIXED_PRECISION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MIXED_PRECISION_AVAILABLE = False\n",
    "    class autocast:\n",
    "        def __enter__(self):\n",
    "            return self\n",
    "        def __exit__(self, *args):\n",
    "            pass\n",
    "\n",
    "def load_original_data():\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img_resized = cv2.resize(img, (448, 224))\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        age_counts = Counter(ages_grouped)\n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 3}\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        \n",
    "        for img, age in zip(images, ages_grouped):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def enhanced_augment_image(image):\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    if random.random() < 0.8:\n",
    "        alpha = random.uniform(0.7, 1.3)\n",
    "        beta = random.randint(-25, 25)\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        gamma = random.uniform(0.8, 1.2)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = np.random.normal(0, 7, image.shape).astype(np.int16)\n",
    "        image_int16 = image.astype(np.int16)\n",
    "        noisy_image = np.clip(image_int16 + noise, 0, 255)\n",
    "        image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_augmented_data(X_train, y_train, multiplier=25):\n",
    "    class_counts = Counter(y_train)\n",
    "    max_count = max(class_counts.values())\n",
    "    target_count = max_count * multiplier\n",
    "    \n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    for class_idx in range(len(set(y_train))):\n",
    "        class_mask = y_train == class_idx\n",
    "        class_images = X_train[class_mask]\n",
    "        current_count = len(class_images)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "        \n",
    "        for _ in range(4):\n",
    "            X_aug.extend(class_images)\n",
    "            y_aug.extend([class_idx] * current_count)\n",
    "        \n",
    "        needed = target_count - (current_count * 4)\n",
    "        for i in range(needed):\n",
    "            orig_idx = random.randint(0, current_count - 1)\n",
    "            aug_img = enhanced_augment_image(class_images[orig_idx].copy())\n",
    "            X_aug.append(aug_img)\n",
    "            y_aug.append(class_idx)\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "class OptimizedDataset(Dataset):\n",
    "    def __init__(self, X, y, test_time_aug=False):\n",
    "        self.X = torch.FloatTensor(X if isinstance(X, np.ndarray) else np.array(X))\n",
    "        self.y = torch.LongTensor(y if isinstance(y, np.ndarray) else np.array(y))\n",
    "        self.test_time_aug = test_time_aug\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].clone()\n",
    "        label = self.y[idx].clone()\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != (224, 448):\n",
    "            image = F.interpolate(image.unsqueeze(0), size=(224, 448), mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        if self.test_time_aug and random.random() < 0.5:\n",
    "            image = torch.flip(image, [2])\n",
    "        \n",
    "        image = (image - self.mean) / self.std\n",
    "        return image, label\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.handles = []\n",
    "        \n",
    "        handle1 = self.target_layer.register_forward_hook(self.forward_hook)\n",
    "        handle2 = self.target_layer.register_backward_hook(self.backward_hook)\n",
    "        self.handles.extend([handle1, handle2])\n",
    "    \n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "        self.handles = []\n",
    "    \n",
    "    def generate_cam(self, input_image, class_idx):\n",
    "        self.model.eval()\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        input_image = input_image.to(device)\n",
    "        \n",
    "        input_image.requires_grad_()\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        class_score = output[:, class_idx]\n",
    "        class_score.backward()\n",
    "        \n",
    "        if self.gradients is None or self.activations is None:\n",
    "            return np.zeros((224, 448))\n",
    "        \n",
    "        gradients = self.gradients[0].to(device)\n",
    "        activations = self.activations[0].to(device)\n",
    "        \n",
    "        weights = torch.mean(gradients, dim=(1, 2))\n",
    "        \n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32, device=device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "        \n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        if cam.max() > 0:\n",
    "            cam = cam / cam.max()\n",
    "        \n",
    "        return cam.detach().cpu().numpy()\n",
    "\n",
    "class ResNet34EnsembleTrainer:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            if MIXED_PRECISION_AVAILABLE:\n",
    "                self.scaler = GradScaler()\n",
    "                self.use_amp = True\n",
    "            else:\n",
    "                self.use_amp = False\n",
    "        else:\n",
    "            self.use_amp = False\n",
    "    \n",
    "    def create_resnet34_model(self):\n",
    "        model = timm.create_model('resnet34', pretrained=True, num_classes=self.num_classes)\n",
    "        \n",
    "        frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "        for name, param in model.named_parameters():\n",
    "            for frozen_layer in frozen_layers:\n",
    "                if name.startswith(frozen_layer):\n",
    "                    param.requires_grad = False\n",
    "                    break\n",
    "        \n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_single_fold(self, train_loader, val_loader, fold_idx):\n",
    "        model = self.create_resnet34_model()\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        \n",
    "        backbone_params = []\n",
    "        classifier_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    backbone_params.append(param)\n",
    "        \n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': backbone_params, 'lr': 0.0003},\n",
    "            {'params': classifier_params, 'lr': 0.001}\n",
    "        ], weight_decay=0.03)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80, eta_min=1e-6)\n",
    "        \n",
    "        max_epochs = 80\n",
    "        patience = 20\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        best_state = None\n",
    "        \n",
    "        # Track training history\n",
    "        training_history = {\n",
    "            'train_accs': [],\n",
    "            'val_accs': [],\n",
    "            'train_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            train_loss_total = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss_total += loss.item()\n",
    "                train_batches += 1\n",
    "                \n",
    "                # Clear intermediate tensors every few batches\n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            train_loss = train_loss_total / train_batches\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            val_loss_total = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    if self.use_amp:\n",
    "                        with autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss_total += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    # Clear memory during validation too\n",
    "                    if batch_idx % 5 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss = val_loss_total / val_batches\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Record training history\n",
    "            training_history['train_accs'].append(train_acc)\n",
    "            training_history['val_accs'].append(val_acc)\n",
    "            training_history['train_losses'].append(train_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "            # Periodic GPU memory cleanup\n",
    "            if epoch % 10 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        return model, best_val_acc, training_history\n",
    "    \n",
    "    def train_ensemble(self, images, ages):\n",
    "        if not isinstance(images, np.ndarray):\n",
    "            images = np.array(images)\n",
    "        if not isinstance(ages, np.ndarray):\n",
    "            ages = np.array(ages)\n",
    "        \n",
    "        unique_ages = sorted(list(set(ages)))\n",
    "        label_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        trained_models = []\n",
    "        cv_scores = []\n",
    "        training_histories = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(images, y_indices)):\n",
    "            X_train_fold = images[train_idx]\n",
    "            y_train_fold = y_indices[train_idx]\n",
    "            X_val_fold = images[val_idx]\n",
    "            y_val_fold = y_indices[val_idx]\n",
    "            \n",
    "            X_train_aug, y_train_aug = create_augmented_data(X_train_fold, y_train_fold, multiplier=15)\n",
    "            \n",
    "            train_dataset = OptimizedDataset(X_train_aug, y_train_aug)\n",
    "            val_dataset = OptimizedDataset(X_val_fold, y_val_fold, test_time_aug=True)\n",
    "            \n",
    "            batch_size = 16 if torch.cuda.is_available() else 8\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "            model, val_acc, history = self.train_single_fold(train_loader, val_loader, fold + 1)\n",
    "            \n",
    "            trained_models.append(model)\n",
    "            cv_scores.append(val_acc)\n",
    "            training_histories.append(history)\n",
    "            print(f\"Fold {fold + 1}/5 completed: {val_acc:.1f}% validation accuracy\")\n",
    "            \n",
    "            # Clear GPU memory after each fold\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return trained_models, cv_scores, label_mapping, training_histories\n",
    "    \n",
    "    def evaluate_model_with_tta(self, model, test_loader):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "        all_labels = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs1 = model(images)\n",
    "                flipped = torch.flip(images, [3])\n",
    "                outputs2 = model(flipped)\n",
    "                \n",
    "                avg_outputs = (outputs1 + outputs2) / 2\n",
    "                probs = F.softmax(avg_outputs, dim=1)\n",
    "                _, predicted = torch.max(avg_outputs, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_probabilities.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy, all_predictions, all_probabilities, all_labels\n",
    "    \n",
    "    def evaluate_ensemble(self, models, cv_scores, test_loader):\n",
    "        scores_array = np.array(cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_ensemble_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                ensemble_outputs = torch.zeros(images.size(0), self.num_classes).to(self.device)\n",
    "                \n",
    "                for model, weight in zip(models, weights):\n",
    "                    outputs1 = model(images)\n",
    "                    flipped = torch.flip(images, [3])\n",
    "                    outputs2 = model(flipped)\n",
    "                    avg_outputs = (outputs1 + outputs2) / 2\n",
    "                    \n",
    "                    ensemble_outputs += weight * F.softmax(avg_outputs, dim=1)\n",
    "                \n",
    "                _, predicted = torch.max(ensemble_outputs, 1)\n",
    "                \n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_ensemble_probs.extend(ensemble_outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        ensemble_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        return ensemble_acc, np.array(all_ensemble_probs), np.array(all_labels)\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, models, cv_scores, label_mapping, X_test, y_test, training_histories):\n",
    "        self.models = models\n",
    "        self.cv_scores = cv_scores\n",
    "        self.label_mapping = label_mapping\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.training_histories = training_histories\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.unique_ages = sorted(list(label_mapping.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        \n",
    "        Path(\"analysis_plots\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def evaluate_individual_models(self):\n",
    "        test_dataset = OptimizedDataset(self.X_test, self.y_test, test_time_aug=True)\n",
    "        batch_size = 16 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trainer = ResNet34EnsembleTrainer(self.num_classes)\n",
    "        individual_results = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            accuracy, preds, probs, labels = trainer.evaluate_model_with_tta(model, test_loader)\n",
    "            \n",
    "            individual_results.append({\n",
    "                'model_name': f'ResNet34_Fold_{i+1}',\n",
    "                'accuracy': accuracy,\n",
    "                'cv_score': self.cv_scores[i],\n",
    "                'predictions': np.array(preds),\n",
    "                'probabilities': np.array(probs),\n",
    "                'true_labels': np.array(labels)\n",
    "            })\n",
    "        \n",
    "        return individual_results\n",
    "    \n",
    "    def evaluate_ensemble(self, individual_results):\n",
    "        test_dataset = OptimizedDataset(self.X_test, self.y_test, test_time_aug=True)\n",
    "        batch_size = 16 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        trainer = ResNet34EnsembleTrainer(self.num_classes)\n",
    "        ensemble_acc, ensemble_probs, true_labels = trainer.evaluate_ensemble(self.models, self.cv_scores, test_loader)\n",
    "        \n",
    "        ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'ensemble_accuracy': ensemble_acc,\n",
    "            'ensemble_predictions': ensemble_preds,\n",
    "            'ensemble_probabilities': ensemble_probs,\n",
    "            'true_labels': true_labels\n",
    "        }\n",
    "    \n",
    "    def calculate_metrics(self, individual_results, ensemble_result):\n",
    "        metrics = {}\n",
    "        \n",
    "        for i, result in enumerate(individual_results):\n",
    "            preds = result['predictions']\n",
    "            true_labels = result['true_labels']\n",
    "            \n",
    "            accuracy = np.mean(preds == true_labels) * 100\n",
    "            f1_macro = f1_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            f1_weighted = f1_score(true_labels, preds, average='weighted', zero_division=0) * 100\n",
    "            precision = precision_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            recall = recall_score(true_labels, preds, average='macro', zero_division=0) * 100\n",
    "            \n",
    "            metrics[f'model_{i+1}'] = {\n",
    "                'accuracy': accuracy,\n",
    "                'f1_macro': f1_macro,\n",
    "                'f1_weighted': f1_weighted,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'cv_score': result['cv_score']\n",
    "            }\n",
    "        \n",
    "        if ensemble_result:\n",
    "            ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "            true_labels = ensemble_result['true_labels']\n",
    "            \n",
    "            ensemble_accuracy = np.mean(ensemble_preds == true_labels) * 100\n",
    "            ensemble_f1_macro = f1_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            ensemble_f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted', zero_division=0) * 100\n",
    "            ensemble_precision = precision_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            ensemble_recall = recall_score(true_labels, ensemble_preds, average='macro', zero_division=0) * 100\n",
    "            \n",
    "            metrics['ensemble'] = {\n",
    "                'accuracy': ensemble_accuracy,\n",
    "                'f1_macro': ensemble_f1_macro,\n",
    "                'f1_weighted': ensemble_f1_weighted,\n",
    "                'precision': ensemble_precision,\n",
    "                'recall': ensemble_recall\n",
    "            }\n",
    "            \n",
    "            class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "            metrics['classification_report'] = classification_report(\n",
    "                true_labels, ensemble_preds,\n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "            metrics['class_names'] = class_names\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def create_performance_plots(self, individual_results, ensemble_result, metrics):\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        model_names = [f'Fold {i+1}' for i in range(len(individual_results))]\n",
    "        accuracies = [result['accuracy'] for result in individual_results]\n",
    "        cv_scores = [result['cv_score'] for result in individual_results]\n",
    "        \n",
    "        if ensemble_result:\n",
    "            model_names.append('Ensemble')\n",
    "            accuracies.append(ensemble_result['ensemble_accuracy'])\n",
    "            cv_scores.append(np.mean(cv_scores))\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(model_names)))\n",
    "        \n",
    "        bars = ax1.bar(model_names, accuracies, alpha=0.8, color=colors, edgecolor='black', linewidth=2)\n",
    "        ax1.axhline(y=70, color='red', linestyle='--', linewidth=2, label=\"Target: 70%\")\n",
    "        \n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        ax1.set_ylabel('Test Accuracy (%)')\n",
    "        ax1.set_title('Model Performance Comparison')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # CV vs Test comparison\n",
    "        test_accs = [result['accuracy'] for result in individual_results]\n",
    "        cv_accs = [result['cv_score'] for result in individual_results]\n",
    "        \n",
    "        ax2.scatter(cv_accs, test_accs, alpha=0.7, s=100, c=colors[:-1] if ensemble_result else colors)\n",
    "        \n",
    "        min_acc = min(min(cv_accs), min(test_accs)) - 5\n",
    "        max_acc = max(max(cv_accs), max(test_accs)) + 5\n",
    "        ax2.plot([min_acc, max_acc], [min_acc, max_acc], 'k--', alpha=0.5)\n",
    "        \n",
    "        ax2.set_xlabel('Cross-Validation Accuracy (%)')\n",
    "        ax2.set_ylabel('Test Accuracy (%)')\n",
    "        ax2.set_title('CV vs Test Performance')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # F1 Scores\n",
    "        f1_scores = [metrics[f'model_{i+1}']['f1_macro'] for i in range(len(individual_results))]\n",
    "        if ensemble_result and 'ensemble' in metrics:\n",
    "            f1_scores.append(metrics['ensemble']['f1_macro'])\n",
    "        \n",
    "        ax3.bar(model_names, f1_scores, alpha=0.7, color='lightgreen', edgecolor='darkgreen')\n",
    "        ax3.set_ylabel('F1 Score (%)')\n",
    "        ax3.set_title('F1 Score (Macro) Comparison')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Class distribution\n",
    "        if ensemble_result:\n",
    "            true_labels = ensemble_result['true_labels']\n",
    "            ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "            class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "            \n",
    "            true_dist = [np.sum(true_labels == i) for i in range(len(class_names))]\n",
    "            pred_dist = [np.sum(ensemble_preds == i) for i in range(len(class_names))]\n",
    "            \n",
    "            x = np.arange(len(class_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax4.bar(x - width/2, true_dist, width, label='True Distribution', alpha=0.7, color='skyblue')\n",
    "            ax4.bar(x + width/2, pred_dist, width, label='Predicted Distribution', alpha=0.7, color='salmon')\n",
    "            \n",
    "            ax4.set_xlabel('Age Class')\n",
    "            ax4.set_ylabel('Number of Samples')\n",
    "            ax4.set_title('True vs Predicted Distribution')\n",
    "            ax4.set_xticks(x)\n",
    "            ax4.set_xticklabels(class_names)\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('analysis_plots/performance_overview.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def create_confusion_matrix(self, ensemble_result):\n",
    "        if not ensemble_result:\n",
    "            return\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        true_labels = ensemble_result['true_labels']\n",
    "        ensemble_preds = ensemble_result['ensemble_predictions']\n",
    "        class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "        \n",
    "        cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   cbar_kws={'label': 'Number of Samples'})\n",
    "        ax1.set_title('Confusion Matrix (Counts)')\n",
    "        ax1.set_xlabel('Predicted Age Class')\n",
    "        ax1.set_ylabel('True Age Class')\n",
    "        \n",
    "        cm_norm = confusion_matrix(true_labels, ensemble_preds, normalize='true')\n",
    "        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Greens', ax=ax2,\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   cbar_kws={'label': 'Proportion'})\n",
    "        ax2.set_title('Confusion Matrix (Normalized)')\n",
    "        ax2.set_xlabel('Predicted Age Class')\n",
    "        ax2.set_ylabel('True Age Class')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('analysis_plots/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def create_training_curves(self):\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "        \n",
    "        for fold, history in enumerate(self.training_histories):\n",
    "            ax = axes[fold]\n",
    "            epochs = range(1, len(history['train_accs']) + 1)\n",
    "            \n",
    "            ax.plot(epochs, history['train_accs'], 'b-', label='Training', linewidth=2, alpha=0.8)\n",
    "            ax.plot(epochs, history['val_accs'], 'r-', label='Validation', linewidth=2, alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Accuracy (%)')\n",
    "            ax.set_title(f'Fold {fold + 1} Training Curves')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('analysis_plots/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def run_analysis(self):\n",
    "        individual_results = self.evaluate_individual_models()\n",
    "        ensemble_result = self.evaluate_ensemble(individual_results)\n",
    "        metrics = self.calculate_metrics(individual_results, ensemble_result)\n",
    "        \n",
    "        self.create_performance_plots(individual_results, ensemble_result, metrics)\n",
    "        self.create_confusion_matrix(ensemble_result)\n",
    "        self.create_training_curves()\n",
    "        \n",
    "        return individual_results, ensemble_result, metrics\n",
    "\n",
    "class GradCAMVisualizer:\n",
    "    def __init__(self, models, label_mapping, X_test, y_test):\n",
    "        self.models = models\n",
    "        self.label_mapping = label_mapping\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.unique_ages = sorted(list(label_mapping.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        \n",
    "        Path(\"gradcam_visualizations\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.FloatTensor(image)\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != (224, 448):\n",
    "            image = F.interpolate(image.unsqueeze(0), size=(224, 448), \n",
    "                                mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image = (image - mean) / std\n",
    "        \n",
    "        return image.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def overlay_heatmap(self, image, heatmap, alpha=0.6):\n",
    "        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "        \n",
    "        heatmap_colored = cv2.applyColorMap(\n",
    "            (heatmap_resized * 255).astype(np.uint8), \n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        heatmap_colored = heatmap_colored.astype(np.float32) / 255.0\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_display = image\n",
    "        else:\n",
    "            image_display = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        overlaid = alpha * heatmap_colored + (1 - alpha) * image_display\n",
    "        return overlaid\n",
    "    \n",
    "    def select_diverse_samples(self, num_samples):\n",
    "        selected_indices = []\n",
    "        \n",
    "        for class_idx in range(self.num_classes):\n",
    "            class_indices = np.where(np.array(self.y_test) == class_idx)[0]\n",
    "            if len(class_indices) > 0:\n",
    "                selected_indices.append(np.random.choice(class_indices))\n",
    "        \n",
    "        remaining_needed = num_samples - len(selected_indices)\n",
    "        if remaining_needed > 0:\n",
    "            available_indices = [i for i in range(len(self.y_test)) if i not in selected_indices]\n",
    "            additional = np.random.choice(available_indices, \n",
    "                                        min(remaining_needed, len(available_indices)), \n",
    "                                        replace=False)\n",
    "            selected_indices.extend(additional)\n",
    "        \n",
    "        return selected_indices[:num_samples]\n",
    "    \n",
    "    def visualize_model_attention(self, num_samples=6):\n",
    "        sample_indices = self.select_diverse_samples(num_samples)\n",
    "        \n",
    "        num_cols = 2 + len(self.models)\n",
    "        fig, axes = plt.subplots(num_samples, num_cols, figsize=(4*num_cols, 4*num_samples))\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        grad_cams = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            try:\n",
    "                target_layer = model.layer4[-1].conv2\n",
    "                grad_cam = GradCAM(model, target_layer)\n",
    "                grad_cams.append(grad_cam)\n",
    "            except Exception as e:\n",
    "                grad_cams.append(None)\n",
    "        \n",
    "        try:\n",
    "            for sample_idx, idx in enumerate(sample_indices):\n",
    "                original_image = self.X_test[idx]\n",
    "                true_label = self.y_test[idx]\n",
    "                true_age = self.unique_ages[true_label]\n",
    "                \n",
    "                input_tensor = self.preprocess_image(original_image.copy())\n",
    "                \n",
    "                if original_image.max() > 1.0:\n",
    "                    display_image = original_image.astype(np.float32) / 255.0\n",
    "                else:\n",
    "                    display_image = original_image.astype(np.float32)\n",
    "                \n",
    "                axes[sample_idx, 0].imshow(display_image)\n",
    "                axes[sample_idx, 0].set_title(f'Original\\nTrue: Age {true_age}', fontsize=10)\n",
    "                axes[sample_idx, 0].axis('off')\n",
    "                \n",
    "                model_heatmaps = []\n",
    "                \n",
    "                for model_idx, (model, grad_cam) in enumerate(zip(self.models, grad_cams)):\n",
    "                    if grad_cam is None:\n",
    "                        axes[sample_idx, model_idx + 1].text(0.5, 0.5, 'Failed', \n",
    "                                                           transform=axes[sample_idx, model_idx + 1].transAxes,\n",
    "                                                           ha='center', va='center')\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        with torch.no_grad():\n",
    "                            model_output = model(input_tensor)\n",
    "                            model_pred = torch.argmax(model_output, dim=1).item()\n",
    "                        \n",
    "                        heatmap = grad_cam.generate_cam(input_tensor.clone(), model_pred)\n",
    "                        model_heatmaps.append(heatmap)\n",
    "                        \n",
    "                        overlaid = self.overlay_heatmap(display_image, heatmap)\n",
    "                        \n",
    "                        axes[sample_idx, model_idx + 1].imshow(overlaid)\n",
    "                        axes[sample_idx, model_idx + 1].set_title(f'Fold {model_idx + 1}\\nPred: Age {self.unique_ages[model_pred]}', fontsize=9)\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        axes[sample_idx, model_idx + 1].text(0.5, 0.5, 'Error', \n",
    "                                                           transform=axes[sample_idx, model_idx + 1].transAxes,\n",
    "                                                           ha='center', va='center')\n",
    "                        axes[sample_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                \n",
    "                # Create ensemble heatmap\n",
    "                valid_heatmaps = [h for h in model_heatmaps if h is not None]\n",
    "                if valid_heatmaps:\n",
    "                    ensemble_heatmap = np.mean(valid_heatmaps, axis=0)\n",
    "                    ensemble_overlaid = self.overlay_heatmap(display_image, ensemble_heatmap)\n",
    "                    \n",
    "                    axes[sample_idx, -1].imshow(ensemble_overlaid)\n",
    "                    axes[sample_idx, -1].set_title(f'Ensemble\\nAverage', fontsize=10)\n",
    "                    axes[sample_idx, -1].axis('off')\n",
    "                else:\n",
    "                    axes[sample_idx, -1].text(0.5, 0.5, 'No Valid\\nHeatmaps', \n",
    "                                            transform=axes[sample_idx, -1].transAxes,\n",
    "                                            ha='center', va='center')\n",
    "                    axes[sample_idx, -1].axis('off')\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        finally:\n",
    "            for grad_cam in grad_cams:\n",
    "                if grad_cam is not None:\n",
    "                    grad_cam.remove_hooks()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gradcam_visualizations/resnet34_ensemble_attention.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def run_gradcam_analysis(self):\n",
    "        self.visualize_model_attention(num_samples=6)\n",
    "\n",
    "def save_models_and_ensemble(models, cv_scores, label_mapping, ensemble_acc, training_histories):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_dir = f\"resnet34_ensemble_{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save individual models\n",
    "    for i, (model, score) in enumerate(zip(models, cv_scores)):\n",
    "        model_path = os.path.join(save_dir, f\"resnet34_fold_{i+1}_{score:.1f}pct.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_architecture': 'resnet34',\n",
    "            'fold': i+1,\n",
    "            'cv_score': score,\n",
    "            'num_classes': len(label_mapping),\n",
    "            'label_mapping': label_mapping,\n",
    "            'input_size': (224, 448)\n",
    "        }, model_path)\n",
    "    \n",
    "    # Save ensemble\n",
    "    ensemble_path = os.path.join(save_dir, \"resnet34_ensemble.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dicts': [model.state_dict() for model in models],\n",
    "        'architectures_used': ['resnet34'] * len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'num_classes': len(label_mapping),\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': (224, 448)\n",
    "    }, ensemble_path)\n",
    "    \n",
    "    # Save data splits and training histories\n",
    "    with open(os.path.join(save_dir, \"training_histories.pkl\"), 'wb') as f:\n",
    "        pickle.dump(training_histories, f)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'timestamp': timestamp,\n",
    "        'architecture': 'resnet34',\n",
    "        'num_folds': len(models),\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': float(np.mean(cv_scores)),\n",
    "        'cv_std': float(np.std(cv_scores)),\n",
    "        'ensemble_score': ensemble_acc,\n",
    "        'label_mapping': label_mapping,\n",
    "        'input_size': '448x224'\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    return save_dir\n",
    "\n",
    "def main():\n",
    "    print(\"ResNet-34 Ensemble Training, Analysis, and Visualization Pipeline\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        images, ages = load_original_data()\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = ResNet34EnsembleTrainer(num_classes=len(set(ages)))\n",
    "        \n",
    "        # Train ensemble\n",
    "        print(\"Training ensemble...\")\n",
    "        models, cv_scores, label_mapping, training_histories = trainer.train_ensemble(images, ages)\n",
    "        \n",
    "        # Create test set\n",
    "        y_indices = np.array([label_mapping[age] for age in ages])\n",
    "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
    "            images, y_indices, test_size=0.2, random_state=42, stratify=y_indices\n",
    "        )\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        test_dataset = OptimizedDataset(X_test, y_test, test_time_aug=True)\n",
    "        batch_size = 32 if torch.cuda.is_available() else 8\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        ensemble_acc, _, _ = trainer.evaluate_ensemble(models, cv_scores, test_loader)\n",
    "        \n",
    "        # Save models\n",
    "        print(\"Saving models...\")\n",
    "        save_dir = save_models_and_ensemble(models, cv_scores, label_mapping, ensemble_acc, training_histories)\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(\"\\nTraining Results:\")\n",
    "        print(f\"CV Scores: {[f'{score:.1f}%' for score in cv_scores]}\")\n",
    "        print(f\"CV Mean: {np.mean(cv_scores):.1f}% ¬± {np.std(cv_scores):.1f}%\")\n",
    "        print(f\"Ensemble Test Accuracy: {ensemble_acc:.1f}%\")\n",
    "        print(f\"Training Time: {elapsed:.1f} minutes\")\n",
    "        print(f\"Models saved to: {save_dir}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        print(\"\\nRunning model analysis...\")\n",
    "        analyzer = ModelAnalyzer(models, cv_scores, label_mapping, X_test, y_test, training_histories)\n",
    "        individual_results, ensemble_result, metrics = analyzer.run_analysis()\n",
    "        \n",
    "        # Run Grad-CAM visualization\n",
    "        print(\"\\nRunning Grad-CAM visualization...\")\n",
    "        gradcam_viz = GradCAMVisualizer(models, label_mapping, X_test, y_test)\n",
    "        gradcam_viz.run_gradcam_analysis()\n",
    "        \n",
    "        print(\"\\nPipeline Complete!\")\n",
    "        print(\"Check 'analysis_plots/' for performance analysis\")\n",
    "        print(\"Check 'gradcam_visualizations/' for attention maps\")\n",
    "        \n",
    "        return {\n",
    "            'models': models,\n",
    "            'cv_scores': cv_scores,\n",
    "            'ensemble_score': ensemble_acc,\n",
    "            'save_directory': save_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88400500-db6c-4273-ae06-c35835b9f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Group Specific GradCAM Analysis Script\n",
    "# Shows attention maps for one representative image from each age group\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "def load_original_data():\n",
    "    \"\"\"Load and process the original deer tooth images\"\"\"\n",
    "    try:\n",
    "        fpath = \"G:\\\\Dropbox\\\\AI Projects\\\\buck\\\\tooth_analysis\\\\images\\\\*.png\"\n",
    "        \n",
    "        image_paths = glob.glob(fpath)\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No images found at {fpath}\")\n",
    "        \n",
    "        images = []\n",
    "        ages = []\n",
    "        filenames = []\n",
    "        \n",
    "        print(f\"Processing {len(image_paths)} image files...\")\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Convert BGR to RGB for correct color display\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, (448, 224))\n",
    "                \n",
    "                filename = os.path.basename(img_path)\n",
    "                filename_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = filename_no_ext.split('_')\n",
    "                \n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                bbb_part = parts[1]\n",
    "                \n",
    "                if 'p' not in bbb_part:\n",
    "                    continue\n",
    "                \n",
    "                value_str = bbb_part.replace('p', '.')\n",
    "                try:\n",
    "                    age_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                ages.append(age_value)\n",
    "                filenames.append(filename)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No valid images loaded\")\n",
    "        \n",
    "        # Group ages: anything >= 5.5 becomes 5.5\n",
    "        ages_grouped = [5.5 if age >= 5.5 else age for age in ages]\n",
    "        \n",
    "        # Filter out classes with too few samples\n",
    "        age_counts = Counter(ages_grouped)\n",
    "        print(f\"Age distribution: {dict(age_counts)}\")\n",
    "        \n",
    "        valid_ages = {age for age, count in age_counts.items() if count >= 1}  # At least 1 sample for visualization\n",
    "        \n",
    "        filtered_images = []\n",
    "        filtered_ages = []\n",
    "        filtered_filenames = []\n",
    "        \n",
    "        for img, age, filename in zip(images, ages_grouped, filenames):\n",
    "            if age in valid_ages:\n",
    "                filtered_images.append(img)\n",
    "                filtered_ages.append(age)\n",
    "                filtered_filenames.append(filename)\n",
    "        \n",
    "        print(f\"Available age groups: {sorted(list(valid_ages))}\")\n",
    "        \n",
    "        return np.array(filtered_images), filtered_ages, filtered_filenames\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def find_latest_ensemble_directory():\n",
    "    \"\"\"Find the most recent ResNet-34 ensemble directory\"\"\"\n",
    "    patterns = [\"resnet34_ensemble_*\"]\n",
    "    \n",
    "    dirs = []\n",
    "    for pattern in patterns:\n",
    "        dirs.extend(glob.glob(pattern))\n",
    "    \n",
    "    if not dirs:\n",
    "        raise FileNotFoundError(\"No ResNet-34 ensemble directories found! Please run the training script first.\")\n",
    "    \n",
    "    latest_dir = max(dirs, key=os.path.getmtime)\n",
    "    print(f\"Found ensemble directory: {latest_dir}\")\n",
    "    return latest_dir\n",
    "\n",
    "def load_trained_ensemble(ensemble_dir):\n",
    "    \"\"\"Load the trained ResNet-34 ensemble models\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(os.path.join(ensemble_dir, \"metadata.json\"), 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    label_mapping = metadata['label_mapping']\n",
    "    num_classes = len(label_mapping)\n",
    "    \n",
    "    # Load individual models\n",
    "    models = []\n",
    "    cv_scores = metadata['cv_scores']\n",
    "    \n",
    "    for fold in range(1, 6):  # 5 folds\n",
    "        # Find model file for this fold\n",
    "        model_files = glob.glob(os.path.join(ensemble_dir, f\"resnet34_fold_{fold}_*.pth\"))\n",
    "        if not model_files:\n",
    "            print(f\"Warning: No model file found for fold {fold}\")\n",
    "            continue\n",
    "        \n",
    "        model_path = model_files[0]\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Create ResNet-34 model\n",
    "        model = timm.create_model('resnet34', pretrained=False, num_classes=num_classes)\n",
    "        \n",
    "        # Apply same modifications as training\n",
    "        frozen_layers = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']\n",
    "        for name, param in model.named_parameters():\n",
    "            for frozen_layer in frozen_layers:\n",
    "                if name.startswith(frozen_layer):\n",
    "                    param.requires_grad = False\n",
    "                    break\n",
    "        \n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Load trained weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        models.append(model)\n",
    "        print(f\"Loaded fold {fold} model: {cv_scores[fold-1]:.1f}% CV accuracy\")\n",
    "    \n",
    "    return models, label_mapping, cv_scores\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"GradCAM implementation for ResNet-34\"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.handles = []\n",
    "        \n",
    "        handle1 = self.target_layer.register_forward_hook(self.forward_hook)\n",
    "        handle2 = self.target_layer.register_backward_hook(self.backward_hook)\n",
    "        self.handles.extend([handle1, handle2])\n",
    "    \n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "        self.handles = []\n",
    "    \n",
    "    def generate_cam(self, input_image, class_idx):\n",
    "        self.model.eval()\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        input_image = input_image.to(device)\n",
    "        \n",
    "        input_image.requires_grad_()\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        class_score = output[:, class_idx]\n",
    "        class_score.backward()\n",
    "        \n",
    "        if self.gradients is None or self.activations is None:\n",
    "            return np.zeros((224, 448))\n",
    "        \n",
    "        gradients = self.gradients[0].to(device)\n",
    "        activations = self.activations[0].to(device)\n",
    "        \n",
    "        weights = torch.mean(gradients, dim=(1, 2))\n",
    "        \n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32, device=device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "        \n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        if cam.max() > 0:\n",
    "            cam = cam / cam.max()\n",
    "        \n",
    "        return cam.detach().cpu().numpy()\n",
    "\n",
    "class AgeGroupGradCAMAnalyzer:\n",
    "    \"\"\"Analyzer for age group specific GradCAM visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, ensemble_dir=None):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        print(\"Age Group Specific GradCAM Analyzer\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Device: {self.device}\")\n",
    "        \n",
    "        # Find ensemble directory if not provided\n",
    "        if ensemble_dir is None:\n",
    "            ensemble_dir = find_latest_ensemble_directory()\n",
    "        \n",
    "        self.ensemble_dir = ensemble_dir\n",
    "        \n",
    "        # Load data and models\n",
    "        self.load_data_and_models()\n",
    "        \n",
    "        # Create output directory\n",
    "        Path(\"age_group_gradcam\").mkdir(exist_ok=True)\n",
    "        \n",
    "        print(\"Ready for age group GradCAM analysis\")\n",
    "    \n",
    "    def load_data_and_models(self):\n",
    "        \"\"\"Load original data and trained models\"\"\"\n",
    "        print(\"Loading original data...\")\n",
    "        self.images, self.ages, self.filenames = load_original_data()\n",
    "        \n",
    "        print(\"Loading trained ensemble...\")\n",
    "        self.models, self.label_mapping, self.cv_scores = load_trained_ensemble(self.ensemble_dir)\n",
    "        \n",
    "        # Create reverse mapping for age indices - ensure consistency\n",
    "        # Convert string keys to floats for consistency with loaded data\n",
    "        self.age_to_idx = {}\n",
    "        self.idx_to_age = {}\n",
    "        \n",
    "        for age_str, idx in self.label_mapping.items():\n",
    "            age_float = float(age_str)\n",
    "            self.age_to_idx[age_float] = idx\n",
    "            self.idx_to_age[idx] = age_float\n",
    "        \n",
    "        self.unique_ages = sorted(list(self.age_to_idx.keys()))\n",
    "        self.num_classes = len(self.unique_ages)\n",
    "        \n",
    "        print(f\"Loaded {len(self.models)} models\")\n",
    "        print(f\"Available age groups: {self.unique_ages}\")\n",
    "        print(f\"Age to index mapping: {self.age_to_idx}\")\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.FloatTensor(image)\n",
    "        \n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "        \n",
    "        if image.shape[-2:] != (224, 448):\n",
    "            image = F.interpolate(image.unsqueeze(0), size=(224, 448), \n",
    "                                mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image = (image - mean) / std\n",
    "        \n",
    "        return image.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def overlay_heatmap(self, image, heatmap, alpha=0.6):\n",
    "        \"\"\"Overlay heatmap on original image\"\"\"\n",
    "        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "        \n",
    "        heatmap_colored = cv2.applyColorMap(\n",
    "            (heatmap_resized * 255).astype(np.uint8), \n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        heatmap_colored = heatmap_colored.astype(np.float32) / 255.0\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image_display = image\n",
    "        else:\n",
    "            image_display = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        overlaid = alpha * heatmap_colored + (1 - alpha) * image_display\n",
    "        return overlaid\n",
    "    \n",
    "    def select_representative_images(self):\n",
    "        \"\"\"Select one representative image from each age group\"\"\"\n",
    "        target_ages = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "        selected_samples = {}\n",
    "        \n",
    "        # Group images by age\n",
    "        age_groups = {}\n",
    "        for i, age in enumerate(self.ages):\n",
    "            if age not in age_groups:\n",
    "                age_groups[age] = []\n",
    "            age_groups[age].append(i)\n",
    "        \n",
    "        print(\"Selecting representative images:\")\n",
    "        \n",
    "        # Select one image from each target age group if available\n",
    "        for target_age in target_ages:\n",
    "            if target_age in age_groups:\n",
    "                # Choose the first image from this age group (could be randomized)\n",
    "                idx = age_groups[target_age][0]\n",
    "                selected_samples[target_age] = {\n",
    "                    'index': idx,\n",
    "                    'filename': self.filenames[idx],\n",
    "                    'image': self.images[idx],\n",
    "                    'age': self.ages[idx]\n",
    "                }\n",
    "                print(f\"  Age {target_age}: {self.filenames[idx]} (index {idx})\")\n",
    "            else:\n",
    "                print(f\"  Age {target_age}: No images available\")\n",
    "        \n",
    "        return selected_samples\n",
    "    \n",
    "    def get_ensemble_prediction(self, input_tensor):\n",
    "        \"\"\"Get ensemble prediction for an image\"\"\"\n",
    "        # Use CV scores as weights\n",
    "        scores_array = np.array(self.cv_scores)\n",
    "        weights = np.exp(scores_array / 20)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        ensemble_probs = np.zeros(self.num_classes)\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "                ensemble_probs += weights[i] * probs\n",
    "        \n",
    "        predicted_class = np.argmax(ensemble_probs)\n",
    "        confidence = ensemble_probs[predicted_class]\n",
    "        \n",
    "        return predicted_class, confidence, ensemble_probs\n",
    "    \n",
    "    def create_age_group_visualization(self):\n",
    "        \"\"\"Create comprehensive age group GradCAM visualization\"\"\"\n",
    "        print(\"Creating age group GradCAM visualization...\")\n",
    "        \n",
    "        selected_samples = self.select_representative_images()\n",
    "        \n",
    "        if not selected_samples:\n",
    "            print(\"No representative images found!\")\n",
    "            return\n",
    "        \n",
    "        # Sort by age for consistent display\n",
    "        sorted_ages = sorted(selected_samples.keys())\n",
    "        num_ages = len(sorted_ages)\n",
    "        \n",
    "        # Create figure: ages x (original + models + ensemble + prediction)\n",
    "        num_cols = 2 + len(self.models) + 2  # original + models + ensemble + prediction bars\n",
    "        fig, axes = plt.subplots(num_ages, num_cols, figsize=(4*num_cols, 4*num_ages))\n",
    "        \n",
    "        if num_ages == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        # Initialize GradCAM for each model\n",
    "        grad_cams = []\n",
    "        for model in self.models:\n",
    "            try:\n",
    "                target_layer = model.layer4[-1].conv2  # Last conv layer in ResNet-34\n",
    "                grad_cam = GradCAM(model, target_layer)\n",
    "                grad_cams.append(grad_cam)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to setup GradCAM for model: {e}\")\n",
    "                grad_cams.append(None)\n",
    "        \n",
    "        try:\n",
    "            for age_idx, age in enumerate(sorted_ages):\n",
    "                sample = selected_samples[age]\n",
    "                original_image = sample['image']\n",
    "                true_age = sample['age']\n",
    "                filename = sample['filename']\n",
    "                \n",
    "                # Preprocess for model\n",
    "                input_tensor = self.preprocess_image(original_image.copy())\n",
    "                \n",
    "                # Get ensemble prediction\n",
    "                pred_class, confidence, all_probs = self.get_ensemble_prediction(input_tensor)\n",
    "                predicted_age = self.idx_to_age[pred_class]\n",
    "                \n",
    "                # Display original image\n",
    "                if original_image.max() > 1.0:\n",
    "                    display_image = original_image.astype(np.float32) / 255.0\n",
    "                else:\n",
    "                    display_image = original_image.astype(np.float32)\n",
    "                \n",
    "                axes[age_idx, 0].imshow(display_image)\n",
    "                axes[age_idx, 0].set_title(f'Age {true_age}\\n{filename}', fontsize=10)\n",
    "                axes[age_idx, 0].axis('off')\n",
    "                \n",
    "                # Generate GradCAM for each model\n",
    "                model_heatmaps = []\n",
    "                \n",
    "                for model_idx, (model, grad_cam) in enumerate(zip(self.models, grad_cams)):\n",
    "                    if grad_cam is None:\n",
    "                        axes[age_idx, model_idx + 1].text(0.5, 0.5, 'Failed', \n",
    "                                                         transform=axes[age_idx, model_idx + 1].transAxes,\n",
    "                                                         ha='center', va='center')\n",
    "                        axes[age_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Get individual model prediction\n",
    "                        with torch.no_grad():\n",
    "                            model_output = model(input_tensor)\n",
    "                            model_pred = torch.argmax(model_output, dim=1).item()\n",
    "                        \n",
    "                        # Generate heatmap using true class for consistency\n",
    "                        true_class_idx = self.age_to_idx[true_age]\n",
    "                        heatmap = grad_cam.generate_cam(input_tensor.clone(), true_class_idx)\n",
    "                        model_heatmaps.append(heatmap)\n",
    "                        \n",
    "                        # Create overlay\n",
    "                        overlaid = self.overlay_heatmap(display_image, heatmap)\n",
    "                        \n",
    "                        # Display\n",
    "                        axes[age_idx, model_idx + 1].imshow(overlaid)\n",
    "                        axes[age_idx, model_idx + 1].set_title(f'Fold {model_idx + 1}\\nCV: {self.cv_scores[model_idx]:.1f}%', fontsize=9)\n",
    "                        axes[age_idx, model_idx + 1].axis('off')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing fold {model_idx + 1} for age {age}: {e}\")\n",
    "                        axes[age_idx, model_idx + 1].text(0.5, 0.5, 'Error', \n",
    "                                                         transform=axes[age_idx, model_idx + 1].transAxes,\n",
    "                                                         ha='center', va='center')\n",
    "                        axes[age_idx, model_idx + 1].axis('off')\n",
    "                        model_heatmaps.append(None)\n",
    "                \n",
    "                # Create ensemble heatmap (average of valid heatmaps)\n",
    "                valid_heatmaps = [h for h in model_heatmaps if h is not None]\n",
    "                if valid_heatmaps:\n",
    "                    ensemble_heatmap = np.mean(valid_heatmaps, axis=0)\n",
    "                    ensemble_overlaid = self.overlay_heatmap(display_image, ensemble_heatmap)\n",
    "                    \n",
    "                    axes[age_idx, -2].imshow(ensemble_overlaid)\n",
    "                    axes[age_idx, -2].set_title(f'Ensemble\\nPred: Age {predicted_age}', fontsize=10)\n",
    "                    axes[age_idx, -2].axis('off')\n",
    "                else:\n",
    "                    axes[age_idx, -2].text(0.5, 0.5, 'No Valid\\nHeatmaps', \n",
    "                                          transform=axes[age_idx, -2].transAxes,\n",
    "                                          ha='center', va='center')\n",
    "                    axes[age_idx, -2].axis('off')\n",
    "                \n",
    "                # Show prediction probabilities\n",
    "                class_names = [f'Age {age}' for age in self.unique_ages]\n",
    "                bars = axes[age_idx, -1].bar(range(len(class_names)), all_probs)\n",
    "                axes[age_idx, -1].set_xticks(range(len(class_names)))\n",
    "                axes[age_idx, -1].set_xticklabels(class_names, rotation=45, fontsize=8)\n",
    "                axes[age_idx, -1].set_ylabel('Probability')\n",
    "                axes[age_idx, -1].set_title(f'Confidence\\n{confidence:.2f}', fontsize=10)\n",
    "                \n",
    "                # Color the bars\n",
    "                bars[pred_class].set_color('red')\n",
    "                true_class_idx = self.age_to_idx[true_age]\n",
    "                bars[true_class_idx].set_color('green')\n",
    "                \n",
    "                # Clear GPU memory\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        finally:\n",
    "            # Clean up all GradCAMs\n",
    "            for grad_cam in grad_cams:\n",
    "                if grad_cam is not None:\n",
    "                    grad_cam.remove_hooks()\n",
    "        \n",
    "        # Add overall title\n",
    "        fig.suptitle('Age Group Specific GradCAM Analysis - ResNet-34 Ensemble', fontsize=16, y=0.98)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        plt.savefig('age_group_gradcam/age_group_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Age group GradCAM analysis saved to 'age_group_gradcam/age_group_analysis.png'\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nAnalysis Summary:\")\n",
    "        for age in sorted_ages:\n",
    "            sample = selected_samples[age]\n",
    "            print(f\"Age {age}: {sample['filename']}\")\n",
    "    \n",
    "    def create_simplified_comparison(self):\n",
    "        \"\"\"Create a simplified side-by-side comparison of all age groups\"\"\"\n",
    "        print(\"Creating simplified age group comparison...\")\n",
    "        \n",
    "        selected_samples = self.select_representative_images()\n",
    "        \n",
    "        if not selected_samples:\n",
    "            print(\"No representative images found!\")\n",
    "            return\n",
    "        \n",
    "        sorted_ages = sorted(selected_samples.keys())\n",
    "        num_ages = len(sorted_ages)\n",
    "        \n",
    "        # Create simple 2-row visualization: original images and ensemble attention\n",
    "        fig, axes = plt.subplots(2, num_ages, figsize=(4*num_ages, 8))\n",
    "        \n",
    "        if num_ages == 1:\n",
    "            axes = axes.reshape(2, 1)\n",
    "        \n",
    "        # Initialize GradCAM for ensemble (use first model as representative)\n",
    "        grad_cam = None\n",
    "        if self.models:\n",
    "            try:\n",
    "                target_layer = self.models[0].layer4[-1].conv2\n",
    "                grad_cam = GradCAM(self.models[0], target_layer)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to setup GradCAM: {e}\")\n",
    "        \n",
    "        try:\n",
    "            for age_idx, age in enumerate(sorted_ages):\n",
    "                sample = selected_samples[age]\n",
    "                original_image = sample['image']\n",
    "                filename = sample['filename']\n",
    "                \n",
    "                # Display original image\n",
    "                if original_image.max() > 1.0:\n",
    "                    display_image = original_image.astype(np.float32) / 255.0\n",
    "                else:\n",
    "                    display_image = original_image.astype(np.float32)\n",
    "                \n",
    "                axes[0, age_idx].imshow(display_image)\n",
    "                axes[0, age_idx].set_title(f'Age {age}', fontsize=14, fontweight='bold')\n",
    "                axes[0, age_idx].axis('off')\n",
    "                \n",
    "                # Generate and display attention map\n",
    "                if grad_cam is not None:\n",
    "                    try:\n",
    "                        input_tensor = self.preprocess_image(original_image.copy())\n",
    "                        true_class_idx = self.age_to_idx[age]\n",
    "                        heatmap = grad_cam.generate_cam(input_tensor.clone(), true_class_idx)\n",
    "                        overlaid = self.overlay_heatmap(display_image, heatmap)\n",
    "                        \n",
    "                        axes[1, age_idx].imshow(overlaid)\n",
    "                        axes[1, age_idx].set_title('Attention Map', fontsize=12)\n",
    "                        axes[1, age_idx].axis('off')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error generating attention for age {age}: {e}\")\n",
    "                        axes[1, age_idx].text(0.5, 0.5, 'Error', \n",
    "                                             transform=axes[1, age_idx].transAxes,\n",
    "                                             ha='center', va='center')\n",
    "                        axes[1, age_idx].axis('off')\n",
    "                else:\n",
    "                    axes[1, age_idx].text(0.5, 0.5, 'No GradCAM', \n",
    "                                         transform=axes[1, age_idx].transAxes,\n",
    "                                         ha='center', va='center')\n",
    "                    axes[1, age_idx].axis('off')\n",
    "        \n",
    "        finally:\n",
    "            if grad_cam is not None:\n",
    "                grad_cam.remove_hooks()\n",
    "        \n",
    "        # Add row labels\n",
    "        axes[0, 0].set_ylabel('Original Images', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_ylabel('Attention Maps', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('age_group_gradcam/simplified_age_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Simplified comparison saved to 'age_group_gradcam/simplified_age_comparison.png'\")\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run complete age group specific GradCAM analysis\"\"\"\n",
    "        print(\"\\nStarting Age Group GradCAM Analysis\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Create comprehensive visualization\n",
    "            self.create_age_group_visualization()\n",
    "            \n",
    "            # Create simplified comparison\n",
    "            self.create_simplified_comparison()\n",
    "            \n",
    "            print(\"\\nAge Group GradCAM Analysis Complete!\")\n",
    "            print(\"Generated files:\")\n",
    "            print(\"- age_group_gradcam/age_group_analysis.png: Comprehensive analysis\")\n",
    "            print(\"- age_group_gradcam/simplified_age_comparison.png: Simplified comparison\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in analysis: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run age group specific GradCAM analysis\"\"\"\n",
    "    print(\"Age Group Specific GradCAM Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Initialize analyzer\n",
    "        analyzer = AgeGroupGradCAMAnalyzer()\n",
    "        \n",
    "        # Run complete analysis\n",
    "        analyzer.run_complete_analysis()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ffe2c-08d5-4532-af7c-cfdacd263f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BUCK Environment",
   "language": "python",
   "name": "buck-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
